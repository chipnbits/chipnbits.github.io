{
  "hash": "eb386085f28b4e5957863f2540a01bb4",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Lecture 2: Image Denoising with SVD\"\nsubtitle: \"Applications of Least Squares and SVD\"\ndate: 2024-09-15\nauthor: \"Simon Ghyselincks\"\ndescription: >-\n    Image denoising and deblurring are important techniques in signal processing and recovery. I this coding exercise, we will explore the application of least squares, SVD, and the pseudoinverse to denoise and deblur images.\ncategories:\n  - Optimization\n  - Inverse Theory\n  - Python\n  - Torch\n  - SVD\n\nimage: imgs/gaussian_plot.png\ndraft: false\n\neditor: \n  render-on-save: false\n---\n\n\n\n\n\n\n# Image Denoising and Deblurring\n\nThe motivation for the exercise comes from a real world problem. The Hubble space telescope when launched had a defect in its mirror. This defect caused the images to be blurred. The problem was initially addressed by using signal processing techniques to remove the aberrations from the images.\n\n### Point Spread Function\n\nFor such an image processing problem, we can consider the continuous incoming light as striking a 2D mirror that distorts the light, followed by a 2D sensor that captures the light. In this context we suppose that we have a noise kernel or a point spread function (PSF) that describes the distortion of the light at the mirror. The point spread function, being a convolution kernel, behaves as a Green's function for the system in the continuous case:\n\n$$ \\vec{b}(x,y) = \\int_{\\mathcal{X}} \\int_{\\mathcal{Y}} \\vec{G}(x - x', y - y') \\vec{u}(x',y') \\, dx' dy' $$\n\nwhere $\\vec{b}(x,y)$ is the blurred image data that is recovered at the sensor, $\\vec{u}(x',y')$ is the true image data, and $\\vec{G}(x,y)$ is the point spread function.\n\nIn the special case that the point spread function is $\\delta(x-x',y-y')$, then the image data is not distorted and the sensor captures the true image data. However our experiment is to consider cases where there could be even severe distortions and see how this impacts the proposition of recovering the true image data, $\\vec{u}(x',y')$ from our sensor data, $\\vec{b}(x,y)$.\n\n#### Discrete PSF\n\nThe discrete analog of the continuous PSF can be more conveniently treated with we essentially flatten the the 2D mesh into a 1D vector, a common operation for signal processing. The unflattened case we have:\n\n$$ b_{ij} = \\sum_{k=1}^{n} \\sum_{l=1}^{m} \\Delta x \\Delta y G(x_i - x_k, y_j - y_l) u_{kl} $$\n\n\nwhere $b$ is the blurred image data at the sensor, $u$ is the true image data, and $G$ is the discrete point spread function. If we flatten the 2D mesh into a 1D vector we can represent this as a 1D convolution operation:\n$$ \\vec{b} = \\vec{G} * \\vec{u} $$\n\nSince this is a convolution operation, we can process it much more quickly by leveraging the convolution theorem.\n\n$$\\begin{align}\n\\mathcal{F}(\\vec{b}) &= \\mathcal{F}(\\vec{G} * \\vec{u}) \\\\\n\\mathcal{F}(\\vec{b}) &= \\mathcal{F}(\\vec{G}) \\mathcal{F}(\\vec{u}) \\\\\n\\vec{b} &= \\mathcal{F}^{-1}(\\mathcal{F}(\\vec{G}) \\odot \\mathcal{F}(\\vec{u}))\n\\end{align}\n$$\n\nThe $\\odot$ hadamard product is element-wise multiplication, the discrete analog of multiplication of two functions except over an array.\n\n### Matrix Representation of Convolution Operation\n\nIf we flatten the data down into a 1D vector then it is possible to construct a matrix operator that performs the convolution. This is a Toeplitz matrix, a matrix where each descending diagonal from left to right is constant, so that the row vectors represent a sliding window of the convolution kernel. We can flatten out the PSF and construct the matrix using it as the first row entry and then shifting the PSF to the right to fill out the rest of the rows. \n\n# Code Implementation\n\n::: {#c53e6b29 .cell execution_count=2}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport matplotlib\n#matplotlib.use('TkAgg')\nimport numpy as np\nimport torch.optim\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nimport copy\n\nimport seaborn as sns\n\nimport math\nimport os\nimport time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.fft\n```\n:::\n\n\nWe start off by introducing a point spread function within the torch framework. In the case we work with a parameterized gaussian kernel.\n\n### Gaussian Example\n\nThe multivariate extension of the gaussian function is given by:\n$$f(x) = \\exp\\left(-\\frac{1}{2} (x-\\mu)^T \\Sigma^{-1} (x-\\mu)\\right)$$\n\nwhere $\\mu$ is the mean vector, $x$ is a position vector, and $\\Sigma$ is the covariance matrix. The covariance matrix essentially encodes the eigenvectors and corresponding postive eigenvalues of the matrix. The covariance matrix is always symmetric and positive definite. In the context of the code, we are using $C$ as the inverse of the covariance matrix and working with a $\\mu=0$ value. \n\n::: {#mv-plot .cell execution_count=3}\n``` {.python .cell-code}\nfrom scipy.ndimage import convolve\n\ndef multivariate_gaussian(pos, mean, cov):\n    \"\"\"Return the multivariate Gaussian distribution on array pos without using einsum notation.\"\"\"\n    n = mean.shape[0]\n    diff = pos - mean\n    cov_inv = np.linalg.inv(cov)\n    \n    # Compute the exponent\n    diff_cov_inv = diff @ cov_inv\n    exponent = -0.5 * np.sum(diff * diff_cov_inv, axis=-1)\n    \n    # Compute the normalization factor\n    norm_factor = np.sqrt((2 * np.pi) ** n * np.linalg.det(cov))\n    \n    # Return the Gaussian function\n    return np.exp(exponent) / norm_factor\n\n# Define the grid limits and resolution\nX, Y = np.mgrid[-5:5:0.05, -5:5:0.05]\npos = np.dstack((X, Y))\n\n# Parameters\nmean = np.array([0, 0])\neigenvalues = np.array([1, 2])  # Example eigenvalues\nprincipal_axis = np.array([1, 1])  # Example principal axis\n\n# Normalize the principal axis\nprincipal_axis = principal_axis / np.linalg.norm(principal_axis)\n\n# Create the covariance matrix\nD = np.diag(eigenvalues)\northogonal_complement = np.array([-principal_axis[1], principal_axis[0]])\nQ = np.column_stack((principal_axis, orthogonal_complement))\ncov = Q @ D @ Q.T\n\n# Compute the Gaussian function over the grid\nZ = multivariate_gaussian(pos, mean, cov)\n\n# Define the Sobel operators for x and y derivatives\nKdx = np.array([[-1, 0, 1],\n                [-2, 0, 2],\n                [-1, 0, 1]]) / 4.0\n\nKdy = np.array([[-1, -2, -1],\n                [0,  0,  0],\n                [1,  2,  1]]) / 4.0\n\n# Apply the Sobel filters to compute the derivatives\nZdx = convolve(Z, Kdx, mode='constant', cval=0.0)\nZdy = convolve(Z, Kdy, mode='constant', cval=0.0)\n\n\nplt.contourf(X, Y, Z, levels=20, cmap='viridis')\nplt.title('Gaussian Distribution')\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\nplt.axis('equal')\nplt.savefig('figure.png', dpi=300, bbox_inches='tight')\n\n# Plot the Gaussian and its derivatives\nplt.figure(figsize=(7.5, 2.5))\n\n# Plot the Gaussian\nplt.subplot(1, 3, 1)\nplt.contourf(X, Y, Z, levels=20, cmap='viridis')\nplt.title('Gaussian Distribution')\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\nplt.axis('equal')\n\n# Plot the derivative in x\nplt.subplot(1, 3, 2)\nplt.contourf(X, Y, Zdx, levels=20, cmap='RdBu')\nplt.title('Derivative in X (Sobel Filter)')\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\nplt.axis('equal')\n\n# Plot the derivative in y\nplt.subplot(1, 3, 3)\nplt.contourf(X, Y, Zdy, levels=20, cmap='RdBu')\nplt.title('Derivative in Y (Sobel Filter)')\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\nplt.axis('equal')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Multivariate Gaussian and its Derivatives](index_files/figure-html/mv-plot-output-1.png){#mv-plot-1 width=624 height=449}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/mv-plot-output-2.png){#mv-plot-2 width=748 height=230}\n:::\n:::\n\n\n### Extending to Combination of Gaussian and Derivative\n\nWe can compute the MV gaussian from the inverse covariance matrix $C$ with a mean of $\\mu=0$ along with a dimensional scaling metric $t$. For the purposes of forming interesting and varied PSFs, we include the linear combination of the gaussian and a Sobel operator to axpproximate the derivative of the gaussian.\n\n$$\\begin{align}\nS_x &= \\frac{1}{4} \\begin{bmatrix} -1 & 0 & 1 \\\\ -2 & 0 & 2 \\\\ -1 & 0 & 1 \\end{bmatrix} \\\\\nS_y &= \\frac{1}{4} \\begin{bmatrix} -1 & -2 & -1 \\\\ 0 & 0 & 0 \\\\ 1 & 2 & 1 \\end{bmatrix}\n\\end{align}\n$$\n\nThese operators act like edge detection or derivatives. The $n_0$, $n_x$, and $n_y$ parameters in the code are used to scale the gaussian and the derivatives.\n\n::: {#bb04fe4e .cell execution_count=4}\n``` {.python .cell-code}\nclass gaussianConv(nn.Module):\n    \"\"\"\n    A PyTorch module that applies a Gaussian convolution to an input image using \n    a parameterized Gaussian Point Spread Function (PSF). The PSF is derived \n    from a covariance matrix and the derivatives of the Gaussian are computed \n    for edge detection.\n\n    Args:\n        C (torch.Tensor): Inverse of covariance matrix used to define the shape of the Gaussian.\n        t (float, optional): Scaling factor for the Gaussian, default is np.exp(5).\n        n0 (float, optional): Scaling factor for the original PSF, default is 1.\n        nx (float, optional): Scaling factor for the derivative along the x-axis, default is 1.\n        ny (float, optional): Scaling factor for the derivative along the y-axis, default is 1.\n    \"\"\"\n    def __init__(self, C, t=np.exp(5), n0=1, nx=1, ny=1):\n        super(gaussianConv, self).__init__()\n\n        self.C = C\n        self.t = t\n        self.n0 = n0\n        self.nx = nx\n        self.ny = ny\n\n    def forward(self, image):\n        \"\"\"\n        Apply the Gaussian convolution and derivatives to an input image.\n\n        This method performs convolution of the input image with a Gaussian\n        Point Spread Function (PSF) that includes the original Gaussian and\n        its derivatives along x and y axes. The convolution is performed\n        using the Fourier Transform for efficiency.\n\n        Args:\n            image (torch.Tensor): Input image tensor of shape (Batch, Channels, Height, Width).\n        \n        Returns:\n            torch.Tensor: The convolved image of the same shape as the input.\n        \"\"\"\n\n        # Generate the PSF and calculate the center shift required for alignment\n        P, center = self.psfGauss(image.shape[-1], image.device)\n\n        # Shift the PSF so that its center aligns with the origin (top-left corner)\n        P_shifted = torch.roll(P, shifts=center, dims=[2, 3])\n\n        # Compute the Fourier Transform of the shifted PSF\n        S = torch.fft.fft2(P_shifted)\n\n        # Compute the Fourier Transform of the input image\n        I_fft = torch.fft.fft2(image)\n\n        # Multiply the Fourier Transforms element-wise (convolution theorem with Hadamard product)\n        B_fft = S * I_fft\n\n        # Compute the inverse Fourier Transform to get back to the spatial domain\n        B = torch.real(torch.fft.ifft2(B_fft))\n\n        # Return the convolved image\n        return B\n\n    def psfGauss(self, dim, device='cpu'):\n        \"\"\"\n        Generate the Gaussian PSF and its derivatives.\n\n        Args:\n            dim (int): Dimension size (assumes square dimensions).\n            device (str, optional): Device to create tensors on, default is 'cpu'.\n\n        Returns:\n            tuple:\n                - PSF (torch.Tensor): The combined PSF including derivatives.\n                - center (list): Shifts required to align the PSF with the origin.\n        \"\"\"\n        # Define the size of the PSF kernel (assumed to be square)\n        m = dim\n        n = dim\n\n        # Create a meshgrid of (X, Y) coordinates\n        x = torch.arange(-m // 2 + 1, m // 2 + 1, device=device)\n        y = torch.arange(-n // 2 + 1, n // 2 + 1, device=device)\n        X, Y = torch.meshgrid(x, y, indexing='ij')\n        X = X.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, m, n)\n        Y = Y.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, m, n)\n\n        # Extract elements from the covariance matrix\n        # Assuming self.C is a 2x2 tensor\n        cx, cy, cxy = self.C[0, 0], self.C[1, 1], self.C[0, 1]\n\n        # Compute the Gaussian PSF using the meshgrid and covariance elements\n        PSF = torch.exp(-self.t * (cx * X ** 2 + cy * Y ** 2 + 2 * cxy * X * Y))\n\n        # Normalize the PSF so that its absolute sum is 1\n        PSF0 = PSF / torch.sum(PSF.abs())\n\n        # Define derivative kernels (Sobel operators) for edge detection\n        Kdx = torch.tensor([[-1, 0, 1],\n                            [-2, 0, 2],\n                            [-1, 0, 1]], dtype=PSF0.dtype, device=device) / 4\n        Kdy = torch.tensor([[-1, -2, -1],\n                            [0, 0, 0],\n                            [1, 2, 1]], dtype=PSF0.dtype, device=device) / 4\n\n        # Reshape kernels to match convolution requirements\n        Kdx = Kdx.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, 3, 3)\n        Kdy = Kdy.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, 3, 3)\n\n        # Convolve the PSF with the derivative kernels to obtain derivatives\n        # Padding ensures the output size matches the input size\n        PSFdx = F.conv2d(PSF0, Kdx, padding=1)\n        PSFdy = F.conv2d(PSF0, Kdy, padding=1)\n\n        # Combine the original PSF and its derivatives using the scaling factors\n        PSF_combined = self.n0 * PSF0 + self.nx * PSFdx + self.ny * PSFdy\n\n        # Calculate the center shift required to align the PSF with the origin\n        center = [1 - m // 2, 1 - n // 2]\n\n        # Return the combined PSF and center shift\n        return PSF_combined, center\n```\n:::\n\n\n### Creating a Toy Dataset\n\nOften in computational science we test our strategies on toy datasets, simplified data that allows for easier debugging and understanding of the problem at task. In this case, rather than use a real image, we construct a geometric image that will be easier to analyse visually for its correctness when it comes to denoising and deblurring. The dataset is also dimensioned to have a batch and color channel to follow some of the conventions for working with torch tensors, and later some machine learning frameworks. That is $B \\times C \\times H \\times W$, with a single sample, single channel, and a 256x256 image having dimensions $1 \\times 1 \\times 256 \\times 256$.\n\n::: {#cell-toy-dataset .cell execution_count=5}\n``` {.python .cell-code}\nx = torch.zeros(1, 1, 256, 256)\nx[:,:, 120:140, 120:140] = 1.0\nx[:,:, 100:120, 100:120] = -1.0\n\nplt.figure(figsize=(3,3))\nplt.imshow(x[0,0,:,:])\n```\n\n::: {.cell-output .cell-output-display}\n![A sample toy dataset for image denoising and deblurring.](index_files/figure-html/toy-dataset-output-1.png){#toy-dataset width=276 height=268}\n:::\n:::\n\n\nThis simple image is a high and a low signal shown as two square regions, which we will try to recover after applying a point spread function to it (the forward model). The forward model is the convolution of the image with the PSF.\n\n::: {#cell-forward-model .cell execution_count=6}\n``` {.python .cell-code}\nC = torch.tensor([[1, 0],[0, 1]])\nAmv = gaussianConv(C, t=0.001,n0=0, nx=1,  ny=-1)\n\ny = Amv(x)\nplt.subplot(1,2,1)\nplt.imshow(x[0,0,:,:])\nplt.colorbar()\nplt.subplot(1,2,2)\nplt.imshow(y[0,0,:,:])\nplt.colorbar()\nprint()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Forward model for image denoising and deblurring.](index_files/figure-html/forward-model-output-2.png){#forward-model width=651 height=402}\n:::\n:::\n\n\n### Forming a Convolution Matrix\n\nBack to the idea of forming a Toeplitz matrix, we first flatten the data to 1D and then recover the matrix in one of two ways. We can work in the spatial domain where the first row of the matrix is determined by the 1D convolution for the first element, then slide the row by one to form the matrix. The matrix can be quite large, since an $n\\times m$ image will have $n \\times m$ elements once flattened, requiring a $(n\\times m) \\times (n\\times m)$ matrix. A reduction in dimension to the $32 \\times 32$ image will help with the computation.\n\nNote that we are working with a rolling PSF which has a strange effect in that it assumes a periodic boundary condition in both $x$ and $y$. When it comes to convolution, there are many different ways to treat the boundary condition, such as using zero padding or mirroring the boundary. Coding this by hand is a good exercise to understand the convolution operation, but not the purpose of this exercise. \n\n#### Direct Recovery of Convolution Matrix\n\n::: {#cell-convolution-matrix .cell execution_count=7}\n``` {.python .cell-code}\ndim = 32\nx = torch.zeros(1, 1, dim, dim)\nx[:,:, 12:14, 12:14] = 1.0\nx[:,:, 10:12, 10:12] = -1.0\n\nAmv = gaussianConv(C, t=0.1,n0=1, nx=0.1,  ny=0.1)\n\n# Flatten the image and the PSF\nx_flat = x.flatten()\n\nkernel, center = Amv.psfGauss(x.shape[-1]) # Get a square conv kernel \n\n# Since we are using the conv kernel as a filter operation, we use the transpose of the kernel\n# to fill the convolution matrix. \n\nkernel = kernel.transpose(2,3) \n# Roll shifts the kernel from the center of the box to the top left corner\nkernel_shifted = torch.roll(kernel, shifts=center, dims=[2, 3])\n\nplt.subplot(1,3,1)\nplt.imshow(kernel[0,0,:,:])\nplt.title('PSF Centered')\nplt.subplot(1,3,2)\nplt.title('PSF Shifted with Roll')\nplt.imshow(kernel_shifted[0,0,:,:])\n\n# Flatten the kernel\nkernel_flat = kernel_shifted.flatten()\n\n# Form the convolution matrix\nn = x_flat.shape[0]\nm = kernel_flat.shape[0]\nA_conv = torch.zeros(n, n)\n\nfor i in range(n):\n    A_conv[i, :] = torch.roll(kernel_flat, shifts=i, dims=[0])\n\nplt.subplot(1,3,3)\nplt.imshow(A_conv)\nplt.title('Convolution Matrix');\n```\n\n::: {.cell-output .cell-output-display}\n![Forming a convolution matrix for the forward model.](index_files/figure-html/convolution-matrix-output-1.png){#convolution-matrix width=617 height=226}\n:::\n:::\n\n\n#### Recovery Using Linearity of Operator\n\nSince the convolution operation that is being performed is linear, one way to recover the matrix operator under this assumption is to pass through the basis vectors and recover the column vectors in this fashion:\n\n$$\\begin{bmatrix} a_1 \\mid a_2 \\mid \\ldots \\mid a_n \\end{bmatrix} \\mathbf{e}_i = \\mathbf{A} \\mathbf{e}_i  = \\mathbf{a}_i$$\n\nwhere $\\mathbf{e}_i$ is the $i$th basis vector.\n\n::: {#cell-convolution-matrix-2 .cell execution_count=8}\n``` {.python .cell-code}\nA_conv_lin = torch.zeros(n, n)\n\nk=0\nfor i in range(x.shape[-2]):\n  for j in range(x.shape[-1]):\n    e_ij = torch.zeros_like(x)\n    e_ij[:,:, i, j] = 1.0\n    y = Amv(e_ij)\n    A_conv_lin[:, k] = y.flatten()\n    k = k+1\n\nplt.subplot(1,2,1)\nplt.imshow(A_conv_lin)\nplt.title('Convolution Matrix (Linear)')\nplt.colorbar()\nplt.subplot(1,2,2)\nplt.imshow(A_conv-A_conv_lin)\nplt.title('Difference from Direct')\nplt.colorbar()\n```\n\n::: {.cell-output .cell-output-display}\n![Forming a convolution matrix for the forward model using linearity.](index_files/figure-html/convolution-matrix-2-output-1.png){#convolution-matrix-2 width=659 height=400}\n:::\n:::\n\n\nNow comparing this method against the known convolution result using the class defined earlier with the forward model:\n\n::: {#961a2bce .cell execution_count=9}\n``` {.python .cell-code}\nb_forward = Amv(x)\n\nb_mat_toeplitz = A_conv @ x_flat\nb_mat_linear = A_conv_lin @ x_flat\n\nplt.subplot(1,3,1)\nplt.imshow(b_forward[0,0,:,:])\nplt.subplot(1,3,2)\nplt.imshow(b_mat_toeplitz.reshape(x.shape[-2:]))\nplt.subplot(1,3,3) \nplt.imshow(b_mat_linear.reshape(x.shape[-2:]))\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-9-output-1.png){width=604 height=208}\n:::\n:::\n\n\nWe can see that there are some differences between the two methods but in principle they should be the same, (Not sure where the difference is coming from). The important method is actually the one which extracts the columns, as it is more generalizable. So we will continue with that.\n\n::: {#final-conv-matrix .cell execution_count=10}\n``` {.python .cell-code}\nAmat = A_conv_lin\n```\n:::\n\n\n## Least Squares Recovery with SVD and Pseudoinverse\n\nNow that we have a matrix operator recovered we can formulate the forward problem as $A\\mathbf{x} = \\mathbf{b}$ with our known $A$ and $\\mathbf{b}$, and we want to recover $\\mathbf{x}$. To do this we use the SVD decomposition to gather the pseudo inverse. We can decide to filter out some of the singular values that are very small to improve the conditioning on the matrix as well, using a cutoff value for example.\n\n### SVD Decomposition\n\n::: {#492131e8 .cell execution_count=11}\n``` {.python .cell-code}\nU, S, V = torch.svd(Amat.to(torch.float64))\nb = Amv(x)\n```\n:::\n\n\nNow we make a log plot of the singular values to see how they decay, noting that we lose numerical precision around the $10^{-6}$ mark. We can also asses what the frobenius norm of the difference between the original matrix and the reconstructed matrix is to get a sense of the error in the decomposition and reconstruction.\n\n::: {#cell-svd-decomposition .cell execution_count=12}\n``` {.python .cell-code}\nplt.semilogy(S)\nplt.xlabel('Singular Value Index')\nplt.ylabel('Singular Value')\n\nloss = F.mse_loss(Amat, U @ torch.diag(S) @ V.T)\nprint(f\"The loss is {loss}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe loss is 1.812403923995022e-34\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![SVD Decomposition of the Convolution Matrix.](index_files/figure-html/svd-decomposition-output-2.png){#svd-decomposition width=642 height=429}\n:::\n:::\n\n\nThe loss is quite small which is a good sign that the decomposition is working well within the numerical precision of the machine.\n\n### Initial Attempt at Pseudoinverse\n\nTo recover the original image data we first naively try to invert the matrix to see what happens.\n\n::: {#cell-naive-pseudoinverse .cell execution_count=13}\n``` {.python .cell-code}\nxhat = torch.linalg.solve(Amat,b.reshape(dim**2))\nplt.subplot(1,2,1)\nplt.imshow(xhat.reshape(x.shape[-2:]))\nplt.title('Naive Inverse')\nplt.subplot(1,2,2)\nplt.imshow(x.reshape(x.shape[-2:]))\nplt.title('Original Image');\n```\n\n::: {.cell-output .cell-output-display}\n![Naive Pseudoinverse Recovery of the Original Image.](index_files/figure-html/naive-pseudoinverse-output-1.png){#naive-pseudoinverse width=604 height=315}\n:::\n:::\n\n\nWow, not even close! This is because the matrix is so ill conditioned that it is effectively low rank and not invertible. We can improve the situation by filtering out the singular values that are very small.\n\n### Pseudoinverse with Filtering\n\nWe can filter out the poor conditioning singular values and exclude those values from the inversion. To get an idea of what the values are doing, we can plot the first few singular values and the corresponding singular vector that they project onto. In the case of the SVD the most important information about the matrix is captured in the left-most vectors of the matrix $U$.\n\n::: {#1a36578d .cell execution_count=14}\n``` {.python .cell-code}\nn= 5\nfor i in range(n):\n  plt.subplot(1,n,i+1)\n  plt.imshow(U[:,i+1].reshape(x.shape[-2:]))\n  plt.title(f'Mode {i}')\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-14-output-1.png){width=603 height=158}\n:::\n:::\n\n\nFor the inverse problem, the most import singular values are conversely found in the left-most vectors of the matrix $V$. We can also check what the right-most vectors are doing, as they will blow up in value when inverting small singular values. They are high frequency modes of the image, creating the reconstruction issues when they are subjected to error in numerical precision.\n\n::: {#9e5aaa70 .cell execution_count=15}\n``` {.python .cell-code}\nn= 5\nfor i in range(n):\n  plt.subplot(1,n,i+1)\n  plt.imshow(V[:,i+1].reshape(x.shape[-2:]))\n  plt.title(f'Mode {i}')\nplt.show()\n\nfor i in range(n):\n  plt.subplot(1,n,i+1)\n  plt.imshow(V[:,-(i+1)].reshape(x.shape[-2:]))\n  plt.title(f'Mode {V.shape[1]-i}')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-1.png){width=603 height=158}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-2.png){width=603 height=158}\n:::\n:::\n\n\nThese modes are the most important ones, as they contain the big-picture detail without the high frequency noise. We can now filter out the singular values that are very small and invert the matrix to recover the original image.\n\n::: {#cell-pseudoinverse-filter .cell execution_count=16}\n``` {.python .cell-code}\nb_flat = b.flatten().to(torch.float64)\nx_flat = x.flatten().to(torch.float64)\nthresholds = [1e-1, 1e-3, 1e-6, 1e-7, 1e-8, 1e-10]\n\nplt.figure(figsize=(7,5))  # Adjust the figure size as needed\n\nfor idx, threshold in enumerate(thresholds):\n    # Filter the singular values\n    S_filtered = S.clone()\n    S_filtered[S_filtered < threshold] = 0\n\n    # Compute the reciprocal of the filtered singular values\n    S_inv = torch.zeros_like(S_filtered)\n    non_zero_mask = S_filtered > 0\n    S_inv[non_zero_mask] = 1 / S_filtered[non_zero_mask]\n\n    # Construct the pseudoinverse of Amat\n    A_pinv = V @ torch.diag(S_inv) @ U.T\n\n    # Reconstruct the original image\n    xhat = A_pinv @ b_flat\n\n    # Compute the reconstruction error\n    error = torch.norm(xhat - x_flat, p='fro').item()\n\n    # Plot the reconstructed image in the appropriate subplot\n    plt.subplot(2, 3, idx + 1)  # idx + 1 because subplot indices start at 1\n    plt.imshow(xhat.reshape(x.shape[-2:]))\n    plt.title(f'Threshold {threshold}\\nError: {error:.4f}')\n    plt.colorbar()\n    plt.axis('off')  # Optionally turn off axis ticks and labels\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Pseudoinverse Recovery of the Original Image with Filtering.](index_files/figure-html/pseudoinverse-filter-output-1.png){#pseudoinverse-filter width=661 height=464}\n:::\n:::\n\n\nLooking at the results, around the $10^{-7}$ mark we start to a peak level of recovery, as measured by the error in the Frobenius norm of the reconstruction. But what happens when we add noise to the data signal?\n\n### Adding Noise to the Signal\n\nNow we add some noise to the signal and try least squares again for the direct solution\n\n::: {#cell-pseudoinverse-filter-noised .cell execution_count=17}\n``` {.python .cell-code}\nb_flat = b.flatten().to(torch.float64)\nx_flat = x.flatten().to(torch.float64)\nAmat = Amat.to(torch.float64)\n\nalpha = .01\nnoise = torch.randn_like(b_flat) * alpha\n\nH = Amat.T @ Amat + alpha**2 * torch.eye(Amat.shape[0])\nxhat = torch.linalg.solve(H, Amat.T @ (b_flat + noise))\n\nplt.subplot(1,2,1)\nplt.imshow(x[0,0])\nplt.title('Original Image')\nplt.subplot(1,2,2)\nplt.imshow(xhat.reshape(x.shape[-2:]))\nplt.title('Reconstructed Image');\n```\n\n::: {.cell-output .cell-output-display}\n![Pseudoinverse Recovery of the Original Image with Noise.](index_files/figure-html/pseudoinverse-filter-noised-output-1.png){#pseudoinverse-filter-noised width=604 height=315}\n:::\n:::\n\n\nThe reconstruction is not very good, the noise has been amplifed all over the image. We can try the pseudoinverse method again with the noise added to the signal.\n\n::: {#cell-pseudoinverse-filter-noised-recovery .cell execution_count=18}\n``` {.python .cell-code}\nAmat_noisy = Amat + alpha * torch.eye(Amat.shape[0])\nUn, Sn, Vn = torch.svd(Amat_noisy)\n\nthresholds = [.5, .1, .05, .03, .005, .001]\n\nplt.figure(figsize=(7,5))  # Adjust the figure size as needed\n\nfor idx, threshold in enumerate(thresholds):\n    # Filter the singular values\n    S_filtered = Sn.clone()\n    S_filtered[S_filtered < threshold] = 0\n\n    # Compute the reciprocal of the filtered singular values\n    S_inv = torch.zeros_like(S_filtered)\n    non_zero_mask = S_filtered > 0\n    S_inv[non_zero_mask] = 1 / S_filtered[non_zero_mask]\n\n    # Construct the pseudoinverse of Amat\n    A_pinv = Vn @ torch.diag(S_inv) @ Un.T\n\n    # Reconstruct the original image\n    xhat = A_pinv @ (b_flat + noise)\n\n    # Compute the reconstruction error\n    error = torch.norm(xhat - x_flat, p='fro').item()\n\n    # Plot the reconstructed image in the appropriate subplot\n    plt.subplot(2, 3, idx + 1)  # idx + 1 because subplot indices start at 1\n    plt.imshow(xhat.reshape(x.shape[-2:]))\n    plt.title(f'Threshold {threshold}\\nError: {error:.4f}')\n    plt.colorbar()\n    plt.axis('off')  # Optionally turn off axis ticks and labels\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Pseudoinverse Recovery of the Original Image with Noise.](index_files/figure-html/pseudoinverse-filter-noised-recovery-output-1.png){#pseudoinverse-filter-noised-recovery width=661 height=462}\n:::\n:::\n\n\nThe small addition of noise is quite significant in the recovery threshold for reconstruction. Using a higher threshold for the singular values becomes important when dealing with noise in the signal. Previously numerical precision was the main issue, but now the measurement noise is the main issue.\n\n",
    "supporting": [
      "index_files\\figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}
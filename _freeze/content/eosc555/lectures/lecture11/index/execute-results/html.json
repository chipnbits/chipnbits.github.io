{
  "hash": "34859d92f0556728fcd2302d5c9a126a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Lecture 11\"\nsubtitle: \"Score Matching and Diffusion\"\ndate: 2024-11-25\nauthor: \"Simon Ghyselincks\"\ndescription: >-\n    Score matching has been used in machine learning to estimate the parameters of a probability distribution from emiprical samples. This lecture will introduce the concept of score matching and its connection to diffusion models and generative AI.\ncategories:\n  - Machine Learning\n  - Neural Networks\n  - Score Matching\n\ndraft: false\n\neditor: \n  render-on-save: false\n\nfilters:\n  - pseudocode\n  - diagram\n\nbibliography: references.bib\nbiblatexoptions: \"style=numeric,sorting=nyt\"  # Uses numbered style and sorts by name-year-title\nbiblio-style: numeric-comp  # A numeric style in biblatex, similar to IEEE, with compressed citation ranges\n\npseudocode:\n  caption-prefix: \"Algorithm\"\n  reference-prefix: \"Algorithm\"\n  caption-number: true\n---\n\n\n\n::: {.hidden}\n$$\n\\def\\argmin{\\operatorname*{argmin}}\n\\def\\bmat#1{\\begin{bmatrix}#1\\end{bmatrix}}\n\\def\\Diag{\\mathbf{Diag}}\n\\def\\ip#1{\\langle #1 \\rangle}\n\n\\def\\maximize#1{\\displaystyle\\maxim_{#1}}\n\n\\def\\minimize#1{\\displaystyle\\minim_{#1}}\n\\def\\norm#1{\\|#1\\|}\n\\def\\proj{\\mathbf{proj}}\n\\def\\R{\\mathbb R}\n\\def\\Re{\\mathbb R}\n\\def\\Rn{\\R^n}\n\\def\\rank{\\mathbf{rank}}\n\\def\\range{{\\mathbf{range}}}\n\\def\\span{{\\mathbf{span}}}\n\\def\\textt#1{\\quad\\text{#1}\\quad}\n\\def\\trace{\\mathbf{trace}}\n\\def\\bf#1{\\mathbf{#1}}\n$$\n:::\n\n\n\n## Score Matching\n\nPreviously in [Lecture 10](../lecture8/index.qmd#score-function), the concept of score as the gradient of the log-likelihood was introduced. \n\nFor a probability distribution $\\pi(x, \\theta)$ parameterized by $\\theta$, the distribution can be thought of as a potential function $\\phi(x, \\theta)$ which is normalized by the partition function $Z(\\theta)$:\n\n$$ \\pi(x; \\theta) = \\underbrace{\\frac{1}{Z(\\theta)}}_{\\text{Partition}} \\exp(-\\underbrace{\\phi(x; \\theta)}_{\\text{Potential}}) $$\n\nThe score is defined as:\n\n$$s(x; \\theta) := \\nabla_x \\log \\left(\\pi(x)\\right) = -\\nabla_x \\phi(x;\\theta)$$\n\n### The Big Idea\n\nScore matching was first proposed by Hyvärinen in 2005 [@hyvarinen2005scorematching] as a method to estimate model parameters without computing the partition function $\\frac{1}{Z(\\theta)}$, which is often computationally expensive or intractable.\n\nHyvärinen suggested directly matching the score of the model to the score of the data by minimizing the expected squared difference between them:\n\n$$ \\min_\\theta \\mathbb{E}_{x \\sim \\pi(x)} \\left[ \\left\\| s_{\\theta}(x, \\theta) - s_{\\text{true}(x)} \\right\\|^2 \\right] $$\n\n\n#### Inuitive Explanation\n\n1. If the gradients of two potential functions are equal, the functions themselves differ by at most a constant:\n\n$$ \n\\begin{align*}\n\\nabla_x \\phi(x; \\theta) &= \\nabla_x  \\phi_\\text{true}(x) \\implies\\\\\n\\phi(x; \\theta) &= \\phi_\\text{true}(x) + C\n\\end{align*}\n$$\n\nWhere $C$ is a constant independent of $x$. This follows from the fundamental theorem of calculus and is analogous to the principle in physics where two potentials producing the same field differ by a constant.\n\n2. Normalization by the partition function $Z(\\theta)$ does not affect the relation between the potentials:\n\nThe partition function $Z(\\theta)$ adjusts for any constant differences between the potential functions, ensuring the probability distributions are properly normalized:\n\n$$ \n\\begin{align*}\n\\pi(x) &= \\frac{1}{Z(\\theta)} \\exp(-\\phi(x; \\theta)) \\\\\n&= \\frac{1}{Z(\\theta)} \\exp(-\\phi_\\text{true}(x) - C) \\\\\n&= \\frac{\\exp(-C)}{Z(\\theta)} \\exp(-\\phi_\\text{true}(x))  \\\\\n&= \\frac{1}{Z_{\\text{true}}} \\exp(-\\phi_\\text{true}(x)) \\\\\n\\end{align*}\n$$\n\nThe relation between the two functions is preserved by the partition function, which differs by constant $e^{-C}$ for a difference in potential of $C$. The probability distributions must be equal, as shown above.\n\nIf we can match the score, then we indirectly match the probability distributions without needing to first compute the partition function. This is the idea behind score matching.\n\n#### Visualization of Score Matching and Potentials\n\n::: {#25d8585b .cell layout-ncol='3' execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set the Seaborn style for modern-looking plots\nsns.set(style=\"whitegrid\", context=\"talk\")\n\n# Define the potential functions\ndef potential_model(x, shift=0):\n    \"\"\"Model potential with an optional scalar shift.\"\"\"\n    return 0.5 * x**2 + shift  # Quadratic potential\n\ndef potential_data(x):\n    \"\"\"Data potential.\"\"\"\n    return 0.5 * x**2  # Quadratic potential with no shift\n\n# Analytical gradients (scores)\ndef gradient_potential_model(x):\n    \"\"\"Gradient of the model potential with respect to x.\"\"\"\n    return x\n\ndef gradient_potential_data(x):\n    \"\"\"Gradient of the data potential with respect to x.\"\"\"\n    return x\n\n# Define the range of x values\nx = np.linspace(-3, 3, 500)\n\n# Compute potentials\nmodel_potential = potential_model(x, shift=1)\ndata_potential = potential_data(x)\n\n# Compute gradients (scores)\nmodel_gradient = gradient_potential_model(x)\ndata_gradient = gradient_potential_data(x)\n\n# Compute partition functions for normalization\ndx = x[1] - x[0]  # Differential element for integration\nZ_model = np.sum(np.exp(-model_potential)) * dx\nZ_data = np.sum(np.exp(-data_potential)) * dx\n\n# Compute normalized probability densities\nnormalized_model = np.exp(-model_potential) / Z_model\nnormalized_data = np.exp(-data_potential) / Z_data\n\n# Create DataFrames for plotting with Seaborn\ndf_potentials = pd.DataFrame({\n    'x': np.tile(x, 2),\n    'Potential': np.concatenate([model_potential, data_potential]),\n    'Type': ['Model Potential (shift=1)'] * len(x) + ['Data Potential (no shift)'] * len(x)\n})\n\ndf_gradients = pd.DataFrame({\n    'x': np.tile(x, 2),\n    'Gradient': np.concatenate([model_gradient, data_gradient]),\n    'Type': ['Gradient of Model Potential'] * len(x) + ['Gradient of Data Potential'] * len(x)\n})\n\ndf_normalized = pd.DataFrame({\n    'x': np.tile(x, 2),\n    'Probability Density': np.concatenate([normalized_model, normalized_data]),\n    'Type': ['Normalized Model Potential'] * len(x) + ['Normalized Data Potential'] * len(x)\n})\n\nfigsize = (5, 3)\n\n# Define custom dash patterns\ndash_styles = {\n    'Model Potential (shift=1)': '',\n    'Data Potential (no shift)': (5, 5),  # Solid line\n    'Gradient of Model Potential': '',\n    'Gradient of Data Potential': (5, 5),\n    'Normalized Model Potential': '',\n    'Normalized Data Potential': (5, 5)\n}\n\nplt.figure(figsize=figsize)\n# Plot potentials\nsns.lineplot(\n    data=df_potentials,\n    x='x',\n    y='Potential',\n    hue='Type',\n    style='Type',\n    dashes=dash_styles,\n    palette='deep',\n)\nplt.xlabel('x')\nplt.ylabel('Potential Energy')\nplt.legend(title='')\nplt.show()\n\nplt.figure(figsize=figsize)\n# Plot gradients (scores)\nsns.lineplot(\n    data=df_gradients,\n    x='x',\n    y='Gradient',\n    hue='Type',\n    style='Type',\n    dashes=dash_styles,\n    palette='muted',\n)\nplt.xlabel('x')\nplt.ylabel('Gradient')\nplt.legend(title='')\nplt.show()\n\nplt.figure(figsize=figsize)\n# Plot normalized probability densities\nsns.lineplot(\n    data=df_normalized,\n    x='x',\n    y='Probability Density',\n    hue='Type',\n    style='Type',\n    dashes=dash_styles,\n    palette='bright',\n)\nplt.xlabel('x')\nplt.ylabel('Probability Density')\nplt.legend(title='')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-1.png){width=448 height=305}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-2.png){width=461 height=305}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-3.png){width=467 height=305}\n:::\n:::\n\n\n### Eliminating True Score\n\nThe score for the data $s_{\\text{true}}$ is unknown, but it can be eliminated using calculus tricks, as shown in [@hyvarinen2005scorematching]. The expected squared difference can be rewritten as:\n\n$$\n\\begin{align*}\n& \\ \\min_\\theta \\mathbb{E} \\frac{1}{2} \\left[ \\left\\| s_{\\theta}(x, \\theta) - s_{\\text{true}}(x) \\right\\|^2 \\right] \\\\\n&= \\min_\\theta  \\frac{1}{2}  \\int_\\Omega \\left\\| s_{\\theta}(x, \\theta) - s_{\\text{true}}(x) \\right\\|^2 \\pi(x) \\, dx \\\\\n&= \\min_\\theta  \\frac{1}{2}  \\int_\\Omega \\left\\| s_{\\theta}(x, \\theta) \\right\\|^2 \\pi(x) \\, dx - \\int_\\Omega s_{\\theta}(x, \\theta)^\\intercal s_{\\text{true}}(x) \\pi(x) \\, dx + \\frac{1}{2} \\int_\\Omega \\left\\| s_{\\text{true}}(x) \\right\\|^2 \\pi(x) \\, dx \\\\\n\\end{align*}\n$$\n\nBut $\\|s_{\\text{true}}\\|$ is a constant since it is not a variable that can be changed, it can be discarded from the minimization problem:\n\n$$\n\\begin{align*}\n&= \\min_\\theta \\frac{1}{2}  \\int_\\Omega \\left\\| s_{\\theta}(x, \\theta) \\right\\|^2 \\pi(x) \\, dx - \\int_\\Omega s_{\\theta}(x, \\theta)^\\intercal s_{\\text{true}}(x) \\pi(x) \\, dx \\\\\n\\end{align*}\n$$\n\nTo eliminate $s_{\\text{true}}$, the definition of score can be used to rewrite the term:\n\n$$\n\\begin{align*}\n& \\ -\\int_\\Omega s_{\\theta}(x, \\theta)^\\intercal s_{\\text{true}}(x) \\pi(x) \\, dx\\\\\n&= -\\int_\\Omega  \\pi(x) \\left(\\nabla_x \\log(\\pi(x))\\right)^\\intercal  s_\\theta(x; \\theta) \\, dx \\\\\n& = -\\int_\\Omega  \\frac{\\pi(x)}{\\pi(x)}\\left(\\nabla_x \\pi(x)\\right)^\\intercal  s_\\theta(x; \\theta) \\, dx \\\\\n& = -\\int_\\Omega  \\nabla_x \\pi(x)^\\intercal  s_\\theta(x; \\theta) \\, dx \\\\\n\\end{align*}\n$$\n\nIntegration by parts allows for the gradient term to be swapped to the score term. If we assume that the probability of the true distribution goes to zero $\\pi(x) \\rightarrow 0$ at the boundaries $\\partial \\Omega$, then the flux integral boundary term from integration by parts vanishes. When working with integration by parts in multivarible calculus, the gradient $\\nabla$ and negative divergence $-\\nabla \\cdot$ opeartors are adjoints of each other, $\\nabla = (-\\nabla \\cdot)^\\intercal$. This allows for the gradient to be swapped to the score term:\n\n$$\n\\begin{align*}\n& = -\\int_\\Omega  \\nabla_x \\pi(x)^\\intercal  s_\\theta(x; \\theta) \\, dx \\\\\n&= -\\int_{\\partial \\Omega} \\pi(x) s_\\theta(x; \\theta) \\cdot dx + \\int_\\Omega  \\pi(x) \\nabla_x \\cdot s_\\theta(x; \\theta) \\, dx \\\\\n&= \\int_\\Omega  \\pi(x) \\nabla_x \\cdot s_\\theta(x; \\theta) \\, dx \\\\\n\\int_\\Omega s_{\\theta}(x, \\theta)^\\intercal s_{\\text{true}}(x) \\pi(x) \\, dx &= \\int_\\Omega  \\pi(x) \\nabla_x^2 \\phi(x;\\theta) \\, dx \\\\\n\\end{align*}\n$$\n\nBack to the minimization problem, this term can be substituted back in:\n\n$$\n\\begin{align*}\n& \\ \\min_\\theta \\mathbb{E}_{x \\sim \\pi(x)} \\frac{1}{2} \\left[ \\left\\| s_{\\theta}(x, \\theta) - s_{\\text{true}(x)} \\right\\|^2 \\right]\\\\\n &= \\min \\frac{1}{2}  \\int_\\Omega \\left\\| \\nabla_x \\phi(x;\\theta) \\right\\|^2 \\pi(x) \\, dx + \\int_\\Omega  \\pi(x) \\nabla_x^2 \\phi(x;\\theta) \\, dx \\\\\n &= \\min_{theta} \\mathbb{E}_{x \\sim \\pi(x)} \\left[ \\left\\| \\nabla_x \\phi(x;\\theta) \\right\\|^2 + \\nabla_x^2 \\phi(x;\\theta) \\right] \\\\\n\\end{align*}\n$$\n\n## Evaluation of the Objective\n\nThe minimization objective does not require using the true score which has been eliminated. The $\\nabla_x^2 \\phi(x;\\theta)$ term can be evaluated as the trace of the Hessian matrix of the potential function $\\phi(x;\\theta)$:\n\n$$\n\\nabla_x^2 \\phi(x;\\theta) = \\text{Tr} \\left( \\nabla_x^2 \\phi(x;\\theta) \\right) = \\sum_i \\frac{\\partial^2 \\phi(x;\\theta)}{\\partial x_i^2}\n$$\n\nThis component places a penalty on positive curvature in the potential function, preferring highly negative curvature in regions of high probability density, similar to a Gaussian or peaked distribution. It can be though of as a regularization term that prefers peaked distributions.\n\nThe $\\left\\| \\nabla_x \\phi(x;\\theta) \\right\\|^2$ term is the squared norm of the gradient, which penalizes large gradients. With this term alone, the optimal distribution would be as flat as possible to make the gradient as small as possible. It is the opposition of the minimization objective of the two terms that leads to a balanced and matched distribution.\n\nIn practice, we can estimate the true expectation over all $x$ by sampling from the model distribution. Once such way is to use the empiral samples $\\{x_1, x_2, \\ldots, x_N\\}$ to estimate the expectation. If they are assumed to be i.i.d. samples from the model distribution, the expectation can be approximated as:\n\n$$\n\\begin{align*}\n\\mathbb{E}_{x \\sim \\pi(x)} \\left[ \\left\\| \\nabla_x \\phi(x;\\theta) \\right\\|^2 + \\nabla_x^2 \\phi(x;\\theta) \\right] &\\approx \\frac{1}{N} \\sum_{i=1}^N \\left\\| \\nabla_x \\phi(x_i;\\theta) \\right\\|^2 + \\nabla_x^2 \\phi(x_i;\\theta) \\\\\n\\end{align*}\n$$\n\nThis can be applied to all samples, or batches of samples to get a gradient estimate for the minimization objective in $\\theta$:\n\n$$\n\\begin{align*}\ng &\\approx \\nabla_\\theta \\left[ \\frac{1}{N} \\sum_{i=1}^N \\left\\| \\nabla_x \\phi(x_i;\\theta) \\right\\|^2 + \\nabla_x^2 \\phi(x_i;\\theta) \\right] \\\\\n\\end{align*}\n$$\n\n### Computing the Laplacian\n\nThe Laplacian of the potential function $\\phi(x;\\theta)$ can be computed as the trace of the Hessian matrix of the potential function:\n\n$$\n\\begin{align*}\n\\nabla_x^2 \\phi(x;\\theta) &= \\text{tr} \\left( \\nabla_x^2 \\phi(x;\\theta) \\right) \\\\\n&= \\sum_i \\frac{\\partial^2 \\phi(x;\\theta)}{\\partial x_i^2}\n\\end{align*}\n$$\n\nThe trace of a matrix such as a Hessian which is a linear operator can be estimated without having to know the explicit matrix. For example the Hessian may be an operator that is too large to store in memory. Or the Hessian may not be explicitly known, but the operation $Hx$ can be computed for example. \n\nA process first proposed by Hutchinson [@Hutchinson1990], known as randomized linear algebra allows for computing the trace when only the $H(x)$ operation is known.  A random varible is used to sample as follows:\n\n$$\n\\begin{align*}\n\\text{tr} \\left(A\\right) &= \\text{tr} \\left(AI\\right) \\\\\n&= \\text{tr} \\left( A \\mathbb{E}_{x\\sim\\mathcal{N}(0,I)} x x^\\intercal \\right)\\\\\n&= \\mathbb{E}_{x\\sim\\mathcal{N}(0,I)} \\text{tr} \\left( A x x^\\intercal \\right)\\\\\n&= \\mathbb{E} \\text{tr} \\left(x^\\intercal A x  \\right)\\\\\n&\\approxeq \\frac{1}{N} \\sum_{i=1}^N x_i^\\intercal A x_i\n\\end{align*}\n$$\n\nThe normal distribution by definition has a covariance matrix that is identity $I$ so the expectation of the outer product of the random variable $x$ is the identity matrix. Other random variables can be used as well, further details on the process can be found in Bai, Fahey, and Golub [@Bai1996].\n\n## Applications of Learned Score\n\n### MAP Estimation\n\nNow that we have a method to learn the score of a distribution, it can be used as the regularization term of the gradient in MAP estimation. In [Lecture10](../lecture10/index.qmd), the score was used as part of the MAP minimization gradient.\n\n::: {.callout-note icon=false}\n# MAP Estimation \n**Objective:**\n$$\\min_x \\left( \\frac{1}{2\\sigma^2}\\|F(x)-b\\|^2 + \\phi(x, \\theta) \\right)$$\n**Gradient:**\n$$ g = \\frac{1}{\\sigma^2} J^T(x) (F(x) - b) + s(x, \\theta)$$\n**Gradient Descent:**\n$$ x_{k+1} = x_k - \\mu J^T(x) (F(x) - b) - s(x, \\theta)$$ \n:::\n\nSo using many empirically drawn samples $x_i$, the $\\pi(x)$ distribution can be indirectly estimated using score matching, learning the score $s(x, \\theta)$. The learned score can then be used for the gradient of the MAP estimation problem, where it is representative of the regularization term, informed by the prior distribution $\\pi(x)$. In the case of a matrix operator for the forward problem $F(x) = Ax$, its Jacobian $J(x)$ is the same as the matrix operator $J(x) = A$.\n\n### Diffusion Models and Homotopy\n\nIn [Lecture 7](../lecture7/index.qmd), the concept of a homotopy beteween two functions was introduced. A homotopy provides a continuous path between an smoothing function $g(x)$ and a target function $f(x)$, parameterized by a scalar $t$. In the case of a gaussian smoothing function $g(x)$, $t$ acts as a variance parameter:\n$$\nh(x, t) = t f(x) + (1-t) g(x)\n$$\n\n#### Proposition: Convolution of Random Variables\nThe sum of two independent random variables is a convolution of their probability distributions. If $X \\sim \\pi_x(x)$ and $Y \\sim \\pi_y(y)$, then the sum $W = X + Y$ has a probability distribution $\\pi_w(w)$ that is the convolution of the two distributions:\n\n$$\n\\begin{align*}\n\\pi_w(w) &= \\int \\pi_x(x) \\pi_y(z-x) \\, dx \\\\\n\\end{align*}\n$$\n\n---\n\nFor a dataset $x\\sim \\pi(x)$ and a latent variable $z\\sim \\mathcal{N}(0, I)$, then define a new random variable $x_t$ that is the sum of the two variables:\n\n$$\nx_t = \\sqrt{t}x + \\sqrt{1-t} z\n$$\n\nThe homotopy proceeds slightlt differently with the time scheduling but it still begins and ends with the starting and target distributions. This new random variable $x_t$ will be the convolution of the two distributions, such that $\\pi_{x_t}(x_t)$ is the convolution of $t \\pi(x)$ and $\\mathcal{N}(0, (1-t)I)$:\n\n$$ \\pi(x_t) = \\int \\pi(x-\\frac{\\xi}{t}) \\exp\\left(-\\frac{\\|\\xi\\|^2}{2(1-t)}\\right) \\, d\\xi $$\n\n",
    "supporting": [
      "index_files\\figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}
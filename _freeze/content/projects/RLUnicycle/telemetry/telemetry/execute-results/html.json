{
  "hash": "2fb2e82323d7ba578d70afe98b58615a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Telemetry and Database Systems for Capstone Projects\"\nsubtitle: \"A build guide\"\nauthor: \"Simon Ghyselincks, Team 2411\"\ndate: last-modified # Adds the current date\nformat:\n  html:\n    toc: true # Generates a table of contents\n    toc-depth: 3  # Specifies depth of sections to include in TOC\n    number-sections: false  # Numbers the sections\n    theme: cosmo  # Specifies a Bootstrap theme\n    pandoc-args: [\"--mathjax\"]  # Enables MathJax for LaTeX math rendering \n\n    mermaid:\n      theme: neutral\n\nexecute:\n  cache: true  # Enables caching of code execution results\n---\n\n\n\n\n# Purpose \n\nThis guide provides a comprehensive overview of the telemetry and database systems employed in our \"Learning to Balance\" reinforcement learning unicycle project. It includes hardware recommendations, a detailed explanation of the networked services used, and example code to illustrate software implementation.\n\n![Telemetry Overview](imgs/NetworkDiagram.drawio.svg){fig-align=\"center\"}\n\nThe telemetry and database system functions as a two-way pipeline controlling the flow of data from sensors, motors, and control decisions. Data from the robot is efficiently offloaded to a server, considering limited processing power and the necessity for a stable control loop. The server further processes this data and manages control signals sent back to the robot for parameter adjustments or commands. By utilizing a central server and internet connectivity, the database, live telemetry, and control panel can be accessed from any networked computer via a browser or software API, globally.\n\n## Prerequisites\n\nThis guide assumes familiarity with running commands on a Linux command line and access to a terminal on your client device (e.g., personal laptop). This could be through WSL or VSCode on Windows, or a terminal on a Mac or Linux machine.\n\nBasic understanding of Python is recommended, as some examples use Python. However, the same libraries are available in other languages such as C++.\n\n### Hardware Recommendation and Requirements\n\n#### Server\n\nWe recommend the Lenovo M900 series of refurbished tiny PCs as an affordable option that meets the computational needs for a server. The device's SSD was set to dual boot into Linux Ubuntu 22.04 to run the server. This type of device is capable of handling the computational load of running multiple services simultaneously, including database management, messaging, and control services. It can also serve as a workstation for the team.\n\nWe tested the Raspberry Pi 4B 8GB with an external SSD, but its processing power is at the limit for these requirements. Therefore, it is not recommended for use as a server, especially considering the cost-effectiveness of a refurbished Lenovo.\n\n::: {layout-ncol=2}\n![Lenovo Server](imgs/lenovoserver.png){width=80%}\n\n![Wifi Dongle](imgs/chipset.png){width=30%}\n:::\n\n#### Robot Wi-Fi\n\nOur robot uses an NVIDIA Jetson Nano 4GB, which does not include built-in Wi-Fi. Additionally, a real-time ([PREEMPT_RT](../rtkernel/rtpatch.qmd)) patch has been applied to our Linux kernel. Many Wi-Fi dongle drivers are incompatible with the low-level kernel changes made by the patch; for example, the rtl8188EUS driver stopped working after the patch.\n\nWe recommend the MT7601U chipset USB Wi-Fi dongle, which works without the need for additional drivers on Ubuntu 22.04, Ubuntu 16.04 PREEMPT-RT, and Raspbian. This dongle is reliable for use with outdated and/or patched Linux kernels, is inexpensive, and can be found on Amazon or Aliexpress.\n\n# Telemetry Services Overview\n\nThe telemetry and control command communications are managed through a series of services running on a central server. Client devices, the server, and the robot are all visible to each other through a virtual network managed with [ZeroTier](https://www.zerotier.com/). This allows for secure communication between devices over the internet without exposing their IP addresses to the public.\n\nThe principal components of the software stack are as follows:\n\n<table style=\"width:100%;\">\n\n<tr>\n  <td style=\"width:20%;\"><img src=\"imgs/mqtt-logo.png\" ></td>\n  <td> - <strong><a href=\"https://mqtt.org/\">Mosquitto MQTT Broker</a></strong>:  A publisher-subscriber model that allows rapid message passing between devices across topics. It is similar to the ROS topic system but is more lightweight and can be used for a wider range of applications.</td>\n</tr>\n\n<tr>\n  <td style=\"width:20%;\"><img src=\"imgs/telegraf-logo.png\" ></td>\n  <td> - <strong><a href=\"https://www.influxdata.com/time-series-platform/telegraf/\">Telegraf</a></strong>: A plugin-driven server agent for collecting and reporting metrics. It acts as a localized central switchboard for data from MQTT topics and inputs them into the InfluxDB database.</td>\n</tr>\n\n<tr>\n  <td style=\"width:20%;\"><img src=\"imgs/influx-logo.png\" ></td>\n  <td> - <strong><a href=\"https://www.influxdata.com/\">InfluxDB</a></strong>: A time-series database used to store telemetry data streamed from the robot. It features a web browser interface for data exploration and APIs in Python and other languages for database queries.</td>\n</tr>\n\n<tr>\n  <td style=\"width:20%;\"><img src=\"imgs/grafan-logo.png\" ></td>\n  <td> - <strong><a href=\"https://grafana.com/\">Grafana</a></strong>: A powerful open-source platform for creating dashboards and visualizing time-series data. It supports various data sources through plugins, including InfluxDB. For live telemetry with a fast refresh rate, the MQTT plugin can connect to the MQTT broker and display streaming data in real-time.</td>\n</tr>\n\n<tr>\n  <td colspan=\"2\"> - <strong><a href=\"https://nodered.org/\">Node-Red</a></strong>: A flow-based, open-source development tool for visual programming. It provides a browser-based editor that makes it easy to wire together flows using a wide range of nodes. In our case, this enables a synchronized control panel accessible through a web browser.</td>\n</tr>\n</table>\n\n\nA simplified flowchart of the system is shown below:\n\n\n\n\n```{mermaid}\n\nflowchart TD\n  %% Customizing colors for subgraphs and nodes\n  style Robot fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Server fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px\n  style Clients fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n\n  Y[Robot]\n  Z[Server]\n\n  %% Define a class for black text\n  classDef blackText fill:none,color:#000,stroke:none;\n\n  subgraph Robot\n    A[IMU Sensors] -->|Data| D(Control Loop)\n    B[Motors] <-->|Feedback| D\n    C[Controller] <-->|Commands| D\n    D <--> E(Communication Multiprocess)\n  end\n  \n  subgraph Server\n    E <--> F[MQTT Broker]\n    F -->|Metrics| G[Telegraf]\n    G -->|Write| H[InfluxDB]\n    F -->|Visualization| I[Grafana]\n  end\n\n  %% Clients section coloring applied to individual floating nodes\n    I -->|Live Telemetry| J[Dashboard]\n    K[Node-RED] -->|Commands| F\n    L[Xbox Controller] -->|Commands| F\n    H -->|Data| M[Data Explorer and API]\n\n  \n  %% Styling for the floating client items\n  style J fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style K fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style L fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style M fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style Y fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Z fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px\n\n```\n\n\n\n\nWe will now examine each of these services and how to configure them for a robotics project.\n\n## ZeroTier Virtual Network\nZeroTier allows all authorized devices on the network to communicate directly using assigned virtual IP addresses, similar to running a local network over a Wi-Fi router.\n\n**IP Addresses:**\nWhen a website address is entered into a browser, the request is sent to a Domain Name Server (DNS), which translates the address into an IP address—a unique identifier that functions like a postal address, marking the exact location of a server on the internet. For example:\n\n```bash\n❯ ping google.com\nPING google.com (142.251.33.78) 56(84) bytes of data.\n64 bytes from sea09s28-in-f14.1e100.net (142.251.33.78): icmp_seq=1 ttl=114 time=21.6 ms\n```\n\nThe Google webpage can be accessed by typing the IP address directly into the browser. The number is a unique identifier for that server on the internet.\n\n**Public and Private IP Addresses:**\nThe IP protocol reserves certain ranges of IP addresses for pivate networks. For example, the entire block of addresses `192.168.0.0 – 192.168.255.255` do not point to the wider internet but is reserved for local devices. This is why home routers can all have the same common IP address of `192.168.0.1` without creating any conflicts. It acts as a local addressing system, like apartment numbers in a building.\n\n**Network Ports:**\nPorts differentiate between different services running on the same IP address. For example, a web server might run on port 80, while an email server might run on port 25. When entering a website address, the browser automatically connects to the server on port 80. To connect to a different service, you can specify the port using a colon, e.g., `http://172.22.1.1:8086/` connects to port `8086` which is commonly used for InfluxDB.\n\n**Local Host:**\nThe IP address `http://localhost` s a special address that points to the local machine. It is used to access services running on the same machine without needing to know the IP address.\n\nThe clients on the ZeroTier network connect to the robot and server using their assigned virtual IP addresses managed by the ZeroTier service.\n\n### Setting up ZeroTier Network\nTo setup a network you should first create a free account at [https://my.zerotier.com/](https://my.zerotier.com/). It is advisable to set up a team email so that any team member can log in to manage the network as needed. Once you have an account, you can create a network and add devices to it. The network ID is a 16-digit number used to identify the network.\n\n### ZeroTier Client Setup\n\n*Every* device intended to be part of the network -- including laptops, the server, and the Jetson -- should have the ZeroTier client installed. After installation, enter the network ID from the ZeroTier website into the client, and approve the device to join the network. Assign static IP addresses, especially for critical devices like the server. This can be managed via the ZeroTier website.\n\n**Installation Instructions:**\n[Download the ZeroTier client here](https://www.zerotier.com/download/).\n\n#### Steps:\n\n1. **Download and Install the ZeroTier client** for your operating system:\n\n2. **Start the ZeroTier service**:\n   - **On Windows**:\n     - Open the ZeroTier client, which will add an icon to the system tray.\n     - Right-click on the icon and select `Join Network`, then enter the network ID.\n     - Set the client UI to launch on startup.\n\n   - **On Linux**:\n     Run the following commands:\n     ```bash\n     sudo systemctl enable zerotier-one\n     sudo systemctl start zerotier-one\n     sudo zerotier-cli join YOUR_NETWORK_ID\n     ```\n\n3. **Approve the device**:  \n   Take note of the client ID and either log into the ZeroTier website or use the command-line interface to approve the device for network access.\n\n4. **Verify the connection**:  \n   After approval, you can verify the connection by pinging another connected device on the network using its assigned virtual IP address.\n\n5. **Assign a static IP (optional)**:  \n   For important devices like the server or the Jetson, assign static IP addresses through the ZeroTier web console under the **Members** tab. This ensures consistent IP allocation across reboots.\n\n---\n\n### Managing IP Addresses\n\nBelow is an example of a ZeroTier network where the server has been assigned the static IP address `172.22.1.1` on the network:\n\n![ZeroTier Network and Access](imgs/zerotier-panel.png){width=80%, fig-align=\"center\"}\n\n## Connecting to Robot Controller using SSH\n\nWith the virtual network established, you can enable remote access to the robot controller via SSH. SSH is a secure shell protocol that allows you to run command-line commands on a remote device. This is very useful for managing the robot, running scripts, and updating software code. Use the virtual IP address assigned to the robot on the ZeroTier network. It is recommended to assign a static IP address using the ZeroTier UI or CLI so that the address does not change between reboots.\n\nFor faster access to SSH devices, consider setting up an alias or an SSH key once SSH is verified working for a device. More information on SSH can be found [here](https://www.digitalocean.com/community/tutorials/ssh-essentials-working-with-ssh-servers-clients-and-keys.)\n\n**Example:**\nOur robot has the static ip address `172.22.0.5`. To connect from a linux terminal on a computer connected to the private network with zerotier client installed, run the following command:\n\n```bash\nssh jetson@172.22.0.5\n```\n\nThis will attempt to log in to the username `jetson` on the robot controller, prompting for the user password (the same as if logging in directly on the robot). For a controller running Linux, we recommend setting up different users on the system so that each team member can log in to their own account and manage their own files and credentials. Software between user accounts can be shared using symbolic links to a central repository or using GitHub to manage individual software branches.\n\n#### VSCode Server\n\nThe Jetson is also able to handle [VSCode Server] (https://code.visualstudio.com/docs/remote/ssh), although the outdated Ubuntu 16.04 requires running an older version of the VSCode IDE to SSH in. Be aware that VSCode Server is active on the Jetson when SSHed in, which consumes some system resources; however, in practice, it has not been a performance issue. For best performance, running the robot through a simple terminal is recommended. The benefit of SSHing through VSCode is that it provides a GUI interface for software development and file management on the robot, as if you were using VSCode on your own computer.\n\n## MQTT Overview\n\n::: {.image-wrap}\n![](imgs/mqtt-logo.png)\n:::\n\nMQTT is a lightweight messaging protocol that provides an efficient and cost-effective method for telemetry-based communication between devices. MQTT messages are routed through the Lenovo server acting as the broker using Mosquitto. The robot can publish data to a topic, which can be picked up by various subscribers such as Grafana or other laptops and devices connected to the broker and subscribed to the topic. Similarly, commands can be sent back to the robot via a command topic to turn it on or off or adjust parameters. The default port for MQTT is `1883`.\n\nFor setup, installation, and maintenance of the broker, we recommend installing MQTT Explorer on any device connected to the network. This allows for monitoring all messaging and client connections across the system.\n\nDownload from [MQTT Explorer](https://mqtt-explorer.com/)\n\n#### Key Features of MQTT\n\n| Feature                     | Description                                                                                     |\n|------------------------------|-------------------------------------------------------------------------------------------------|\n| **Lightweight Protocol**      | Ideal for constrained devices and networks with limited bandwidth.                              |\n| **Publish-Subscribe Model**   | Allows devices to publish messages to a topic and any client subscribed to that topic will receive the messages. |\n| **Reliable Message Delivery** | Offers various levels of Quality of Service (QoS) to guarantee message delivery.                |\n| **Minimal Overhead**          | Adds only a small overhead to each message, ensuring efficient use of network resources.        |\n\n![](https://i.imgur.com/SDVurr8.png)\n\n### Installing Mosquitto MQTT Broker\nFrom the server open a terminal and run the following commands to install the MQTT broker:\n\n```bash\nsudo apt update\nsudo apt install mosquitto mosquitto-clients\nsudo systemctl enable mosquitto\nsudo systemctl start mosquitto\n```\n\nAfter installation, open MQTT Explorer and connect to the broker using the IP address of the server and the default port. You should see the server as a client connected to the broker.\n\n![Connecting to MQTT Broker](imgs/mqtt-explorer.png){width=80%, fig-align=\"center\"}\n\nOnce connected, some test messages can be sent through the GUI and verified that they are being received by the server.\n\nFor more detailed instructions or help, consider using additional resources or consult the [Mosquitto documentation](https://mosquitto.org/documentation/).\n\n### Interfacing with Software\n\nMQTT interfaces with Python, Node-RED, and Grafana to provide a network of communication topics. The broker can be accessed by any device on the ZeroTier network; messages can be sent to a topic, or actions can be taken based on a message received from a topic.\n\nBelow is an example Python script for publishing messages to the MQTT broker. This script publishes a test message to the topic `jetson/telemetry` every second. Note that the two key components of a successful message are the topic and the message payload. The topic is the address to which the message is sent, and the payload is the data being sent. The payload can be a string, a number, or a JSON object. For our project, we use JSON objects to send data.\n\nThe package is installed using pip: `pip install paho-mqtt`\n\n::: {#9c6cd46f .cell execution_count=2}\n``` {.python .cell-code}\nimport json\nimport time\nimport paho.mqtt.client as mqtt\nimport random\n\n# Define the MQTT settings\nbroker_address = \"172.22.1.1\"  # Lenovo's IP address (replace with your broker IP)\nport = 1883\ntopic = \"jeston/telemetry\"\n\n# Create an MQTT client instance\nclient = mqtt.Client()\n\n# Define the callback for receiving messages\ndef on_message(client, userdata, message):\n    print(f\"Message received on topic {message.topic}: {message.payload.decode()}\")\n\n# Define the callback for connecting to the broker\ndef on_connect(client, userdata, flags, rc):\n    print(\"Connected to broker with result code \" + str(rc))\n    # Subscribe to the topic when connected\n    client.subscribe(topic)\n\n# Assign the callbacks\nclient.on_message = on_message\nclient.on_connect = on_connect\n\n# Connect to the broker\nclient.connect(broker_address, port)\n\n# Start the loop to process messages\nclient.loop_start()\n\n# Publish some test messages to the topic every second\ntry:\n  range(3)\n  for i in range(3):\n        message = {\"sensor\": \"temperature\", \"value\": 20 + random.random() * 5}\n        client.publish(topic, json.dumps(message))\n        print(f\"Published message: {message}\")\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    print(\"Exiting...\")\n\n# Stop the loop and disconnect\nclient.loop_stop()\nclient.disconnect()\n```\n:::\n\n\nIn this demo script, the client is both publishing and subscribing to the same topic. In practice, we use multiple topics for different data streams and commands. A more advanced implementation for assigning topics and managing data can be found in our repository: [RLUnicycle](https://github.com/Team-2411-RL-Unicycle/rl-unicycle)\n\nThis test script is useful for publishing test data when it comes to verifying the installation of InfluxDB and Grafana ahead.\n\nWe are now at this stage in the setup:\n\n\n\n\n```{mermaid}\n\nflowchart TD\n  %% Customizing colors for subgraphs and nodes\n  style Robot fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Server fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px\n  style Clients fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n\n  Y[Robot]\n  Z[Server]\n\n  %% Define a class for black text\n  classDef blackText fill:none,color:#000,stroke:none;\n\n  subgraph Robot\n    E(Jetson)\n  end\n  \n  subgraph Server\n    E <--> F[MQTT Broker]\n  end\n\n  %% Clients section coloring applied to individual floating nodes\n    K[Python Script] -->|Commands| F\n    L[Laptop] -->|SSH| E\n    L -->|MQTT Explorer| F\n    L --> K\n  \n  %% Styling for the floating client items\n  style K fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style L fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style Y fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Z fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px\n```\n\n\n\n\n## Telegraf and InfluxDB\n\n::: {.image-wrap}\n![](imgs/telegraf-logo.png)\n![](imgs/influx-logo.png)\n:::\n\n[Telegraf](https://docs.influxdata.com/telegraf/v1/install/) and [InfluxDB](https://docs.influxdata.com/influxdb/v2/install/) are free and open-source products from InfluxData. Telegraf is driven by a configuration file that organizes incoming data from multiple sources for processing and forwarding into the InfluxDB database. InfluxDB is a time-series database used to store telemetry data streamed from the robot. It features a web browser interface for data exploration and APIs in Python and other languages for database queries.\n\nFollow the instructions in the links above to install both services on the server.\n\n### InfluxDB Configuration\nThe InfluxDB database can be accessed through a web browser by navigating to the IP address of the Lenovo server on port 8086. For example, `http://172.22.1.1:8086/`. A login process will establish a username, password, and organization. The organization is simply a way to group data together across users. A bucket is a way to group data together within an organization. For our database we have assigned the organization name as `Capstone` and the bucket name as `telegraf` but these are free to choose. Once the organization and bucket have been created, the database is ready to receive data.\n\n### Telegraf Configuration\nThe Telegraf configuration file is located at `/etc/telegraf/telegraf.conf` by default. The default configuration is extensive, with many lines commented out. It is advisable to back up the original file and then remove unnecessary commented lines for clarity.\n\nTelegraf acts as a central messaging switchboard. To utilize it, we need to connect the MQTT topics into the switchboard and connect the output to the InfluxDB database for storage. The main changes suggested from the default configuration are:\n\n1. Remove the logging of server stats from the pool of inputs.\n2. Add the MQTT input plugin to the configuration file.\n3. Add the InfluxDB output plugin to the configuration file.\n\nA simplified header is shown below:\n\n\n\n```{conf}\n# Default Header\n[global_tags]\n\n# Configuration for telegraf agent\n[agent]\n  ## Default data collection interval for all inputs\n  interval = \"10s\"\n  round_interval = true\n  metric_batch_size = 1000\n  metric_buffer_limit = 10000\n  collection_jitter = \"0s\"\n  flush_interval = \"10s\"\n  flush_jitter = \"0s\"\n  precision = \"\"\n\n  ## Override default hostname, if empty use os.Hostname()\n  hostname = \"\"\n  ## If set to true, do no set the \"host\" tag in the telegraf agent.\n  omit_hostname = true\n  ```\n\n\n\n\n::: {.grid}\n\n::: {.g-col-4}\n![](imgs/influx-api-token.png)\n:::\n\n::: {.g-col-8}\nNow, add InfluxDB as an output plugin and MQTT as an input plugin. The MQTT plugin listens to messages on particular topics, and the InfluxDB plugin writes the data to the database. The configuration for the InfluxDB output plugin is shown below.\n\nNote the **token** above can be generated through the InfluxDB web interface. \n:::\n\n:::\n\n\n\n\n\n```{conf}\n[[outputs.influxdb_v2]]\n  # localhost assumes telegraf and influxdb are on the same server\n  urls = [\"http://localhost:8086\"]\n  token = \"api token from InfluxDB\"\n  organization = \"Capstone\"\n  bucket = \"telegraf\"\n\n[[outputs.prometheus_client]]\n    listen = \":9273\"\n    metric_version = 2\n```\n\n\n\n\n\n\nFinally the incoming messages from MQTT are processed. A very important consideration here is to fully automate the process of message conversion from JSON to adopt a robot-driven database. The core principle is that changes in the robot software and telemetry should not change either this configuration file or the database schema. In our case, all messages that are to be databased start with `robot/` and the topic indicates the data category. For example `robot/imu1` is the MQTT topic that recieves information on the imu sensor\n\n ```\n {ax: 0.1, ay: 0.2, az: 0.3, gx: 0.4, gy: 0.5, gz: 0.6}\n ```\n \n Telegraph identifies that this is to be databased, removes the `robot/` prepend, records the json message `_measurement` as `imu1` and the `_field` as `ax`, `ay`, `az`, `gx`, `gy`, `gz`. \n\n\n\n\n```{conf}\n[[processors.starlark]]\n  source = '''\ndef apply(metric):\n    # Get the topic tag value (e.g., \"robot/motor\")\n    topic = metric.tags.get(\"topic\")\n    \n    # Extract the part after \"robot/\"\n    if topic.startswith(\"robot/\"):\n        measurement = topic.split(\"robot/\", 1)[1]\n        # Set the new measurement based on the tail of the topic\n        metric.name = measurement\n    \n    return metric\n'''\n\n# MQTT Consumer Input Plugin\n[[inputs.mqtt_consumer]]\n  servers = [\"tcp://localhost:1883\"]\n\n  topics = [\n    \"robot/#\"  # Subscribe to all subtopics under robot/\n  ]\n  qos = 0\n  client_id = \"telegraf_mqtt_consumer\"\n  data_format = \"json\"\n  ## Use a part of the topic or JSON structure as the measurement name.\n  json_name_key = \"measurement\"\n```\n\n\n\n\nThis completes the configuration file. The other components that record server metrics can be removed to keep the database focused.\n\n### Testing the Configuration with Data Explorer\n\nReturn to the MQTT Python script and send messages to a `robot/` topic for testing. They should now be automatically processed into the database as described. Verify that the messages are passing through the MQTT broker, then confirm they are reaching the InfluxDB database using the Data Explorer.\n\n![](imgs/data-explorer.png)\n\nf successful, the Data Explorer will show that the bucket has new data. The measurement filter will display the topic passed to MQTT, the field will show the keys from the passed JSON, and the data will show the values. Note that InfluxDB automatically applies data operations such as aggregation to reduce the number of sample points. This can be managed using the window period on the right-hand side.\n\nInfluxDB has its own query language, which can be previewed by clicking the **Script Editor** button. This provides direct insight into how the data is processed when a query is sent and can be edited to fine-tune the settings or used as an API call from elsewhere (e.g., from a Python script to create plots).\n\n```\nfrom(bucket: \"telegraf\")\n  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)\n  |> filter(fn: (r) => r[\"_measurement\"] == \"sensors/imu\")\n  |> filter(fn: (r) => r[\"_field\"] == \"accel_x\")\n  |> aggregateWindow(every: 100ms, fn: mean, createEmpty: false)\n  |> yield(name: \"mean\")\n```\n\nThe `accel_x` is being aggregated into 100ms sample periods using the mean of all values in that window. This can be modified to get raw data or changed to a different aggregation function. The range values can also be set to relative times to get the last 10 minutes of data, for example.\n\n```\nfrom(bucket: \"telegraf\")\n  |> range(start: -10m)\n  |> filter(fn: (r) => r[\"_measurement\"] == \"sensors/imu\")\n  |> filter(fn: (r) => r[\"_field\"] == \"accel_x\")\n```\n\nBuilding these queries through the script editor is a good way to get the correct string to use in a Python script to query the database.\n\n### Example Python Query\n\nTo illustrate how this can be integrated into Python for data analysis, here is a simple example. This script queries the last one minute of data from the database and plots the acceleration data over time.\n\n::: {#af00b236 .cell freeze='true' execution_count=3}\n``` {.python .cell-code}\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom influxdb_client import InfluxDBClient\n\n# Server IP address with InfluxDB port\nurl = \"http://172.22.1.1:8086\"\ntoken = \"gGu-3t4Avltf6-yHamGXItRfOKBQIDLgWEfhdURE7wURQazK_yvIa8O9k0O-_doXX8Q0Acy82vVavb5AcM2Lhw==\"\norg = \"Capstone\"\nbucket = \"telegraf\"\n\nclient = InfluxDBClient(url=url, token=token, org=org)\n\n# Query for the last 10 minutes of data\nlast_mins = 1\nquery = f'''\nfrom(bucket: \"{bucket}\")\n  |> range(start: -{last_mins}m)\n  |> filter(fn: (r) => r[\"_measurement\"] == \"sensors/imu\")\n  |> filter(fn: (r) => r[\"_field\"] == \"accel_x\")\n  |> aggregateWindow(every: 1s, fn: mean, createEmpty: false)\n'''\n\n# Query the data\nquery_api = client.query_api()\ntables = query_api.query(org=org, query=query)\n\n# Extract values (accel_x) from query response\nvalues = [record.get_value() for table in tables for record in table.records]\n\n# Plot using Seaborn\nplt.figure(figsize=(5, 3))\nsns.lineplot(data=values, linewidth=2.5)\n\n# Customize plot\nplt.title('Acceleration Data (accel_x) Over Time', fontsize=16)\nplt.xlabel('Steps', fontsize=14)\nplt.ylabel('Acceleration (accel_x)', fontsize=14)\nplt.tight_layout()\n\n# Display the plot\nplt.show()\n```\n:::\n\n\nThis concludes the setup of the MQTT, Telegraf, and InfluxDB services. The next step is to setup Grafana for live telemetry and database dashboards. \n\n---\n\nAt this stage in the setup, the system architecture is as follows:\n\n\n\n\n```{mermaid}\n\nflowchart TD\n  %% Customizing colors for subgraphs and nodes\n  style Robot fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Server fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px\n  style Clients fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n\n  Y[Robot]\n  Z[Server]\n\n  %% Define a class for black text\n  classDef blackText fill:none,color:#000,stroke:none;\n\n  subgraph Robot\n    E(Jetson)\n  end\n  \n  subgraph Server\n    E <--> F[MQTT Broker]\n    F -->|Metrics| G[Telegraf]\n    G -->|Write| H[InfluxDB]\n  end\n\n  %% Clients section coloring applied to individual floating nodes\n    K[Python Script] -->|Commands| F\n    L[Laptop] -->|SSH| E\n    L -->|MQTT Explorer| F\n    L --> K\n    H -->|Data| M[Data Explorer and API]\n  \n  %% Styling for the floating client items\n  style K fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style L fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style M fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style Y fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Z fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px\n```\n\n\n\n\n## Grafana Live Telemetry\n\n![](imgs/grafan-logo.png){width=30%}\n\n [Grafana](https://grafana.com/grafana/download) is a powerful open-source platform for creating dashboards and visualizing time-series data. Grafana supports a wide range of data sources and can display both live and historical data. While it can refresh data from InfluxDB at a rate of every 5 seconds, this is too slow for live monitoring of a dynamic system. Instead, live telemetry is pulled directly from the MQTT broker.\n\n To begin, [download](https://grafana.com/grafana/download) and install Grafana on the server. The default port for Grafana is `3000`. Once installed, open up a web browser and navigate to `http://localhost:3000/` to access the Grafana dashboard. The default login is `admin` with the password `admin`. \n\n### Adding Data Sources\n\nGrafana needs to be configured with data sources:\n\n1. **InfluxDB Data Source**:\n\n   - The InfluxDB data source is included by default as a plugin.\n   - Specify the correct query language and provide the necessary credentials and address (`http://localhost:8086`).\n\n2. **MQTT Data Source**:\n\n   - To view MQTT data in real time, install a plugin to connect Grafana to the Mosquitto broker: [MQTT Datasource Plugin](https://github.com/grafana/mqtt-datasource).\n   - In Grafana, navigate to **Configuration** > **Data Sources** > **Add data source**.\n   - Select MQTT from the list of available data sources.\n   - Name the data source and specify the connection to the MQTT broker (`tcp://localhost:1883`).\n   - Add a username and password if configured for the broker.\n\n### Creating Dashboards and Panels\n\nNow it is time to setup a dashboard, a collection of data panels. The Grafana interface is user friendly, but we are interested in some key settings.\n\n1. The window of time that is being displayed in the dashboard.\n2. The MQTT topics that are being fetched for display.\n3. The keys from the JSON that are being displayed.\n\nFor this stage, it is recommended to either have a robot sensor streaming data, or a surrogate Python script sending out data to the MQTT broker so that there are live streaming messages to display.\n\n:::{.grid}\n\n::: {.g-col-6}\n![](imgs/grafana-step1.png){width=100%}\n\n:::\n\n::: {.g-col-6}\n#### Step 1: Create a New Dashboard\n- Log into the Grafana homepage from any device connected to the private network using the server IP: `http://172.22.1.1:3000/`.\n- Navigate to **Dashboards** and select **New Dashboard**.\n- Save the new dashboard. Remember to save periodically to avoid losing changes.\n- Adjust the time range of the dashboard to the last 30 seconds to see recent data streaming in. Apply the time range.\n:::\n:::\n\n:::{.grid}\n\n::: {.g-col-6}\n![](imgs/grafana-step2.png){width=100%}\n:::\n\n::: {.g-col-6}\n#### Step 2: Add a Visualization Panel\n\n- Select the **Add a visualization** button to make the first panel. \n- Enter the MQTT topic and verify that data is streaming using MQTT Explorer. \n- The data should begin streaming in the panel preview. \n- Use the **Query Inspector** and **Data** tab to verify that data is being received and processed correctly if the visualization is not showing as expected.\n:::\n\n:::\n\n#### Step 3: Customize the Panel\n\n![](imgs/grafana-step3.png)\nSelect the **Transform Data** tab and then **Filter fields by name** option. Fields that are to be omitted can be removed from the identifier list and will not be displayed in the panel. Finally the right hand side of the panel configuration can be used to fully customize the display of data, panel title, etc.\n\nSave and apply the panel change. Now is a good time to bookmark the dashboard for easy access in the future. The live telemetry has limitations in how much data can be displayed at once, since it is sampling from a moving buffer and not storing the data like the database. Too many panels with too much data will cause the system to stutter, so the recommendation is to downsample the data to about 10Hz or less unless full sample resolution is needed.\n\n### Notes on Downsampling\n\nAs of now, an effective way to downsample the incoming data in Grafana has not been found. Telegraf has some data processing capabilities for downsampling, but it would require rebroadcasting over a new MQTT topic. The simplest solution we have found is to downsample data on the robot side by sending full-resolution data to each of the `robot/` topics and every $n$ th message to a `downsampled/` topic. This can be implemented with few lines of code and does not add significant overhead.\n\n---\n\nAt this stage in the setup, the system architecture is as follows:\n\n\n\n\n```{mermaid}\n\nflowchart TD\n  %% Customizing colors for subgraphs and nodes\n  style Robot fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Server fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px\n  style Clients fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n\n  Y[Robot]\n  Z[Server]\n\n  %% Define a class for black text\n  classDef blackText fill:none,color:#000,stroke:none;\n\n  subgraph Robot\n    E(Jetson)\n  end\n  \n  subgraph Server\n    E <--> F[MQTT Broker]\n    F -->|Metrics| G[Telegraf]\n    G -->|Write| H[InfluxDB]\n    F -->|Visualization| I[Grafana]\n  end\n\n  %% Clients section coloring applied to individual floating nodes\n    I -->|Live Telemetry| J[Dashboard]\n    H -->|Data| M[Data Explorer and API]\n\n  \n  %% Styling for the floating client items\n  style J fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style M fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style Y fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Z fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px\n\n```\n\n\n\n\n# Robot Software Architecture\n\nAn automated data pipeline now exists between the robot software system and the database and telemetry panel. However, there are considerations when handling data within the robot controller, especially since the control loop is sensitive to timing and delays.\n\nTo address these issues, the telemetry handling and output of the robot are separated into a parallel process that is not part of the control loop. Crucially, the process has lower priority and will not interfere or cause delays in the time-sensitive portions of the code.\n\nWe follow two core principles in our software implementation:\n\n1. Data-driven design: The data classes within the robot system dictate the structure of the database and communication topics. IMU data is naturally packaged into a single topic, as is motor data, etc. This approach simplifies data management and ensures correct data processing.\n\n2. Asynchronous processing: The telemetry process runs on a separate core from the main control loop. In Python, this is achieved using multiprocessing since the Python Global Interpreter Lock (GIL) prevents a single process from running on multiple cores. The two processes communicate through two unidirectional queues: one for data out and one for commands in.\n\nThe details of the implementation can be viewed through our repository: [**RLUnicycle**](https://github.com/Team-2411-RL-Unicycle/rl-unicycle). The multiprocessing with queues are initiated in `main.py`, data packaging is handled by `teledata.py`, and the communication thread is handled by `mqtt.py`.\n\n#### `main.py`\nThe main entry point for the robot handles the asynchronous processes using data queues for input and output to send messages between the control loop and communications:\n\n**Code Example: Main entry point for the robot handling asynchronous processes.**\n\n::: {#main-entry .cell execution_count=4}\n``` {.python .cell-code code-fold=\"true\"}\nimport logging\nimport argparse\nimport multiprocessing\nimport asyncio\n\nasync def main():\n    args = parse_args()\n    setup_logging()\n    logger = logging.getLogger()\n    logger.debug(\"Logger initialized\")\n\n    try:\n        set_realtime_priority(priority=99)\n    except PermissionError as e:\n        logger.error(f\"Failed to set real-time priority: {e}\")\n        return\n\n    telemetry_queue = multiprocessing.Queue()\n    command_queue = multiprocessing.Queue()\n    shutdown_event = multiprocessing.Event()\n\n    # Start the MQTT process\n    mqtt_process = multiprocessing.Process(\n        target=start_mqtt_process,\n        args=(telemetry_queue, command_queue, shutdown_event),\n    )\n    mqtt_process.start()\n\n    # Initialize and start the robot\n    robot = RobotSystem(\n        telemetry_queue,\n        command_queue,\n        start_motors=not args.no_motors,\n        controller_type=args.controller,\n        config_file=args.config_file,\n    )\n\n    try:\n        await robot.start(shutdown_event)\n    except KeyboardInterrupt:\n        logger.info(\"Shutdown signal received\")\n        shutdown_event.set()\n    except Exception as e:\n        logger.exception(f\"An unexpected error occurred: {e}\")\n    finally:\n        await robot.shutdown()\n\n        # Terminate and clean up the MQTT process\n        shutdown_event.set()\n        mqtt_process.join(timeout=5)\n        if mqtt_process.is_alive():\n            mqtt_process.kill()\n            logger.warning(\n                \"MQTT process did not terminate gracefully, forcing termination.\"\n            )\n\n        logger.info(\"Cleanup complete. Exiting program.\")\n```\n:::\n\n\n#### `robot/teledata.py`\nThe `@dataclass` decorator in Python is used to define structures that hold the data in fields. A method to convert them to dictionary/JSON is also included in a TelemetryData base class. A generalist debug data class is also provided to allow for ad-hoc data to be sent to the telemetry system during development that has not been assigned a specific topic. The fields are coupled with the MQTT topic and the database measurement name within the dataclass object.\n\nA sample of the abstract class and a data class for IMU data is shown below:\n\n**Code Example: A sample of the abstract class and a data class for IMU data.**\n\n::: {#743e8c09 .cell execution_count=5}\n``` {.python .cell-code code-fold=\"true\"}\nfrom abc import ABC, abstractmethod\nfrom dataclasses import asdict, dataclass, field\nfrom typing import Any, Dict\n\n\nclass TelemetryData(ABC):\n    \"\"\"\n    Abstract base class for telemetry data. All telemetry sent identifying a topic,\n    and with the data fields as the labels for the data.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def topic(self) -> str:\n        pass\n\n    def get_data(self):\n        \"\"\"\n        Returns a dictionary of the telemetry data excluding the topic.\n        Uses asdict() if the subclass is a dataclass.\n        \"\"\"\n        return asdict(self)  # Convert to dictionary without the topic\n\n    def to_mqtt(self):\n        \"\"\"\n        Returns the topic and the data as a tuple (topic, data).\n        The data does not include the topic field.\n        \"\"\"\n        return (self.topic, self.get_data())  # Return tuple for sending to MQTT\n\n\n@dataclass(frozen=True)\nclass IMUData(TelemetryData):\n    \"\"\"Data returned from the IMU sensor\"\"\"\n\n    accel_x: float  # 1.0 = 9.8 m/s^2\n    accel_y: float\n    accel_z: float\n    gyro_x: float  # degrees per second\n    gyro_y: float\n    gyro_z: float\n\n    @property\n    def topic(self) -> str:\n        return \"robot/sensors/imu\"  # Class-level topic\n\n    def get_accel(self) -> tuple:\n        return (self.accel_x, self.accel_y, self.accel_z)\n\n    def get_gyro(self) -> tuple:\n        return (self.gyro_x, self.gyro_y, self.gyro_z)\n```\n:::\n\n\n#### `robot/rwip.py`\nAt the end of a control cycle, all data classes are packed into a single list and sent to the telemetry process. Opening the inter-process queue incurs an overhead, so it is more efficient to send one single outgoing packet per control cycle.\n\n**Code Example: Packaging of TelemetryData objects into a list and sending them to the telemetry process.**\n\n::: {#data-sending .cell execution_count=6}\n``` {.python .cell-code code-fold=\"true\"}\n### SEND COMMS ###\ndata_list = [imudata, euler_angles, control_data, tele_debug_data]\nawait self._send_telemetry(data_packet=data_list)\n\nasync def _send_telemetry(\n    self, data_packet: Union[List[td.TelemetryData], td.TelemetryData]\n) -> None:\n    \"\"\"\n    Send telemetry data to the telemetry queue.\n    \"\"\"\n    self.send_queue.put(data_packet)\n```\n:::\n\n\n#### Telemetry Process `communication/mqtt.py`\nThe telemetry process is essentially a wrapper around the existing Paho MQTT client. It is designed to unpack the data classes from the incoming queue and send them to their corresponding topics. It additionally handles downsampling the data to a lower rate for the Grafana panels. It has a standby loop that listens for incoming commands over a control topic and routes them to the control cycle through the command queue as needed.\n\n**Code Example: Parsing of TelemetryData objects and sending them to the MQTT broker.**\n\n::: {#ea21d807 .cell execution_count=7}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\ndef telemetry_loop(self):\n        while not self.shutdown_event.is_set():\n            try:\n                while not self.send_queue.empty():\n                    batch = self.send_queue.get()\n\n                    self.batch_count += 1  # Increment batch counter\n                    if self.batch_count >= self.downsample_rate:\n                        self.batch_count = 0\n                        is_downsampled = True\n                    else:\n                        is_downsampled = False\n\n                    if isinstance(batch, list):\n                        for telemetry_data in batch:\n                            self.process_telemetry_data(telemetry_data, is_downsampled)\n                    else:\n                        self.process_telemetry_data(batch, is_downsampled)\n            except Exception as e:\n                logger.exception(f\"Error in telemetry_loop: {e}\")\n\n            time.sleep(self.loop_time)\n\ndef process_telemetry_data(\n    self, telemetry_data: TelemetryData, is_downsampled: bool\n):\n    # Check that the telemetry data is an instance of the TelemetryData class\n    if not isinstance(telemetry_data, TelemetryData):\n        logger.error(f\"Invalid telemetry data: {telemetry_data}\")\n        return\n\n    try:\n        topic, data = telemetry_data.to_mqtt()\n\n        # Publish to the original topic\n        self.publish_data(topic, data)\n        # logger.debug(f\"Published to {topic}: {data}\")\n\n        # If this is a downsampled batch, also publish to the downsampled topic\n        if is_downsampled:\n            downsampled_topic = f\"downsampled/{topic}\"\n            self.publish_data(downsampled_topic, data)\n            # logger.debug(f\"Published to {downsampled_topic}: {data}\")\n\n    except Exception as e:\n        logger.exception(f\"Error processing telemetry data for topic {topic}: {e}\")\n\ndef publish_data(self, topic, data):\n    self.client.publish(topic, json.dumps(data))\n    pass\n```\n:::\n\n\n# Command Management\n\nThe established connection with the robot controller also allows for remote commands to be sent in real-time. These commands can adjust tuning parameters or control the robot. We have a control panel that is synchronized across all devices through a web browser using Node-RED.\n\n### Node Red\n\n[NodeRed](https://nodered.org/) is a flow-based, open-source development tool for visual programming developed by IBM. It is used for wiring together hardware devices, APIs, and online services in new and interesting ways. It provides a browser-based editor that makes it easy to wire together flows using a wide range of nodes. In our case, this enables a synchronized control panel accessible through a web browser.\n\nNodeRed can be installed on the server, with default port of `1880`. \n\n![Node Red Dashboard](imgs/nodereddash.png)\n\nThe Node-RED dashboard allows for the creation of custom dashboards that provide a GUI for the robotics project.\n\n### XBox Controller\nA controller can be connected through a PC to an MQTT topic using Paho-MQTT and Python. This opens up some interesting avenues for assisted control of the robot.\n\n# Conclusion\n\nThe setup of the Lenovo server, ZeroTier network, MQTT broker, Telegraf, InfluxDB, Grafana, and Node-RED provides a powerful platform for the development of a capstone project. These services are all open-source and free to use. They are well-documented and have large communities of users that can assist with any issues that may arise.\n\nBy following this guide, you should have a robust telemetry and database system for your robotics project.\n\nAt this point in the setup, if you have followed the guide, the system architecture is as follows:\n\n![Telemetry Overview](imgs/NetworkDiagram.drawio.svg){fig-align=\"center\"}\n\nBest of luck with your robotics project!\n\n",
    "supporting": [
      "telemetry_files"
    ],
    "filters": [],
    "includes": {}
  }
}
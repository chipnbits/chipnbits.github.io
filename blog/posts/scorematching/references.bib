@article{hyvarinenEstimationNonNormalizedStatistical,
  title = {Estimation of {{Non-Normalized Statistical Models}} by {{Score Matching}}},
  author = {Hyvarinen, Aapo},
  abstract = {One often wants to estimate statistical models where the probability density function is known only up to a multiplicative normalization constant. Typically, one then has to resort to Markov Chain Monte Carlo methods, or approximations of the normalization constant. Here, we propose that such models can be estimated by minimizing the expected squared distance between the gradient of the log-density given by the model and the gradient of the log-density of the observed data. While the estimation of the gradient of log-density function is, in principle, a very difficult non-parametric problem, we prove a surprising result that gives a simple formula for this objective function. The density function of the observed data does not appear in this formula, which simplifies to a sample average of a sum of some derivatives of the log-density given by the model. The validity of the method is demonstrated on multivariate Gaussian and independent component analysis models, and by estimating an overcomplete filter set for natural image data.},
  langid = {english},
  file = {C:\Users\sghys\Zotero\storage\GFBUV9WT\Hyvarinen - Estimation of Non-Normalized Statistical Models by.pdf}
}

@article{lyuInterpretationGeneralizationScore2009,
  title = {Interpretation and {{Generalization}} of {{Score Matching}}},
  author = {Lyu, Siwei},
  year = {2009},
  abstract = {Score matching is a recently developed parameter learning method that is particularly effective to complicated high dimensional density models with intractable partition functions. In this paper, we study two issues that have not been completely resolved for score matching. First, we provide a formal link between maximum likelihood and score matching. Our analysis shows that score matching finds model parameters that are more robust with noisy training data. Second, we develop a generalization of score matching. Based on this generalization, we further demonstrate an extension of score matching to models of discrete data.},
  langid = {english},
  file = {C:\Users\sghys\Zotero\storage\7DHD9UD8\Lyu - 2009 - Interpretation and Generalization of Score Matchin.pdf}
}

@misc{raschkaKernelDensityEstimation0000,
  title = {Kernel Density Estimation via the {{Parzen-Rosenblatt}} Window Method},
  author = {Raschka, Sebastian},
  year = {09:00:00 +0000},
  journal = {Sebastian Raschka, PhD},
  urldate = {2024-05-19},
  abstract = {The Parzen-window method (also known as Parzen-Rosenblatt window method)is a widely used non-parametric approach to estimate a probabilitydensity function p(...},
  howpublished = {https://sebastianraschka.com/Articles/2014\_kernel\_density\_est.html},
  langid = {english},
  file = {C:\Users\sghys\Zotero\storage\6CLWJ5CR\2014_kernel_density_est.html}
}

@article{sheddenFittingInferenceLinear,
  title = {Fitting and Inference for Linear Models Using Least Squares},
  author = {Shedden, Kerby},
  langid = {english},
  file = {C:\Users\sghys\Zotero\storage\C7TG2VL3\Shedden - Fitting and inference for linear models using leas.pdf}
}

@article{vincentConnectionScoreMatching2011,
  title = {A {{Connection Between Score Matching}} and {{Denoising Autoencoders}}},
  author = {Vincent, Pascal},
  year = {2011},
  month = jul,
  journal = {Neural Computation},
  volume = {23},
  number = {7},
  pages = {1661--1674},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/NECO_a_00142},
  urldate = {2024-05-16},
  abstract = {Denoising autoencoders have been previously shown to be competitive alternatives to restricted Boltzmann machines for unsupervised pretraining of each layer of a deep architecture. We show that a simple denoising autoencoder training criterion is equivalent to matching the score (with respect to the data) of a specific energy-based model to that of a nonparametric Parzen density estimator of the data. This yields several useful insights. It defines a proper probabilistic model for the denoising autoencoder technique, which makes it in principle possible to sample from them or rank examples by their energy. It suggests a different way to apply score matching that is related to learning to denoise and does not require computing second derivatives. It justifies the use of tied weights between the encoder and decoder and suggests ways to extend the success of denoising autoencoders to a larger family of energy-based models.},
  langid = {english},
  file = {C:\Users\sghys\Zotero\storage\VYRWVSEB\Vincent - 2011 - A Connection Between Score Matching and Denoising .pdf}
}

@misc{krizhevsky2009learning,
  author = {Alex Krizhevsky},
  title = {Learning Multiple Layers of Features from Tiny Images},
  year = {2009},
  url = {https://www.cs.toronto.edu/~kriz/cifar.html},
  note = {Accessed: 2024-05-22}
}
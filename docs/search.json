[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Simon Ghyselincks Personal Website",
    "section": "",
    "text": "Welcome to my personal site! I’m Simon Ghyselincks, a PhD-track student at the University of British Columbia (UBC) in the Department of Computer Science."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Simon Ghyselincks Personal Website",
    "section": "",
    "text": "Welcome to my personal site! I’m Simon Ghyselincks, a PhD-track student at the University of British Columbia (UBC) in the Department of Computer Science."
  },
  {
    "objectID": "index.html#academics-and-projects",
    "href": "index.html#academics-and-projects",
    "title": "Simon Ghyselincks Personal Website",
    "section": "Academics and Projects",
    "text": "Academics and Projects\nI am currently working with Eldad Haber from UBC Earth and Ocean Sciences and Michael Friedlander in Computer Science on generative AI and optimization with application to geophysics. My recent work explores the application of advances in normalizing flows with stochastic interpolants to generate 3d models of the earth’s crust. My undergraduate two-year senior capstone project is “Learning to Balance” which explores the application of reinforcement learning to a reaction wheel robot with complex dynamics. Read more about my projects here.\n\nFeel free to connect with me on LinkedIn or check out my GitHub."
  },
  {
    "objectID": "index.html#my-journey",
    "href": "index.html#my-journey",
    "title": "Simon Ghyselincks Personal Website",
    "section": "My Journey",
    "text": "My Journey\nRead more about my journey and past pursuits here."
  },
  {
    "objectID": "content/projects/RLUnicycle/rtkernel/rtpatch.html",
    "href": "content/projects/RLUnicycle/rtkernel/rtpatch.html",
    "title": "RT Kernel on Jetson Nano",
    "section": "",
    "text": "The following guide is intended to provide step-by-step instructions on how to compile a real-time (RT) Linux kernel for the NVIDIA Jetson Nano. The RT kernel is based on the PREEMPT_RT patch, which adds real-time capabilities to the Linux kernel by making it fully preemptible and reducing the latency of the kernel’s interrupt handling.\nThis guide has been modified from some valuable instructions found at: https://forums.developer.nvidia.com/t/applying-a-preempt-rt-patch-to-jetpack-4-5-on-jetson-nano/168428/4\n\n\nFirst download the BSP from the NVIDIA website. The BSP contains the kernel source code, device tree files, and other necessary files for building the kernel. The BSP also contains the sample root filesystem, which is used to create the final image for the Jetson Nano. You may wish to look up the most recent version of the Tegra for Linux, in this case we are using R32.7.4.\nYou can download all of these files onto a Linux machine specifically running Ubuntu 18.04. Another option that has been tested is compiling on the Jetson Nano itself which is running the correct version of Linux by default. For our project we installed 18.04 on a laptop and compiled the kernel there.\n\n\n\n\n\n\nNote\n\n\n\nSource Files:\nhttps://developer.nvidia.com/embedded/linux-tegra-r3274\n\n\nDownload:\n\nDriver Package (BSP)\nSample Root File System\nDriver Package (BSP) Sources\nGCC Tool Chain can also be obtained via the command line:\nwget http://releases.linaro.org/components/toolchain/binaries/7.3-2018.05/aarch64-linux-gnu/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz\n\nPile all the files into a single directory and install packages\nsudo apt-get update \nsudo apt-get install libncurses5-dev \nsudo apt-get install build-essential \nsudo apt-get install bc \nsudo apt-get install lbzip2 \nsudo apt-get install qemu-user-static \nsudo apt-get install python\n\nmkdir $HOME/jetson_nano \ncd $HOME/jetson_nano\nExtract all of the files\nsudo tar xpf jetson-210_linux_r32.7.4_aarch64.tbz2\ncd Linux_for_Tegra/rootfs/ \nsudo tar xpf ../../tegra_linux_sample-root-filesystem_r32.7.4_aarch64.tbz2\ncd ../../ \ntar -xvf gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz \nsudo tar -xjf public_sources.tbz2 \ntar -xjf Linux_for_Tegra/source/public/kernel_src.tbz2\n\n\n\nGo into extracted kernel source and apply RT patch\ncd kernel/kernel-4.9/\n./scripts/rt-patch.sh apply-patches\nConfigure and compile:\nTEGRA_KERNEL_OUT=jetson_nano_kernel \nmkdir $TEGRA_KERNEL_OUT \nexport CROSS_COMPILE=$HOME/jetson_nano/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu/bin/aarch64-linux-gnu- \nmake ARCH=arm64 O=$TEGRA_KERNEL_OUT tegra_defconfig \nmake ARCH=arm64 O=$TEGRA_KERNEL_OUT menuconfig\nThe menu config opens an old school BIOS menu. Set the proper settings for the RT kernel:\n\nGeneral setup → Timer subsystem → Timer tick handling → Full dynticks system (tickless)\nKernel Features → Preemption Model: Fully Preemptible Kernel (RT)\nKernel Features → Timer frequency: 1000 HZ\n\nAt this point you can go tamper with device tree files (.dtsi) or other things, next step is the compile stage!\n\n\nI tried to modify\ntegra210-porg-gpio-p3448-0000-b00.dtsi \nthe source file, found using a find file function in terminal. It did not fix things. In general the P3450 model requires the p3448-0000-3449-b00 series of files. This was confirmed by looking at all the source configs and scripts.\n\n\n\nmake ARCH=arm64 O=$TEGRA_KERNEL_OUT -j4\n\nsudo cp jetson_nano_kernel/arch/arm64/boot/Image $HOME/jetson_nano/Linux_for_Tegra/kernel/Image\nsudo cp -r jetson_nano_kernel/arch/arm64/boot/dts/* $HOME/jetson_nano/Linux_for_Tegra/kernel/dtb/\nsudo make ARCH=arm64 O=$TEGRA_KERNEL_OUT modules_install INSTALL_MOD_PATH=$HOME/jetson_nano/Linux_for_Tegra/rootfs/\n\ncd $HOME/jetson_nano/Linux_for_Tegra/rootfs/\nsudo tar --owner root --group root -cjf kernel_supplements.tbz2 lib/modules\nsudo mv kernel_supplements.tbz2  ../kernel/\n\ncd ..\nsudo ./apply_binaries.sh\nThe image creator requires the device model. For the 4GB Jetson nano it is -r 300. This will select the correct dtb:\ncd tools\nsudo ./jetson-disk-image-creator.sh -o jetson_nano.img -b jetson-nano -r 300\nIt is crucial to select the correct device tree since it will not boot otherwise. If you are unsure of which to select, follow through the source cocde in the jetson-disk-image-creator.sh to find what the different flags do. Or try the NVIDIA forums but good luck over there!\nUse Balena etcher to put image in $HOME/jetson_nano/Linux_for_Tegra/tools/jetson_nano.img onto the SD card",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "RT Kernel on Jetson Nano"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/rtkernel/rtpatch.html#download-source-files-and-install-packages",
    "href": "content/projects/RLUnicycle/rtkernel/rtpatch.html#download-source-files-and-install-packages",
    "title": "RT Kernel on Jetson Nano",
    "section": "",
    "text": "First download the BSP from the NVIDIA website. The BSP contains the kernel source code, device tree files, and other necessary files for building the kernel. The BSP also contains the sample root filesystem, which is used to create the final image for the Jetson Nano. You may wish to look up the most recent version of the Tegra for Linux, in this case we are using R32.7.4.\nYou can download all of these files onto a Linux machine specifically running Ubuntu 18.04. Another option that has been tested is compiling on the Jetson Nano itself which is running the correct version of Linux by default. For our project we installed 18.04 on a laptop and compiled the kernel there.\n\n\n\n\n\n\nNote\n\n\n\nSource Files:\nhttps://developer.nvidia.com/embedded/linux-tegra-r3274\n\n\nDownload:\n\nDriver Package (BSP)\nSample Root File System\nDriver Package (BSP) Sources\nGCC Tool Chain can also be obtained via the command line:\nwget http://releases.linaro.org/components/toolchain/binaries/7.3-2018.05/aarch64-linux-gnu/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz\n\nPile all the files into a single directory and install packages\nsudo apt-get update \nsudo apt-get install libncurses5-dev \nsudo apt-get install build-essential \nsudo apt-get install bc \nsudo apt-get install lbzip2 \nsudo apt-get install qemu-user-static \nsudo apt-get install python\n\nmkdir $HOME/jetson_nano \ncd $HOME/jetson_nano\nExtract all of the files\nsudo tar xpf jetson-210_linux_r32.7.4_aarch64.tbz2\ncd Linux_for_Tegra/rootfs/ \nsudo tar xpf ../../tegra_linux_sample-root-filesystem_r32.7.4_aarch64.tbz2\ncd ../../ \ntar -xvf gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz \nsudo tar -xjf public_sources.tbz2 \ntar -xjf Linux_for_Tegra/source/public/kernel_src.tbz2",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "RT Kernel on Jetson Nano"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/rtkernel/rtpatch.html#apply-rt-patch",
    "href": "content/projects/RLUnicycle/rtkernel/rtpatch.html#apply-rt-patch",
    "title": "RT Kernel on Jetson Nano",
    "section": "",
    "text": "Go into extracted kernel source and apply RT patch\ncd kernel/kernel-4.9/\n./scripts/rt-patch.sh apply-patches\nConfigure and compile:\nTEGRA_KERNEL_OUT=jetson_nano_kernel \nmkdir $TEGRA_KERNEL_OUT \nexport CROSS_COMPILE=$HOME/jetson_nano/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu/bin/aarch64-linux-gnu- \nmake ARCH=arm64 O=$TEGRA_KERNEL_OUT tegra_defconfig \nmake ARCH=arm64 O=$TEGRA_KERNEL_OUT menuconfig\nThe menu config opens an old school BIOS menu. Set the proper settings for the RT kernel:\n\nGeneral setup → Timer subsystem → Timer tick handling → Full dynticks system (tickless)\nKernel Features → Preemption Model: Fully Preemptible Kernel (RT)\nKernel Features → Timer frequency: 1000 HZ\n\nAt this point you can go tamper with device tree files (.dtsi) or other things, next step is the compile stage!\n\n\nI tried to modify\ntegra210-porg-gpio-p3448-0000-b00.dtsi \nthe source file, found using a find file function in terminal. It did not fix things. In general the P3450 model requires the p3448-0000-3449-b00 series of files. This was confirmed by looking at all the source configs and scripts.\n\n\n\nmake ARCH=arm64 O=$TEGRA_KERNEL_OUT -j4\n\nsudo cp jetson_nano_kernel/arch/arm64/boot/Image $HOME/jetson_nano/Linux_for_Tegra/kernel/Image\nsudo cp -r jetson_nano_kernel/arch/arm64/boot/dts/* $HOME/jetson_nano/Linux_for_Tegra/kernel/dtb/\nsudo make ARCH=arm64 O=$TEGRA_KERNEL_OUT modules_install INSTALL_MOD_PATH=$HOME/jetson_nano/Linux_for_Tegra/rootfs/\n\ncd $HOME/jetson_nano/Linux_for_Tegra/rootfs/\nsudo tar --owner root --group root -cjf kernel_supplements.tbz2 lib/modules\nsudo mv kernel_supplements.tbz2  ../kernel/\n\ncd ..\nsudo ./apply_binaries.sh\nThe image creator requires the device model. For the 4GB Jetson nano it is -r 300. This will select the correct dtb:\ncd tools\nsudo ./jetson-disk-image-creator.sh -o jetson_nano.img -b jetson-nano -r 300\nIt is crucial to select the correct device tree since it will not boot otherwise. If you are unsure of which to select, follow through the source cocde in the jetson-disk-image-creator.sh to find what the different flags do. Or try the NVIDIA forums but good luck over there!\nUse Balena etcher to put image in $HOME/jetson_nano/Linux_for_Tegra/tools/jetson_nano.img onto the SD card",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "RT Kernel on Jetson Nano"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/rtkernel/rtpatch.html#setting-python-scheduling-privileges",
    "href": "content/projects/RLUnicycle/rtkernel/rtpatch.html#setting-python-scheduling-privileges",
    "title": "RT Kernel on Jetson Nano",
    "section": "2.1 Setting Python Scheduling Privileges",
    "text": "2.1 Setting Python Scheduling Privileges\nNote that for this description our team is using Python 3.8 in a virtual environment, the instructions path files may change slightly if using a different version.\nThe scheduling priority is a top-level system command and is usually locked behind ‘sudo’. This is problematic when running a Python script because we don’t want to run it as sudo allowing it full access to wreak havoc on the OS. The solution is to grant only the scheduling part of ‘sudo’ to the Python interpreter:\nThis command only needs to be set once after Python 3.8 is installed (the same in use in our venv): sudo setcap 'cap_sys_nice=eip' /usr/bin/python3.8\n\nsetcap: This is a utility that sets or changes the capabilities of a file/executable. Capabilities are a Linux feature that allow for more fine-grained access control; they provide a way to grant specific privileges to executables that normally only the root user would have.\n'cap_sys_nice=eip': This argument specifies the capabilities to be set on the file, in this case, /usr/bin/python3.8. It’s composed of three parts:\n\ncap_sys_nice: This is the specific capability being set. cap_sys_nice allows the program to raise process nice values (which can deprioritize processes) and change real-time scheduling priorities and policies, without requiring full root privileges.\ne: This stands for “effective” and means the capability is “activated” and can be used by the executable.\ni: This stands for “inheritable”, meaning this capability can be inherited by child processes created by the executable.\np: This stands for “permitted”, which means the capability is allowed for the executable. It’s a part of the set of capabilities that the executable is permitted to use.\n\n/usr/bin/python3.8: This is the path to the Python 3.8 executable. The command sets the specified capabilities on this specific file.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "RT Kernel on Jetson Nano"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/rtkernel/rtpatch.html#setting-script-specific-rt",
    "href": "content/projects/RLUnicycle/rtkernel/rtpatch.html#setting-script-specific-rt",
    "title": "RT Kernel on Jetson Nano",
    "section": "2.2 Setting Script Specific RT",
    "text": "2.2 Setting Script Specific RT\nThe ‘RT’ scheduling priority is code 99. Some imported C implementation allows for resetting the scheduling for the process. The function is wrapped in try/except block to ensure it activates.\n# Define constants for the scheduling policy\nSCHED_FIFO = 1  # FIFO real-time policy\n\nclass SchedParam(ctypes.Structure):\n    _fields_ = [('sched_priority', ctypes.c_int)]\n\ndef set_realtime_priority(priority=99):\n    libc = ctypes.CDLL('libc.so.6')\n    param = SchedParam(priority)\n    # Set the scheduling policy to FIFO and priority for the entire process (0 refers to the current process)\n    if libc.sched_setscheduler(0, SCHED_FIFO, ctypes.byref(param)) != 0:\n        raise ValueError(\"Failed to set real-time priority. Check permissions.\") \nWe run this function at the start of the script which will reassign the scheduling priority to the highest level. This can be verified to work by opening the system monitor and checking the priority of the script such as with htop.\n\n\n\nRT Priority Enabled",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "RT Kernel on Jetson Nano"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html",
    "title": "Dynamics and Control",
    "section": "",
    "text": "The following is a demonstration of the derivation for the equations of motion for a single degree of freedom reaction wheel inverted pendulum. The approach used is energy methods via the Lagrangian using classical mechanics.\nAn automated derivation sequence using MATLAB is presented, which allows for parsing the equations of motion for an arbitrary system such as a 4-DOF unicycle robot. The code for the auto-derivation has been tested by hand against known solutions in the literature, as explored by (Brevik 2017), (Montoya and Gil-González 2020).",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#mass-and-center-of-mass-measurements",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#mass-and-center-of-mass-measurements",
    "title": "Dynamics and Control",
    "section": "Mass and Center of Mass Measurements",
    "text": "Mass and Center of Mass Measurements\nThe mass and center of mass (CM) were measured using a lab scale and a balancing method, respectively.\n\nFlywheel: The wheel and rings mass (denoted as \\(m_w\\)) was measured to be 346g. The CM of the wheel from the pendulum hinge (denoted as \\(l_w\\)) is 180mm. This was measured in CAD and also with a ruler.\nPendulum and Motor: The combined mass of the pendulum and motor with stator (denoted as \\(m_p\\)) was measured to be 531g. The CM of the pendulum with motor and stator (denoted as \\(l_p\\)) is 100mm. The pendulum CM is found by balancing the apparatus with removed flywheel overtop of a fulcrum and finding the stable resting point position.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#inertia-calculations",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#inertia-calculations",
    "title": "Dynamics and Control",
    "section": "Inertia Calculations",
    "text": "Inertia Calculations\nThe moment of inertia for each component was calculated using the parallel axis theorem and the physical dimensions provided by CAD models and direct measurement.\n\nWheel Inertia\nThe wheel inertia (denoted as \\(I_w\\)) was found by comparing the CAD weight to the measured weight of the flywheel to find agreement: \\[I_w = 725\\ \\text{kg}\\cdot\\text{mm}^2\\] In particular the metal rings were weighed and set to be the same weight in CAD which is the most influential part of the moment in question.\n\n\nPendulum Inertia\nThe pendulum moment of inertia (denoted as \\(I_p\\)) is a composite value derived from the inertia of individual components:\n\nBattery: The battery contributes an inertia of: \\[I_{\\text{battery}} = \\frac{1}{12} \\cdot 0.185 \\cdot (70^2 + 35^2) + 0.185 \\cdot 50^2 = 446\\ \\text{kg}\\cdot\\text{mm}^2\\]\nPendulum Arm: The corrected inertia for the pendulum arm is: \\[I_{\\text{arm}} = 346\\ \\text{kg}\\cdot\\text{mm}^2 + 0.102 \\cdot 45^2 = 552\\ \\text{kg}\\cdot\\text{mm}^2\\]\nMotor and Mount: The combined inertia for the motor and mount is: \\[I_{\\text{motor}} = 0.5 \\cdot 0.206 \\cdot 30^2 + 0.206 \\cdot 75^2 = 1251.75\\ \\text{kg}\\cdot\\text{mm}^2\\]\n\nThe total pendulum inertia is then calculated as the sum of the components: \\[I_p = I_{\\text{battery}} + I_{\\text{arm}} + I_{\\text{motor}} = 2250\\ \\text{kg}\\cdot\\text{mm}^2\\]",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#kinetic-energy",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#kinetic-energy",
    "title": "Dynamics and Control",
    "section": "Kinetic Energy",
    "text": "Kinetic Energy\n\\[\\begin{aligned}\nT &= T_p+T_w \\\\\nT_p &= \\frac{1}{2}(\\underbrace{I_p + m_pl_p^2}_{\\text{Parallel Axis Theorem}})\\dot{\\varphi}^2\\\\\nT_w&=\\frac{1}{2}m_w(\\underbrace{l_w\\dot{\\varphi}}_{\\text{Speed of CM}})^2 +  \\frac{1}{2}I_w(\\underbrace{\\dot{\\varphi}+\\dot{\\theta}}_{\\text{net rotation earth frame}})^2\\\\\nT_{net} &= \\frac{1}{2} \\left(I_p + m_p l_p^2 + I_w + m_w l_w^2\\right) \\dot{\\varphi}^2 + \\frac{1}{2} I_w (\\dot{\\varphi} + \\dot{\\theta})^2 \\\\\n&= \\frac{1}{2} \\left(I_p + m_p l_p^2\\right) \\dot{\\varphi}^2 + \\frac{1}{2} I_w \\left(\\dot{\\varphi}^2 + 2\\dot{\\varphi}\\dot{\\theta} + \\dot{\\theta}^2\\right)\\\\\nT_{net}&=\\frac{1}{2} [\\dot{\\varphi}, \\dot{\\theta}] \\begin{bmatrix}\n    I_p + m_pl_p^2 + I_w + m_wl_w^2 & I_w \\\\\n    I_w & I_w\n\\end{bmatrix} \\begin{bmatrix}\n    \\dot{\\varphi} \\\\\n\\dot{\\theta}\n\\end{bmatrix}\n\\end{aligned}\\]\nThis gives the form using the inertia matrix M, note the matrix is always symmetric.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#potential-energy",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#potential-energy",
    "title": "Dynamics and Control",
    "section": "Potential Energy",
    "text": "Potential Energy\nThe potential energy is taken by projecting the position of the center of masses onto the vertical axis using \\(\\cos(\\varphi)\\), noting that the angle \\(\\theta\\) has no impact on the potential since the wheel is radially symmetric. \\[U = (m_pl_p + m_wl_w)g \\cos (\\varphi) = m_0 \\cos (\\varphi)\\] We can simplify future equations by assigning an equivalent variable \\(m_0 = (m_p l_p + m_w l_w)g\\)\nThis gives the complete Lagrangian \\[\\mathcal{L}(\\varphi,\\theta,\\dot \\varphi,\\dot \\theta)= KE - PE = \\frac{1}{2}\\mathbf{\\dot q}^{T}\\mathbf{M}\\mathbf{\\dot q}-m_0cos(\\varphi)\\]",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#matlab-derivation",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#matlab-derivation",
    "title": "Dynamics and Control",
    "section": "Matlab Derivation",
    "text": "Matlab Derivation\nThe required files to run this code are included at https://github.com/Team-2411-RL-Unicycle/pid-control The automated E-L solver uses a modified version of a file made by (Veng 2023). It is incorporated into the RWIPpid_derivation.m file. The derivation technique is validated against the equations derived by (Brevik 2017).\nThe first step is to define symbolic variables for all of the parameters, states, and inputs\nsyms mp lp Ip mw lw Iw real\nparams = [mp, lp, Ip, mw, lw, Iw];\n% Define numerical values for the parameters\nvalues = [.531, 0.100, 0.002250, .346, 0.180, 0.000725];\ng=9.81;\n% State variables\nsyms phi theta dphi dtheta real\nq = [phi, theta];\ndq = [dphi, dtheta];\n% Input\nsyms tau real\n\n% Potential energy mass\nm0 = (mp*lp + mw*lw)*g; % Effective U=mgh for combined parts\n% Mass matrix\nM = [(Ip + mp*lp^2 + Iw +mw*lw^2), Iw;\n    Iw, Iw];\nlagrangian = (1/2)*([dphi, dtheta])*M*([dphi, dtheta]') - m0 * cos(phi);\n% Non-conservative forces in each coordinate q\nQ = [0, tau];\nThe Lagrangian and its non-conservative forces are fully defined now. The equations are solved using the modified imported library and the solution equations for each second time derivative is solved giving \\(\\frac{d}{dt}\\dot{q}\\), these solutions can be packed into a single array to form a matrix.\n[eqs, ddq] = EulerLagrange(q,dq,lagrangian,Q);\n% Explicit equations:\nexp_eqs = ddq == eqs;\n% Solve equations to isolate ddphi and ddtheta\nddqSolutions = solve(ddq == eqs, ddq);\n% Convert solutions to cell array\nddqSolutionEquations = struct2cell(ddqSolutions) ;\nddqArray = [ddqSolutionEquations{:}].';",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#derived-equations-of-motion",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#derived-equations-of-motion",
    "title": "Dynamics and Control",
    "section": "Derived Equations of Motion",
    "text": "Derived Equations of Motion\nOnce we have \\(n\\) 2nd order ODEs for \\(n\\) general coordinates and their \\(n\\) general time derivatives we have enough to make a first order system of ODEs that characterize the system. The time-domain non-linearized result from the derivation is given below.\n\\[\\frac{d}{dt}\\vec{x} = \\vec{G}(\\vec{x}, t) = \\begin{bmatrix}\nd\\varphi \\\\\nd\\theta \\\\\n\\frac{g_0 l_p m_p \\sin(\\phi) - \\tau + g_0 l_w m_w \\sin(\\phi)}{m_p l_p^2 + m_w l_w^2 + I_p} \\\\\n\\frac{m_p \\tau l_p^2 - I_w g_0 m_p \\sin(\\phi) l_p + m_w \\tau l_w^2 - I_w g_0 m_w \\sin(\\phi) l_w + I_p \\tau + I_w \\tau}{I_w (m_p l_p^2 + m_w l_w^2 + I_p)}\n\\end{bmatrix}, \\quad x = \\begin{bmatrix}\n\\varphi \\\\ \\theta \\\\ \\dot{\\varphi} \\\\ \\dot{\\theta}\n\\end{bmatrix}\\]\nNote that there is no explicit time dependence in the function \\(G\\) the inverted pendulum dynamics and rigid body characteristics are constant over time. From inspection of the solutions we see that \\(\\theta\\), the angle of the wheel does not play a role in the function \\(G\\) and can be removed entirely if desired.\nThese system dynamics can be used to create a time-domain non-linear simulation using Euler’s method to get numerical solutions. Friction can be added as a damping coefficient \\(\\beta\\) such that we superimpose \\(\\ddot{\\varphi} = - \\beta \\dot{\\varphi}\\) onto the solution for example.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#linearization",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#linearization",
    "title": "Dynamics and Control",
    "section": "Linearization",
    "text": "Linearization\nWe wish to convert \\[\\vec{G}(\\vec{x}, t) \\approx Ax + Bu\\] via linearization about the operating point. We choose the upright position as the target and note that \\(\\varphi\\) is the only variable present in \\(G\\). \\(\\hat{\\vec{x}}=0\\) is the chosen linearization point:\n\\[\\frac{d}{dt}\\vec{x} \\approx \\hat{\\vec{x}} + \\left. \\text{Jacobian}\\{\\vec{G}(\\vec{x}, t)\\} \\right|_{\\vec{x}=\\hat{\\vec{x}}} (\\vec{x}-\\hat{\\vec{x}}) = \\left. \\Big(A\\Big) \\right|_{\\vec{x}=\\hat{\\vec{x}}} \\vec{x}\\]\nWe perform a similar linearization to get the effect of the system inputs by taking the Jacobian with respect to \\(\\tau\\). The two combined give the cannonical \\(\\frac{d}{dt}x = Ax + Bu\\) of controls engineering. The final step is to take the Laplace transform of the entire equation and then solve for the transfer function between the system inputs \\(u\\) or in this case \\(\\tau\\) and the observables we want (mainly the system state \\(x\\)) but this generalizes to any observable that is a function of \\(x\\) and \\(u\\)\nState Vector \\[{\\mathbf{x}} =\n\\begin{bmatrix}\n    x_1 \\\\\n    x_2 \\\\\n    \\vdots\n\\end{bmatrix}\\] Input Vector \\[{\\mathbf{u}} =\n\\begin{bmatrix}\n    u_1 \\\\\n    u_2 \\\\\n    \\vdots\n\\end{bmatrix}\\] Output Vector \\[{\\mathbf{y}} =\n\\begin{bmatrix}\n    y_1 \\\\\n    y_2 \\\\\n    \\vdots\n\\end{bmatrix}\\]\nState Equation \\[\\dot{\\mathbf{x}} =\n\\begin{bmatrix}\n    \\dot{x}_1 \\\\\n    \\dot{x}_2 \\\\\n    \\vdots\n\\end{bmatrix}\n= \\mathbf{A}{\\mathbf{x}} + \\mathbf{B}{\\mathbf{u}}\\] Output Equation \\[{\\mathbf{y}} = \\mathbf{C}{\\mathbf{x}} + \\mathbf{D}{\\mathbf{u}}\\]\nState Transition Matrix \\[\\mathbf{\\Phi} = (s\\mathbf{I} - \\mathbf{A})^{-1}\\] Transfer Functions \\[\\frac{{\\mathbf{y}}}{{\\mathbf{u}}} = \\mathbf{C}\\mathbf{\\Phi}\\mathbf{B} + \\mathbf{D}\\]\nWe solve for the transfer matrix \\(y = Gu\\) at \\(x=0\\), noting that in our case \\(y=x\\)",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#matlab-derivation-1",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#matlab-derivation-1",
    "title": "Dynamics and Control",
    "section": "MATLAB Derivation",
    "text": "MATLAB Derivation\n% Phi, dPhi, dTheta\nX = [q(1)' ; dq']\n% The inputs are non-zero entries of Q (non-conservative forces)\nU = Q(Q ~= 0);\n% Vector functionn for the derivative of the state vector\ndX = [dphi; ddqArray]\n\n% Compute the Jacobian matrices to get nonlinear state matrices dX = Ax + Bu\nA = jacobian(dX, X);\nB = jacobian(dX, U);\n\n% Substitute or linearize about an equilibrium point\n% Define equilibrium point (for example, all zeros)\nx0 = [0; 0; 0];\n% Substitute equilibrium values x0 into A and B\nAeq = subs(A, X, x0)\nBeq = subs(B, X, x0)\n\n% U to X transfer function\n% dX = Ax + Bu implies  sX = Ax + Bu, solve for x = Gtf*u\nsyms s\nGtf = (s*eye(length(X)) - Aeq)^(-1)*Beq",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#system-transfer-function",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#system-transfer-function",
    "title": "Dynamics and Control",
    "section": "System Transfer Function",
    "text": "System Transfer Function\n\\[\\begin{pmatrix}\n\\varphi(s)\\\\\n\\dot{\\varphi}(s)\\\\\n\\dot\\theta(s)\n\\end{pmatrix}=\n\\begin{pmatrix}\n-\\frac{1}{{m_p l_p^2 s^2 - g_0 m_p l_p + m_w l_w^2 s^2 - g_0 m_w l_w + I_p s^2}} \\\\\n-\\frac{s}{{m_p l_p^2 s^2 - g_0 m_p l_p + m_w l_w^2 s^2 - g_0 m_w l_w + I_p s^2}} \\\\\n\\frac{{m_p l_p^2 + m_w l_w^2 + I_p + I_w}}{{I_w s (m_p l_p^2 + m_w l_w^2 + I_p)}} + \\frac{{g_0 l_p m_p + g_0 l_w m_w}}{{s (m_p l_p^2 + m_w l_w^2 + I_p)(m_p l_p^2 s^2 - g_0 m_p l_p + m_w l_w^2 s^2 - g_0 m_w l_w + I_p s^2)}}\n\\end{pmatrix}\n\\tau(s)\\]\nWe note that for our control problem we are trying to control the angle \\(\\varphi\\) using torque, so the function of interest is the upper row equation:\n\\[\\varphi(s) = \\Big(-\\frac{1}{{m_p l_p^2 s^2 - g_0 m_p l_p + m_w l_w^2 s^2 - g_0 m_w l_w + I_p s^2}}\\Big) \\tau(s)\\]\nOr rearranging we see that we have function of the form \\(\\frac{1}{s^2+a^2}\\): \\[\\varphi(s) = \\left(-\\frac{1}{s^2(m_p l_p^2 + m_w l_w^2 + I_p) - m_0}\\right) \\tau(s)\\]\nThis is a function with one pole in the RH plane making it unstable.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#pd-controller-for-pendulum-angle",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#pd-controller-for-pendulum-angle",
    "title": "Dynamics and Control",
    "section": "PD Controller for Pendulum Angle",
    "text": "PD Controller for Pendulum Angle\nThe PD Controller for \\(\\varphi\\) is tuned using the assumption that the torque requests have little delay before reaching the intended value. This is because the motor controller is running at 100 times faster than the main control loop frequency of 100Hz. Thus we model the feedback loop of Controller -&gt; \\(G(s)\\) -&gt; \\(H(s)\\) Sensor Fusion. The sensor fusion and torque request mechanism are modeled as a delay of one \\(100Hz\\) control cycle.\nA PD controller is selected because of the dynamic setpoint that is being controlled by the cascade arrangement. If we were to include an I term then the controller would not be memoryless and would have undesirable response characteristics to the dynamic \\(\\varphi\\) setpoint being requested by the higher level controller. The PD control model is a robust choice for a controller for this robot state parameter, (Brevik 2017).\nThe MATLAB pid tuner is used to get feasible starting values based on this loop. The experimental parameters applied to the robot were found to closely match the predicted values.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#pi-controller-for-wheel-velocity",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#pi-controller-for-wheel-velocity",
    "title": "Dynamics and Control",
    "section": "PI Controller for Wheel Velocity",
    "text": "PI Controller for Wheel Velocity\nThe PI controller is tuned heuristically once a good underlying PD controller for the angle is found. A starting value of around \\(K_p = 0.1\\) was found to be helpful. Blending of integral term with a corresponding reduction of \\(P\\) is one approach to further tuning.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/eosc555/lectures/project/index.html",
    "href": "content/eosc555/lectures/project/index.html",
    "title": "Project Work 1",
    "section": "",
    "text": "$$ \n$$"
  },
  {
    "objectID": "content/eosc555/lectures/project/index.html#motivation",
    "href": "content/eosc555/lectures/project/index.html#motivation",
    "title": "Project Work 1",
    "section": "Motivation",
    "text": "Motivation\nGeomagnetic inversion from recovered magnetic readings above ground is a classic problem in geophysics. Much of the data that we have about subsurface geology must be collected via indirect methods such as magnetic and seismic surveys, or sparse sampling via boreholes. The data can be expensive to collect, where the objective is to detect underground structures such as ore bodies, oil and gas deposits, or aquifers. The goal is to recover a 3D distribution of some of the physical properties of the Earth from the incomplete data, a non-linear and ill-posed problem.\nThis project explores the use of machine learning and optimization techniques to attempt an inversion of the data, using electromagnetic equations to model the propogation of the Earth’s magnetic field through the subsurface on a known data set. The goal is to develop a model that can take the forward problem data and invert it to recover the true starting distribution.\n\nBackground\nA background on the magnetic principles that underpin the problem can be found at Geophysics for Practicing Geophysicists.\nThe subsurface of the Earth is composed of materials with differences in magnetic susceptibility \\(\\chi\\) and conductivity \\(\\sigma\\). The magnetic susceptibility relates a material’s magnetization \\(M\\) to the magnetic field \\(H\\) via the equation \\(M = \\chi H\\). When the magnetic field of the Earth passes through this material it creates a magnetization response, causing small magnetic anomolies that can be measured above ground. The magnetic field passing through the subsurface is assumed to be uniform and known over the survey area.\nThe magnetization effect can be calculated by integrating the magnetic effect over each infinetesimally small volume of the subsurface, since the total effect will be the sum of the parts, similar to analysing electric fields from charge distributions. It is easier to first calculate the magnetic potential and then take the curl to get the field:\n\\[\\mathbf{B}(r) = \\nabla \\times \\mathbf{A}(r) \\] \\[\\mathbf{A}(r) = \\frac{\\mu_0}{4\\pi} \\int_V \\mathbf{M}(r') \\frac{1}{|\\mathbf{r} - \\mathbf{r'}|} dV'\\]\nwhere \\(\\mathbf{B}\\) is the magnetic field, \\(\\mathbf{A}\\) is the magnetic potential, \\(\\mathbf{M}\\) is the magnetization, and \\(\\mu_0\\) is the magnetic permeability of free space. The equations above are for the case where there are no free currents, which is a good assumption to make for the Earth’s subsurface.\nThe integral is of the form of a convolution with the kernel \\(\\frac{1}{|\\mathbf{r} - \\mathbf{r'}|}\\), which can be computed using the Fast Fourier Transform (FFT) to speed up the computation. The operation \\(\\mathbf{B}(r) = \\nabla \\times \\mathbf{A}(r)\\) can also be carried through into the integral since it is a linear operator.\nUsing all of the above information yields the integral equation that is dependent on the magnetic susceptibility \\(\\chi\\) and the magnetic field \\(\\mathbf{H}_0\\):\n\\[ \\mathbf{B}_A(\\mathbf{r}) = \\frac{\\mu_0}{4\\pi} \\int_V \\chi(\\mathbf{r'}) \\mathbf{H}_0 \\cdot \\nabla^2 \\left( \\frac{1}{|\\mathbf{r} - \\mathbf{r'}|} \\right) dV' \\]\nThe resulting magnetic field anomaly \\(\\mathbf{B}_A\\) is projected onto the direction of the magnetic field \\(\\mathbf{H}_0\\) to get the observed anomaly in magnetic field strength at any point above the Earth’s surface in the forward model. For survey work, the probed field is usually measured over a planar surface above the ground, forming a 2D image.\nSee Geophysics for Practicing Geophysicists for more images and interactive examples."
  },
  {
    "objectID": "content/eosc555/lectures/project/index.html#coding-the-forward-model",
    "href": "content/eosc555/lectures/project/index.html#coding-the-forward-model",
    "title": "Project Work 1",
    "section": "Coding the Forward Model",
    "text": "Coding the Forward Model\nThe model is programmed into the Magnetics class below. Note that the FFT is used to speed up the computation of the convolution integral. An explicit adjoint operation is defined to speed up the process of inverting data when using techniques that make use of it.\n\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom scipy.constants import mu_0\n    \nclass Magnetics(nn.Module):\n    \"\"\"\n    A PyTorch module to perform forward and adjoint computations for magnetic inversion problems.\n    \"\"\"\n    def __init__(self, dim, h, dirs, device='cpu'):\n        \"\"\"\n        Initialize the Magnetics module.\n\n        Parameters:\n            dim (list or tuple): Mesh dimensions [nx, ny, nz].\n            h (list or tuple): Cell sizes [dx, dy, dz].\n            dirs (list or tuple): Magnetic field directions [I, A, I0, A0] in radians.\n                                  I  - Magnetization dip angle\n                                  A  - Magnetization declination angle\n                                  I0 - Geomagnetic dip angle\n                                  A0 - Geomagnetic declination angle\n            device (str): Device to perform computations ('cpu' or 'cuda').\n        \"\"\"\n        super(Magnetics, self).__init__()\n        self.dim = dim\n        self.h = h\n        self.dirs = dirs\n        self.device = device\n\n        # Compute the scaling factor\n        dV = torch.prod(self.h.clone().detach())\n        mu_0 = 1.0  # Magnetic permeability (set to 1 for simplicity)\n        zeta = mu_0 / (4 * np.pi)\n        self.mudV = zeta * dV\n\n    def fft_kernel(self, P, center):\n        \"\"\"\n        Compute the 2D shifted FFT of the kernel P.\n\n        Parameters:\n            P (torch.Tensor): The point spread function (PSF) kernel.\n            center (list): Center indices for fftshift.\n\n        Returns:\n            torch.Tensor: The shifted FFT of P.\n        \"\"\"\n        # Shift the kernel for FFT operations\n        S = torch.roll(P, shifts=center, dims=[0, 1])\n        S = torch.fft.fftshift(S)\n        # Compute the 2D FFT\n        S = torch.fft.fft2(S)\n        # Shift the quadrants back\n        S = torch.fft.fftshift(S)\n        return S\n\n    def forward(self, M, height=0):\n        \"\"\"\n        Perform the forward computation using FFT.\n\n        Parameters:\n            M (torch.Tensor): The magnetization model tensor of shape B,C,X,Y,Z.\n\n        Returns:\n            torch.Tensor: The computed magnetic data.\n        \"\"\"\n        dz = self.h[2]\n        z = height + dz / 2  # Starting depth\n\n        data = 0  # Initialize the data\n\n        # Loop through each layer in the z-direction\n        for i in range(M.shape[-1]):\n            # Extract the i-th layer of the model\n            m_layer = M[..., i].to(self.device)\n\n            # Compute the point spread function (PSF) for the current layer\n            psf, center, _ = self.psf_layer(z)\n\n            # Compute the FFT of the PSF kernel\n            s_fft = self.fft_kernel(psf, center)\n\n            # Compute the FFT of the model layer\n            m_fft = torch.fft.fftshift(m_layer)\n            m_fft = torch.fft.fft2(m_fft)\n            m_fft = torch.fft.fftshift(m_fft)\n\n            # Perform the convolution in the frequency domain\n            b_fft = s_fft * m_fft\n            b_fft = torch.fft.fftshift(b_fft)\n\n            # Convert back to the spatial domain\n            b_spatial = torch.real(torch.fft.ifft2(b_fft))\n\n            # Accumulate the data from each layer\n            data += b_spatial\n\n            # Update depth\n            z += dz\n\n        return self.mudV * data\n\n    def adjoint(self, data, height=0):\n        \"\"\"\n        Perform the adjoint operation.\n\n        Parameters:\n            data (torch.Tensor): The observed magnetic data tensor.\n\n        Returns:\n            torch.Tensor: The adjoint result (model update).\n        \"\"\"\n        dz = self.h[2]\n        z = height + dz / 2  # Starting depth\n\n        # Initialize the result tensor\n        m_adj = torch.zeros(\n            1, 1, self.dim[0], self.dim[1], self.dim[2], device=self.device\n        )\n\n        for i in range(self.dim[2]):\n            # Compute the PSF for the current layer\n            psf, center, _ = self.psf_layer(z)\n\n            # Compute the FFT of the PSF kernel\n            s_fft = self.fft_kernel(psf, center)\n\n            # Compute the FFT of the input data\n            data_fft = torch.fft.fft2(data)\n            data_fft = torch.fft.fftshift(data_fft)\n\n            # Perform the adjoint operation in the frequency domain\n            b_fft = torch.conj(s_fft) * data_fft\n\n            # Convert back to the spatial domain\n            b_spatial = torch.fft.fftshift(b_fft)\n            b_spatial = torch.real(torch.fft.ifft2(b_spatial))\n            b_spatial = torch.fft.fftshift(b_spatial)\n\n            # Store the result for the current layer\n            m_adj[..., i] = b_spatial\n\n            # Update depth\n            z += dz\n\n        return self.mudV * m_adj\n\n    def psf_layer(self, z):\n        \"\"\"\n        Compute the point spread function (PSF) for a layer at depth z.\n\n        Parameters:\n            z (float): The depth of the layer.\n\n        Returns:\n            psf (torch.Tensor): The computed PSF.\n            center (list): Center indices for fftshift.\n            rf (torch.Tensor): The radial factor (unused but computed for completeness).\n        \"\"\"\n        # Unpack magnetic field directions\n        I, A, I0, A0 = self.dirs  # Dip and declination angles for magnetization and geomagnetic field\n\n        # Compute half-dimensions\n        nx2, ny2 = self.dim[0] // 2, self.dim[1] // 2\n\n        dx, dy = self.h[0], self.h[1]\n\n        # Create coordinate grids\n        x = dx * torch.arange(-nx2 + 1, nx2 + 1, device=self.device)\n        y = dy * torch.arange(-ny2 + 1, ny2 + 1, device=self.device)\n        X, Y = torch.meshgrid(x, y, indexing='ij')\n\n        # Center indices for fftshift\n        center = [1 - nx2, 1 - ny2]\n\n        # Compute the radial factor\n        rf = (X**2 + Y**2 + z**2) ** 2.5\n\n        # Compute components of the PSF\n        cos_I = torch.cos(I)\n        sin_I = torch.sin(I)\n        cos_A = torch.cos(A)\n        sin_A = torch.sin(A)\n        cos_I0 = torch.cos(I0)\n        sin_I0 = torch.sin(I0)\n        cos_A0 = torch.cos(A0)\n        sin_A0 = torch.sin(A0)\n\n        PSFx = ((2 * X**2 - Y**2 - z**2) * cos_I * sin_A +\n                3 * X * Y * cos_I * cos_A +\n                3 * X * z * sin_I) / rf\n\n        PSFy = (3 * X * Y * cos_I * sin_A +\n                (2 * Y**2 - X**2 - z**2) * cos_I * cos_A +\n                3 * Y * z * sin_I) / rf\n\n        PSFz = (3 * X * z * cos_I * sin_A +\n                3 * Y * z * cos_I * cos_A +\n                (2 * z**2 - X**2 - Y**2) * sin_I) / rf\n\n        # Combine components to get the total PSF\n        psf = (PSFx * cos_I0 * cos_A0 +\n               PSFy * cos_I0 * sin_A0 +\n               PSFz * sin_I0)\n\n        return psf, center, rf\n\nTo test the forward and adjoint operations we can apply a standard adjoint test. This is always a good policy when implementing new operators to determine if there are any issues with the code. We expect that \\[ \\langle A(X), Q \\rangle = \\langle X, A^*(Q) \\rangle \\]\nwhere \\(A\\) is the forward operator and \\(A^*\\) is the adjoint operator. The code below performs the adjoint test for the forward model defined above.\n\n\nShow the code\nimport pyvista as pv\npv.set_jupyter_backend(\"static\")\n\ndef adjoint_test(op, adj, arg):\n    \"\"\"\n    Adjoint test for a given operator.\n\n    Parameters:\n        op (callable): Forward operator.\n        adj (callable): Adjoint operator.\n        arg (torch.Tensor): Input to the forward operator.\n    \"\"\"\n\n    X = arg\n    D = op(X)\n    Q = torch.rand_like(D)\n\n    # Compute the inner product &lt;A(X), Q&gt;\n    inner_prod1 = torch.sum(D * Q)\n\n    # Compute the inner product &lt;X, adj(Q)&gt;\n    W = adj(Q)\n    inner_prod2 = torch.sum(X * W)\n\n    print(\"Adjoint test:\", inner_prod1.item(), inner_prod2.item())\n\n\n# Set a magnetics model\ndx, dy, dz = 100.0, 100.0, 100.0\nn1, n2, n3 = 256, 256, 128\ndim = torch.tensor([n1, n2, n3])\nh = torch.tensor([dx, dy, dz])\ndirs = torch.tensor([np.pi / 2, np.pi / 2, np.pi / 2, np.pi / 2])\nforMod = Magnetics(dim, h, dirs)\n\n# set the magnetization of the material\nM = torch.zeros(*dim)\nM[120:140, 120:140, 20:40] = 0.3\nM[20:40, 20:40, 10:20] = 0.1\n\nM = M.unsqueeze(0).unsqueeze(0)\nadjoint_test(forMod.forward, forMod.adjoint, M)  \n\n\nAdjoint test: 4.638533115386963 4.638533592224121"
  },
  {
    "objectID": "content/eosc555/lectures/project/index.html#plotting-the-model",
    "href": "content/eosc555/lectures/project/index.html#plotting-the-model",
    "title": "Project Work 1",
    "section": "Plotting the Model",
    "text": "Plotting the Model\nA simple toy dataset was used to test the adjoint opearation. It is very helpful to have a set of visualization tools to verify the input and output data against expected values. A library of commands that make use of Pyvista are provided below.\n\n\nShow the code\ndef plot_model_2d(M, n_slices=None, cmap=\"rainbow\", figsize=(12, 6)):\n    \"\"\"\n    Plot an array of 2D slices for a given 3D tensor in a single grid-style plot.\n    \n    Parameters:\n    - M (torch.Tensor): 3D tensor representing the model (e.g., [x, y, z]).\n    - n_slices (int, optional): Number of slices to plot. Defaults to all slices.\n    - cmap (str): Colormap for the plot.\n    - figsize (tuple): Size of the figure.\n\n    Returns:\n    - matplotlib.figure.Figure: The created figure.\n    \"\"\"\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    # Dimensions of the 3D tensor\n    nx, ny, nz = M.shape[-3], M.shape[-2], M.shape[-1]\n    \n    # Determine the number of slices\n    if n_slices is None:\n        n_slices = nz\n    else:\n        n_slices = min(n_slices, nz)\n    \n    # Determine the grid shape (rows and columns)\n    ncols = int(np.ceil(np.sqrt(n_slices)))\n    nrows = int(np.ceil(n_slices / ncols))\n\n    # Create a blank canvas for the grid plot\n    grid = torch.zeros((nrows * nx, ncols * ny), dtype=M.dtype, device=M.device)\n    \n    # Fill the grid with slices\n    slice_idx = 0\n    for i in range(nrows):\n        for j in range(ncols):\n            if slice_idx &lt; n_slices:\n                grid[i * nx:(i + 1) * nx, j * ny:(j + 1) * ny] = M[..., slice_idx]\n                slice_idx += 1\n\n    # Plot the grid\n    fig = plt.figure(figsize=figsize)\n    plt.imshow(grid.cpu().detach().numpy(), cmap=cmap)\n    plt.colorbar()\n    plt.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\ndef plot_model(M, plotter = None, threshold_value=0.05):\n    \"\"\"\n    Plot the magnetization model with an outline showing the overall bounds.\n    \n    Parameters:\n        M (torch.Tensor): Magnetization model tensor of shape [B, C, X, Y, Z] or [X, Y, Z].\n        threshold_value (float): Threshold value for magnetization to visualize.\n    \"\"\"\n    \n    if plotter is None:\n        plotter = pv.Plotter()\n    \n    # Remove unnecessary dimensions if present\n    M = torch.squeeze(M)\n    \n    # Convert the PyTorch tensor to a NumPy array\n    m_plot = M.detach().cpu().numpy()\n    \n    # Define grid parameters\n    spacing = (1.0, 1.0, 1.0)  \n    origin = (0.0, 0.0, 0.0)   \n    \n    # Create a PyVista Uniform Grid (ImageData)\n    grid = pv.ImageData()\n    \n    # Set grid dimensions (number of points = cells + 1)\n    grid.dimensions = np.array(m_plot.shape) + 1\n    grid.spacing = spacing\n    grid.origin = origin\n    \n    # Assign magnetization data to cell data\n    grid.cell_data[\"M\"] = m_plot.flatten(order=\"F\")\n    \n    # Apply threshold to isolate regions with M &gt; threshold_value\n    thresholded = grid.threshold(value=threshold_value, scalars=\"M\")\n    \n    # Create an outline of the entire grid\n    outline = grid.outline()\n        \n    # Add the thresholded mesh\n    plotter.add_mesh(thresholded, cmap = \"rainbow\", opacity=0.5, show_edges=True, label='Magnetization &gt; {:.2f}'.format(threshold_value))\n    \n    # Add the outline mesh\n    plotter.add_mesh(outline, color=\"black\", line_width=2, label='Model Bounds')\n    \n    # Optionally, add axes and a legend for better context\n    plotter.add_axes()\n    plotter.add_legend()\n    \n    # Set camera position for better visualization (optional)\n    plotter.view_isometric()\n    \n    return plotter\n\ndef plot_model_with_slider(M):\n    \"\"\"\n    Plot the magnetization model with an interactive slider for threshold value.\n\n    Parameters:\n        M (torch.Tensor): Magnetization model tensor of shape [B, C, X, Y, Z] or [X, Y, Z].\n    \"\"\"\n\n    # Remove unnecessary dimensions if present\n    M = torch.squeeze(M)\n\n    # Convert the PyTorch tensor to a NumPy array\n    m_plot = M.detach().cpu().numpy()\n\n    # Define grid parameters\n    spacing = (1.0, 1.0, 1.0)  \n    origin = (0.0, 0.0, 0.0)   \n\n    # Create a PyVista Uniform Grid (ImageData)\n    grid = pv.ImageData()\n\n    # Set grid dimensions (number of points = cells + 1)\n    grid.dimensions = np.array(m_plot.shape) + 1\n    grid.spacing = spacing\n    grid.origin = origin\n\n    # Assign magnetization data to cell data\n    grid.cell_data[\"M\"] = m_plot.flatten(order=\"F\")\n\n    # Create an outline of the entire grid\n    outline = grid.outline()\n\n    # Create a PyVista plotter\n    plotter = pv.Plotter()\n    plotter.add_mesh(outline, color=\"black\", line_width=2, label='Model Bounds')\n\n    # Add axes and a legend\n    plotter.add_axes()\n    plotter.add_legend()\n\n    # Set camera position for better visualization\n    plotter.view_isometric()\n\n    # Define a callback function for the slider\n    def threshold_callback(value):\n        # Remove previous thresholded mesh if exists\n        if 'thresholded' in plotter.actors:\n            plotter.remove_actor('thresholded')\n        # Apply threshold to isolate regions with M &gt; value\n        thresholded = grid.threshold(value=float(value), scalars=\"M\")\n        # Add the thresholded mesh\n        plotter.add_mesh(thresholded, name='thresholded', cmap=\"rainbow\", opacity=0.5, show_edges=True, label=f'Magnetization &gt; {value:.2f}')\n        plotter.render()\n\n    # Initial threshold value\n    initial_threshold = 0.05\n\n    # Apply initial threshold and plot\n    thresholded = grid.threshold(value=initial_threshold, scalars=\"M\")\n    plotter.add_mesh(thresholded, name='thresholded', cmap=\"rainbow\", opacity=0.5, show_edges=True, label=f'Magnetization &gt; {initial_threshold:.2f}')\n\n    # Add the slider widget\n    plotter.add_slider_widget(\n        threshold_callback,\n        [0.0, np.max(m_plot)],\n        value=initial_threshold,\n        title='Threshold Value',\n        pointa=(0.025, 0.1),\n        pointb=(0.225, 0.1),\n        style='modern',\n    )\n\n    # Show the plot\n    plotter.show()\n\ndef plot_model_with_forward(\n    mag_data,\n    forward_data,\n    spacing=(1.0, 1.0, 1.0),\n    height=0,\n    zoom=1.0,\n    plotter=None,\n    threshold_value=0.05,\n):\n    if plotter is None:\n        plotter = pv.Plotter()\n\n    # Remove unnecessary dimensions if present\n    M = mag_data.squeeze()\n    M = M.cpu().numpy()\n    D = forward_data.squeeze().cpu().numpy()\n\n    # Define grid parameters XYZ spacing\n    origin = (0.0, 0.0, 0.0)\n\n    # Create a PyVista Uniform Grid (ImageData) for the 3D volume\n    grid = pv.ImageData()\n\n    # Set grid dimensions (number of points = cells + 1)\n    grid.dimensions = np.array(M.shape) + 1\n    grid.spacing = spacing\n    grid.origin = origin\n\n    # Assign magnetization data to cell data\n    grid.cell_data[\"M\"] = M.flatten(order=\"F\")\n\n    # Apply threshold to isolate regions with M &gt; threshold_value\n    thresholded = grid.threshold(value=threshold_value, scalars=\"M\").flip_z()\n    outline = grid.outline()\n\n    # Add the thresholded mesh\n    plotter.add_mesh(\n        thresholded,\n        cmap=\"rainbow\",\n        opacity=0.7,\n        show_edges=True,\n        label=\"Magnetization &gt; {:.2f}\".format(threshold_value),\n    )\n\n    # Add the outline mesh\n    plotter.add_mesh(outline, color=\"black\", line_width=2, label=\"Model Bounds\")\n\n    # Create a structured grid for the 2D surface data\n    nx, ny = D.shape\n    x = np.linspace(0, nx * spacing[0], nx)\n    y = np.linspace(0, ny * spacing[1], ny)\n    X, Y = np.meshgrid(x, y)\n    Z = np.full_like(X, -height)  # Position the surface above the volume\n\n    # Create a PyVista mesh for the 2D surface\n    surface_mesh = pv.StructuredGrid(X, Y, Z)\n    surface_mesh.point_data[\"Forward Data\"] = D.flatten(order=\"F\")\n\n    # Add the 2D surface to the plotter\n    plotter.add_mesh(\n        surface_mesh,\n        cmap=\"coolwarm\",\n        show_edges=False,\n        opacity=0.3,\n        label=\"Forward Problem Data\",\n    )\n\n    # Add axes and a legend\n    plotter.add_axes()\n    plotter.add_legend()\n    plotter.camera_position = [\n        (-54507.19712327622, -49446.175185560685, -53221.11813207309),\n        (128.0, 128.0, 64.0),\n        (0.44554389292076074, 0.38017371952961604, -0.8105298158982375),\n    ]\n\n    # Adjust the zoom to fit data in window\n    plotter.camera.zoom(zoom)\n\n\n    return plotter\n\n\n\np = pv.Plotter()\nD = forMod(M)\nD = D.squeeze()\np = plot_model_with_forward(M, D, h, height=0, plotter=p)\noutput_file = \"imgs/magnetic_inversion_plot.png\"\np.show(screenshot=output_file)\n\n\n\n\nA simple model and forward data."
  },
  {
    "objectID": "content/eosc555/lectures/project/index.html#inverting-the-magnetic-readings",
    "href": "content/eosc555/lectures/project/index.html#inverting-the-magnetic-readings",
    "title": "Project Work 1",
    "section": "Inverting the Magnetic Readings",
    "text": "Inverting the Magnetic Readings\nThe magnetic anomaly readings above ground are but a 2D slice from the 3D data that is being recovered. This is like trying to reconstruct a 3D object from the shadow that it casts, a very ill conditioned problem. To get a gauge of the problem difficulty we attempt a simple inversion using the conjugate gradient method developed in earlier lectures.\nThe inversion problem is to recover the magnetization model \\(M\\) from the observed magnetic data \\(D\\) using the forward model \\(A\\), its adjoint \\(A^*\\), and the conjugate gradient method. The null space of the forward operator is quite large, meaning there are infinite possible solutions, so a regularization term is added to the objective function to constrain the solution. The model is\n\\[D = A(M) + \\epsilon\\]\nwhere \\(\\epsilon\\) is the noise in the data.\n\nObjective Function\nThe objective function to minimize is\n\\[ J(M) = \\frac{1}{2} \\| A(M) - D \\|_2^2 + \\alpha R(M) \\]\nwhere \\(R(M)\\) is the regularization term and \\(\\alpha\\) is the regularization parameter. In this example a weight matrix \\(W\\) is used on the flattened magnetic data.\n\\[ R(M) = \\frac{1}{2} \\| W(M) \\|_2^2\\]\nThe solution to this problem is given in Lecture 4 using the normal equations.\n\\[ (A^*A + \\alpha W^*W) M_{sol} = A^*D\\]\nThe conjugate gradient method is used to solve the system of equations. The adjoint of the regularization term is also defined to speed up the process of inverting data when using techniques that make use of it.\n\n\nRegularization Implementation\nThe penalty or prior that this is to incur is the finite difference between neighboring cells in the model. This is an approximation of the gradient at each point in the magnetic data, functioning as a slope penalty regularization as discussed previously in Lecture 8.\nThe finite difference matrix in 1D is\n\\[W = \\begin{bmatrix} 1 & -1 & 0 & \\cdots & 0 \\\\0 & 1 & -1 & \\cdots & 0 \\\\\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\0 & 0 & 0 & \\cdots & -1 \\end{bmatrix}\\]\nand it can be extended to 2D and 3D by applying the finite difference in each dimension over the flattened data, thus it is a linear operator. It is simpler to compute the value as a summation in practice, applied to the flattened data: \\[\\|W(M)\\|^2 = \\sum_i^N\\sum_j^S\\sum_k^Q (M_{i,j,k} - M_{i+1,j,k})^2 + (M_{i,j,k} - M_{i,j+1,k})^2 + (M_{i,j,k} - M_{i,j,k+1})^2\\] We take the mean over each dimension to normalize across any small variations in the data size due to the loss of boundary cells when applying the finite difference.\nA generalized linear adjoint computation in PyTorch is also defined in code, so that the regularization term has a defined adjoint operation for the optimization algorithm. The regularization term to be defined is the operator before the squared norm is applied.\n\ndef regularization(x):\n    gx = x[:,:,1:,:,:] - x[:,:,:-1,:,:]\n    gy = x[:,:,:,1:,:] - x[:,:,:,:-1,:]\n    gz = x[:,:,:,:,1:] - x[:,:,:,:,:-1]\n    # Concatenate the flattened gradients together and return as the W(M) vector    \n    return torch.cat([torch.flatten(gx), torch.flatten(gy), torch.flatten(gz)])\n\ndef adjoint(A, v, x_sample):\n    \"\"\" \n    Take the adjoint of the forward operator A with respect to the input vector v.\n    \n    Parameters:\n        A (callable): Forward operator.\n        v (torch.Tensor): Input vector.\n        x_sample (torch.Tensor): Sample input for dimensioning (dummy data).\n    \"\"\"\n    \n    x = torch.zeros_like(x_sample)\n    x.requires_grad = True\n    b = A(x)\n    # Compute the dot product of the forward operator with the input vector\n    h = torch.sum(b * v)\n    # Compute the gradient of the dot product with respect to the input image\n    adjoint = torch.autograd.grad(h, x, create_graph=True)[0]\n    return adjoint\n\n\n\nData Set for Fitting\nA new data set with three blocks is created for a more interesting test case.\n\n\nShow the code\ndef gen_true_data(dim):\n\n    # set the magnetization model\n    xtrue = torch.zeros(*dim)\n    xtrue[30:50, 40:50, 10:20] = 0.6\n    xtrue[20:40, 20:40, 5:15] = 0.2\n    xtrue[10:15, 10:15, 2:5] = 0.5\n    \n    return xtrue\n\n# Set the model parameters\nn1 = 64\nn2 = 64\nn3 = 32\ndim = torch.tensor([n1,n2,n3])\nh = torch.tensor([100.0, 100.0, 100.0])\ndirs = torch.tensor([np.pi/2, np.pi/2, np.pi/2, np.pi/2])\nforMod = Magnetics(dim, h, dirs)\n\n# Generate the true data\nxtrue = gen_true_data(dim)\nxtrue = xtrue.unsqueeze(0).unsqueeze(0)\n\nD = forMod(xtrue)\nnoise = torch.randn_like(D)\nD = D + 0.001*noise\n\n# Plot the true model and forward data\np = pv.Plotter()\np = plot_model_with_forward(xtrue, D, h, height=0, zoom = 4.0, plotter=p)\noutput_file = \"imgs/magnetic_inversion_proj.png\"\np.show(screenshot=output_file)\n\n\n\n\n\nModel with forward data\n\n\n\n\n\n\nConjugate Gradient Method\nThe equation to solve is \\((A^*A + \\alpha W^*W) M_{sol} = A^*D\\) which should be defined in the standard form for a conjugate gradient problem, \\(Cx = b\\). To fit this form a new linear operator \\(C\\) is defined as \\(C := A^*A + \\alpha W^*W\\) and the right hand side \\(b = A^*D\\). The conjugate gradient method is then applied to solve the system of equations.\n\nimport matplotlib.pyplot as plt\n\ndef conj_gradient(A, b, x0=None, niter=20, tol=1e-2, alpha=1e-2, verbose=True):\n    \"\"\"\n    Solve Ax=b using the conjugate gradient method.\n\n    Paramters:\n        A (callable): A function that computes the operator Ax.\n        b (torch.Tensor): The right-hand side vector.\n        x0 (torch.Tensor, optional): The initial guess. Defaults to None.\n        niter (int, optional): Maximum number of iterations. Defaults to 20.\n        tol (float, optional): Tolerance for the residual. Defaults to 1e-2.\n        alpha (float, optional): Step size for the conjugate gradient method. Defaults to 1e-2.\n    \"\"\"\n    if x0 is None:\n        r = b\n    else:\n        r = b - A(x0)\n\n    q = r\n    x = torch.zeros_like(b)\n    for i in range(niter):\n        Aq = A(q)\n        alpha = (r * r).sum() / (q * Aq).sum()\n        x = x + alpha * q\n        rnew = r - alpha * Aq\n        beta = (rnew**2).sum() / (r**2).sum()\n        q = rnew + beta * q\n        r = rnew.clone()\n        if verbose:\n            print(\"iter = %3d    res = %3.2e\" % (i, r.norm() / b.norm()))\n        if r.norm() / b.norm() &lt; tol:\n            break\n    return x\n\n# Generate the true data\nxtrue = gen_true_data(dim)\nxtrue = xtrue.unsqueeze(0).unsqueeze(0)\n\nD = forMod(xtrue)\nnoise = torch.randn_like(D)\nD = D + 0.001*noise\n\n# Define the forward operator with regularization\nreg_param = 1e-4\nreg_func = lambda x: regularization(x)\ndef A(x, alpha=reg_param):\n    y1 = forMod(x)\n    y1 = forMod.adjoint(y1)\n    \n    y2 = reg_func(x)\n    y2 = adjoint(reg_func, y2, x)\n    return y1 + alpha*y2\n\nb = forMod.adjoint(D)\n\n# Check dimensions and functioning\ny = A(xtrue)\n\n# Solve the inverse problem using the conjugate gradient method\nx0 = torch.zeros_like(xtrue)\n\nxinv = conj_gradient(A, b, x0, niter=20, tol=1e-6, alpha=1e-2, verbose=True)\n    \n# Verify that the gradient is zero at the solution\nxtest = xinv.clone().detach().requires_grad_(True)\nloss = 0.5 * (D - forMod(xtest)).norm()**2 + 0.5 * reg_param * torch.sum(reg_func(xtest)**2)\nloss.backward()\n\n# Print the norm of the gradient\ngradient_norm = xtest.grad.norm().item()\nprint(f\"Gradient norm at xinv: {gradient_norm:.6e}\")\n\n# Get misfit and regularization\nmisfit = 0.5 * (D - forMod(xinv)).norm()**2\nreg = 0.5 * reg_param * torch.sum(reg_func(xtest)**2)\nprint(f\"Misfit: {misfit:.6e}, Regularization: {reg:.6e}\")\n\n\n# Optionally, set a tolerance and assert\ntolerance = 1e-4\nif gradient_norm &lt; tolerance:\n    print(f\"Verification Passed: Gradient norm {gradient_norm:.2e} is below the tolerance {tolerance:.2e}.\")\nelse:\n    print(f\"Verification Failed: Gradient norm {gradient_norm:.2e} exceeds the tolerance {tolerance:.2e}.\")\n\niter =   0    res = 1.47e-01\niter =   1    res = 3.31e-02\niter =   2    res = 6.97e-03\niter =   3    res = 1.34e-03\niter =   4    res = 2.93e-04\niter =   5    res = 1.38e-04\niter =   6    res = 2.79e-04\niter =   7    res = 1.43e-03\niter =   8    res = 4.25e-03\niter =   9    res = 1.72e-03\niter =  10    res = 3.04e-04\niter =  11    res = 7.72e-05\niter =  12    res = 8.64e-05\niter =  13    res = 3.84e-04\niter =  14    res = 1.96e-03\niter =  15    res = 1.21e-03\niter =  16    res = 1.94e-04\niter =  17    res = 6.02e-05\niter =  18    res = 9.90e-05\niter =  19    res = 4.94e-04\nGradient norm at xinv: 4.354817e-04\nMisfit: 7.700652e-08, Regularization: 1.644024e-05\nVerification Failed: Gradient norm 4.35e-04 exceeds the tolerance 1.00e-04.\n\n\nNow that the inversion is performed, the results can be checked against the true forward model to see if they match correctly.\n\n\nShow the code\n# Plot the results   \npred = forMod(xinv) # predicted 2d data\n\nplt.subplot(1, 2, 1)\nplt.imshow(D.view(n1, n2).cpu().detach().numpy(), cmap='rainbow')\nplt.title('Data')\nplt.colorbar()\n\nplt.subplot(1, 2, 2)\nplt.imshow(pred.view(n1,n2).cpu().detach().numpy(), cmap='rainbow')\nplt.title('Inverted model')\nplt.colorbar()\n\nplt.show() \n\n\n\n\n\nForward model comparison.\n\n\n\n\nThis looks like a perfect fit, but as we will see, the method has done a poor job of recovering the true model."
  },
  {
    "objectID": "content/eosc555/lectures/project/index.html#results",
    "href": "content/eosc555/lectures/project/index.html#results",
    "title": "Project Work 1",
    "section": "Results",
    "text": "Results\nThe inverted model can be plotted to see how well the inversion has performed.\n\nShow the code\np = pv.Plotter()\np = plot_model_with_forward(xtrue, D, h, height=0, zoom = 4.0, threshold_value=0.05, plotter=p)\np.show()\n\np = pv.Plotter()\nxinv = xinv.detach().cpu()\np = plot_model_with_forward(xinv, D, h, height=0, zoom = 4.0, threshold_value=.05, plotter=p)\np.show()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) True Model\n\n\n\n\n\n\n\n\n\n\n\n(b) Inverted Model\n\n\n\n\n\n\n\nFigure 1: A comparison of true and inverted models.\n\n\n\n\nShow the code\n# Plot the true and inverted models\nplot_model_2d(xtrue, figsize=(3,3))\n\nplot_model_2d(xinv, figsize=(3,3))\n\n\n\n\n\n\n\n\n\n\n\n\n(a) True Model\n\n\n\n\n\n\n\n\n\n\n\n(b) Inverted Model\n\n\n\n\n\n\n\nFigure 2: A comparison of true and inverted models in 2D.\n\n\n\nThe inversion is clearly a failure. The magnetic distrbution for a material with a lower susceptibility that is close to the surface will produce an identical 2D magnetic field to the true data which is material buried much deeper. The model has a preference for shallow material, as material that is far away is more susceptible to noise and closer to the null space of the forward operator.\nTo try and recover the true magnetic model, a more sophisticated inversion method is required. One such method is decribed in a review paper by Crespo et. al (Crespo Marques et al. 2019) and is a topic of exploration in the next project section, where a sparse recovery technique will be used to recover the true model."
  },
  {
    "objectID": "content/eosc555/lectures/lecture8/index.html",
    "href": "content/eosc555/lectures/lecture8/index.html",
    "title": "Lecture 8",
    "section": "",
    "text": "$$ \n$$"
  },
  {
    "objectID": "content/eosc555/lectures/lecture8/index.html#motivation",
    "href": "content/eosc555/lectures/lecture8/index.html#motivation",
    "title": "Lecture 8",
    "section": "Motivation",
    "text": "Motivation\nRevisiting the structure of some inverse problems we have seen so far we generalize the problem as follows. We have some model: \\[u(x) \\rightarrow \\text{model}\\]\nand also a forward process that may not be perfect or have some noise in it that produces the observed data:\n\\[ A(u(x)) + \\epsilon = b \\rightarrow \\text{data}\\]\nwhere the goal is to recover the model \\(u(x)\\) from the data \\(b\\) with a known forward operator \\(A\\) and some noise \\(\\epsilon\\). The problem is that the solution is usually not unique and may have an infinite number of solutions or no solution. We usually will specify the goodness of a solution by some metric, for example, the least squares error:\n\\[\\|A\\hat u - b\\|^2 &lt; \\text{tol}\\]\nwill specify that solutions within a certain tolerance of the data are acceptable.\n\n\n\n\n\n\n\n\nFigure 1: Continuous positive function \\(u(x)\\) with sampled points \\(x_i\\)\n\n\n\n\n\nSince the real world generally is measured via sampling, the \\(u(x_i)\\) are a sample space that estimate the continuous function \\(u(x)\\). Usually there are a huge number of \\(x_i\\) for which we want to estimate \\(u(x)\\), such that there are far more unknowns in \\(u\\) than there are data points in \\(b\\). This gives the least square problem an infinite number of solutions."
  },
  {
    "objectID": "content/eosc555/lectures/lecture8/index.html#simple-regularization",
    "href": "content/eosc555/lectures/lecture8/index.html#simple-regularization",
    "title": "Lecture 8",
    "section": "Simple Regularization",
    "text": "Simple Regularization\nRegularization is a technique used to constrain the solution space of the inverse problem. It may incorporate some prior knowledge of the problem either explicitly or implicitly. The addition of a second term or objective to the least squares problem improves the metric by which the solution is being evaluated to distinguish between the infinite number of solutions. The general form of the regularized least squares problem is:\n\\[\\min_u \\|A u - b\\|^2 + \\alpha R(u)\\]\nAn example of this could be using the \\(L_2\\) norm of the solution as the regularization term:\n\\[R(u) = \\frac{1}{2}\\|u\\|^2\\]\nThe new metric favours solutions where \\(u\\) is small, but it actually includes an even more explicit probabilistic interpretation which can be derived from the Bayesian perspective.\n\nBayesian Inference\nLet the set of model parameters be \\(u\\) and the data be \\(b\\). Then we assume without any prior knowledge of the problem that the data is generated by a model with some noise:\n\\[b = A(u) + \\epsilon\\]\nwhere \\(\\epsilon\\) is a Gaussian noise term with mean zero and variance \\(\\sigma^2\\). The likelihood of the data given the model is then:\n\\[p(b|u) \\propto \\exp\\left(-\\frac{\\|A(u) - b\\|^2}{2\\sigma^2}\\right)\\]\nSimilarly, we can assume a prior distribution on the model parameters \\(u\\):\n\\[p(u) \\propto \\exp\\left(-\\frac{\\|u\\|^2}{2\\beta}\\right)\\]\nwhere \\(\\beta\\) is the amount of standard deviation that we assume to be present in the prior.\n\n\nMaximum Likelyhood Estimation\nIn maximum likelihood estimation (MLE), the objective is to find the model that gives the highest likehood for seeing the data that was observed. Note that the function \\(\\log (.)\\) is a monotonic function so it preserves the ordering of values, so maximizing the likelihood is equivalent to maximizing the log likelihood. The MLE is then:\n\\[\n\\begin{align*}\n\\hat u &= \\arg\\max_u p(b|u)\\\\\n&= \\arg\\max_u \\log p(b|u) \\\\\n&= \\arg\\min_u \\frac{\\|A(u) - b\\|^2}{2\\sigma^2} \\\\\n&= \\arg\\min_u \\|A(u) - b\\|^2.\n\\end{align*}\n\\] Giving the unregularized least squares problem.\n\n\nMaximum A Posteriori Estimation\nIn maximum a posteriori estimation (MAP), the objective is to find the model that gives the highest likelihood for seeing the data that was observed given the prior information. The reason is that it is unintuitive to ask to fit parameters to maximize likelihood of data measured. The driver of the model should be the data itself which is independent of the model. This reverses the probabilistic objective– find the model parameters that are most likely given the observed data. Bayes’ theorem states that:\n\\[p(u|b) = \\frac{p(b|u)p(u)}{p(b)}\\]\nwhere \\(p(b)\\) is the marginal likelihood of the data. The value of \\(p(b)\\) is a constant that does not depend on the model parameters, so we can ignore it when it comes to maximizing the probability.\n\\[\\underbrace{p(u|b)}_{\\text{posterior}} \\propto \\underbrace{p(b|u)}_{\\text{likelihood}} \\underbrace{p(u)}_{\\text{prior}}\\]\nAs in the MLE, the log likelihood is maximized to find the MAP:\n\\[\n\\begin{align*}\n\\hat u &= \\arg\\max_u p(u|b)\\\\\n&= \\arg\\max_u \\log \\Big( p(b|u) p(u) \\Big)\\\\\n&= \\arg\\max_u \\log p(b|u) + \\log p(u) \\\\\n&= \\arg\\max_u -\\frac{\\|A(u) - b\\|^2}{2\\sigma^2} - \\frac{\\|u\\|^2}{2\\beta} \\\\\n&= \\arg\\min_u \\frac{\\|A(u) - b\\|^2}{2\\sigma^2} + \\frac{\\|u\\|^2}{2\\beta} \\\\\n&= \\arg\\min_u \\frac{1}{2}\\|A(u) - b\\|^2 + \\frac{1}{2}\\alpha \\|u\\|^2\n\\end{align*}\n\\]\nwhere \\(\\alpha = \\frac{\\sigma^2}{\\beta}\\) is the regularization parameter. This gives the regularized least squares problem.\nThe choice of the regularization parameter \\(\\alpha\\) is a statistical statement on the expected ratio of noise to prior information. If \\(\\alpha\\) is large, the prior information is trusted more than the data, and if \\(\\alpha\\) is small, the data is trusted more than the prior information.\n\n\nNotes on Interpretation\nIn the Bayesian perspective, the regularization term is grounded in a probabilistic approach that will blindly pick the solution that is most likely given the data and the prior information. The maximum may not always be the best choice when considering the robustness of the solution to noise. The initial choice to regularize with the \\(L_2\\) norm \\(\\|u\\|^2\\) does not make any claims on the likelihood of the model parameters while still yielding the same results.\nProbabilistic approaches to inverse problems with complex distributions are becoming more reliable now with the advent of generative models that learn an underlying probability distribution. While the Gaussian prior is easier to work with, it is simplistic and may not always be the best choice. For example the underlying parameters of a forward model could be the density of a material, or its conductivity, in which case the prior distribution could be something very different from a Gaussian. The choice of prior can be enhanced using a neural network for examples."
  },
  {
    "objectID": "content/eosc555/lectures/lecture8/index.html#choice-of-regularizer",
    "href": "content/eosc555/lectures/lecture8/index.html#choice-of-regularizer",
    "title": "Lecture 8",
    "section": "Choice of Regularizer",
    "text": "Choice of Regularizer\nThe problem of least squares with a regularization term can be generalized as:\n\\[\\min_u \\frac{1}{2}\\|A u - b\\|^2 + \\alpha R(u)\\]\nFor the case of the \\(L_2\\) norm, the problem becomes:\n\\[\n\\begin{align*}\n\\hat u =& \\min_u \\frac{1}{2}\\|A u - b\\|^2 + \\frac{\\alpha}{2}\\|u\\|^2\\\\\n=& A^T(Au - b) + \\alpha u = 0\\\\\n=& (A^TA + \\alpha I)u = A^Tb\n\\end{align*}\n\\]\nThere are many other choices for the regularization term though.\nSome common choices for the regularization term \\(R(u)\\) include:\n\nGaussian \\(L_2\\) Norm Regularization:\n\\[\nR(u) = \\frac{1}{2}\\|u\\|^2 = \\frac{1}{2}\\sum_i u_i^2\n\\]\nAssumes a Gaussian prior on the model parameters \\(u\\), favoring solutions with smaller norms. It penalizes large values in \\(u\\), leading to solutions with smaller magnitudes.\nSlope Penalty:\n\\[\nR(u) = \\int_{\\mathcal{X}} \\frac{1}{2}\\|\\nabla_x u\\|^2 \\, dx = \\int_{\\mathcal{X}} \\frac{1}{2}\\Big( \\frac{\\partial u}{\\partial x_1}^2 + \\frac{\\partial u}{\\partial x_2}^2 \\Big) \\, dx\n\\]\nRecalling that \\(u\\) is a function across a domain \\(\\mathcal{X}\\), the slope penalty penalizes the squared magnitude of the gradient of \\(u\\). It encourages flatness in the solution by penalizing rapid changes in \\(u\\).\nSmoothness Penalty:\n\\[\nR(u) = \\int_{\\mathcal{X}} \\frac{1}{2}\\|\\nabla^2 u\\|^2 \\, dx = \\int_{\\mathcal{X}} \\frac{1}{2}\\Big( \\frac{\\partial^2 u}{\\partial x_1^2} + \\frac{\\partial^2 u}{\\partial x_2^2} \\Big) \\, dx\n\\]\nThe smoothness penalty promotes smoothness in the solution by penalizing changes in the slope of \\(u\\) across the domain.\n\\(L_1\\) Norm Regularization:\n\\[\nR(u) = \\|u\\|_1 = \\sum_i |u_i|\n\\]\nThe \\(L_1\\) norm promotes sparsity in the solution by penalizing the absolute values of \\(u\\). This leads to many parameters being exactly zero, which is desirable in feature selection and compressed sensing applications.\nTotal Variation Regularization:\n\\[\n  R(u) = \\text{TV}(u) = \\int |\\nabla u| \\, dx = \\int \\sqrt{\\left| \\frac{\\partial u}{\\partial x_1} \\right|^2 + \\left| \\frac{\\partial u}{\\partial x_2} \\right|^2} \\, dx   \\]\nTotal Variation (TV) regularization penalizes the total amount of variation in ( u ) without squaring the gradient. It preserves sharp edges while removing noise.\n\nA demonstration of the effects of the regularizer are given below for a case of denoising an image. Note that the operator \\(A\\) is the identity matrix in this case which is a simplification of the problem.\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import gaussian_filter\nfrom scipy.optimize import minimize\nfrom skimage import data\nfrom skimage.transform import resize\nfrom skimage.restoration import denoise_tv_chambolle\n\n# Load the sample grayscale image and normalize\nZ_true = data.camera().astype(np.float64) / 255.0\nZ_true = Z_true*2 - 1  # Normalize to [-1, 1]\n\n# Downsample the image to 32x32\nZ_true= resize(Z_true, (64,64), anti_aliasing=True)\n\n# Add Gaussian noise to simulate observed data\nnp.random.seed(0)  # For reproducibility\nnoise = 0.1 * np.random.normal(size=Z_true.shape)\nZ_noisy = Z_true + noise\n\n# Define different regularization penalties\ndef gaussian_l2_norm(u):\n    return 0.5 * np.sum(u**2)\n\ndef slope_penalty(u):\n    grad_x, grad_y = np.gradient(u)\n    return 0.5 * np.sum(grad_x**2 + grad_y**2)\n\ndef smoothness_penalty(u):\n    laplace_u = np.gradient(np.gradient(u, axis=0), axis=1)\n    return 0.5 * np.sum(laplace_u**2)\n\ndef l1_norm(u):\n    return np.sum(np.abs(u))\n\n# Prepare observed data vector\nA = np.eye(Z_true.size)  # Identity for simplicity\nb = Z_noisy.flatten()\n\n# Regularization strength\nalpha = 1\n\n# Function to solve the regularized least squares problem\ndef regularized_least_squares(A, b, reg_func, alpha):\n    def objective(u):\n        # Least squares term\n        residual = A @ u - b\n        ls_term = 0.5 * np.sum(residual**2)\n        # Regularization term\n        reg_term = alpha * reg_func(u.reshape(Z_true.shape))\n        return ls_term + reg_term\n\n    # Initial guess (flattened noisy image)\n    u0 = b.copy()\n    result = minimize(objective, u0, method='L-BFGS-B')\n    return result.x.reshape(Z_true.shape)\n\n# Apply different regularizations\nrecovered_gaussian_l2 = regularized_least_squares(A, b, gaussian_l2_norm, alpha)\nrecovered_slope = regularized_least_squares(A, b, slope_penalty, alpha)\nrecovered_smoothness = regularized_least_squares(A, b, smoothness_penalty, alpha)\nrecovered_l1 = regularized_least_squares(A, b, l1_norm, alpha)\nrecovered_tv = denoise_tv_chambolle(Z_noisy, weight=alpha*.1)\n\n# Plot original, noisy, and recovered images for each regularizer\nfig, axs = plt.subplots(1, 2)\n\n#Original\nplt.subplot(1,2,1)\nplt.imshow(Z_true, cmap=\"gray\")\nplt.title(\"Original Image\")\nplt.axis(\"off\")\n\n# Noisy Image\nplt.subplot(1,2,2)\nplt.imshow(Z_noisy, cmap=\"gray\")\nplt.title(\"Noisy Image\")\nplt.axis(\"off\")\n\nplt.show()\n\n# Plot original, noisy, and recovered images for each regularizer\nfig, axs = plt.subplots(2,2)\n\n# Gaussian L2 Norm Regularization\nplt.subplot(2, 2, 1)\nplt.imshow(recovered_gaussian_l2, cmap=\"gray\")\nplt.title(\"Gaussian $L_2$ Norm Regularization\")\nplt.axis(\"off\")\n\n# Slope Penalty Regularization\nplt.subplot(2, 2, 2)\nplt.imshow(recovered_slope, cmap=\"gray\")\nplt.title(\"Slope Penalty Regularization\")\nplt.axis(\"off\")\n\n# Smoothness Penalty Regularization\nplt.subplot(2, 2, 3)\nplt.imshow(recovered_smoothness, cmap=\"gray\")\nplt.title(\"Smoothness Penalty Regularization\")\nplt.axis(\"off\")\n\n# Total Variation Regularization\nplt.subplot(2, 2, 4)\nplt.imshow(recovered_tv, cmap=\"gray\")\nplt.title(\"Total Variation Regularization\")\nplt.axis(\"off\")\n\n# Save recontructions\nplt.savefig(\"imgs/regularization_effects.png\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Original and Noised Image\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Reconstructions with Different Regularizations\n\n\n\n\n\n\n\nFigure 2: A comparison of different regularization effects on a noisy image reconstruction.\n\n\n\n\nClosing Notes\nAnother note to be made is that the regularization space itself can be changed by working in a latent space where \\(u = Dz\\) and \\(D\\) is a dictionary or basis that maps the latent space \\(z\\) to the model space \\(u\\). This is somewhat similar to PCA.\n\\[\\frac{1}{2} \\|A(Dz) - b\\|^2 + \\alpha R(z)\\]\nA more modern approach chooses \\(R(u)\\) based on data about the problem itself. For example, given a set of data \\(\\{u_1, u_2, \\ldots, u_n\\}\\), find the distribution \\(\\pi(u)\\) or what \\(R(u)\\) should be. This statistically learned regularization approach leads to neural networks and deep learning, a topic that will be explored further in the next lecture."
  },
  {
    "objectID": "content/eosc555/lectures/lecture6/index.html",
    "href": "content/eosc555/lectures/lecture6/index.html",
    "title": "Lecture 6",
    "section": "",
    "text": "$$ \n$$"
  },
  {
    "objectID": "content/eosc555/lectures/lecture6/index.html#building-the-gauss-newton-optimizer",
    "href": "content/eosc555/lectures/lecture6/index.html#building-the-gauss-newton-optimizer",
    "title": "Lecture 6",
    "section": "Building the Gauss-Newton Optimizer",
    "text": "Building the Gauss-Newton Optimizer\nRecall the algorithm for the Gauss-Newton method:\n\n\n\\begin{algorithm} \\caption{Gauss-Newton Algorithm for Non-linear Least Squares}\\begin{algorithmic} \\State \\textbf{Input:} Initial guess $p_0$, maximum iterations $K$, tolerance $\\epsilon$ \\State \\textbf{Initialize} $p_0$ \\For{$k = 0, 1, 2, \\ldots$} \\State Compute the Jacobian $J_G$ of $G(p)$ at $p_k$ \\State Compute the transpose $J_G^T$ of the Jacobian \\State Compute the residual $r_k =G(p_k)$ (forward model) \\State Compute the step $s_k = (J_G(p_k)^T J_G(p_k) )^{-1} J_G(p_k)^T r_k$ \\State Update the parameters $p_{k+1} = p_k + \\mu_k s_k$ \\If{$\\|s_k\\| &lt; \\epsilon$} \\State \\textbf{Stop} \\EndIf \\EndFor \\State \\textbf{Output:} $p_{k+1}$ as the optimal solution \\end{algorithmic} \\end{algorithm}\n\n\nThen combining all the previous stages of code we have:\n\n# fix all parts of the problem except the parameters\ndef forward_model(params):\n    X = lotka_volterra(params, initial_pop, T=period, nt=n_time_steps)\n    prey = X[0, :]\n    return prey\n\n\ndef gauss_newton_solver(forward_model, p0, data, max_iter=100, tol=1e-6, mu=1, verbose=True):\n    \"\"\"\n    Solve a non-linear least squares problem using the Gauss-Newton method.\n\n    Parameters:\n        forward_model (callable): A function that computes the forward model.\n        p0 (torch.Tensor): The initial guess for the parameters.\n        data (torch.Tensor): The observed data to fit to.\n        max_iter (int): Maximum number of iterations. Defaults to 100.\n        tol (float): Tolerance for the residual. Defaults to 1e-6.\n        mu (float): Step size for the Gauss-Newton method. Defaults to 1.\n        verbose (bool): Whether to print iteration information. Defaults to True.\n    \"\"\"\n\n    predictions = []  # To store predictions at each iteration for animation\n    \n    params = p0\n    for i in range(max_iter):\n        # Compute residual\n        data_pred = forward_model(params)\n        rk = data - data_pred\n        \n        # Store the current predicted data for animation\n        predictions.append(data_pred.detach())\n        \n        # Compute parts for conjugate gradient\n        b = torch.autograd.functional.vjp(forward_model, params, rk)[1]\n        def A(sk):\n            q = torch.autograd.functional.jvp(forward_model, params, sk)[1]\n            a = torch.autograd.functional.vjp(forward_model, params, q)[1]\n            return a\n        s_k = conj_gradient(A, b, niter=20, tol=1e-2, alpha=1e-2, verbose=False)\n        \n        # Update parameters\n        params = params + mu * s_k\n        \n        # Check for convergence\n        if s_k.norm() &lt; tol:\n            print(f'Converged in {i+1} iterations')\n            break\n        if verbose:\n            print(f'Iteration {i+1}/{max_iter}: Residual = {rk.norm().item()}')\n    \n    return params, predictions\n\n\nTesting the Gauss-Newton Optimizer\nA run of the Gauss-Newton optimization method can be performed on the Lotka-Volterra model to fit the prey population data. The optimization method will be run for a maximum of \\(40\\) iterations with a tolerance that will exit early if the step size becomes small enough indicating a local minimum. The results of the optimization can be plotted against the true data, both prey and predator, to see how well the optimization method has performed to recover the missing predator population.\n\n\nShow the code\nperiod = 40.0  # Time horizon as a single float\nn_time_steps = 200\ninitial_pop = torch.rand(2)\n\n# Making a true data set to fit to\nXX, M = generate_data_set(\n    initial_pop=initial_pop, period=period, n_time_steps=n_time_steps, n_realizations=1\n)\nX = XX[0]\nd_true = X[0, :]  # Use the prey population as the data to fit\n\n# Start with an initial guess for the parameters\np0 = torch.tensor([1.7, 1.7, 0.7, 0.7], requires_grad=True)\n\n# Solve the problem\np_opt, predictions = gauss_newton_solver(\n    forward_model, p0, d_true, max_iter=45, tol=1e-4, mu=1e-1, verbose=False\n)\n\n# Make a final plot of the both pred prey true data and the predicted data\nX_hat = lotka_volterra(p_opt, initial_pop, T=period, nt=n_time_steps)\n\nplt.figure()\nplt.plot(X[0, :].detach().numpy(), label=\"True Prey Population\")\nplt.plot(X[1, :].detach().numpy(), label=\"True Predator Population\")\nplt.plot(X_hat[0, :].detach().numpy(), label=\"Predicted Prey Population\")\nplt.plot(X_hat[1, :].detach().numpy(), label=\"Predicted Predator Population\")\nplt.legend()\nplt.xlabel(\"Time Steps\")\nplt.ylabel(\"Population\")\nplt.title(\"True vs Predicted Population\")\nplt.show()\n\n\nComputing realization 1/1\n\n\n\n\n\nTesting the Gauss-Newton optimization method.\n\n\n\n\nThe plot outputs the successive iterations of the method and the data of the forward model as it is fitting in the predicitons tensor. The optimization process can be animated from the successive predictions to get a visual understanding of the optimization method.\n\n\nShow the code\nfrom matplotlib.animation import FuncAnimation\n\n\ndef create_animation(true_data, predictions, filename=\"imgs/fitting_animation.gif\"):\n    fig, ax = plt.subplots()\n    (line1,) = ax.plot([], [], \"r-\", label=\"Predicted Fit\")\n    (line2,) = ax.plot([], [], \"b--\", label=\"True Data\")\n    ax.legend()\n\n    # Set titles and labels\n    ax.set_xlabel(\"Time Steps\")\n    ax.set_ylabel(\"Population\")\n\n    def init():\n        # Set x and y limits based on true_data and predictions\n        ax.set_xlim(0, len(true_data))\n        ax.set_ylim(\n            min(true_data.min(), predictions[0].min()) - 0.1,\n            max(true_data.max(), predictions[0].max()) + 0.1,\n        )\n        line2.set_data(\n            range(len(true_data)), true_data\n        )  # Set true data once, as it remains constant\n        ax.set_title(\"Iteration: 0\")  # Initial title for iteration count\n        return line1, line2\n\n    def update(i):\n        # Update predicted data and title with the current iteration count\n        line1.set_data(range(len(predictions[i])), predictions[i])\n        ax.set_title(f\"Iteration: {i + 1}\")\n        return line1, line2\n\n    # Create animation with updated frames\n    ani = FuncAnimation(fig, update, frames=len(predictions), init_func=init, blit=True)\n    ani.save(filename, writer=\"imagemagick\")\n\n\n# Create the animation\ncreate_animation(\n    d_true.cpu().detach().numpy(),\n    [pred.cpu().numpy() for pred in predictions],\n    \"imgs/fitting_animation.gif\",\n)"
  },
  {
    "objectID": "content/eosc555/lectures/lecture6/index.html#extension-to-time-varying-parameters",
    "href": "content/eosc555/lectures/lecture6/index.html#extension-to-time-varying-parameters",
    "title": "Lecture 6",
    "section": "Extension to Time Varying Parameters",
    "text": "Extension to Time Varying Parameters\nAlthough the previous examples have been for a fixed set of parameters, it is entirely possible in natural systems that the parameters of the model are time dependent. The formulation of the Lotka-Volterra model has incorporated this design from the start by expanding the initial four parameters across the time dimension. However we can pass a full tensor of time varying parameters that is size \\([nt, 4]\\) to the model and the optimization algorithm. The rest of the code does not change at all since the PyTorch library can perform the required gradient computations on a 2D tensor as well.\nThe range of possible solutions and the dimensionality of the problem expands from \\(4\\) parameters to \\(4 \\times nt\\) parameters which means more parameters than there are actual data points. This means that any set of data could be fit perfectly, but it might not be the correct fit. This issue is a hallmark of ill-posed inverse problems. The optimization algorithm will still converge to a solution, but it might not be the correct one.\nSince the ground truth of both predator and prey populations is known, the optimization algorithm can be run with time dependent parameters which will allow more overfitting. The parameters being fixed in time is a sort of regularization that can applied to the problem, and removing it will change the results of the optimization.\n\n# Start with an initial guess for the parameters\np0 = torch.tensor([1.7, 1.7, 0.7, 0.7], requires_grad=True)\n# Extend p0 to repeat over the time steps with individual gradients\np0 = p0.unsqueeze(0).expand(n_time_steps, -1)\n\n# Solve the problem\np_opt, predictions = gauss_newton_solver(\n    forward_model, p0, d_true, max_iter=45, tol=1e-4, mu=1e-1, verbose=False\n)\n\n# Make a final plot of the both pred prey true data and the predicted data\nX_hat = lotka_volterra(p_opt, initial_pop, T=period, nt=n_time_steps)\n\nplt.figure()\nplt.plot(X[0, :].detach().numpy(), label=\"True Prey Population\")\nplt.plot(X[1, :].detach().numpy(), label=\"True Predator Population\")\nplt.plot(X_hat[0, :].detach().numpy(), label=\"Predicted Prey Population\")\nplt.plot(X_hat[1, :].detach().numpy(), label=\"Predicted Predator Population\")\nplt.legend()\nplt.xlabel(\"Time Steps\")\nplt.ylabel(\"Population\")\nplt.title(\"True vs Predicted Population\")\nplt.show()\n\n\n\n\nFitting the Lotka-Volterra model with time-varying parameters."
  },
  {
    "objectID": "content/eosc555/lectures/lecture6/index.html#conclusion",
    "href": "content/eosc555/lectures/lecture6/index.html#conclusion",
    "title": "Lecture 6",
    "section": "Conclusion",
    "text": "Conclusion\nThe Gauss-Newton optimization method is a powerful tool for solving non-linear least squares problems in a fast and efficient manner. It can be extended to any problem that is formulated as a vector of residuals or generally \\(\\| G(p) \\|^2\\) that is to be optimized over \\(p\\). Improved efficiency in the normal equations is done by using the Jacobian-vector product to bypass the costly need to compute a full Jacobian when all that is required is the directional derivative. The normal equtions also present a sub-problem in the optimization routine that can be solved using the conjugate gradient method to find the optimal step size \\(s_k\\). This step direction is then used to perform the gradient descent step in the outer optimization algorithm. Increasing the complexity of the problem by allowing time varying parameters can lead to overfitting and ill-posedness, but the optimization algorithm will still converge to a solution."
  },
  {
    "objectID": "content/eosc555/lectures/lecture4/index.html",
    "href": "content/eosc555/lectures/lecture4/index.html",
    "title": "Lecture 4",
    "section": "",
    "text": "$$ \n$$"
  },
  {
    "objectID": "content/eosc555/lectures/lecture4/index.html#tikhnov-regularization",
    "href": "content/eosc555/lectures/lecture4/index.html#tikhnov-regularization",
    "title": "Lecture 4",
    "section": "Tikhnov Regularization",
    "text": "Tikhnov Regularization\nWe have looked at the least squares formulation for solving inverse problems:\n\\[ \\min \\frac{1}{2} \\|A x - b\\|^2 \\]\nwhere \\(A \\in \\mathbb R^{m \\times n}\\) is a linear operator, \\(x \\in \\mathbb R^n\\) is the unknown model, and \\(b \\in \\mathbb R^m\\) is the data.\nThe least squares problem is often ill-posed, meaning that the solution is not unique or stable. If there are more unknowns than equations, such as the case when \\(n &gt; m\\), then the problem is underdetermined and there are infinitely many solutions.\nWe can return to unique solutions by adding a regularization term to the selection of the \\(x\\) that we want to minimize. The Tikhonov regularization technique adds a penalty term to the least squares problem:\n\\[ \\min \\frac{1}{2} \\|A x - b\\|^2 + \\frac{1}{2}  \\lambda \\|Lx\\|^2 \\]\nwhere \\(L \\in \\mathbb R^{n \\times n}\\) is a regularization matrix. The regularization matrix \\(L\\) is often chosen to be the identity matrix, but other choices are possible.\n\nUniqueness\nTo check the uniqueness of the solution, we can rewrite the problem as a quadratic form:\n\\[ \\min \\frac{1}{2} x^T A^T A x - b^T A x + \\frac{1}{2} \\lambda x^T L^T L x \\] \\[ = \\min \\frac{1}{2} x^T H x - b^T A x + \\frac{1}{2}\\|b\\|^2\\]\nwhere \\(H = A^T A + \\lambda L^T L\\) is the Hessian matrix which is symmetric and positive semi-definite by spectral theorem. If we choose an appropriate \\(\\lambda\\), then the Hessian matrix is positive definite and the problem is well-posed. In the case where \\(L=I\\), the Hessian becomes full rank for \\(\\lambda &gt; 0\\) and the problem is well-posed. The quality that \\(H \\succ 0\\) means that the matrix is invertible.\n\n\nSolution\nThe unique solution is given by by the first order optimatility condition:\n\\[ \\begin{align}\n(A^T A + \\lambda L^T L) \\mathbf{x}_{\\text{RLS}} - A^T b&= 0 \\\\\n\\mathbf{x}_{\\text{RLS}} &= (A^T A + \\lambda L^T L)^{-1} A^T b\n\\end{align}\n\\]\n\n\nSVD Decomposition\nThe solution can be written in terms of the singular value decomposition of \\(A\\), and with the assumption that \\(L=I\\):\n\\[ \\begin{align}\nA &= U \\Sigma V^T \\\\\nA^T A &= V \\Sigma^T \\Sigma V^T \\\\\n\\mathbf{x}_{\\text{RLS}} &= \\left( V \\Sigma^2 V^T + \\lambda I \\right)^{-1} V \\Sigma^T U^T b \\\\\n&= \\left( V \\Sigma^2 V^T + \\lambda I V V^T \\right)^{-1} V \\Sigma^T U^T b\\\\\n&= V \\left( \\Sigma^2 + \\lambda I \\right)^{-1} \\Sigma^T U^T b\\\\\n&= V \\mathbf{Diag}\\left( \\frac{\\sigma_i}{\\sigma_i^2 + \\lambda} \\right) U^T b\\\\\n&= \\sum _i ^ n \\frac{\\sigma_i}{\\sigma_i^2 + \\lambda} \\langle u_i, b \\rangle v_i\n\\end{align}\n\\]\nThis form is more readily comparable to some of the other methods that we have see so far, which are presented in the table below:"
  },
  {
    "objectID": "content/eosc555/lectures/lecture4/index.html#comparison-of-least-squares-methods",
    "href": "content/eosc555/lectures/lecture4/index.html#comparison-of-least-squares-methods",
    "title": "Lecture 4",
    "section": "Comparison of Least Squares Methods",
    "text": "Comparison of Least Squares Methods\n\n\n\n\n\n\n\nMethod\nSolution\n\n\n\n\nTikhonov\n\\(x_{\\text{RLS}} = \\sum _i ^ n \\frac{\\sigma_i}{\\sigma_i^2 + \\lambda} \\langle u_i, b \\rangle v_i\\)\n\n\nThresholded SVD\n\\(x_{\\text{TSVD}} = \\sum _i ^ n h(\\sigma_i) \\langle u_i, b \\rangle v_i\\)\n\n\nGradient Flow\n\\(x_{\\text{SDF}} = \\sum _i ^ n \\frac{\\exp(-\\sigma_i^2 t) - 1}{\\sigma_i} \\langle u_i, b \\rangle v_i\\)\n\n\n\nAs we can see all three methods have a similar form and offer some mechanism for controlling the noise induced by the small singular values of \\(A\\).\n\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef generate_ill_conditioned_matrix(m, n, condition_number):   \n    # Generate random orthogonal matrices U and V\n    U, _ = np.linalg.qr(np.random.randn(m, m))\n    V, _ = np.linalg.qr(np.random.randn(n, n))\n    \n    sigma = np.linspace(1, 1/condition_number, min(m, n))    \n    Sigma = np.diag(sigma)    \n    A = U @ Sigma @ V[:min(m, n), :]\n    \n    return A, sigma\n\n# Seed for reproducibility\nnp.random.seed(4)\nA, S = generate_ill_conditioned_matrix(8, 24, 1e3)\n\n# Create a vector b of size 5 with random values\nb = np.random.randn(8)\n\n# Compute the SVD of A\nU, S, Vt = np.linalg.svd(A, full_matrices=False)\nV = Vt.T\nU = U  # Already in proper shape\n\n# Number of singular values\nn = len(S)\n\n# Define parameters for each method\n# Gradient Flow\nt_values = np.linspace(0, 0.6, 100)\n\n# Tikhonov Regularization\nlambda_values = np.linspace(1e-4, 1, 100)\n\n# Thresholded SVD\nthreshold_values = np.linspace(0, max(S), 100)\n\n# Compute scaling factors for each method\n# Gradient Flow Scaling\ndef gradient_flow_scaling(sigma, t):\n    return (1 - np.exp(-sigma**2 * t)) / sigma\n\ngradient_scalings = np.array([gradient_flow_scaling(s, t_values) for s in S])\n\n# Tikhonov Scaling\ndef tikhonov_scaling(sigma, lambd):\n    return sigma / (sigma**2 + lambd)\n\ntikhonov_scalings = np.array([tikhonov_scaling(s, lambda_values) for s in S])\n\n# Thresholded SVD Scaling\ndef tsvd_scaling(sigma, threshold):\n    return np.where(sigma &gt;= threshold, 1/sigma, 0)\n\ntsvd_scalings = np.array([tsvd_scaling(s, threshold_values) for s in S])\n\n# Initialize the plot with 3 subplots\nfig, axes = plt.subplots(3, 1, figsize=(5, 15))\n\n# Define a color palette\npalette = sns.color_palette(\"husl\", n)\n\n# Plot Gradient Flow\nax = axes[0]\nfor i in range(n):\n    ax.plot(t_values, gradient_scalings[i], color=palette[i], linewidth=2, label=f'$1/\\sigma_{i}$' )\n    ax.axhline(y=1/S[i], color=palette[i], linestyle='--', linewidth=1)\nax.set_yscale('log')\nax.set_xlabel('Time (t)', fontsize=14)\nax.set_ylabel('Scaling Factor', fontsize=14)\nax.set_title('Gradient Flow', fontsize=16)\nax.legend()\nax.grid(True)\n\n# Plot Tikhonov Regularization\nax = axes[1]\nfor i in range(n):\n    ax.plot(lambda_values, tikhonov_scalings[i], color=palette[i], linewidth=2, label=f'$1/\\sigma_{i}$' )\n    ax.axhline(y=1/S[i], color=palette[i], linestyle='--', linewidth=1)\nax.set_yscale('log')\nax.set_xlabel('Regularization Parameter (λ)', fontsize=14)\nax.set_ylabel('Scaling Factor', fontsize=14)\nax.set_title('Tikhonov Regularization', fontsize=16)\nax.legend()\nax.grid(True)\n\n# Plot Thresholded SVD\nax = axes[2]\nfor i in range(n):\n    ax.plot(threshold_values, tsvd_scalings[i], color=palette[i], linewidth=2, label=f'$1/\\sigma_{i}$')\n    ax.axhline(y=1/S[i], color=palette[i], linestyle='--', linewidth=1)\nax.set_yscale('log')\nax.set_xlabel('Threshold (τ)', fontsize=14)\nax.set_ylabel('Scaling Factor', fontsize=14)\nax.set_title('Thresholded SVD', fontsize=16)\nax.legend()\nax.grid(True)\n\n# Adjust layout and add a legend\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nEvolution of scaling factors for three different methods"
  },
  {
    "objectID": "content/eosc555/lectures/lecture4/index.html#solving-least-squares-using-conjugate-gradient",
    "href": "content/eosc555/lectures/lecture4/index.html#solving-least-squares-using-conjugate-gradient",
    "title": "Lecture 4",
    "section": "Solving Least Squares Using Conjugate Gradient",
    "text": "Solving Least Squares Using Conjugate Gradient\nA detailed explanation of this method can be found at Wikipedia\n\nConjugate Vectors Definition\nA set of vectors \\(\\{ p_1, p_2, \\ldots, p_n \\}\\) is said to be conjugate with respect to a matrix \\(A\\) if:\n\\[\n\\langle p_i, A p_j \\rangle = 0 \\quad \\text{for all } i \\neq j\n\\]\nThis is a generalization of the concept of orthoganality to non-symmetric matrices.\nStandard Orthogonality: When $ A = I $ (the identity matrix), the definition reduces to the standard concept of orthogonality. For a symmetric \\(A\\) we also have an orthogonal decomposition of eigenvectors by spectral theorem.\n\nBack to the problem of least squares, we can express the solution $ x $ as a linear combination of conjugate vectors:\n\\[\nx = x_0 + \\sum_{i=1}^n \\alpha_i p_i\n\\]\nwhere:\n\n\\(x_0\\) is an initial guess (can be zero).\n\\(\\alpha_i\\) are scalar coefficients.\n\\(p_i\\) are conjugate vectors with respect to \\(A\\).\n\nTo recover the coefficients of \\(\\alpha_i\\) we can use a projection in the weighted space of \\(A\\):\n\\[ \\begin{align}\nA x_0 + \\sum_{i=1}^n \\alpha_i A p_i &= b\\\\\nr &= b - A x_0\\\\\n\\sum_{i=1}^n \\alpha_i A p_i &= r\\\\\n\\langle p_i, \\sum_{i=1}^n \\alpha_i A p_i \\rangle &= \\langle p_i, r \\rangle\\\\\n\\alpha_i \\langle p_i, A p_i \\rangle &= \\langle p_i, r \\rangle\\\\\n\\alpha_i &= \\frac{\\langle p_i, r \\rangle}{\\langle p_i, A p_i \\rangle}\n\\end{align}\n\\] In the case where \\(x_0\\) is zero, then this reduces to \\[ \\alpha_i = \\frac{\\langle p_i, b \\rangle}{\\langle p_i, A p_i \\rangle} \\]\n\n\nAlgorithm Steps\nInitialize:\n\n\\(x = x_0\\)\n\\(r_0 = b - A x_0\\)\n\\(p_0 = r_0\\)\n\nFor \\(i = 0,1, 2, \\ldots\\):\n\nCompute \\(\\alpha_i\\):\n\\[\n\\alpha_i = \\frac{\\langle r_i, r_i \\rangle}{\\langle p_i, A p_i \\rangle}\n\\]\nUpdate Solution \\(x\\):\n\\[\nx_{i+1} = x_{i} + \\alpha_i p_i\n\\]\nUpdate Residual \\(r\\):\n\\[\nr_{i+1} = r_{i} - \\alpha_i A p_i\n\\]\nCheck for Convergence:\n\nIf \\(\\| r_{i+1} \\|\\) is small enough, stop.\n\nCompute \\(\\beta_i\\):\n\\[\n\\beta_i = \\frac{\\langle r_{i+1}, r_{i+1}\\rangle}{\\langle r_i,r_i \\rangle}\n\\]\nUpdate Conjugate Direction \\(p_{i+1}\\):\n\\[\np_{i+1} = r_{i+1} + \\beta_i p_i\n\\]\n\n\nThe method can be seen better if we trace through the minimization problem for fixed \\(x\\) and with variable \\(\\alpha\\):\n\\[\n\\begin{align}\n& \\min \\frac{1}{2} \\|A (x+\\alpha p) - b\\|^2  \\\\\n&= \\frac{1}{2}r^T r + \\alpha \\langle r, A p \\rangle + \\frac{1}{2} \\alpha^2 \\langle p, A^T A p \\rangle \\\\\n0 &= \\langle r, A p \\rangle + \\alpha \\langle p, A^T A p \\rangle \\\\\n\\alpha &= -\\frac{\\langle r, A p \\rangle}{\\|A p\\|^2}\n\\end{align}\n\\]\nBut we can also trace this through using the expansion of lest squares and removing the \\(\\|b\\|^2\\) term:\n\\[\n\\begin{align}\n& \\min \\frac{1}{2} \\tilde x^T A x - \\tilde x^T b  \\\\\n&= \\frac{1}{2} \\left( x^T A x + 2 \\alpha x^T A p + \\alpha^2 p^T A p \\right) - x^T b - \\alpha p^T b\\\\\n0&= x^TAp + \\alpha p^T A p - p^T b \\\\\n\\alpha &= \\frac{p^T (Ax-b)}{p^T A p}\n\\end {align}\n\\]"
  },
  {
    "objectID": "content/eosc555/lectures/lecture2/index.html",
    "href": "content/eosc555/lectures/lecture2/index.html",
    "title": "Lecture 2",
    "section": "",
    "text": "The motivation for the exercise comes from a real world problem. The Hubble space telescope when launched had a defect in its mirror. This defect caused the images to be blurred. The problem was initially addressed by using signal processing techniques to remove the aberrations from the images.\n\n\nFor such an image processing problem, we can consider the continuous incoming light as striking a 2D mirror that distorts the light, followed by a 2D sensor that captures the light. In this context we suppose that we have a noise kernel or a point spread function (PSF) that describes the distortion of the light at the mirror. The point spread function, being a convolution kernel, behaves as a Green’s function for the system in the continuous case:\n\\[ \\vec{b}(x,y) = \\int_{\\mathcal{X}} \\int_{\\mathcal{Y}} \\vec{G}(x - x', y - y') \\vec{u}(x',y') \\, dx' dy' \\]\nwhere \\(\\vec{b}(x,y)\\) is the blurred image data that is recovered at the sensor, \\(\\vec{u}(x',y')\\) is the true image data, and \\(\\vec{G}(x,y)\\) is the point spread function.\nIn the special case that the point spread function is \\(\\delta(x-x',y-y')\\), then the image data is not distorted and the sensor captures the true image data. However our experiment is to consider cases where there could be even severe distortions and see how this impacts the proposition of recovering the true image data, \\(\\vec{u}(x',y')\\) from our sensor data, \\(\\vec{b}(x,y)\\).\n\n\nThe discrete analog of the continuous PSF can be more conveniently treated with we essentially flatten the the 2D mesh into a 1D vector, a common operation for signal processing. The unflattened case we have:\n\\[ b_{ij} = \\sum_{k=1}^{n} \\sum_{l=1}^{m} \\Delta x \\Delta y G(x_i - x_k, y_j - y_l) u_{kl} \\]\nwhere \\(b\\) is the blurred image data at the sensor, \\(u\\) is the true image data, and \\(G\\) is the discrete point spread function. If we flatten the 2D mesh into a 1D vector we can represent this as a 1D convolution operation: \\[ \\vec{b} = \\vec{G} * \\vec{u} \\]\nSince this is a convolution operation, we can process it much more quickly by leveraging the convolution theorem.\n\\[\\begin{align}\n\\mathcal{F}(\\vec{b}) &= \\mathcal{F}(\\vec{G} * \\vec{u}) \\\\\n\\mathcal{F}(\\vec{b}) &= \\mathcal{F}(\\vec{G}) \\mathcal{F}(\\vec{u}) \\\\\n\\vec{b} &= \\mathcal{F}^{-1}(\\mathcal{F}(\\vec{G}) \\odot \\mathcal{F}(\\vec{u}))\n\\end{align}\n\\]\nThe \\(\\odot\\) hadamard product is element-wise multiplication, the discrete analog of multiplication of two functions except over an array.\n\n\n\n\nIf we flatten the data down into a 1D vector then it is possible to construct a matrix operator that performs the convolution. This is a Toeplitz matrix, a matrix where each descending diagonal from left to right is constant, so that the row vectors represent a sliding window of the convolution kernel. We can flatten out the PSF and construct the matrix using it as the first row entry and then shifting the PSF to the right to fill out the rest of the rows."
  },
  {
    "objectID": "content/eosc555/lectures/lecture2/index.html#least-squares-recovery-with-svd-and-pseudoinverse",
    "href": "content/eosc555/lectures/lecture2/index.html#least-squares-recovery-with-svd-and-pseudoinverse",
    "title": "Lecture 2",
    "section": "Least Squares Recovery with SVD and Pseudoinverse",
    "text": "Least Squares Recovery with SVD and Pseudoinverse\nNow that we have a matrix operator recovered we can formulate the forward problem as \\(A\\mathbf{x} = \\mathbf{b}\\) with our known \\(A\\) and \\(\\mathbf{b}\\), and we want to recover \\(\\mathbf{x}\\). To do this we use the SVD decomposition to gather the pseudo inverse. We can decide to filter out some of the singular values that are very small to improve the conditioning on the matrix as well, using a cutoff value for example.\n\nSVD Decomposition\n\n\nShow the code\nU, S, V = torch.svd(Amat.to(torch.float64))\nb = Amv(x)\n\n\nNow we make a log plot of the singular values to see how they decay, noting that we lose numerical precision around the \\(10^{-6}\\) mark. We can also asses what the frobenius norm of the difference between the original matrix and the reconstructed matrix is to get a sense of the error in the decomposition and reconstruction.\n\n\nShow the code\nplt.semilogy(S)\nplt.xlabel('Singular Value Index')\nplt.ylabel('Singular Value')\n\nloss = F.mse_loss(Amat, U @ torch.diag(S) @ V.T)\nprint(f\"The loss is {loss}\")\n\n\nThe loss is 1.812403923995022e-34\n\n\n\n\n\nSVD Decomposition of the Convolution Matrix.\n\n\n\n\nThe loss is quite small which is a good sign that the decomposition is working well within the numerical precision of the machine.\n\n\nInitial Attempt at Pseudoinverse\nTo recover the original image data we first naively try to invert the matrix to see what happens.\n\n\nShow the code\nxhat = torch.linalg.solve(Amat,b.reshape(dim**2))\nplt.subplot(1,2,1)\nplt.imshow(xhat.reshape(x.shape[-2:]))\nplt.title('Naive Inverse')\nplt.subplot(1,2,2)\nplt.imshow(x.reshape(x.shape[-2:]))\nplt.title('Original Image');\n\n\n\n\n\nNaive Pseudoinverse Recovery of the Original Image.\n\n\n\n\nWow, not even close! This is because the matrix is so ill conditioned that it is effectively low rank and not invertible. We can improve the situation by filtering out the singular values that are very small.\n\n\nPseudoinverse with Filtering\nWe can filter out the poor conditioning singular values and exclude those values from the inversion. To get an idea of what the values are doing, we can plot the first few singular values and the corresponding singular vector that they project onto. In the case of the SVD the most important information about the matrix is captured in the left-most vectors of the matrix \\(U\\).\n\n\nShow the code\nn= 5\nfor i in range(n):\n  plt.subplot(1,n,i+1)\n  plt.imshow(U[:,i+1].reshape(x.shape[-2:]))\n  plt.title(f'Mode {i}')\n\n\n\n\n\n\n\n\n\nFor the inverse problem, the most import singular values are conversely found in the left-most vectors of the matrix \\(V\\). We can also check what the right-most vectors are doing, as they will blow up in value when inverting small singular values. They are high frequency modes of the image, creating the reconstruction issues when they are subjected to error in numerical precision.\n\n\nShow the code\nn= 5\nfor i in range(n):\n  plt.subplot(1,n,i+1)\n  plt.imshow(V[:,i+1].reshape(x.shape[-2:]))\n  plt.title(f'Mode {i}')\nplt.show()\n\nfor i in range(n):\n  plt.subplot(1,n,i+1)\n  plt.imshow(V[:,-(i+1)].reshape(x.shape[-2:]))\n  plt.title(f'Mode {V.shape[1]-i}')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThese modes are the most important ones, as they contain the big-picture detail without the high frequency noise. We can now filter out the singular values that are very small and invert the matrix to recover the original image.\n\n\nShow the code\nb_flat = b.flatten().to(torch.float64)\nx_flat = x.flatten().to(torch.float64)\nthresholds = [1e-1, 1e-3, 1e-6, 1e-7, 1e-8, 1e-10]\n\nplt.figure(figsize=(7,5))  # Adjust the figure size as needed\n\nfor idx, threshold in enumerate(thresholds):\n    # Filter the singular values\n    S_filtered = S.clone()\n    S_filtered[S_filtered &lt; threshold] = 0\n\n    # Compute the reciprocal of the filtered singular values\n    S_inv = torch.zeros_like(S_filtered)\n    non_zero_mask = S_filtered &gt; 0\n    S_inv[non_zero_mask] = 1 / S_filtered[non_zero_mask]\n\n    # Construct the pseudoinverse of Amat\n    A_pinv = V @ torch.diag(S_inv) @ U.T\n\n    # Reconstruct the original image\n    xhat = A_pinv @ b_flat\n\n    # Compute the reconstruction error\n    error = torch.norm(xhat - x_flat, p='fro').item()\n\n    # Plot the reconstructed image in the appropriate subplot\n    plt.subplot(2, 3, idx + 1)  # idx + 1 because subplot indices start at 1\n    plt.imshow(xhat.reshape(x.shape[-2:]))\n    plt.title(f'Threshold {threshold}\\nError: {error:.4f}')\n    plt.colorbar()\n    plt.axis('off')  # Optionally turn off axis ticks and labels\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nPseudoinverse Recovery of the Original Image with Filtering.\n\n\n\n\nLooking at the results, around the \\(10^{-7}\\) mark we start to a peak level of recovery, as measured by the error in the Frobenius norm of the reconstruction. But what happens when we add noise to the data signal?\n\n\nAdding Noise to the Signal\nNow we add some noise to the signal and try least squares again for the direct solution\n\n\nShow the code\nb_flat = b.flatten().to(torch.float64)\nx_flat = x.flatten().to(torch.float64)\nAmat = Amat.to(torch.float64)\n\nalpha = .01\nnoise = torch.randn_like(b_flat) * alpha\n\nH = Amat.T @ Amat + alpha**2 * torch.eye(Amat.shape[0])\nxhat = torch.linalg.solve(H, Amat.T @ (b_flat + noise))\n\nplt.subplot(1,2,1)\nplt.imshow(x[0,0])\nplt.title('Original Image')\nplt.subplot(1,2,2)\nplt.imshow(xhat.reshape(x.shape[-2:]))\nplt.title('Reconstructed Image');\n\n\n\n\n\nPseudoinverse Recovery of the Original Image with Noise.\n\n\n\n\nThe reconstruction is not very good, the noise has been amplifed all over the image. We can try the pseudoinverse method again with the noise added to the signal.\n\n\nShow the code\nAmat_noisy = Amat + alpha * torch.eye(Amat.shape[0])\nUn, Sn, Vn = torch.svd(Amat_noisy)\n\nthresholds = [.5, .1, .05, .03, .005, .001]\n\nplt.figure(figsize=(7,5))  # Adjust the figure size as needed\n\nfor idx, threshold in enumerate(thresholds):\n    # Filter the singular values\n    S_filtered = Sn.clone()\n    S_filtered[S_filtered &lt; threshold] = 0\n\n    # Compute the reciprocal of the filtered singular values\n    S_inv = torch.zeros_like(S_filtered)\n    non_zero_mask = S_filtered &gt; 0\n    S_inv[non_zero_mask] = 1 / S_filtered[non_zero_mask]\n\n    # Construct the pseudoinverse of Amat\n    A_pinv = Vn @ torch.diag(S_inv) @ Un.T\n\n    # Reconstruct the original image\n    xhat = A_pinv @ (b_flat + noise)\n\n    # Compute the reconstruction error\n    error = torch.norm(xhat - x_flat, p='fro').item()\n\n    # Plot the reconstructed image in the appropriate subplot\n    plt.subplot(2, 3, idx + 1)  # idx + 1 because subplot indices start at 1\n    plt.imshow(xhat.reshape(x.shape[-2:]))\n    plt.title(f'Threshold {threshold}\\nError: {error:.4f}')\n    plt.colorbar()\n    plt.axis('off')  # Optionally turn off axis ticks and labels\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nPseudoinverse Recovery of the Original Image with Noise.\n\n\n\n\nThe small addition of noise is quite significant in the recovery threshold for reconstruction. Using a higher threshold for the singular values becomes important when dealing with noise in the signal. Previously numerical precision was the main issue, but now the measurement noise is the main issue."
  },
  {
    "objectID": "content/eosc555/lectures/lecture10/index.html",
    "href": "content/eosc555/lectures/lecture10/index.html",
    "title": "Lecture 10",
    "section": "",
    "text": "$$ \n$$"
  },
  {
    "objectID": "content/eosc555/lectures/lecture10/index.html#gradient-descent-with-score-function",
    "href": "content/eosc555/lectures/lecture10/index.html#gradient-descent-with-score-function",
    "title": "Lecture 10",
    "section": "Gradient Descent with Score Function",
    "text": "Gradient Descent with Score Function\n\n\n\n\n\n\nDefinitions\n\n\n\n\n\n\n\n\n\n\n\nComponent\nDescription\nDimensions\n\n\n\n\n\\(F(x)\\)\nForward operator\n\\(\\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\)\n\n\n\\(x\\)\nModel parameters\n\\(\\mathbb{R}^n\\)\n\n\n\\(b\\)\nObserved data\n\\(\\mathbb{R}^m\\)\n\n\n\\(\\epsilon\\)\nNoise\n\\(\\mathbb{R}^m\\)\n\n\n\\(\\pi(x)\\)\nProbability distribution\n\n\n\n\\(\\phi(x,\\theta)\\)\nPotential function\n\\(\\mathbb{R}^n \\rightarrow \\mathbb{R}\\)\n\n\n\\(\\theta\\)\nLearnable Parameters\n\\(\\mathbb{R}^p\\)\n\n\n\\(Z(\\theta)\\)\nPartition Function\n\\(\\mathbb{R}\\)\n\n\n\\(s(x, \\theta)\\)\nScore Function\n\\(\\mathbb{R}^n\\)\n\n\n\n\n\nThe classic inverse problem is defined as\n\\[b = F(x) + \\epsilon\\]\nwhere \\(F(x)\\) is the forward operator, \\(b\\) is the observed data, and \\(\\epsilon\\) represents the noise in the measurement or process. We often assume that \\(\\epsilon\\) is Gaussian with zero mean and covariance matrix \\(\\Sigma\\).\n\\[ \\epsilon \\sim \\mathcal{N}(0, \\Sigma) \\]\nThe probability of deviation of the observed data from the forward model in this case is given by: \\[\n\\pi(\\epsilon) = \\frac{1}{(2\\pi)^{m/2}|\\Sigma|^{1/2}} \\exp\\left(-\\frac{1}{2}\\epsilon^\\intercal \\Sigma^{-1} \\epsilon\\right)\n\\]\nWithout any prior information about the error, it is difficult to estimate the covariance matrix \\(\\Sigma\\). For the purpose of this analysis we can assume that it is a normal distriution with zero mean and a diagonal \\(\\sigma^2 I\\) covariance matrix. The likelihood function simplifies to:\n\\[ \\pi(\\epsilon) = \\frac{1}{(2\\pi \\sigma^2)^{m/2}} \\exp\\left(-\\frac{1}{2\\sigma^2}\\|b-F(x)\\|^2 \\right) \\]\nTo model the probability distribution of the inverse problem parameters \\(x\\), we introduce a prior distribution \\(\\pi(x)\\). To ensure positivity of \\(\\pi(x)\\) over the entire domain and proper normalization, we define it using a potential function \\(\\phi(x, \\theta)\\): \\[\\pi(x; \\theta) = \\frac{e^{-\\phi(x, \\theta)}}{Z(\\theta)}\\]\nWhere the partion function \\(Z(\\theta)\\) is given by:\n\\[Z(\\theta) = \\int_\\Omega e^{-\\phi(x, \\theta)} dx\\]\nNote the partition function is required to make the probability distribution integrate to \\(1\\). The exponential operator on the potential ensures that all \\(\\pi(x)\\) values are positve since \\(e^\\phi &gt; 0\\) for all \\(z \\in \\mathbb{R}\\). In practice, it is often intractable to directly compute the partition function when updating the model parameters \\(\\theta\\) for distributions that are more complex than a Gaussian.\n\\(\\phi(x, \\theta): \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) maps \\(x\\) to a scalar value, and \\(\\theta\\) are the parameters of the model. For example if we are modeling a Gaussian, the parameters might include the covariance matrix \\(\\Sigma\\). It has a physical interpretation as an energy of a system, where \\(\\phi\\) values correspond to low probability density regions. For this reason it is often called the energy function in physics-inspired models.\n\nMaximum A Posteriori Estimation\nThe goal of maximum a posteriori (MAP) estimation is to find the most likely \\(x\\) given the observed data \\(b\\) and model parameters \\(\\theta\\), maximize the posterior probability \\(\\pi(x|b; \\theta)\\):\n\\[\n\\begin{align*}\n\\max_x \\pi(x|b; \\theta) &= \\max_x \\frac{\\pi(b|x; \\theta) \\pi(x; \\theta)}{\\pi(b)}\\\\\n\\max_x \\underbrace{\\pi(x|b; \\theta)}_{\\text{Posterior}} & = \\max_x \\underbrace{\\pi(b|x; \\theta)}_{\\text{Likelihood}} \\underbrace{\\pi(x; \\theta)}_{\\text{Prior}}\\\\\n\\end{align*}\n\\]\nSince \\(\\pi(b)\\) is independent of \\(x\\), it does not affect the maximization problem. Substituting the likelihood and prior distributions, we have:\n\\[\n\\begin{align*}\n& = \\max_x \\frac{1}{(2\\pi \\sigma^2)^{m/2}} \\exp\\left(-\\frac{1}{2\\sigma^2}\\|b-F(x)\\|^2 \\right) \\frac{1}{Z(\\theta)} e^{-\\phi(x, \\theta)}\n\\end{align*}\n\\]\nThe logarithm is a monotonic function, we can maximize the log-likelihood instead of the likelihood with no loss of generality. \\(\\max_x \\pi(x) = \\max_x \\log(\\pi(x))\\). Intuitively, since the logarithim is always increasing in output, \\(\\log(z) &gt; \\log(y)\\) implies \\(z &gt; y\\). In addition the product of two exponentials is the same as the sum of the exponents, and the maximum of a function is the same as the minimum of the negative of the function. This allows us to rewrite the log-likelihood as:\n\n\n\n\n\n\nMinimization Objective\n\n\n\n\\[\\max_x \\log \\pi(x|b; \\theta) = \\min_x \\left( \\frac{1}{2\\sigma^2}\\|b-F(x)\\|^2 + \\phi(x, \\theta) \\right)\\]\n\n\nWe have looked at methods previously of how to differentiate the forward operator \\(F\\) and perform gradient descent. We take the gradient with respect to \\(x\\) to find the minimum of the function.\n\\[\n\\begin{align*}\ng &= \\nabla_x \\left(\\frac{1}{2\\sigma^2}\\|b-F(x)\\|^2 - \\phi(x, \\theta)\\right)\\\\\n&= \\frac{1}{\\sigma^2} \\frac{\\partial F}{\\partial x} (F(x) - b) - \\nabla_x \\phi(x, \\theta)\\\\\n&= \\frac{1}{\\sigma^2} J^T(x) (F(x) - b) + s(x, \\theta)\n\\end{align*}\n\\]\nUsing gradient descent, we can update the model parameters \\(\\theta\\) by taking steps in away from the direction of the gradient \\(g\\):\n\\[x_{k+1} = x_k - \\alpha g\\]"
  },
  {
    "objectID": "content/eosc555/lectures/lecture10/index.html#score-function",
    "href": "content/eosc555/lectures/lecture10/index.html#score-function",
    "title": "Lecture 10",
    "section": "Score Function",
    "text": "Score Function\n\\(s(x;\\theta)\\) is known as the score function of \\(\\pi(x; theta)\\). \\[s(x, \\theta):= \\nabla_x \\log (\\pi(x)) = - \\nabla_x \\phi(x, \\theta) + C\\]\nIt is the negative gradient of the potential function \\(\\phi(x, \\theta)\\) with respect to \\(x\\). The score function is a generalization of the gradient of the log-likelihood function, and is described in more detail in Schervish’s “Theory of Statistics” (Schervish 1995).\nScore has a physical intution connected to energy potentials and fields. In physics, the electric field \\(\\mathbf{E}\\) is the negative gradient of the electric potential \\(V\\): \\[ \\mathbf{E} = -\\nabla_x V(x)\\]\nSimalarly, the score function is the negative gradient of the potential function \\(\\phi(x, \\theta)\\) in the case where \\(\\pi(x) = e^{-\\phi(x, \\theta)}\\). The score function is the direction in which the probability distribution is most likely to change.\n\nExample: 2D Gaussian Distribution\nConsider a 2D Gaussian distribution with zero mean and covariance \\(\\sigma^2 I\\):\n\n\n\n\n\n\n\nFunction\nExpression\n\n\n\n\nProbability Distribution\n\\(\\pi(x) = \\frac{1}{2\\pi \\sigma^2}\\exp\\left( -\\frac{1}{2\\sigma^2} \\| x \\|^2 \\right)\\)\n\n\nPotential Function\n\\(\\phi(x, \\theta) =  - \\frac{1}{2\\sigma^2} \\| x \\|^2 - \\log(2\\pi \\sigma^2)\\)\n\n\nScore Function\n\\(-\\nabla_x \\phi(x, \\theta) = -\\left( -\\frac{x}{\\sigma^2} x \\right) = \\frac{x}{\\sigma^2}\\)\n\n\n\nIn regions of high probability density, the potential function is low becuase the relation \\(\\pi(x) = e^{-\\phi(x, \\theta)}\\) is monotonic in \\(\\phi(x, \\theta)\\). The score funtion is always pointing in the local direction of the largest directional derivative of the probability distribution \\(\\pi\\).\n\n\nVisualization\nBelow is a visualization of the probability density function (PDF), potential function, and score function of a 2D Gaussian distribution.\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Make plots for a 2D Gaussian distribution heatmap, potential function, and score function\n\n# Define the 2D Gaussian distribution\ndef gaussian_pdf(x, y, sigma=1):\n    return np.exp(-0.5*(x**2 + y**2)/sigma**2)/(2*np.pi*sigma**2)\n\n# Define the potential function\ndef potential_function(x, y, sigma=1):\n    return 0.5*(x**2 + y**2)/sigma**2 - np.log(2*np.pi*sigma**2)\n\n# Define the score function\ndef score_function(x, y, sigma=1):\n    return -np.array([x, y])/sigma**2\n\n# Create a grid of points\nx = np.linspace(-3, 3, 500)\ny = np.linspace(-3, 3, 500)\nX, Y = np.meshgrid(x, y)\n\n# Compute the PDF, potential function, and score function\npdf = gaussian_pdf(X, Y)\npotential = potential_function(X, Y)\nscore = score_function(X, Y)\n\n# Plot the Probability Distribution with a colorbar\nplt.figure(figsize=(4, 3))\nim = plt.imshow(pdf, cmap='viridis', extent=[-3, 3, -3, 3])\nplt.axis('off')\nplt.colorbar(im, shrink=0.8, label=\"Density\")\nplt.show()\n\n# Plot the Potential Function with a colorbar\nplt.figure(figsize=(4, 3))\nim = plt.imshow(potential, cmap='viridis', extent=[-3, 3, -3, 3])\nplt.axis('off')\nplt.colorbar(im, shrink=0.8, label=\"Potential\")\nplt.show()\n\n# Downsample the grid for quiver plotting\nstep = 50  # Downsample by taking every 50th point\nX_downsampled = X[::step, ::step]\nY_downsampled = Y[::step, ::step]\nscore_downsampled = score_function(X_downsampled, Y_downsampled)\n\n# Plot the Score Function as a quiver plot over the PDF\nplt.figure(figsize=(4, 3))\nplt.imshow(pdf, cmap='viridis', extent=[-3, 3, -3, 3])\nplt.quiver(\n    X_downsampled, Y_downsampled, \n    score_downsampled[0], score_downsampled[1], \n    color='black'\n)\nplt.axis('off')\n\n# Save to file\nplt.savefig(\"imgs/score_function.png\", bbox_inches='tight')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Probability Distribution\n\n\n\n\n\n\n\n\n\n\n\n(b) Potential Function\n\n\n\n\n\n\n\n\n\n\n\n(c) Score Function\n\n\n\n\n\n\n\nFigure 1: PDF, Potential Function, and Score Function of a 2D Gaussian Normal Distribution"
  },
  {
    "objectID": "content/eosc555/lectures/lecture10/index.html#maximum-likelihood-estimate-from-samples",
    "href": "content/eosc555/lectures/lecture10/index.html#maximum-likelihood-estimate-from-samples",
    "title": "Lecture 10",
    "section": "Maximum Likelihood Estimate from Samples",
    "text": "Maximum Likelihood Estimate from Samples\nA common problem is estimating a probability distribution \\(\\pi(x)\\) based on a set of empirical samples \\(\\{x_1, x_2, ..., x_N\\}\\). Often in statistical analysis, we are working with an unknown \\(\\pi\\) and attempting to make our best estimate from sampled data. If we assume that the drawn samples are independent and identically distributed (i.i.d.), then the likelihood of the samples is the product of the likelihood of each sample. Recalling that \\(Z(\\theta) = \\int_\\Omega \\pi(x) dx\\), the likelihood of the samples is:\n\\[\n\\begin{align*}\n\\pi(x_1, x_2, ..., x_N) &= \\prod_{i=1}^N \\pi(x_i) = \\pi(x_1) \\pi(x_2) ... \\pi(x_N) \\\\\n&= \\frac{1}{Z(\\theta)} \\exp\\left(-\\phi(x_1, \\theta)\\right) \\frac{1}{Z(\\theta)} \\exp\\left(-\\phi(x_2, \\theta)\\right) ... \\frac{1}{Z(\\theta)} \\exp\\left(-\\phi(x_N, \\theta)\\right) \\\\\n&= \\frac{1}{\\left[Z(\\theta)\\right]^N} \\exp\\left(-\\sum_{i=1}^N \\phi(x_i, \\theta)\\right)\n\\end{align*}\n\\]\nSince some \\(x\\) are observed, the challenge is to find the potential function \\(\\phi(x, \\theta)\\) that maximizes the likelihood of the samples, given the model parameters \\(\\theta\\) and a fixed family of \\(\\phi(,;\\theta)\\) functions.\nThe Maximum Likelihood Estimation (MLE) is the process of finding the parameters \\(\\theta\\) that maximize the likelihood of having observed the samples. Unlike the MAP estimate, there is no posterior and prior distribution. So in this case \\(\\pi(x|\\theta)\\) is being directly maximized. This is equivalent to minimizing the negative log-likelihood as before:\n\\[\n\\begin{align*}\n\\text{MLE} &= \\text{argmax}_\\theta \\frac{1}{\\left[Z(\\theta)\\right]^N} \\exp\\left(-\\sum_{i=1}^N \\phi(x_i, \\theta)\\right)\\\\\n&= \\operatorname*{argmin}_\\theta N \\log(Z(\\theta)) + \\sum_{i=1}^N \\phi(x_i, \\theta)\\\\\n&= \\operatorname*{argmin}_\\theta \\log(Z(\\theta)) + \\frac{1}{N} \\sum_{i=1}^N \\phi(x_i, \\theta)\n\\end{align*}\n\\]\nHowever we again run into the problem of the partition function \\(Z(\\theta)\\) which for most distributions in higher dimensions is intractable to compute. For example we may be trying to solve an integral in \\(100\\) dimensions with no analytical solution.\n\\[ \\int_{x_1} \\int_{x_2} ... \\int_{x_{100}} e^{-\\phi(x, \\theta)} dx_1 dx_2 ... dx_{100} \\]\n\nMinimizing with Gradient Descent\n\n\n\n\n\n\nMinimization Objective\n\n\n\n\\[ \\text{MLE} = \\operatorname*{argmin}_\\theta \\left( \\log(Z(\\theta)) + \\frac{1}{N} \\sum_{i=1}^N \\phi(x_i, \\theta) \\right) \\]\n\n\nThe gradient of the MLE objective with respect to \\(\\theta\\) is:\n\\[\n\\begin{align*}\ng &= \\nabla_\\theta \\left( \\log(Z(\\theta)) + \\frac{1}{N} \\sum_{i=1}^N \\phi(x_i, \\theta) \\right)\\\\\n&= \\nabla_\\theta \\log(Z(\\theta)) + \\frac{1}{N} \\sum_{i=1}^N \\nabla_\\theta \\phi(x_i, \\theta)\n\\end{align*}\n\\]\nThe left side term can be further reduced by using the definition of the partion function \\(Z(\\theta) =  \\int_\\Omega e^{-\\phi(x, \\theta)} dx\\), the probability distribution \\(\\pi_\\theta(x) = e^{-\\phi(x, \\theta)}\\):\n\\[\n\\begin{align*}\n\\nabla_\\theta \\log(Z(\\theta)) &= \\frac{1}{Z(\\theta)}\\nabla_\\theta \\int_\\Omega e^{-\\phi(x, \\theta)} dx\\\\\n&= \\int_\\Omega \\frac{1}{Z(\\theta)}  \\nabla_\\theta e^{-\\phi(x, \\theta)} dx\\\\\n&= - \\int_\\Omega \\frac{1}{Z(\\theta)} e^{-\\phi(x, \\theta)} \\nabla_\\theta \\phi(x, \\theta) dx\\\\\n&= - \\int_\\Omega \\pi(x) \\nabla_\\theta \\phi(x, \\theta) dx\\\\\n&=  \\mathbb{E}_{x \\sim \\pi_\\theta(x)} \\left[ -\\nabla_\\theta \\phi(x, \\theta) \\right]\\\\\n& \\approxeq \\frac{1}{M} \\sum_{i=1}^M -\\nabla_\\theta \\phi(x_i, \\theta)\n\\end{align*}\n\\]\nWe estimate the value of \\(\\nabla_\\theta \\log(Z(\\theta))\\) by taking the expectation value of the score function over the samples. This is a Monte Carlo approximation of the true integral using the available i.i.d. samples \\(\\{ x_1, x_2, ..., x_N \\}\\). The gradient of the MLE objective is then:\n\n\n\n\n\n\nScore Matching Gradient\n\n\n\n\\[ g = \\underbrace{-\\frac{1}{M} \\sum_{i=1}^M \\nabla_\\theta \\phi(\\tilde x_i, \\theta)}_{\\text{Synthesis}} + \\underbrace{\\frac{1}{N} \\sum_{i=1}^N \\nabla_\\theta \\phi(x_i, \\theta)}_{\\text{Analysis}}\\]\n\n\nAn optimal point is reached by first order optimality conditions, where the gradient is zero. The MLE objective is minimized when the synthesis and analysis terms are equal. This is known as score matching and is a method for estimating the parameters of a probability distribution from samples. The synthesis \\(\\tilde x_i\\) terms are drawn randomly from the proposed score \\(\\phi(\\tilde x_i, \\theta)\\) , while the analysis \\(x_i\\) terms are taken over the samples \\(\\{x_1, x_2, ..., x_N\\}\\).\nAs before gradient descent can be used to update the model parameters \\(\\theta\\):\n\\[\\theta_{k+1} = \\theta_k - \\alpha g\\]"
  },
  {
    "objectID": "content/eosc555/lectures/lecture10/index.html#an-application-of-score-langevin-dynamics",
    "href": "content/eosc555/lectures/lecture10/index.html#an-application-of-score-langevin-dynamics",
    "title": "Lecture 10",
    "section": "An Application of Score: Langevin Dynamics",
    "text": "An Application of Score: Langevin Dynamics\nAn example of the usage of a learned score function is in Langevin Dynamics. Langevin Dynamics is a method for sampling from a probability distribution \\(\\pi(x)\\) by simulating a stochastic differential equation (SDE) that converges to the distribution. The SDE is given by:\n\\[dx = -\\nabla_x \\phi(x, \\theta) dt + \\sqrt{2} dW\\]\nThe score function pushes samples towards regions of high probability density, since it is a vector that points in the direction of maximum increase of the probability distribution. The noise term \\(dW\\) is a Wiener process, which is a continuous-time stochastic process that is normally distributed with mean zero and variance \\(dt\\). The Langevin Dynamics algorithm is a discretized version of the SDE:\n\\[x_{k+1} = x_k - \\underbrace{\\Delta t \\nabla_x \\phi(x_k, \\theta)}_\\text{Score Term} + \\underbrace{\\sqrt{2 \\Delta t} z_k}_\\text{Stochastic Term}\\]\nWhere \\(z_k \\sim \\mathcal{N}(0,1)\\) is a random sample from a normal distribution with zero mean and unit variance.\nThe score points in the same direciton as the gradient of the probability distribution, so at each time step, the score term moves the sample to a higher probability region. The stochastic term adds noise to the sample, providing randomness to the process.\n\nCode Example\nBelow is an example of Langevin Dynamics applied to a 2D Gaussian distribution. The score function is used to push the samples towards the center of the distribution, while the stochastic element adds noise and randomization to the process. The animation show an intial uniform sampling grid of points converging to the shape of the Gaussian distribution.\n\n\n\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport seaborn as sns\n\n# Ensure the Pillow writer is available\nfrom matplotlib.animation import PillowWriter\n\n# Define the 2D Gaussian distribution\ndef gaussian_pdf(x, y, sigma=1):\n    return np.exp(-0.5*(x**2 + y**2)/sigma**2)/(2*np.pi*sigma**2)\n\n# Define the potential function\ndef potential_function(x, y, sigma=1):\n    return 0.5*(x**2 + y**2)/sigma**2 - np.log(2*np.pi*sigma**2)\n\n# Define the score function\ndef score_function(x, y, sigma=1):\n    return -np.array([x, y])/sigma**2\n\n# Define the Langevin Dynamics update\ndef langevin_dynamics(samples, sigma=1, dt=0.05):\n    z = np.random.normal(0, 1, samples.shape)\n    score = score_function(samples[:, 0], samples[:, 1], sigma)\n    samples = samples + dt * score.T + np.sqrt(2 * dt) * z\n    return samples\n\n# Create a grid of points for the contour plot\nx = np.linspace(-3, 3, 500)\ny = np.linspace(-3, 3, 500)\nX, Y = np.meshgrid(x, y)\n\n# Compute the PDF for contour plotting\nsigma = .5\npdf = gaussian_pdf(X, Y, sigma)\n\n# Initialize samples on a 5x5 grid\ngrid_size = 10\ngrid_range = np.linspace(-2.5, 2.5, grid_size)\ninitial_samples = np.array([[x, y] for x in grid_range for y in grid_range])\nsamples = initial_samples.copy()\n\n# Set up the figure and axis\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot the initial contour\ncontour = ax.contourf(X, Y, pdf, levels=50, cmap='viridis')\nscatter = ax.scatter(samples[:, 0], samples[:, 1], color='red', s=30, label='Samples')\n\n# Add a legend\nax.legend()\n\n# Function to update the animation at each frame\ndef update(frame):\n    global samples\n    samples = langevin_dynamics(samples, dt=0.002, sigma=sigma)\n    scatter.set_offsets(samples)\n    ax.set_title(f'Langevin Dynamics Iteration: {frame+1}')\n    return scatter,\n\n# Create the animation\nani = animation.FuncAnimation(\n    fig, update, frames=400, interval=200, blit=True, repeat=False\n)\n\n# Save the animation as a GIF\nani.save(\"imgs/langevin_dynamics.gif\", writer=\"imagemagick\", fps=10)\n\n# Display the animation inline (if supported)\nplt.close(fig)\n\n\n\nFigure 2\n\n\n\n\n\n\nLangevin Dynamics to a 2d Gaussian"
  },
  {
    "objectID": "content/eosc555/lectures/lecture10/index.html#map-estimation-with-general-gaussian",
    "href": "content/eosc555/lectures/lecture10/index.html#map-estimation-with-general-gaussian",
    "title": "Lecture 10",
    "section": "MAP Estimation with General Gaussian",
    "text": "MAP Estimation with General Gaussian\nRevisitng the MAP estimation problem, we can consider a more general prior \\(\\pi(x)\\) with mean \\(\\mu = 0\\) and covariance \\(\\Sigma\\):\n\\[\n\\begin{align*}\n\\pi(b|x) &= \\frac{1}{(2\\pi \\sigma^2)^{m/2}} \\exp\\left(-\\frac{1}{2\\sigma^2}\\|b-F(x)\\|^2 \\right)\\\\\n\\pi_\\theta(x) &= \\frac{1}{(2\\pi)^{n/2}|\\Sigma|^{1/2}} \\exp\\left(-\\frac{1}{2}x^\\intercal \\Sigma^{-1} x\\right)\\\\\n\\text{MAP} &= \\min_x \\left( \\frac{1}{2\\sigma^2}\\|b-F(x)\\|^2 + \\frac{1}{2}x^\\intercal \\Sigma^{-1} x \\right)\n\\end{align*}\n\\]\nWe now make a choice of which \\(pi_\\theta(x)\\) to use, as before this is a MLE based on the available empirical samples. For the purpose of finding the gradient, let the minimization parameters be \\(\\theta = \\Sigma^{-1}\\), since the true \\(\\Sigma\\) is positive definite, it can be found by inverting this result. The partition function \\(Z(\\theta)\\) is known for the case of a Gaussian distribution, and so the MLE objective is:\n\\[\n\\begin{align*}\n\\pi(x) &= \\max_\\theta \\Pi_{i=1}^N \\pi_\\theta(x_i)\\\\\n&= \\max_\\theta \\frac{1}{Z(\\theta)^N} \\exp\\left(-\\sum_{i=1}^N \\frac{1}{2}x_i^\\intercal \\Sigma^{-1} x_i\\right)\\\\\n&= \\min_\\theta N \\log(Z(\\theta)) + \\frac{1}{2} \\sum_{i=1}^N x_i^\\intercal \\Sigma^{-1} x_i\\\\\n&= \\min_\\theta -\\log((2\\pi)^{n/2}|\\Sigma|^{1/2}) + \\frac{1}{2N} \\sum_{i=1}^N x_i^\\intercal \\Sigma^{-1} x_i\\\\\n&= \\min_\\theta -\\frac{1}{2}\\log(|\\Sigma|) + \\frac{1}{2N} \\sum_{i=1}^N x_i^\\intercal \\Sigma^{-1} x_i\n\\end{align*}\n\\]\n\nFinding the Gradient\nLeft Term: To find the min using gradient descent we take the gradient of each term with respect to \\(\\Sigma^{-1}\\). The gradient of a log determinant can be found in the matrix cookbook (Petersen and Pedersen 2012) formula (57): \\[ \\nabla_{A} \\log(|A|) = (A^{-1})^\\intercal \\]\nThis can be rewritten as:\n\\[ \\nabla_A \\log(|A^{-1}|) = A^\\intercal\\]\nApplying this to the left term we get:\n\\[ \\nabla_{\\Sigma^{-1}} \\left( -\\frac{1}{2}\\log(|\\Sigma|) \\right) = -\\frac{1}{2} \\Sigma\\]\nRight Term: The gradient of the second term is found by reformulating it as a trace of a new matrix \\(X = \\sum x_i x_i^\\intercal\\):\n\\[\n\\begin{align*}\n\\sum x_j^\\intercal \\Sigma^{-1} x_j &= \\sum \\text{trace} \\left( x_j^\\intercal  \\Sigma^{-1} x_j \\right)\\\\\n&= \\sum \\text{trace} \\left(  \\Sigma^{-1} x_j x_j^\\intercal \\right)\\\\\n&= \\text{trace} \\left(  \\Sigma^{-1} X\\right)\\\\\n\\end{align*}\n\\]\nThe matrix cookbook (Petersen and Pedersen 2012) formula (100) gives the gradient of the trace of a matrix product:\n\\[ \\nabla_X \\text{trace}(XB) = B^\\intercal\\]\nApplying this we get:\n\\[ \\nabla_{\\Sigma^{-1}} \\left( \\frac{1}{2N} \\sum x_i^\\intercal \\Sigma^{-1} x_i \\right) = \\frac{1}{2N} X^\\intercal = \\frac{1}{2N} \\sum x_i x_i^\\intercal\\]\nCombined Result:\nCombining the two terms we get the gradient of the MLE objective with respect to \\(\\Sigma^{-1}\\): \\[\n\\begin{align*}\ng &= \\nabla_{\\Sigma^{-1}} \\left( \\frac{1}{2}\\log(|\\Sigma|^{-1}) + \\frac{1}{2N} \\sum_{i=1}^N x_i^\\intercal \\Sigma^{-1} x_i \\right)\\\\\n&= \\frac{1}{2} \\Sigma^\\intercal - \\frac{1}{2N} \\sum_{i=1}^N x_i x_i^\\intercal\n\\end{align*}\n\\]\nSolving for where the gradient is zero, we find the optimal value of \\(\\Sigma\\), since \\(\\Sigma = \\Sigma^\\intercal\\):\n\\[ \\Sigma = \\frac{1}{N} \\sum_{i=1}^N x_i x_i^\\intercal\\]\nThis is the maximum likelihood estimate of the covariance matrix \\(\\Sigma\\) given the samples \\(\\{x_1, x_2, ..., x_N\\}\\), which can be interpreted as the expectation value of the outer product of the samples. The estimated covariance matrix is the actual true covariance matrix of the sampled data. This is a common result in statistics, where the sample mean is the MLE of the true mean of the distribution.\nUnfortunately, estimating parameters can be very difficult to do for non-Gaussian \\(\\pi_\\theta\\) due to the partition function \\(Z(\\theta)\\) being intractable."
  },
  {
    "objectID": "content/eosc555/lectures/lecture10/index.html#conclusion",
    "href": "content/eosc555/lectures/lecture10/index.html#conclusion",
    "title": "Lecture 10",
    "section": "Conclusion",
    "text": "Conclusion\nMAP estimation on an inverse problem may require the use of a prior distribution \\(\\pi(x)\\) to regularize the solution. The potential function \\(\\phi(x, \\theta)\\) is used to define the probability distribution \\(\\pi(x; \\theta)\\), and the score function \\(s(x, \\theta)\\) is the negative gradient of the potential function.\nIf the prior is not known, an MLE estimate can be made to find the parameters \\(\\theta\\) that maximize the likelihood of the samples based on an assumed parameterized model. The score matching gradient is used to estimate the gradient of the MLE objective with respect to \\(\\theta\\)."
  },
  {
    "objectID": "content/eosc555/index.html",
    "href": "content/eosc555/index.html",
    "title": "EOSC 555B: Nonlinear Inverse Theory",
    "section": "",
    "text": "Lecture notes for EOSC 555B: Nonlinear Inverse Theory taken at the University of British Columbia. Portions of template code originate from the course instrcutor Prof. Eldad Haber, while I’ve added some of my own numerical experiments and examples explored as part of self-study on the topics.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 11\n\n\nScore Matching and Diffusion\n\n\nScore matching has been used in machine learning to estimate the parameters of a probability distribution from emiprical samples. This lecture will introduce the concept of score matching and its connection to diffusion models and generative AI.\n\n\n\n\n\nNov 25, 2024\n\n\n10 min\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 10\n\n\nMAP, MLE, and Score Function\n\n\nIn this mathematical lecture, some of the foundational principles of Bayesian inverse problems and their statistical interpretation are discussed. A set of computational tools are shown that aid in finding the solution to some of these problems.\n\n\n\n\n\nNov 22, 2024\n\n\n18 min\n\n\n\n\n\n\n\n\n\n\n\n\nProject Work 1\n\n\nApplications of Machine Learning in Geophysics\n\n\nGeomagnetic inversions are a common problem in geophysics where the goal is to recover a 3D distribution of the conductivity of a section of Earth using magnetic field measurements taken over a 2D surface above ground. The problem is ill-posed and requires advanced techniques to recover data that matches the true distribution. In this project, a series of advanced techniques are used to try and recover true distributions.\n\n\n\n\n\nNov 15, 2024\n\n\n34 min\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 9\n\n\nMachine Learning and Neural Networks\n\n\nNeural networks have revolutionized the field of machine learning, but how exactly do they work? In this lecture, we will explore the basic structure of these models from a mathematical perspective. We will also discuss the role of regularization and priors in solving inverse problems.\n\n\n\n\n\nNov 5, 2024\n\n\n18 min\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 8\n\n\nRegularization and Priors in Inverse Problems\n\n\nInverse problems often have multiple or infinite solutions. Regularization and priors can be used to constrain the solution space and find a unique solution. This lecture covers the role of regularization and priors in solving inverse problems.\n\n\n\n\n\nNov 3, 2024\n\n\n10 min\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 7\n\n\nHomotopy Optimization\n\n\nGaussian homotopy is a technique that can be used to effectively broadcast the gradient of a non-convex function outward to help scape local minima.\n\n\n\n\n\nOct 22, 2024\n\n\n16 min\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 6\n\n\nAutodiff and Coding Gauss-Newton for Least Squares\n\n\nAutomatic differentiation is a powerful tool for solving optimization problems that can be used to automate the process of Gauss-Newton optimization. Here we put together an implementation of the Gauss-Newton method using PyTorch.\n\n\n\n\n\nOct 8, 2024\n\n\n23 min\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 5\n\n\nGauss Newton for Non-Linear Least Squares Optimization\n\n\nThe Gauss-Newton method is a powerful optimization technique for solving non-linear least squares problems of the form \\(\\min_{p} \\frac{1}{2}\\|F(p)-d\\|^2\\). In this lecture, a derivation of the method is presented along with a comparison to Newton’s method. Finally an algorithm for solving the problem is given.\n\n\n\n\n\nSep 25, 2024\n\n\n17 min\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 4\n\n\nRegularization and the Conjugate Gradient Methods\n\n\nTikhonov regularization is a common technique used in inverse theory to stabilize ill-posed problems. In this lecture, we derive the Tikhonov regularization technique, we also have a look at a least squares solution that does not require the computation of the full SVD of the matrix \\(A\\), using the conjugate gradient method.\n\n\n\n\n\nSep 20, 2024\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 3\n\n\nImage Denoising with Gradient Descent and Early Stopping\n\n\nIn continuation of Lecture 2, we now look at an alternative approach to image denoising using gradient descent and early stopping. We will derive the least squares gradient descent algorithm and analyze it as an ordinary differential equation.\n\n\n\n\n\nSep 17, 2024\n\n\n22 min\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 2\n\n\nImage Denoising with SVD\n\n\nImage denoising and deblurring are important techniques in signal processing and recovery. I this coding exercise, we will explore the application of least squares, SVD, and the pseudoinverse to denoise and deblur images.\n\n\n\n\n\nSep 15, 2024\n\n\n22 min\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 1\n\n\nIntroduction to Inverse Theory\n\n\nInverse theory has broad applications across many scientific disciplines. This lecture introduces the concept of least squares and the singular value decomposition (SVD) as a foundation for understanding inverse theory. We then use these properties to analyse the stability and conditioning of linear systems for solving inverse problems using the pseudoinverse and ML techniques.\n\n\n\n\n\nSep 14, 2024\n\n\n11 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/about/overview.html",
    "href": "content/about/overview.html",
    "title": "Simon Ghyselincks",
    "section": "",
    "text": "Welcome to my personal site! I’m Simon Ghyselincks, a PhD-track student at the University of British Columbia (UBC) in the Department of Computer Science."
  },
  {
    "objectID": "content/about/overview.html#welcome",
    "href": "content/about/overview.html#welcome",
    "title": "Simon Ghyselincks",
    "section": "",
    "text": "Welcome to my personal site! I’m Simon Ghyselincks, a PhD-track student at the University of British Columbia (UBC) in the Department of Computer Science."
  },
  {
    "objectID": "content/about/overview.html#academics-and-projects",
    "href": "content/about/overview.html#academics-and-projects",
    "title": "Simon Ghyselincks",
    "section": "Academics and Projects",
    "text": "Academics and Projects\nI am currently working with Eldad Haber from UBC Earth and Ocean Sciences and Michael Friedlander in Computer Science on generative AI and optimization with application to geophysics. My recent work explores the application of advances in normalizing flows with stochastic interpolants to generate 3d models of the earth’s crust. My undergraduate two-year senior capstone project is “Learning to Balance” which explores the application of reinforcement learning to a reaction wheel robot with complex dynamics. Read more about my projects here.\n\nFeel free to connect with me on LinkedIn or check out my GitHub."
  },
  {
    "objectID": "content/about/overview.html#my-journey",
    "href": "content/about/overview.html#my-journey",
    "title": "Simon Ghyselincks",
    "section": "My Journey",
    "text": "My Journey\nRead more about my journey and past pursuits here."
  },
  {
    "objectID": "blog/posts/welcome/index.html",
    "href": "blog/posts/welcome/index.html",
    "title": "Welcome",
    "section": "",
    "text": "This year, I have been expanding my knowledge of publishing and coding techniques that are designed to make sharing technical work easier, more visual, and more interactive. Michael Friedlander, who teaches CPSC 406 Computational Optimization at UBC, is an advocate for using Julia and Quarto in teaching and research. Drawing inspiration from his work along with Patrick Altmeyer’s website, I have decided to start my own blog using Quarto.\nQuarto is a scientific and technical publishing system built on Pandoc. It is designed to make it easy to write and publish technical content, such as research papers, books, and reports. One of its main features is that it allows for writing content in markdown along with code chunks in Julia, Python, R, and other languages. In addition, Quarto supports a wide range of output formats, including HTML, PDF, and Word. It has the great convenience of being able to port writing from Obsidian or in Latex to a blog post or html with minimal effort.\nI’m excited to use this new tool to share my work and ideas, especially as I continue to learn more about data science, machine learning, and optimization. I hope you find the content here useful and/or interesting."
  },
  {
    "objectID": "blog/posts/welcome/index.html#examples-of-julia-code-and-plots",
    "href": "blog/posts/welcome/index.html#examples-of-julia-code-and-plots",
    "title": "Welcome",
    "section": "Examples of Julia Code and Plots",
    "text": "Examples of Julia Code and Plots\nHere’s a parametrically defined, snail-like surface. Although it exists in 3D space, the surface is two-dimensional in that any location on it can be specified using just two coordinates—similar to how we navigate the surface of the Earth. You van see this incorporated as the two parameters \\(u\\) and \\(v\\) in the code below. These two coordinates map into 3D space that is defined by the functions \\(s1\\), \\(s2\\), and \\(s3\\) giving a vector \\[\\mathbf{s}(u,v) = \\begin{bmatrix}s1(u,v) \\\\ s2(u,v) \\\\ s3(u,v)\\end{bmatrix}\\]\nThe surface is then plotted using the surface function from the Julia Plots package.\nNote the usage of the vectorized operation of the functions \\(s1\\), \\(s2\\), and \\(s3\\) to create the vectors xs, ys, and zs. The passing of the input vectors u and v' creates the required meshgrid for the surface plot.\n\n\nShow the code\nusing Plots\n\n# Your plotting code here\nu = range(0, stop=6π, length=100)\nv = range(0, stop=2π, length=30)\ns1(u, v) = 2 * (1 - exp(u / (6 * π))) * cos(u) * cos(v / 2)^2\ns2(u, v) = 2 * (-1 + exp(u / (6 * π))) * sin(u) * cos(v / 2)^2\ns3(u, v) = 1 - 0.71 * exp(u / (3 * π)) - sin(v) + exp(u / (6 * π)) * sin(v)\n\nxs, ys, zs = s1.(u, v'), s2.(u, v'), s3.(u, v')\nsurface(xs, ys, zs, color=cgrad(:acton), alpha=0.5, legend=false)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Surface Plot Example\n\n\n\n\nThis code is an example of the animation features included in the Julia Plot library found at Julia Plots Package that can be used to create a gif. The gif below shows a parametric plot of a heart. Note just how compact the code is for creating this gif and the natural expression that the code has. This is the power of Julia.\n\n\nShow the code\nusing Plots\n\n@userplot CirclePlot\n@recipe function f(cp::CirclePlot)\n    x, y, i = cp.args\n    n = length(x)\n    inds = circshift(1:n, 1 - i)\n    linewidth --&gt; range(0, 10, length = n)\n    seriesalpha --&gt; range(0, 1, length = n)\n    aspect_ratio --&gt; 1\n    label --&gt; false\n    x[inds], y[inds]\nend\n\nn = 400\nt = range(0, 2π, length = n)\nx = 16sin.(t).^3\ny = 13cos.(t) .- 5cos.(2t) .- 2cos.(3t) .- cos.(4t)\n\nanim = @animate for i ∈ 1:n\n    circleplot(x, y, i, line_z = 1:n, cbar = false, c = :reds, framestyle = :none)\nend every 5\ngif(anim, \"anim_fps15.gif\", fps = 15, show_msg = false)\n\n\n\n\n\n\n\nFigure 2: Heart Animation Example"
  },
  {
    "objectID": "blog/posts/CAP-conference-poster/index.html",
    "href": "blog/posts/CAP-conference-poster/index.html",
    "title": "Generative Modeling for Structural Geology",
    "section": "",
    "text": "CUPC Conference Poster\n\nThis is an embedded &lt;a target=\"_blank\" href=\"https://office.com\"&gt;Microsoft Office&lt;/a&gt; presentation, powered by &lt;a target=\"_blank\" href=\"https://office.com/webapps\"&gt;Office&lt;/a&gt;.\n\n\n\nConference PresentationThis is an embedded &lt;a target=\"_blank\" href=\"https://office.com\"&gt;Microsoft Office&lt;/a&gt; presentation, powered by &lt;a target=\"_blank\" href=\"https://office.com/webapps\"&gt;Office&lt;/a&gt;."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Posts",
    "section": "",
    "text": "Generative Modeling for Structural Geology\n\n\nMaterials from the CUPC 2024 Conference\n\n\nA copy of the conference poster and presentation slides for the 2024 Canadian Association of Physicists Undegraduate Research Conference held at UBC\n\n\n\n\n\nOct 21, 2024\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nScore Matching for Density Estimation\n\n\nEstimation of the probability density function using score matching\n\n\nScore matching is a method for indirectly estimating the probability density function of a distribution. In this post, I will explain the score matching method as well as some of its limitations.\n\n\n\n\n\nJun 22, 2024\n\n\n17 min\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome\n\n\nA first post using Quarto\n\n\nFind out more about the tools I’m using to create this blog.\n\n\n\n\n\nApr 22, 2024\n\n\n4 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/scorematching/index.html",
    "href": "blog/posts/scorematching/index.html",
    "title": "Score Matching for Density Estimation",
    "section": "",
    "text": "The Problem of Density Estimation\nWhen working with a set of data, one of the tasks that we often want to do is to estimate the underlying probability density function (PDF) of the data. Knowing the probability distribution is a powerful tool that allows to make predictions, generate new samples, and understand the data better. For example, we may have a coin and want to know the probability of getting heads or tails. We can flip the coin many times and count the number of heads and tails to estimate the probability of each outcome. However, when it comes to higher dimensional spaces that are continuous in distribution, the problem of estimating the PDF in this way becomes intractable.\nFor example, with a set of small images such as the CIFAR-10 dataset, the images are 32x32 pixels with 3 color channels. The number of dimensions in the data space is 32x32x3 = 3072. With 8-bit images the number of all possible unique images is \\(255^{3072}\\), which is an incomprehensibly large number. The 60,000 images that are included in CIFAR-10 represent but a tiny fraction of samples in the space of all possible images.\n Figure 1: Sample images from the CIFAR-10 dataset (Krizhevsky 2009)\nTo demonstrate the issue with random image generation in such a sparsely populated space, we can generate a random 32x32 image with 3 color channels and display it.\n\n\nShow the code\nusing Plots, Images\n\n# Generate 6 random images and display them in a grid\nplots = []\nfor i in 1:6\n    # Generate a random 32x32 3-channel image\n    im = rand(3, 32, 32)\n    im = colorview(RGB, im)\n    p = plot(im, showaxis=false, showgrid=false, title=\"Random Image $i\")\n    push!(plots, p)\nend\n\n# Create a plot with a 2x3 grid layout\nplot_grid = plot(plots..., layout=(2, 3), size=(800, 400))\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYes we have successfuly generated random 32x32 color images, but they are not very useful or interesting.\nIf there were some way to learn the underlying distribution of the data, we could generate new samples that are realistic (probable) but that have never been seen before by sampling from higher probability regions of the learned distribution. So how do recent developments in machine learning manage to generate new and plausible samples from high dimensional data sets?\nOne of the techniques that has been developed is called generative modeling. Generative models are a class of machine learning models that are trained to learn the underlying distribution of the data. Once the model has learned the distribution, it can generate new samples that are similar to the training data.\nOne of the powerful techniques that allows for learning a probability distribution is score matching.\n\n\nParameter Estimation\nLet us take a moment to consider the problem of fitting a model to data in the most simple sense. Suppose that we have a set of data points and want to fit a linear model by drawing a line through it. One of the techniques that can be used is to minimize the sum of the squared errors between the data points and the line. This is known as the method of least squares.\nWe have model \\(f(x) = \\hat y = mx + b\\) with free parameters \\(\\theta = {m, b}\\) and data points \\((x_i, y_i)\\). The objective is to find the parameters \\(\\theta\\) that minimize the sum of the squared errors \\(J\\) between the predicted values \\(\\hat y_i\\) and the true values \\(y_i\\).: \\[  \\text{arg}\\min_{m,b} J(m,b) = \\text{arg}\\min_{m,b} \\sum_{i=1}^{n} (\\hat y_i - y_i)^2 \\]\nWe could use some calculus at this point to solve the minimization problem but more general matrix methods can be used to solve the problem.\n\\[\\begin{align*}\n    X &= \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{bmatrix} , \\quad  \\vec{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} , \\quad \\vec{\\theta} &= \\begin{bmatrix} b \\\\ m \\end{bmatrix} \\\\\n    \\text{arg}\\min_{\\vec{\\theta}} J(\\vec{\\theta}) &= \\text{arg}\\min_{\\vec{\\theta}} ||\\vec{\\hat y} - \\vec{y}||^2\\\\\n    \\text{arg}\\min_{\\vec{\\theta}} J(\\vec{\\theta}) &= \\text{arg}\\min_{\\vec{\\theta}} ||X\\vec{\\theta} - \\vec{y}||^2\n\\end{align*}\\]\nThe solution to this problem is well known and can be found by solving the normal equations: \\[ X^T X \\vec{\\theta} = X^T \\vec{y} \\]\nAn example of this optimization problem is shown below where we generate some random data points and fit a line to them.\n\n\nShow the code\nusing Plots, Random\n\n# Generate some random data points with correlation along a line\nRandom.seed!(1234)\nn_points = 10\nx = rand(n_points)\nm_true = 0.8; b_true = -1\ny = .8* x .- 1 + 0.3 * randn(n_points)\n\n# Create the matrix X\nX = hcat(ones(n_points), x)\n\n# Solve the normal equations to find the parameters theta\ntheta = X \\ y\n\n# Generate x values for the complete line\nx_line = range(minimum(x) - 0.1, maximum(x) + 0.1, length=100)\nX_line = hcat(ones(length(x_line)), x_line)\n\n# Compute the y values for the line\ny_hat_line = X_line * theta\n\n# Compute the fitted values for the original data points\ny_hat = X * theta\n\n# Unpack learned parameters\nb, m = theta\n\n# Plot the data points and the fitted line\ntitle_text = \"Fitted Line: y = $(round(m, digits=2))x + $(round(b, digits=2)) vs. \\n True Line: y = $(m_true)x + $(b_true)\"\np1 = scatter(x, y, label=\"Data Points\", color=:red, ms=5, aspect_ratio=:equal, xlabel=\"x\", ylabel=\"y\", title=title_text)\nplot!(p1, x_line, y_hat_line, label=\"Fitted Line\", color=:blue)\n# Add dashed lines for residuals\nfor i in 1:n_points\n    plot!(p1, [x[i], x[i]], [y[i], y_hat[i]], color=:black, linestyle=:dash, label=\"\")\nend\n\ndisplay(p1)\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is a simple example of parameter estimation but it shows some of the important concepts that are used in more complex models. There is an underlying distribution which is a line with some error or noise added to it. We collected some random points from the distribution and then used them in an optimization problem where we minimized the squared error between the predicted values and the true values. The best solution is the parameters \\(\\theta\\) that minimize the error. In doing so we recovered a line that is close to the one that was used to generate the data.\n\n\nEstimating a Density Function\nWhen it comes to estimating denstity we are constrained by the fact that any model must sum to 1 of the entire sample space.\n\n\nDenoising Autoencoders\nDenoising Autoencoders (DAE) are a type of machine learning model that is trained to reconstruct the input data from a noisy or corrupted version of the input. The DAE is trained to take an sample such as an image with unwanted noise and restore it to the original sample.\nIn the process of learning the denoising parameters, the DAE also can learn the score function the underlying distribution of noisy samples, which is a kernel density estimate of the true distribution.\nThe score function is an operator defined as: \\[ s(f(x)) = \\nabla_x \\log f(x) \\]\nWhere \\(f(x)\\) is the density function or PDF of the distribution.\nBy learning a score function for a model, we can reverse the score operation to obtain the original density function it was derived from. This is the idea behind score matching, where we indirectly find the the pdf of a distribution by matching the score of a proposed model \\(p(x;\\theta)\\) to the score of the true distribution \\(q(x)\\).\nAnother benefit of learning the score function of a distribution is that it can be used to move from less probable regions of the distribution to more probable regions using gradient ascent. This is useful when it comes to generative models, where we want to generate new samples from the distribution that are more probable.\nHowever one of the challenges is that the score function is not always well-defined, especially in regions of low probability where there are sparse samples. This can make it difficult to learn the score function accurately in these regions.\nThis post explores some of those limitations and how increasing the bandwidth of the noise kernel in the DAE can help to stabilize the score function in regions of low probability.\n\n\nSample of Score Matching\nSuppose we have a distribution in 2D space that consists of three Gaussians as our ground truth. We can plot this pdf and its gradient field.\n\n\nShow the code\nusing Plots, Distributions\n\n# Define the ground truth distribution\nfunction p(x, y)\n    mu1, mu2, mu3 = [-1, -1], [1, 1], [1, -1]\n    sigma1, sigma2, sigma3 = [0.5 0.3; 0.3 0.5], [0.5 0.3; 0.3 0.5], [0.5 0; 0 0.5]\n\n    return 0.2 * pdf(MvNormal(mu1, sigma1), [x, y]) + 0.2 * pdf(MvNormal(mu2, sigma2), [x, y]) + 0.6 * pdf(MvNormal(mu3, sigma3), [x, y])\nend\n\n# Plot the distribution using a heatmap\nheatmap(\n    -3:0.01:3, -3:0.01:3, p,\n    c=cgrad(:davos, rev=true),\n    aspect_ratio=:equal,\n    xlabel=\"x\", ylabel=\"y\", title=\"Ground Truth PDF q(x)\",\n    xlims=(-3, 3), ylims=(-3, 3),\n    xticks=[-3, 3], yticks=[-3, 3]\n)\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\nSampling from the distribution can be done by generating 100 random points\n\n\nShow the code\nusing Random, Plots, Distributions\n\n# Define the ground truth distribution\nfunction p(x, y)\n    mu1, mu2, mu3 = [-1, -1], [1, 1], [1, -1]\n    sigma1, sigma2, sigma3 = [0.5 0.3; 0.3 0.5], [0.5 0.3; 0.3 0.5], [0.5 0; 0 0.5]\n\n    return 0.2 * pdf(MvNormal(mu1, sigma1), [x, y]) + 0.2 * pdf(MvNormal(mu2, sigma2), [x, y]) + 0.6 * pdf(MvNormal(mu3, sigma3), [x, y])\nend\n\n# Sample 200 points from the ground truth distribution\nn_points = 200\npoints = []\n\n# Set random seed for reproducibility\nRandom.seed!(1234)\n\nwhile length(points) &lt; n_points\n    x = rand() * 6 - 3\n    y = rand() * 6 - 3\n    if rand() &lt; p(x, y)\n        push!(points, (x, y))\n    end\nend\n\n# Plot the distribution using a heatmap\n# heatmap(\n#     -3:0.01:3, -3:0.01:3, p,\n#     c=cgrad(:davos, rev=true),\n#     aspect_ratio=:equal,\n#     xlabel=\"x\", ylabel=\"y\", title=\"Ground Truth PDF q(θ)\",\n\n# )\n\n# Scatter plot of the sampled points\nscatter([x for (x, y) in points], [y for (x, y) in points], label=\"Sampled Points\", color=:red, ms=2,\n     xlims=(-3, 3), ylims=(-3, 3),\n     xticks=[-3, 3], yticks=[-3, 3])\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom this sampling of points we can visualize the effect of the choice of noise bandwidth on the kernel density estimate.\n\n\nShow the code\nusing Plots, Distributions, ForwardDiff\n\n# Define the ground truth distribution\nfunction p(x, y)\n    mu1, mu2, mu3 = [-1, -1], [1, 1], [1, -1]\n    sigma1, sigma2, sigma3 = [0.5 0.3; 0.3 0.5], [0.5 0.3; 0.3 0.5], [0.5 0; 0 0.5]\n\n    return 0.2 * pdf(MvNormal(mu1, sigma1), [x, y]) + 0.2 * pdf(MvNormal(mu2, sigma2), [x, y]) + 0.6 * pdf(MvNormal(mu3, sigma3), [x, y])\nend\n\n# Define the log of the distribution\nfunction log_p(x, y)\n    val = p(x, y)\n    return val &gt; 0 ? log(val) : -Inf\nend\n\n# Function to compute the gradient using ForwardDiff\nfunction gradient_log_p(u, v)\n    grad = ForwardDiff.gradient(x -&gt; log_p(x[1], x[2]), [u, v])\n    return grad[1], grad[2]\nend\n\n# Generate a grid of points\nxs = -3:0.5:3\nys = -3:0.5:3\n\n# Create meshgrid manually\nxxs = [x for x in xs, y in ys]\nyys = [y for x in xs, y in ys]\n\n# Compute the gradients at each point\nU = []\nV = []\nfor x in xs\n    for y in ys\n        u, v = gradient_log_p(x, y)\n\n        push!(U, u)\n        push!(V, v)\n    end\nend\n\n# Convert U and V to arrays\nU = reshape(U, length(xs), length(ys))\nV = reshape(V, length(xs), length(ys))\n\n# Plot the distribution using a heatmap\nheatmap(\n    -3:0.01:3, -3:0.01:3, p,\n    c=cgrad(:davos, rev=true),\n    aspect_ratio=:equal,\n    xlabel=\"x\", ylabel=\"y\", title=\"Ground Truth PDF q(x) with score\",\n    xlims=(-3, 3), ylims=(-3, 3),\n    xticks=[-3, 3], yticks=[-3, 3]\n)\n\n# Flatten the gradients and positions for quiver plot\nxxs_flat = [x for x in xs for y in ys]\nyys_flat = [y for x in xs for y in ys]\n\n# Plot the vector field\nquiver!(xxs_flat, yys_flat, quiver=(vec(U)/20, vec(V)/20), color=:green, quiverkeyscale=0.5)\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\nNow we apply a Gaussian kernel to the sample points to create the kernel density estimate:\n\n\nShow the code\nusing Plots, Distributions, KernelDensity\n\n# Convert points to x and y vectors\nx_points = [x for (x, y) in points]\ny_points = [y for (x, y) in points]\n\n# Perform kernel density estimation using KernelDensity.jl\nparzen = kde((y_points, x_points); boundary=((-3,3),(-3,3)), bandwidth = (.3,.3))\n\n# Plot the ground truth PDF\np1 = heatmap(\n    -3:0.01:3, -3:0.01:3, p,\n    c=cgrad(:davos, rev=true),\n    aspect_ratio=:equal,\n    xlabel=\"x\", ylabel=\"y\", title=\"Ground Truth PDF q(x)\",\n    xlims=(-3, 3), ylims=(-3, 3),\n    xticks=[-3, 3], yticks=[-3, 3]\n)\n\n# Scatter plot of the sampled points on top of the ground truth PDF\nscatter!(p1, x_points, y_points, label=\"Sampled Points\", color=:red, ms=2)\n\n\n# Plot the kernel density estimate\np2 = heatmap(\n    parzen.x, parzen.y, parzen.density,\n    c=cgrad(:davos, rev=true),\n    aspect_ratio=:equal,\n    xlabel=\"x\", ylabel=\"y\", title=\"Kernel Density Estimate\",\n    xlims=(-3, 3), ylims=(-3, 3),\n    xticks=[-3, 3], yticks=[-3, 3]\n)\n\n# Scatter plot of the sampled points on top of the kernel density estimate\nscatter!(p2, x_points,  y_points, label=\"Sampled Points\", color=:red, ms=2)\n\n# Arrange the plots side by side\nplot(p1, p2, layout = @layout([a b]), size=(800, 400))\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\nNow looking at the density estimate across many bandwidths, we can see the effect on adding more and more noise to the original sampled points and our density estimate that we are learning. At very large bandwidths the estimate becomes a uniform distribution.\n\n\nShow the code\nusing Plots, Distributions, KernelDensity\n# Define the range of bandwidths for the animation\nbandwidths = [(0.01 + 0.05 * i, 0.01 + 0.05 * i) for i in 0:40]\n\n# Create the animation\nanim = @animate for bw in bandwidths\n    kde_result = kde((x_points,y_points); boundary=((-6, 6), (-6, 6)), bandwidth=bw)\n\n    p2 = heatmap(\n        kde_result.x, kde_result.y, kde_result.density',\n        c=cgrad(:davos, rev=true),\n        aspect_ratio=:equal,\n        xlabel=\"x\", ylabel=\"y\", title=\"Kernel Density Estimate,Bandwidth = $(round(bw[1],digits=2))\",\n        xlims=(-6, 6), ylims=(-6, 6),\n        xticks=[-6, 6], yticks=[-6, 6]\n    )\n\n    scatter!(p2, x_points, y_points, label=\"Sampled Points\", color=:red, ms=2)\nend\n\n# Save the animation as a GIF\ngif(anim, \"parzen_density_animation_with_gradients.gif\", fps=2,show_msg = false)\n\n\n\n\n\nNow we can compute the score of the kernel density estimate to see how it changes with the bandwidth. The score function of the distribution is numerically unstable at regions of sparse data. Recalling that the score is the gradient of the log-density funtion, when the density is very low the function approaches negative infinity. Within the limits of numerical precision, taking the log of the density function will result in a negative infinity in sparse and low probability regions. Higher bandwidths of KDE using the Gaussian kernel for example, spread out both the discrete sampling and the true distribution over space. This extends the region of numerical stability for a higher bandwidth.\nThe regions with poor numerical stability can be seen as noise artifacts and missing data in the partial derivatives of the log-density function. Some of these artifacts may also propogate from the fourier transform calculations that the kernel density estimate uses.\n\n\nShow the code\nusing Plots, Distributions, KernelDensity, ForwardDiff\n\n# Define the range of bandwidths for the animation\nbandwidths = [(0.01 + 0.05 * i, 0.01 + 0.05 * i) for i in 0:30]\n\nboundary = (-10, 10)\n# Create the animation\nanim = @animate for bw in bandwidths\n    kde_result = kde((x_points, y_points); boundary=(boundary, boundary), bandwidth=bw)\n\n        # Compute log-density\n    log_density = log.(kde_result.density)\n\n    # Compute gradients of log-density\n    grad_x = zeros(size(log_density))\n    grad_y = zeros(size(log_density))\n\n    # Compute gradients using finite difference centered difference\n    for i in 2:size(log_density, 1)-1\n        for j in 2:size(log_density, 2)-1\n            grad_x[i, j] = (log_density[i+1, j] - log_density[i-1, j]) / (kde_result.x[i+1] - kde_result.x[i-1])\n            grad_y[i, j] = (log_density[i, j+1] - log_density[i, j-1]) / (kde_result.y[j+1] - kde_result.y[j-1])\n        end\n    end\n    # Downsample the gradients and coordinates by selecting every 10th point\n    downsample_indices_x = 1:10:size(grad_x, 1)\n    downsample_indices_y = 1:10:size(grad_y, 2)\n\n    grad_x_downsampled = grad_x[downsample_indices_x, downsample_indices_y]\n    grad_y_downsampled = grad_y[downsample_indices_x, downsample_indices_y]\n\n    x_downsampled = kde_result.x[downsample_indices_x]\n    y_downsampled = kde_result.y[downsample_indices_y]\n\n    xxs_flat = repeat(x_downsampled, inner=[length(y_downsampled)])\n    yys_flat = repeat(y_downsampled, outer=[length(x_downsampled)])\n\n    grad_x_flat = grad_x_downsampled[:]\n    grad_y_flat = grad_y_downsampled[:]\n\n    # Plot heatmaps of the gradients\n    p1 = heatmap(\n        kde_result.x, kde_result.y, grad_x',\n        c=cgrad(:davos, rev=true),\n        aspect_ratio=:equal,\n        xlabel=\"x\", ylabel=\"y\", title=\"Partial Derivative of Log-Density wrt x \\n Bandwidth = $(round(bw[1],digits=2))\",\n        xlims=boundary, ylims=boundary\n    )\n\n    # Overlay the scatter plot of the sampled points\n    scatter!(p1, x_points, y_points, label=\"Sampled Points\", color=:red, ms=2)\n\n    p2 = heatmap(\n        kde_result.x, kde_result.y, grad_y',\n        c=cgrad(:davos, rev=true),\n        aspect_ratio=:equal,\n        xlabel=\"x\", ylabel=\"y\", title=\"Partial Derivative of Log-Density wrt y \\n Bandwidth = $(round(bw[1],digits=2))\",\n        xlims=boundary, ylims=boundary\n    )\n\n    # Overlay the scatter plot of the sampled points\n    scatter!(p2, x_points, y_points, label=\"Sampled Points\", color=:red, ms=2)\n\n    plot(p1, p2, layout = @layout([a b]), size=(800, 400))\nend\n# Save the animation as a GIF\ngif(anim, \"parzen_density_partials.gif\", fps=2, show_msg=false)\n\n\n\n\n\nAnd combining the gradient overtop of the ground truth distribution that is modeled with the kernel density estimate, starting with the larger bandwidths and moving to the smaller bandwidths, we can see that the region of numerical stability is extended with the larger bandwidths. The larger bandwidths also remove some of the precision in the model, with larger bandwidths the model approaches a single gaussian distribution.\n\n\nShow the code\n# Define the range of bandwidths for the animation\nbandwidths = [(0.01 + 0.2 * i, 0.01 + 0.2 * i) for i in 0:10]\nbandwidths = reverse(bandwidths)\n\nboundary = (-10, 10)\n# Create the animation\nanim = @animate for bw in bandwidths\n    kde_result = kde((x_points, y_points); boundary=(boundary, boundary), bandwidth=bw)\n\n    # Compute log-density\n    log_density = log.(kde_result.density)\n\n    # Compute gradients of log-density\n    grad_x = zeros(size(log_density))\n    grad_y = zeros(size(log_density))\n\n    # Compute gradients using finite difference centered difference\n    for i in 2:size(log_density, 1)-1\n        for j in 2:size(log_density, 2)-1\n            grad_x[i, j] = (log_density[i+1, j] - log_density[i-1, j]) / (kde_result.x[i+1] - kde_result.x[i-1])\n            grad_y[i, j] = (log_density[i, j+1] - log_density[i, j-1]) / (kde_result.y[j+1] - kde_result.y[j-1])\n        end\n    end\n    # Downsample the gradients and coordinates by selecting every 10th point\n    downsample_indices_x = 1:20:size(grad_x, 1)\n    downsample_indices_y = 1:20:size(grad_y, 2)\n\n    grad_x_downsampled = grad_x[downsample_indices_x, downsample_indices_y]\n    grad_y_downsampled = grad_y[downsample_indices_x, downsample_indices_y]\n\n    x_downsampled = kde_result.x[downsample_indices_x]\n    y_downsampled = kde_result.y[downsample_indices_y]\n\n    xxs_flat = repeat(x_downsampled, inner=[length(y_downsampled)])\n    yys_flat = repeat(y_downsampled, outer=[length(x_downsampled)])\n\n    grad_x_flat = grad_x_downsampled[:]\n    grad_y_flat = grad_y_downsampled[:]\n\n     # Plot the actual distribution\n    x_range = boundary[1]:0.01:boundary[2]\n    y_range = boundary[1]:0.01:boundary[2]\n    p1 = heatmap(\n        x_range, y_range, p,\n        c=cgrad(:davos, rev=true),\n        aspect_ratio=:equal,\n        xlabel=\"x\", ylabel=\"y\", title=\"Ground Truth PDF q(x)\\n with score of Kernel Density Estimate, \\n Bandwidth = $(round(bw[1],digits=2))\",\n        xlims=boundary, ylims=boundary,\n        size=(800, 800)\n    )\n\n    # Plot a quiver plot of the downsampled gradients\n    quiver!(yys_flat, xxs_flat, quiver=(grad_x_flat/10, grad_y_flat/10), \n    color=:green, quiverkeyscale=0.5, aspect_ratio=:equal)\nend\n# Save the animation as a GIF\ngif(anim, \"parzen_density_gradient_animation_with_gradients.gif\", fps=2, show_msg=false)\n\n\n\n\n\n\n\n\n\n\nReferences\n\nKrizhevsky, Alex. 2009. “Learning Multiple Layers of Features from Tiny Images.” https://www.cs.toronto.edu/~kriz/cifar.html."
  },
  {
    "objectID": "content/about/biography.html",
    "href": "content/about/biography.html",
    "title": "Bio",
    "section": "",
    "text": "I wasn’t always so academically focused. In fact, I had a ten year career in forestry where I planted over 2 million trees along with a variety of other projects. I also spent some years living in the Peruvian Amazon working as a travel guide and translator.\nI came back to study at UBC in 2020 to revisit my interest in science and technology, after an injury required me to change lifestyles. In 2025 I graduated with a BASc in Engineering Physics and have continued my education further with a PhD program in Computer Science. It has been a challenging but rewarding journey, and I am excited to see where it takes me next."
  },
  {
    "objectID": "content/about/biography.html#some-past-adventures",
    "href": "content/about/biography.html#some-past-adventures",
    "title": "Bio",
    "section": "Some Past Adventures",
    "text": "Some Past Adventures\n\n\n\n\nSta. Clautilde, Rio Napo, Peru\n\n\n\n\n\nTarapoto, San Martin, Peru\n\n\n\n\n\nRemote Helicopter Forestry Work\n\n\n\n\n\nEverest Base Camp\n\n\n\n\n\nDirtbiking in Myanmar\n\n\n\n\n\nSailing to Mexico from Victoria"
  },
  {
    "objectID": "content/CV.html",
    "href": "content/CV.html",
    "title": "CV",
    "section": "",
    "text": "This browser does not support PDFs. Please download the PDF to view it: &lt;a href=\"www/cv/CV.pdf\"&gt;Download PDF&lt;/a&gt;."
  },
  {
    "objectID": "content/eosc555/lectures/lecture1-2/index.html",
    "href": "content/eosc555/lectures/lecture1-2/index.html",
    "title": "Lecture 1",
    "section": "",
    "text": "Inverse theory is a set of mathematical techniques used to infer the properties of a physical system from observations of its output. It is a fundamental tool in many scientific disciplines, including geophysics, seismology, and medical imaging. Inverse theory is used to solve a wide range of problems, such as:\n\nParameter Estimation: Determining the values of unknown parameters in a model that best fit the observed data.\nSystem Identification: Identifying the structure and dynamics of a system from input-output data.\nImage Reconstruction: Reconstructing an image or object from noisy or incomplete measurements.\n\nWhat many of these tasks have in common is that we are working with incomplete information. There is a forward problem that has generated the data that we observe \\(\\vec{b}\\) from a set of input data \\(\\vec{x}\\), and we want to infer the inverse problem that generated the data. However the inverse problem is often ill-posed, meaning that there are multiple solutions that can fit the data equally well. Inverse theory provides a framework for finding the best solution to these problems.\nThe forward problem can be described for example as a differetial equation or operator \\(L\\) that takes in some measured parameters \\(u\\) with model parameters \\(x\\) :\n\\[ L(x)[u] = q \\iff u = L^{-1}(x)[q] \\]\nFor example making measurements of an electromagnetic field in correspondence to conductivity values that are underground we have:\n\\[ \\nabla \\sigma \\nabla u = q + \\text{BC}\\]\nWe measure the \\(u\\) at some points and use that to try and form an estimate of the conductivity \\(\\sigma\\). The forward problem is to solve for \\(u\\) given \\(\\sigma\\) and the inverse problem is to solve for \\(\\sigma\\) given \\(u\\). The forward problem is often well-posed and the inverse problem is often ill-posed.\nFor a computational framework we can discretize the the equation so that the operator is a matrix \\(A\\) and the data is a vector \\(\\vec{b}\\):\n\\[ \\underbrace{A}_{\\text{Forward Map}} \\underbrace{\\vec{x}}_{\\text{Model Parameters}} + \\epsilon = \\underbrace{\\vec{b}}_{\\text{Observed Data}} \\]\nIn this case we may have a sparse set of measurements \\(b\\) and a large set of \\(x\\) making the problem underdetermined. The goal of inverse theory is to find the best estimate of \\(x\\) given \\(b\\).\n\n\nTo illustrate the concept of inverse theory, consider the following example:\n\nSuppose that you have agreed to meet a friend to watch them during a triathlon race but you showed up late and missed the start. They are expecting for you to have been there at some point during the time at which they were changing from a running phase to a cycle phase. They expect you to know the time at which they made the transition. However you only know the overall start time and finish time of the race.\nIf the race starts at time \\(t=0\\) and then ends at time \\(t=b\\) how do you use this information to deduce the actual time \\(t_r \\in [0,b]\\) at which they crossed the transition zone of the race?\n\nThe first restriction on feasible solutions is the domain \\([0,b]\\) so that we know that \\(0&lt;t_r&lt;b\\).\nAfter this there are some other techniquest that we could use to better inform the probability of the occurence at different times. For example, we might have a good idea of their fitness level or average running speed from previous experience. Or in the abscence of this information there might be average times for the competitors that are available to further inform the problem and reduce the amount of error in the estimate.\n\n\n\nFor cases where the matrix \\(A\\) is not full rank, the singular value decomposition (SVD) provides a more general framework for solving the least squares problem. The SVD decomposes the matrix \\(A\\) into three matrices \\(U\\), \\(\\Sigma\\), and \\(V\\)\n\\[ A = U \\Sigma V^T \\]\nThe matrices have the following special properties:\n\nOrthogonal Subspaces: \\(U\\) and \\(V\\) are orthogonal matrices, meaning that \\(U^TU = I\\) and \\(V^TV = I\\), that is \\(U^T = U^{-1}\\) and $V^T = V^{-1}.\nOrdered Singular Values: \\(\\Sigma\\) is a diagonal matrix with non-negative values on the diagonal, known as the singular values of \\(A\\). The singular values are ordered such that \\(\\sigma_1 \\geq \\sigma_2 \\geq \\ldots \\geq \\sigma_r\\). The number of non-zero singular values is equal to the rank of \\(A\\).\n\nSupposed that we have a \\(\\text{rank}(A) = r\\) matrix \\(A\\) which maps from \\(\\mathbb{R}^m\\rightarrow \\mathbb{R}^n\\). A fundamental way to view this mapping is as a composition of three linear transformations: a rotation \\(V\\), a scaling \\(\\Sigma\\), and another rotation \\(U\\). The orthogonal matrix \\(V\\) has the property that all of its rows and columns are orthogonal to each other, and the vectors themselves are normalized to \\(1\\). To see this property of the orthogonal matrix consider that \\(V^T V = I\\) and \\(V V^T = I\\):\n\\[ \\begin{align}\nZ = V^T V &= I \\\\\nz_{ij} = \\langle v_i, v_j \\rangle &= \\delta_{ij} \\end{align} \\]\nEach of the elements of the matrix \\(V^T\\) is the dot product of the \\(i\\)th and \\(j\\)th columns of \\(V\\). The dotproduct of all vectors against themselves is \\(1\\) and the dotproduct of any two different vectors is \\(0\\). So from this we can see that all of the columns of \\(V\\) are orthogonal to each other. The same property holds for \\(U\\).\n\\(V^T\\) by our definition of \\(A\\) must accept a vector from \\(\\mathbb{R}^m\\) and the matrix is square, indicating an \\(m \\times m\\) matrix. The matrix \\(U\\) must output a vector in \\(\\mathbb{R}^n\\) and the matrix is square, indicating an \\(n \\times n\\) matrix. The matrix \\(\\Sigma\\) must be \\(n \\times m\\) to map from \\(\\mathbb{R}^m\\) to \\(\\mathbb{R}^n\\).\nIn all its glory:\n\\[\n\\begin{aligned}\nA_{n \\times m} &= U_{n \\times n} \\, \\Sigma_{n \\times m} \\, V^T_{m \\times m} \\\\\n&= \\left[ \\begin{array}{ccc|ccc}\n\\mathbf{u}_1 & \\cdots & \\mathbf{u}_r & \\mathbf{u}_{r+1} & \\cdots & \\mathbf{u}_n\n\\end{array} \\right]_{n \\times n}\n\\left[ \\begin{array}{ccc}\n\\sigma_1 &  &  \\\\\n& \\ddots &  \\\\\n&  & \\sigma_r \\\\\n0 & \\cdots & 0 \\\\\n\\vdots & \\ddots & \\vdots \\\\\n0 & \\cdots & 0\n\\end{array} \\right]_{n \\times m}\n\\left[ \\begin{array}{ccc|ccc}\n\\mathbf{v}^T_1 \\\\\n\\vdots \\\\\n\\mathbf{v}^T_r \\\\\n\\mathbf{v}^T_{r+1} \\\\\n\\vdots \\\\\n  \\mathbf{v}^T_m\n\\end{array} \\right]_{m \\times m}\n\\end{aligned}\n\\]\nIn this case the first \\(r\\) columns of \\(U\\) are the range of \\(A\\), the rest of \\(U\\) is filled with its orthogonal complement. The first \\(r\\) columns of \\(V\\) are the domain of \\(A\\), the rest of \\(V\\) is filled with its orthogonal complement. These are the four fundamental subspaces of the matrix \\(A\\), more information on this can be found at: Wikipedia: SVD\nThe matrices as shown above are for a rectangular \\(A\\) where \\(n&gt;m\\) but the same properties hold for all \\(n,m\\). Some of the singular values \\(\\sigma_i\\) may be zero, in which case the matrix \\(A\\) is not full rank.\nAnother way to decompose the SVD is to write it as a sum of outer products that are scaled by the diagonal matrix of singular values:\n\\[ A = \\sum_{i=1}^r \\sigma_i \\mathbf{u}_i \\mathbf{v}_i^T \\]\nIf \\(\\sigma_i&gt;0\\) then \\(v_i\\) is not in the null space of \\(A\\) because \\(A v_i = \\sigma_i u_i\\). If \\(\\sigma_i = 0\\) then \\(v_i\\) is in the null space of \\(A\\) because \\(A v_i = 0\\).\n\n\nBack to the task of inverting \\(Ax + \\epsilon = b\\) we can apply the SVD decomposition:\n\\[\\begin{align}\nU \\Sigma V^T x + \\epsilon &= b \\\\\n\\Sigma V^T x +&= U^T (b-\\epsilon) \\\\\nV \\Sigma^{-1} U^T (b-\\epsilon) &= x\\\\\nA^+ (b-\\epsilon) &= \\hat{x}\n\\end{align}\\]\nWhere \\(A^+ = V \\Sigma^{-1} U^T\\) is the pseudoinverse of \\(A\\). The pseudoinverse is a generalization of the matrix inverse for non-square matrices. We recover a square matrix by removing all of the absent or zero singular values from \\(\\Sigma\\) and inverting the rest, giving an \\(r \\times r\\) diagonal matrix whose inverse is simply the inverse of each element.\n\\[ \\left[ \\begin{array}{ccc}\n\\sigma_1 &  &  \\\\\n& \\ddots &  \\\\\n&  & \\sigma_r \\\\\n0 & \\cdots & 0 \\\\\n\\vdots & \\ddots & \\vdots \\\\\n0 & \\cdots & 0\n\\end{array} \\right]_{n \\times m}\n\\rightarrow \\left[ \\begin{array}{ccc}\n\\sigma_1^{-1} &  &  \\\\\n  & \\ddots &  \\\\\n  &  & \\sigma_r^{-1} \\\\\n  \\end{array} \\right]_{r \\times r}\\]\nThen \\[\\hat{x} = \\sum_i^N \\sigma_i^{-1} \\mathbf{u}_i^T (b-\\epsilon) \\mathbf{v}_i\\] is the solution to the least squares problem. This can be solved also as a truncated sum since \\(0&lt;N&lt;r\\). In actual practice with real world measurement we end up with many singular values that may be effectively \\(0\\) by nature of being very small relative to the noise in the data and the largest single value. We have that the solution \\(\\hat{x}\\) is a sum of \\(v_i\\) components that form an orthogonal basis \\(\\hat{x} = \\sum_i \\beta_i v_i\\) where \\(\\beta_i = \\frac{u_i^T (b-\\epsilon)}{\\sigma_i}\\). These small singular values blow up in size when inverted and so extra truncation is often necessary to avoid numerical instability and excessive amplification of noise \\(\\epsilon\\).\n\n\n\n\nLeast squares and matrix inversion is a classic starting point for understanding inverse theory. Suppose that we have input data \\(\\vec{x}\\) and output data \\(\\vec{b}\\) that are related by a linear system of equations: \\[Ax = b\\] where \\(A\\) is a matrix of coefficients. In many cases, the system is overdetermined, meaning that there are more equations than unknowns. In this case, there is no exact solution to the system, and we must find the best solution that minimizes the error between the observed data \\(\\vec{b}\\) and the predicted data \\(A\\vec{x}\\). In the simplest form of inversion that we can attempt, we can solve the least squares solution. In this case we reject all of the observed data that is from the null space of \\(A\\) assuming a zero value for each of those parameters.\n\n\nLet \\(A\\) be a \\(3 \\times 2\\) matrix and \\(\\vec{b}\\) be a \\(3 \\times 1\\) vector. The \\(\\vec{x}\\) that we are trying to solve for is a \\(2 \\times 1\\) vector. The system of equations is given by:\n\\[ A = \\begin{bmatrix}  \\vec{a}_1 & \\vec{a}_2 \\end{bmatrix} \\quad \\vec{x} = \\begin{bmatrix} x_1 \\\\ x_2  \\end{bmatrix}  \\quad \\vec{b} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix} \\]\nIn this case we have an overdetermined system with three equations, two unknowns, and three data samples. If the system of equations is full rank then we are trying to map from a 2D space to a 3D space: \\(A: \\mathbb{R}^2 \\rightarrow \\mathbb{R}^3\\). In this case there is no exact solution to the system for any \\(b\\) that is not in the column space of \\(A\\).\nInstead we can solve for the least squares solution \\(\\vec{x}_{LS}\\) by minimizing the error between the observed data \\(\\vec{b}\\) and the predicted data \\(A\\vec{x}\\) from the forward model.\n\\[ \\vec{x}_{LS} = \\arg \\min_{\\vec{x}} ||A\\vec{x} - \\vec{b}||_2^2 \\]\nWe want to find the argument that minimizes the function \\(f(\\vec{x}) = ||A\\vec{x} - \\vec{b}||_2^2\\). By first order optimality conditions, the gradient of the function must be zero at the minimum.\n\\[ \\begin{align}\n\\nabla f(\\vec{x}) &= 0 \\\\\n\\nabla ||A\\vec{x} - \\vec{b}||_2^2 &= 0 \\\\\n\\nabla (A\\vec{x} - \\vec{b})^T (A\\vec{x} - \\vec{b}) &= 0 \\\\\n\\nabla \\left( \\vec{x}^T A^T A \\vec{x} - 2 \\vec{b}^T A \\vec{x} + \\vec{b}^T \\vec{b} \\right) &= 0 \\\\\n2 A^T A \\vec{x} - 2 A^T \\vec{b} &= 0 \\\\\nA^T A \\vec{x} &= A^T \\vec{b} \\\\\n\\vec{x}_{LS} &= (A^T A)^{-1} A^T \\vec{b}\n\\end{align} \\]\nThis is known as the normal equations for the least squares solution. We take a note of caution here that \\(A^T A\\) must be invertible for this solution to exist. If \\(A\\) is not full rank then the matrix \\(A^T A\\) will not be invertible and other methods must be used.\nWe call the difference between the observed data and the predicted data the residual.\n\\(r = \\vec{b} - A\\vec{x}_{LS}\\)\nUsing this information, what we really want to minimize is the sum of the squares of the residuals: \\(||r||_2^2\\). This is the same as the sum of the squares of the errors in the data.\nThere is an altogether informative way to think about the minimization problem purely in terms of linear algebra and subspaces to derive the same normal equations.\n\n\n\nLeast Squares Visual\n\n\nWe have the range of \\(A\\) or image of \\(A\\) as the subspace of \\(\\mathbb{R}^3\\) that is spanned by the columns of \\(A\\). This subspace is rank \\(2\\) because there are only two columns in \\(A\\), \\(R(A) \\subset \\mathbb{R}^3\\). The inaccessible parts of \\(\\mathbb{R}^3\\) are in the orthogonal complement of \\(R(A)\\), \\(R(A)^\\perp\\). Recalling that \\(R(A)^\\perp = N(A^T)\\) we can diagram the solution to least squares as a minimization of the error vector \\(r\\) in the orthogonal complement of \\(R(A)\\).\nAs seen the \\(r\\) vector is perpendicular to the \\(x_{LS}\\) solution, the projection of \\(r\\) onto \\(R(A)\\) is zero. Since it is in a null space of \\(A^T\\) then \\(A^T r = 0\\).\n\\[ \\begin{align} A^T \\left ( Ax_{LS} - b \\right ) &= 0\\\\\nA^T A x_{LS} &= A^T b \\\\\n\\end {align} \\]\nSo we recover the normal equations without using any of the machinery of calculus.\nFor a review on the four fundamental subspaces of a matrix see the UBC Math 307 notes on the topic: Math 307"
  },
  {
    "objectID": "content/eosc555/lectures/lecture1-2/index.html#the-singular-value-decomposition",
    "href": "content/eosc555/lectures/lecture1-2/index.html#the-singular-value-decomposition",
    "title": "Lecture 1",
    "section": "",
    "text": "For cases where the matrix \\(A\\) is not full rank, the singular value decomposition (SVD) provides a more general framework for solving the least squares problem. The SVD decomposes the matrix \\(A\\) into three matrices \\(U\\), \\(\\Sigma\\), and \\(V\\)\n\\[ A = U \\Sigma V^T \\]\nThe matrices have the following special properties:\n\nOrthogonal Subspaces: \\(U\\) and \\(V\\) are orthogonal matrices, meaning that \\(U^TU = I\\) and \\(V^TV = I\\), that is \\(U^T = U^{-1}\\) and $V^T = V^{-1}.\nOrdered Singular Values: \\(\\Sigma\\) is a diagonal matrix with non-negative values on the diagonal, known as the singular values of \\(A\\). The singular values are ordered such that \\(\\sigma_1 \\geq \\sigma_2 \\geq \\ldots \\geq \\sigma_r\\). The number of non-zero singular values is equal to the rank of \\(A\\).\n\nSupposed that we have a \\(\\text{rank}(A) = r\\) matrix \\(A\\) which maps from \\(\\mathbb{R}^m\\rightarrow \\mathbb{R}^n\\). A fundamental way to view this mapping is as a composition of three linear transformations: a rotation \\(V\\), a scaling \\(\\Sigma\\), and another rotation \\(U\\). The orthogonal matrix \\(V\\) has the property that all of its rows and columns are orthogonal to each other, and the vectors themselves are normalized to \\(1\\). To see this property of the orthogonal matrix consider that \\(V^T V = I\\) and \\(V V^T = I\\):\n\\[ \\begin{align}\nZ = V^T V &= I \\\\\nz_{ij} = \\langle v_i, v_j \\rangle &= \\delta_{ij} \\end{align} \\]\nEach of the elements of the matrix \\(V^T\\) is the dot product of the \\(i\\)th and \\(j\\)th columns of \\(V\\). The dotproduct of all vectors against themselves is \\(1\\) and the dotproduct of any two different vectors is \\(0\\). So from this we can see that all of the columns of \\(V\\) are orthogonal to each other. The same property holds for \\(U\\).\n\\(V^T\\) by our definition of \\(A\\) must accept a vector from \\(\\mathbb{R}^m\\) and the matrix is square, indicating an \\(m \\times m\\) matrix. The matrix \\(U\\) must output a vector in \\(\\mathbb{R}^n\\) and the matrix is square, indicating an \\(n \\times n\\) matrix. The matrix \\(\\Sigma\\) must be \\(n \\times m\\) to map from \\(\\mathbb{R}^m\\) to \\(\\mathbb{R}^n\\).\nIn all its glory:\n\\[\n\\begin{aligned}\nA_{n \\times m} &= U_{n \\times n} \\, \\Sigma_{n \\times m} \\, V^T_{m \\times m} \\\\\n&= \\left[ \\begin{array}{ccc|ccc}\n\\mathbf{u}_1 & \\cdots & \\mathbf{u}_r & \\mathbf{u}_{r+1} & \\cdots & \\mathbf{u}_n\n\\end{array} \\right]_{n \\times n}\n\\left[ \\begin{array}{ccc}\n\\sigma_1 &  &  \\\\\n& \\ddots &  \\\\\n&  & \\sigma_r \\\\\n0 & \\cdots & 0 \\\\\n\\vdots & \\ddots & \\vdots \\\\\n0 & \\cdots & 0\n\\end{array} \\right]_{n \\times m}\n\\left[ \\begin{array}{ccc|ccc}\n\\mathbf{v}^T_1 \\\\\n\\vdots \\\\\n\\mathbf{v}^T_r \\\\\n\\mathbf{v}^T_{r+1} \\\\\n\\vdots \\\\\n  \\mathbf{v}^T_m\n\\end{array} \\right]_{m \\times m}\n\\end{aligned}\n\\]\nIn this case the first \\(r\\) columns of \\(U\\) are the range of \\(A\\), the rest of \\(U\\) is filled with its orthogonal complement. The first \\(r\\) columns of \\(V\\) are the domain of \\(A\\), the rest of \\(V\\) is filled with its orthogonal complement. These are the four fundamental subspaces of the matrix \\(A\\), more information on this can be found at: Wikipedia: SVD\nThe matrices as shown above are for a rectangular \\(A\\) where \\(n&gt;m\\) but the same properties hold for all \\(n,m\\). Some of the singular values \\(\\sigma_i\\) may be zero, in which case the matrix \\(A\\) is not full rank.\nAnother way to decompose the SVD is to write it as a sum of outer products that are scaled by the diagonal matrix of singular values:\n\\[ A = \\sum_{i=1}^r \\sigma_i \\mathbf{u}_i \\mathbf{v}_i^T \\]\nIf \\(\\sigma_i&gt;0\\) then \\(v_i\\) is not in the null space of \\(A\\) because \\(A v_i = \\sigma_i u_i\\). If \\(\\sigma_i = 0\\) then \\(v_i\\) is in the null space of \\(A\\) because \\(A v_i = 0\\).\n\n\nBack to the task of inverting \\(Ax + \\epsilon = b\\) we can apply the SVD decomposition:\n\\[\\begin{align}\nU \\Sigma V^T x + \\epsilon &= b \\\\\n\\Sigma V^T x +&= U^T (b-\\epsilon) \\\\\nV \\Sigma^{-1} U^T (b-\\epsilon) &= x\\\\\nA^+ (b-\\epsilon) &= \\hat{x}\n\\end{align}\\]\nWhere \\(A^+ = V \\Sigma^{-1} U^T\\) is the pseudoinverse of \\(A\\). The pseudoinverse is a generalization of the matrix inverse for non-square matrices. We recover a square matrix by removing all of the absent or zero singular values from \\(\\Sigma\\) and inverting the rest, giving an \\(r \\times r\\) diagonal matrix whose inverse is simply the inverse of each element.\n\\[ \\left[ \\begin{array}{ccc}\n\\sigma_1 &  &  \\\\\n& \\ddots &  \\\\\n&  & \\sigma_r \\\\\n0 & \\cdots & 0 \\\\\n\\vdots & \\ddots & \\vdots \\\\\n0 & \\cdots & 0\n\\end{array} \\right]_{n \\times m}\n\\rightarrow \\left[ \\begin{array}{ccc}\n\\sigma_1^{-1} &  &  \\\\\n  & \\ddots &  \\\\\n  &  & \\sigma_r^{-1} \\\\\n  \\end{array} \\right]_{r \\times r}\\]\nThen \\[\\hat{x} = \\sum_i^N \\sigma_i^{-1} \\mathbf{u}_i^T (b-\\epsilon) \\mathbf{v}_i\\] is the solution to the least squares problem. This can be solved also as a truncated sum since \\(0&lt;N&lt;r\\). In actual practice with real world measurement we end up with many singular values that may be effectively \\(0\\) by nature of being very small relative to the noise in the data and the largest single value. We have that the solution \\(\\hat{x}\\) is a sum of \\(v_i\\) components that form an orthogonal basis \\(\\hat{x} = \\sum_i \\beta_i v_i\\) where \\(\\beta_i = \\frac{u_i^T (b-\\epsilon)}{\\sigma_i}\\). These small singular values blow up in size when inverted and so extra truncation is often necessary to avoid numerical instability and excessive amplification of noise \\(\\epsilon\\)."
  },
  {
    "objectID": "content/eosc555/lectures/lecture1-2/index.html#least-squares",
    "href": "content/eosc555/lectures/lecture1-2/index.html#least-squares",
    "title": "Lecture 1",
    "section": "",
    "text": "Least squares and matrix inversion is a classic starting point for understanding inverse theory. Suppose that we have input data \\(\\vec{x}\\) and output data \\(\\vec{b}\\) that are related by a linear system of equations: \\[Ax = b\\] where \\(A\\) is a matrix of coefficients. In many cases, the system is overdetermined, meaning that there are more equations than unknowns. In this case, there is no exact solution to the system, and we must find the best solution that minimizes the error between the observed data \\(\\vec{b}\\) and the predicted data \\(A\\vec{x}\\). In the simplest form of inversion that we can attempt, we can solve the least squares solution. In this case we reject all of the observed data that is from the null space of \\(A\\) assuming a zero value for each of those parameters.\n\n\nLet \\(A\\) be a \\(3 \\times 2\\) matrix and \\(\\vec{b}\\) be a \\(3 \\times 1\\) vector. The \\(\\vec{x}\\) that we are trying to solve for is a \\(2 \\times 1\\) vector. The system of equations is given by:\n\\[ A = \\begin{bmatrix}  \\vec{a}_1 & \\vec{a}_2 \\end{bmatrix} \\quad \\vec{x} = \\begin{bmatrix} x_1 \\\\ x_2  \\end{bmatrix}  \\quad \\vec{b} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix} \\]\nIn this case we have an overdetermined system with three equations, two unknowns, and three data samples. If the system of equations is full rank then we are trying to map from a 2D space to a 3D space: \\(A: \\mathbb{R}^2 \\rightarrow \\mathbb{R}^3\\). In this case there is no exact solution to the system for any \\(b\\) that is not in the column space of \\(A\\).\nInstead we can solve for the least squares solution \\(\\vec{x}_{LS}\\) by minimizing the error between the observed data \\(\\vec{b}\\) and the predicted data \\(A\\vec{x}\\) from the forward model.\n\\[ \\vec{x}_{LS} = \\arg \\min_{\\vec{x}} ||A\\vec{x} - \\vec{b}||_2^2 \\]\nWe want to find the argument that minimizes the function \\(f(\\vec{x}) = ||A\\vec{x} - \\vec{b}||_2^2\\). By first order optimality conditions, the gradient of the function must be zero at the minimum.\n\\[ \\begin{align}\n\\nabla f(\\vec{x}) &= 0 \\\\\n\\nabla ||A\\vec{x} - \\vec{b}||_2^2 &= 0 \\\\\n\\nabla (A\\vec{x} - \\vec{b})^T (A\\vec{x} - \\vec{b}) &= 0 \\\\\n\\nabla \\left( \\vec{x}^T A^T A \\vec{x} - 2 \\vec{b}^T A \\vec{x} + \\vec{b}^T \\vec{b} \\right) &= 0 \\\\\n2 A^T A \\vec{x} - 2 A^T \\vec{b} &= 0 \\\\\nA^T A \\vec{x} &= A^T \\vec{b} \\\\\n\\vec{x}_{LS} &= (A^T A)^{-1} A^T \\vec{b}\n\\end{align} \\]\nThis is known as the normal equations for the least squares solution. We take a note of caution here that \\(A^T A\\) must be invertible for this solution to exist. If \\(A\\) is not full rank then the matrix \\(A^T A\\) will not be invertible and other methods must be used.\nWe call the difference between the observed data and the predicted data the residual.\n\\(r = \\vec{b} - A\\vec{x}_{LS}\\)\nUsing this information, what we really want to minimize is the sum of the squares of the residuals: \\(||r||_2^2\\). This is the same as the sum of the squares of the errors in the data.\nThere is an altogether informative way to think about the minimization problem purely in terms of linear algebra and subspaces to derive the same normal equations.\n\n\n\nLeast Squares Visual\n\n\nWe have the range of \\(A\\) or image of \\(A\\) as the subspace of \\(\\mathbb{R}^3\\) that is spanned by the columns of \\(A\\). This subspace is rank \\(2\\) because there are only two columns in \\(A\\), \\(R(A) \\subset \\mathbb{R}^3\\). The inaccessible parts of \\(\\mathbb{R}^3\\) are in the orthogonal complement of \\(R(A)\\), \\(R(A)^\\perp\\). Recalling that \\(R(A)^\\perp = N(A^T)\\) we can diagram the solution to least squares as a minimization of the error vector \\(r\\) in the orthogonal complement of \\(R(A)\\).\nAs seen the \\(r\\) vector is perpendicular to the \\(x_{LS}\\) solution, the projection of \\(r\\) onto \\(R(A)\\) is zero. Since it is in a null space of \\(A^T\\) then \\(A^T r = 0\\).\n\\[ \\begin{align} A^T \\left ( Ax_{LS} - b \\right ) &= 0\\\\\nA^T A x_{LS} &= A^T b \\\\\n\\end {align} \\]\nSo we recover the normal equations without using any of the machinery of calculus.\nFor a review on the four fundamental subspaces of a matrix see the UBC Math 307 notes on the topic: Math 307"
  },
  {
    "objectID": "content/eosc555/lectures/lecture11/index.html",
    "href": "content/eosc555/lectures/lecture11/index.html",
    "title": "Lecture 11",
    "section": "",
    "text": "$$ \n$$"
  },
  {
    "objectID": "content/eosc555/lectures/lecture11/index.html#score-matching",
    "href": "content/eosc555/lectures/lecture11/index.html#score-matching",
    "title": "Lecture 11",
    "section": "Score Matching",
    "text": "Score Matching\nPreviously in Lecture 10, the concept of score as the gradient of the log-likelihood was introduced.\nFor a probability distribution \\(\\pi(x, \\theta)\\) parameterized by \\(\\theta\\), the distribution can be thought of as a potential function \\(\\phi(x, \\theta)\\) which is normalized by the partition function \\(Z(\\theta)\\):\n\\[ \\pi(x; \\theta) = \\underbrace{\\frac{1}{Z(\\theta)}}_{\\text{Partition}} \\exp(-\\underbrace{\\phi(x; \\theta)}_{\\text{Potential}}) \\]\nThe score is defined as:\n\\[s(x; \\theta) := \\nabla_x \\log \\left(\\pi(x)\\right) = -\\nabla_x \\phi(x;\\theta)\\]\n\nThe Big Idea\nScore matching was first proposed by Hyvärinen in 2005 (Hyvärinen 2005) as a method to estimate model parameters without computing the partition function \\(\\frac{1}{Z(\\theta)}\\), which is often computationally expensive or intractable.\nHyvärinen suggested directly matching the score of the model to the score of the data by minimizing the expected squared difference between them:\n\\[ \\min_\\theta \\mathbb{E}_{x \\sim \\pi(x)} \\left[ \\left\\| s_{\\theta}(x, \\theta) - s_{\\text{true}(x)} \\right\\|^2 \\right] \\]\n\nInuitive Explanation\n\nIf the gradients of two potential functions are equal, the functions themselves differ by at most a constant:\n\n\\[\n\\begin{align*}\n\\nabla_x \\phi(x; \\theta) &= \\nabla_x  \\phi_\\text{true}(x) \\implies\\\\\n\\phi(x; \\theta) &= \\phi_\\text{true}(x) + C\n\\end{align*}\n\\]\nWhere \\(C\\) is a constant independent of \\(x\\). This follows from the fundamental theorem of calculus and is analogous to the principle in physics where two potentials producing the same field differ by a constant.\n\nNormalization by the partition function \\(Z(\\theta)\\) does not affect the relation between the potentials:\n\nThe partition function \\(Z(\\theta)\\) adjusts for any constant differences between the potential functions, ensuring the probability distributions are properly normalized:\n\\[\n\\begin{align*}\n\\pi(x) &= \\frac{1}{Z(\\theta)} \\exp(-\\phi(x; \\theta)) \\\\\n&= \\frac{1}{Z(\\theta)} \\exp(-\\phi_\\text{true}(x) - C) \\\\\n&= \\frac{\\exp(-C)}{Z(\\theta)} \\exp(-\\phi_\\text{true}(x))  \\\\\n&= \\frac{1}{Z_{\\text{true}}} \\exp(-\\phi_\\text{true}(x)) \\\\\n\\end{align*}\n\\]\nThe relation between the two functions is preserved by the partition function, which differs by constant \\(e^{-C}\\) for a difference in potential of \\(C\\). The probability distributions must be equal, as shown above.\nIf we can match the score, then we indirectly match the probability distributions without needing to first compute the partition function. This is the idea behind score matching.\n\n\nVisualization of Score Matching and Potentials\n\nShow the code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set the Seaborn style for modern-looking plots\nsns.set(style=\"whitegrid\", context=\"talk\")\n\n# Define the potential functions\ndef potential_model(x, shift=0):\n    \"\"\"Model potential with an optional scalar shift.\"\"\"\n    return 0.5 * x**2 + shift  # Quadratic potential\n\ndef potential_data(x):\n    \"\"\"Data potential.\"\"\"\n    return 0.5 * x**2  # Quadratic potential with no shift\n\n# Analytical gradients (scores)\ndef gradient_potential_model(x):\n    \"\"\"Gradient of the model potential with respect to x.\"\"\"\n    return x\n\ndef gradient_potential_data(x):\n    \"\"\"Gradient of the data potential with respect to x.\"\"\"\n    return x\n\n# Define the range of x values\nx = np.linspace(-3, 3, 500)\n\n# Compute potentials\nmodel_potential = potential_model(x, shift=1)\ndata_potential = potential_data(x)\n\n# Compute gradients (scores)\nmodel_gradient = gradient_potential_model(x)\ndata_gradient = gradient_potential_data(x)\n\n# Compute partition functions for normalization\ndx = x[1] - x[0]  # Differential element for integration\nZ_model = np.sum(np.exp(-model_potential)) * dx\nZ_data = np.sum(np.exp(-data_potential)) * dx\n\n# Compute normalized probability densities\nnormalized_model = np.exp(-model_potential) / Z_model\nnormalized_data = np.exp(-data_potential) / Z_data\n\n# Create DataFrames for plotting with Seaborn\ndf_potentials = pd.DataFrame({\n    'x': np.tile(x, 2),\n    'Potential': np.concatenate([model_potential, data_potential]),\n    'Type': ['Model Potential (shift=1)'] * len(x) + ['Data Potential (no shift)'] * len(x)\n})\n\ndf_gradients = pd.DataFrame({\n    'x': np.tile(x, 2),\n    'Gradient': np.concatenate([model_gradient, data_gradient]),\n    'Type': ['Gradient of Model Potential'] * len(x) + ['Gradient of Data Potential'] * len(x)\n})\n\ndf_normalized = pd.DataFrame({\n    'x': np.tile(x, 2),\n    'Probability Density': np.concatenate([normalized_model, normalized_data]),\n    'Type': ['Normalized Model Potential'] * len(x) + ['Normalized Data Potential'] * len(x)\n})\n\nfigsize = (5, 3)\n\n# Define custom dash patterns\ndash_styles = {\n    'Model Potential (shift=1)': '',\n    'Data Potential (no shift)': (5, 5),  # Solid line\n    'Gradient of Model Potential': '',\n    'Gradient of Data Potential': (5, 5),\n    'Normalized Model Potential': '',\n    'Normalized Data Potential': (5, 5)\n}\n\nplt.figure(figsize=figsize)\n# Plot potentials\nsns.lineplot(\n    data=df_potentials,\n    x='x',\n    y='Potential',\n    hue='Type',\n    style='Type',\n    dashes=dash_styles,\n    palette='deep',\n)\nplt.xlabel('x')\nplt.ylabel('Potential Energy')\nplt.legend(title='')\nplt.show()\n\nplt.figure(figsize=figsize)\n# Plot gradients (scores)\nsns.lineplot(\n    data=df_gradients,\n    x='x',\n    y='Gradient',\n    hue='Type',\n    style='Type',\n    dashes=dash_styles,\n    palette='muted',\n)\nplt.xlabel('x')\nplt.ylabel('Gradient')\nplt.legend(title='')\nplt.show()\n\nplt.figure(figsize=figsize)\n# Plot normalized probability densities\nsns.lineplot(\n    data=df_normalized,\n    x='x',\n    y='Probability Density',\n    hue='Type',\n    style='Type',\n    dashes=dash_styles,\n    palette='bright',\n)\nplt.xlabel('x')\nplt.ylabel('Probability Density')\nplt.legend(title='')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEliminating True Score\nThe score for the data \\(s_{\\text{true}}\\) is unknown, but it can be eliminated using calculus tricks, as shown in (Hyvärinen 2005). The expected squared difference can be rewritten as:\n\\[\n\\begin{align*}\n& \\ \\min_\\theta \\mathbb{E} \\frac{1}{2} \\left[ \\left\\| s_{\\theta}(x, \\theta) - s_{\\text{true}}(x) \\right\\|^2 \\right] \\\\\n&= \\min_\\theta  \\frac{1}{2}  \\int_\\Omega \\left\\| s_{\\theta}(x, \\theta) - s_{\\text{true}}(x) \\right\\|^2 \\pi(x) \\, dx \\\\\n&= \\min_\\theta  \\frac{1}{2}  \\int_\\Omega \\left\\| s_{\\theta}(x, \\theta) \\right\\|^2 \\pi(x) \\, dx - \\int_\\Omega s_{\\theta}(x, \\theta)^\\intercal s_{\\text{true}}(x) \\pi(x) \\, dx + \\frac{1}{2} \\int_\\Omega \\left\\| s_{\\text{true}}(x) \\right\\|^2 \\pi(x) \\, dx \\\\\n\\end{align*}\n\\]\nBut \\(\\|s_{\\text{true}}\\|\\) is a constant since it is not a variable that can be changed, it can be discarded from the minimization problem:\n\\[\n\\begin{align*}\n&= \\min_\\theta \\frac{1}{2}  \\int_\\Omega \\left\\| s_{\\theta}(x, \\theta) \\right\\|^2 \\pi(x) \\, dx - \\int_\\Omega s_{\\theta}(x, \\theta)^\\intercal s_{\\text{true}}(x) \\pi(x) \\, dx \\\\\n\\end{align*}\n\\]\nTo eliminate \\(s_{\\text{true}}\\), the definition of score can be used to rewrite the term:\n\\[\n\\begin{align*}\n& \\ -\\int_\\Omega s_{\\theta}(x, \\theta)^\\intercal s_{\\text{true}}(x) \\pi(x) \\, dx\\\\\n&= -\\int_\\Omega  \\pi(x) \\left(\\nabla_x \\log(\\pi(x))\\right)^\\intercal  s_\\theta(x; \\theta) \\, dx \\\\\n& = -\\int_\\Omega  \\frac{\\pi(x)}{\\pi(x)}\\left(\\nabla_x \\pi(x)\\right)^\\intercal  s_\\theta(x; \\theta) \\, dx \\\\\n& = -\\int_\\Omega  \\nabla_x \\pi(x)^\\intercal  s_\\theta(x; \\theta) \\, dx \\\\\n\\end{align*}\n\\]\nIntegration by parts allows for the gradient term to be swapped to the score term. If we assume that the probability of the true distribution goes to zero \\(\\pi(x) \\rightarrow 0\\) at the boundaries \\(\\partial \\Omega\\), then the flux integral boundary term from integration by parts vanishes. When working with integration by parts in multivarible calculus, the gradient \\(\\nabla\\) and negative divergence \\(-\\nabla \\cdot\\) opeartors are adjoints of each other, \\(\\nabla = (-\\nabla \\cdot)^\\intercal\\). This allows for the gradient to be swapped to the score term:\n\\[\n\\begin{align*}\n& = -\\int_\\Omega  \\nabla_x \\pi(x)^\\intercal  s_\\theta(x; \\theta) \\, dx \\\\\n&= -\\int_{\\partial \\Omega} \\pi(x) s_\\theta(x; \\theta) \\cdot dx + \\int_\\Omega  \\pi(x) \\nabla_x \\cdot s_\\theta(x; \\theta) \\, dx \\\\\n&= \\int_\\Omega  \\pi(x) \\nabla_x \\cdot s_\\theta(x; \\theta) \\, dx \\\\\n\\int_\\Omega s_{\\theta}(x, \\theta)^\\intercal s_{\\text{true}}(x) \\pi(x) \\, dx &= \\int_\\Omega  \\pi(x) \\nabla_x^2 \\phi(x;\\theta) \\, dx \\\\\n\\end{align*}\n\\]\nBack to the minimization problem, this term can be substituted back in:\n\\[\n\\begin{align*}\n& \\ \\min_\\theta \\mathbb{E}_{x \\sim \\pi(x)} \\frac{1}{2} \\left[ \\left\\| s_{\\theta}(x, \\theta) - s_{\\text{true}(x)} \\right\\|^2 \\right]\\\\\n&= \\min \\frac{1}{2}  \\int_\\Omega \\left\\| \\nabla_x \\phi(x;\\theta) \\right\\|^2 \\pi(x) \\, dx + \\int_\\Omega  \\pi(x) \\nabla_x^2 \\phi(x;\\theta) \\, dx \\\\\n&= \\min_{theta} \\mathbb{E}_{x \\sim \\pi(x)} \\left[ \\left\\| \\nabla_x \\phi(x;\\theta) \\right\\|^2 + \\nabla_x^2 \\phi(x;\\theta) \\right] \\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "content/eosc555/lectures/lecture11/index.html#evaluation-of-the-objective",
    "href": "content/eosc555/lectures/lecture11/index.html#evaluation-of-the-objective",
    "title": "Lecture 11",
    "section": "Evaluation of the Objective",
    "text": "Evaluation of the Objective\nThe minimization objective does not require using the true score which has been eliminated. The \\(\\nabla_x^2 \\phi(x;\\theta)\\) term can be evaluated as the trace of the Hessian matrix of the potential function \\(\\phi(x;\\theta)\\):\n\\[\n\\nabla_x^2 \\phi(x;\\theta) = \\text{Tr} \\left( \\nabla_x^2 \\phi(x;\\theta) \\right) = \\sum_i \\frac{\\partial^2 \\phi(x;\\theta)}{\\partial x_i^2}\n\\]\nThis component places a penalty on positive curvature in the potential function, preferring highly negative curvature in regions of high probability density, similar to a Gaussian or peaked distribution. It can be though of as a regularization term that prefers peaked distributions.\nThe \\(\\left\\| \\nabla_x \\phi(x;\\theta) \\right\\|^2\\) term is the squared norm of the gradient, which penalizes large gradients. With this term alone, the optimal distribution would be as flat as possible to make the gradient as small as possible. It is the opposition of the minimization objective of the two terms that leads to a balanced and matched distribution.\nIn practice, we can estimate the true expectation over all \\(x\\) by sampling from the model distribution. Once such way is to use the empiral samples \\(\\{x_1, x_2, \\ldots, x_N\\}\\) to estimate the expectation. If they are assumed to be i.i.d. samples from the model distribution, the expectation can be approximated as:\n\\[\n\\begin{align*}\n\\mathbb{E}_{x \\sim \\pi(x)} \\left[ \\left\\| \\nabla_x \\phi(x;\\theta) \\right\\|^2 + \\nabla_x^2 \\phi(x;\\theta) \\right] &\\approx \\frac{1}{N} \\sum_{i=1}^N \\left\\| \\nabla_x \\phi(x_i;\\theta) \\right\\|^2 + \\nabla_x^2 \\phi(x_i;\\theta) \\\\\n\\end{align*}\n\\]\nThis can be applied to all samples, or batches of samples to get a gradient estimate for the minimization objective in \\(\\theta\\):\n\\[\n\\begin{align*}\ng &\\approx \\nabla_\\theta \\left[ \\frac{1}{N} \\sum_{i=1}^N \\left\\| \\nabla_x \\phi(x_i;\\theta) \\right\\|^2 + \\nabla_x^2 \\phi(x_i;\\theta) \\right] \\\\\n\\end{align*}\n\\]\n\nComputing the Laplacian\nThe Laplacian of the potential function \\(\\phi(x;\\theta)\\) can be computed as the trace of the Hessian matrix of the potential function:\n\\[\n\\begin{align*}\n\\nabla_x^2 \\phi(x;\\theta) &= \\text{tr} \\left( \\nabla_x^2 \\phi(x;\\theta) \\right) \\\\\n&= \\sum_i \\frac{\\partial^2 \\phi(x;\\theta)}{\\partial x_i^2}\n\\end{align*}\n\\]\nThe trace of a matrix such as a Hessian which is a linear operator can be estimated without having to know the explicit matrix. For example the Hessian may be an operator that is too large to store in memory. Or the Hessian may not be explicitly known, but the operation \\(Hx\\) can be computed for example.\nA process first proposed by Hutchinson (Hutchinson 1990), known as randomized linear algebra allows for computing the trace when only the \\(H(x)\\) operation is known. A random varible is used to sample as follows:\n\\[\n\\begin{align*}\n\\text{tr} \\left(A\\right) &= \\text{tr} \\left(AI\\right) \\\\\n&= \\text{tr} \\left( A \\mathbb{E}_{x\\sim\\mathcal{N}(0,I)} x x^\\intercal \\right)\\\\\n&= \\mathbb{E}_{x\\sim\\mathcal{N}(0,I)} \\text{tr} \\left( A x x^\\intercal \\right)\\\\\n&= \\mathbb{E} \\text{tr} \\left(x^\\intercal A x  \\right)\\\\\n&\\approxeq \\frac{1}{N} \\sum_{i=1}^N x_i^\\intercal A x_i\n\\end{align*}\n\\]\nThe normal distribution by definition has a covariance matrix that is identity \\(I\\) so the expectation of the outer product of the random variable \\(x\\) is the identity matrix. Other random variables can be used as well, further details on the process can be found in Bai, Fahey, and Golub (Bai, Fahey, and Golub 1996)."
  },
  {
    "objectID": "content/eosc555/lectures/lecture11/index.html#applications-of-learned-score",
    "href": "content/eosc555/lectures/lecture11/index.html#applications-of-learned-score",
    "title": "Lecture 11",
    "section": "Applications of Learned Score",
    "text": "Applications of Learned Score\n\nMAP Estimation\nNow that we have a method to learn the score of a distribution, it can be used as the regularization term of the gradient in MAP estimation. In Lecture10, the score was used as part of the MAP minimization gradient.\n\n\n\n\n\n\nMAP Estimation\n\n\n\nObjective: \\[\\min_x \\left( \\frac{1}{2\\sigma^2}\\|F(x)-b\\|^2 + \\phi(x, \\theta) \\right)\\] Gradient: \\[ g = \\frac{1}{\\sigma^2} J^T(x) (F(x) - b) + s(x, \\theta)\\] Gradient Descent: \\[ x_{k+1} = x_k - \\mu J^T(x) (F(x) - b) - s(x, \\theta)\\]\n\n\nSo using many empirically drawn samples \\(x_i\\), the \\(\\pi(x)\\) distribution can be indirectly estimated using score matching, learning the score \\(s(x, \\theta)\\). The learned score can then be used for the gradient of the MAP estimation problem, where it is representative of the regularization term, informed by the prior distribution \\(\\pi(x)\\). In the case of a matrix operator for the forward problem \\(F(x) = Ax\\), its Jacobian \\(J(x)\\) is the same as the matrix operator \\(J(x) = A\\).\n\n\nDiffusion Models and Homotopy\nIn Lecture 7, the concept of a homotopy beteween two functions was introduced. A homotopy provides a continuous path between an smoothing function \\(g(x)\\) and a target function \\(f(x)\\), parameterized by a scalar \\(t\\). In the case of a gaussian smoothing function \\(g(x)\\), \\(t\\) acts as a variance parameter: \\[\nh(x, t) = t f(x) + (1-t) g(x)\n\\]\n\nProposition: Convolution of Random Variables\nThe sum of two independent random variables is a convolution of their probability distributions. If \\(X \\sim \\pi_x(x)\\) and \\(Y \\sim \\pi_y(y)\\), then the sum \\(W = X + Y\\) has a probability distribution \\(\\pi_w(w)\\) that is the convolution of the two distributions:\n\\[\n\\begin{align*}\n\\pi_w(w) &= \\int \\pi_x(x) \\pi_y(z-x) \\, dx \\\\\n\\end{align*}\n\\]\n\nFor a dataset \\(x\\sim \\pi(x)\\) and a latent variable \\(z\\sim \\mathcal{N}(0, I)\\), then define a new random variable \\(x_t\\) that is the sum of the two variables:\n\\[\nx_t = \\sqrt{t}x + \\sqrt{1-t} z\n\\]\nThe homotopy proceeds slightlt differently with the time scheduling but it still begins and ends with the starting and target distributions. This new random variable \\(x_t\\) will be the convolution of the two distributions, such that \\(\\pi_{x_t}(x_t)\\) is the convolution of \\(t \\pi(x)\\) and \\(\\mathcal{N}(0, (1-t)I)\\):\n\\[ \\pi(x_t) = \\int \\pi(x-\\frac{\\xi}{t}) \\exp\\left(-\\frac{\\|\\xi\\|^2}{2(1-t)}\\right) \\, d\\xi \\]"
  },
  {
    "objectID": "content/eosc555/lectures/lecture3/index.html",
    "href": "content/eosc555/lectures/lecture3/index.html",
    "title": "Lecture 3: Image Denoising with Gradient Descent and Early Stopping",
    "section": "",
    "text": "Often times we wish to find the gradient of a multi-variable function that is formulated as a linear algebra operation. In this case there are some useful “vector” derivatives and rules that can simplify the process of calculating more complex expressions. The gradient with respect to vector \\(\\mathbf{x}\\) is generally denoted as \\(\\nabla_{\\mathbf{x}}\\) or alternatively \\(\\partial_{\\mathbf{x}}\\), somewhat of an abuse of notation.\n\n\n\\[\\phi(x) = a^\\top x = \\sum_i a_i x_i\\]\nThis is a vector dotproduct and the gradient is simply the vector \\(a\\). There is a subtlety here in that the vector is usually transposed to be a column vector, but this is not always the case. Some people in the field of statistics prefer to use row vector, this can cause some confusion. The general convention is a column vector.\n\\[\\nabla_{\\mathbf{x}} \\phi = a\\]\n\n\n\n\\[\\phi(x) = Ax\\]\nBased on the previous process we are expecting to potentially get \\(A^\\top\\) as the gradient, however the transpose does not occur in this case because we are not returning a vector that needs to be reshaped into a column form.\n\\[\\nabla_{\\mathbf{x}} \\phi = A\\]\n\n\n\nOften we may encounter quadratic linear functions that are of the form: \\[ \\phi(x) = x^\\top A x\\]\nOne way to determine the gradient is to expand the expression and evaluate for a single \\(\\frac{\\partial}{\\partial x_i}\\) term. This method can be found at Mark Schmidt Notes Instead we can apply a chain rule for matrix differentiation that is based on the product rule for differentiation. The chain rule for matrix differentiation is as follows:\n\\[\\frac{d f(g,h)}{d x} = \\frac{d (g(x)^\\top)}{d x} \\frac{\\partial f(g,h)}{\\partial g} + \\frac{d (h(x)^\\top)}{d x} \\frac{\\partial f(g,h)}{\\partial h}\\]\n\\[ \\begin {align*}\n\\phi(x) &= x^\\top A x \\\\\n\\nabla_{\\mathbf{x}} \\phi &= \\nabla_{\\mathbf{x}} (x^\\top A x) \\\\\n&= \\nabla_{\\mathbf{x}} x^\\top (A x) =  \\nabla_{\\mathbf{x}} x^\\top y\\\\\n&= (\\nabla_{\\mathbf{x}} x) \\nabla_{\\mathbf{x}} x^\\top y + \\nabla_{\\mathbf{x}} y^\\top \\nabla_{\\mathbf{y}} x^\\top y\\\\\n&= I y + \\nabla_{\\mathbf{x}} (x^\\top A^\\top) x\\\\\n&= (A x) + A^\\top x\\\\\n&= (A + A^\\top) x\n\\end {align*}\n\\]\nThis fits with the generalization for a scalar quadratic form where we end up with \\((cx^2)' = (c + c^\\top)x = 2cx\\) where \\(c\\) is a scalar.\n\n\n\nAnother form of interest is the hadamard product of two vectors. \\[\\phi(x) = (Ax)^2 = Ax \\odot Ax\\]\nFor this one let \\(y=Ax\\) and we can index each element of the vector \\(y\\) as \\(y_i = \\sum_j A_{ij} x_j\\). The hadamard product is a vector \\(z\\) where \\(z_i = y_i^2\\), we can compute the jacobian since now we are taking the gradient with respect to a vector.\nThe Jacobian will contain the partial derivatives:\n\\[\\frac{d\\vec{z}}{d\\vec{x}} = \\begin{bmatrix} \\frac{\\partial z_1}{\\partial x_1} & \\frac{\\partial z_1}{\\partial x_2} & \\cdots & \\frac{\\partial z_1}{\\partial x_n} \\\\\n\\frac{\\partial z_2}{\\partial x_1} & \\frac{\\partial z_2}{\\partial x_2} & \\cdots & \\frac{\\partial z_2}{\\partial x_n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial z_n}{\\partial x_1} & \\frac{\\partial z_n}{\\partial x_2} & \\cdots & \\frac{\\partial z_n}{\\partial x_n} \\end{bmatrix}\n\\]\nIf we can recover this then we have the gradient of the hadamard product.\n\\[\n\\begin{align*}\nz_i &= y_i^2 = \\left( \\sum_j A_{ij} x_j \\right)^2\\\\\n\\frac{\\partial}{\\partial x_j} y_i^2 &= 2 y_i \\frac{\\partial y_i}{\\partial x_j} = 2 y_i A_{ij}\\\\\n\\frac{d\\vec{z}}{d\\vec{x}} &= 2 \\begin{bmatrix} y_1 A_{1j} & y_1 A_{2j} & \\cdots & y_1 A_{nj} \\\\\ny_2 A_{1j} & y_2 A_{2j} & \\cdots & y_2 A_{nj} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\ny_n A_{1j} & y_n A_{2j} & \\cdots & y_n A_{nj} \\end{bmatrix}\\\\\n&= 2 \\cdot \\text{diag}(\\vec{y})A\\\\\n&= 2 \\cdot \\text{diag}(Ax)A\n\\end{align*}\n\\]\n\n\n\nWe look at taking the gradient of the expansion of least squares to find the gradient for this optimization objective.\n\\[\\phi(x) = \\frac{1}{2} ||Ax - b||^2 = \\frac{1}{2} (x^\\top A^\\top A x - 2 b^\\top A x + b^\\top b)\\]\n\\[ \\begin{align*}\n\\nabla_{\\mathbf{x}} \\phi &= \\nabla_{\\mathbf{x}} \\left( \\frac{1}{2} (x^\\top A^\\top A x - 2 b^\\top A x + b^\\top b) \\right)\\\\\n&= \\nabla_{\\mathbf{x}} \\left( \\frac{1}{2} x^\\top A^\\top A x \\right) - \\nabla_{\\mathbf{x}} \\left( b^\\top A x \\right)\\\\\n&= \\frac{1}{2} (A^\\top A + A^\\top A) x - A^\\top b\\\\\n&= A^\\top A x - A^\\top b\\\\\n\\end{align*}\n\\]\nReturning to the first-order optimality condition we have: \\[A^\\top A x = A^\\top b\\]\nAt which point it is in question if \\(A^\\top A\\) is invertible. The invertibility of \\(A^\\top A\\) is determined by the rank of \\(A\\). The rank of A for a non-square matrix is the number of independent columns. If we examine \\(A^\\top Ax = 0\\) then we see that this is only true where the range of \\(A\\) is in the nullspace of \\(A^\\top\\). But \\(N(A^\\top) = R(A)^\\perp\\) so they are orthogonal subspaces and will never coincide unless \\(Ax=0\\). So then \\(A^\\top A x = 0\\) implies that \\(Ax = 0\\) which means that if the null space of \\(A=\\{0\\}\\) then the null space of \\(A^\\top A = \\{0\\}\\) and \\(A^\\top A\\) is invertible. Since \\(A^\\top A\\) is symmetric and positive definite, it is invertible.\n\\(A^\\top A\\) is invertible \\(\\iff\\) \\(A\\) is full rank, that is all the columns are independent. For non-square matrices, an \\(m&gt;n\\) matrix that is wide will trivially not satisfy this condition. A tall matrix \\(m&lt;n\\) will satisfy the condition if the columns are independent."
  },
  {
    "objectID": "content/eosc555/lectures/lecture3/index.html#derivations-of-linear-algebra-gradients",
    "href": "content/eosc555/lectures/lecture3/index.html#derivations-of-linear-algebra-gradients",
    "title": "Lecture 3: Image Denoising with Gradient Descent and Early Stopping",
    "section": "",
    "text": "Often times we wish to find the gradient of a multi-variable function that is formulated as a linear algebra operation. In this case there are some useful “vector” derivatives and rules that can simplify the process of calculating more complex expressions. The gradient with respect to vector \\(\\mathbf{x}\\) is generally denoted as \\(\\nabla_{\\mathbf{x}}\\) or alternatively \\(\\partial_{\\mathbf{x}}\\), somewhat of an abuse of notation.\n\n\n\\[\\phi(x) = a^\\top x = \\sum_i a_i x_i\\]\nThis is a vector dotproduct and the gradient is simply the vector \\(a\\). There is a subtlety here in that the vector is usually transposed to be a column vector, but this is not always the case. Some people in the field of statistics prefer to use row vector, this can cause some confusion. The general convention is a column vector.\n\\[\\nabla_{\\mathbf{x}} \\phi = a\\]\n\n\n\n\\[\\phi(x) = Ax\\]\nBased on the previous process we are expecting to potentially get \\(A^\\top\\) as the gradient, however the transpose does not occur in this case because we are not returning a vector that needs to be reshaped into a column form.\n\\[\\nabla_{\\mathbf{x}} \\phi = A\\]\n\n\n\nOften we may encounter quadratic linear functions that are of the form: \\[ \\phi(x) = x^\\top A x\\]\nOne way to determine the gradient is to expand the expression and evaluate for a single \\(\\frac{\\partial}{\\partial x_i}\\) term. This method can be found at Mark Schmidt Notes Instead we can apply a chain rule for matrix differentiation that is based on the product rule for differentiation. The chain rule for matrix differentiation is as follows:\n\\[\\frac{d f(g,h)}{d x} = \\frac{d (g(x)^\\top)}{d x} \\frac{\\partial f(g,h)}{\\partial g} + \\frac{d (h(x)^\\top)}{d x} \\frac{\\partial f(g,h)}{\\partial h}\\]\n\\[ \\begin {align*}\n\\phi(x) &= x^\\top A x \\\\\n\\nabla_{\\mathbf{x}} \\phi &= \\nabla_{\\mathbf{x}} (x^\\top A x) \\\\\n&= \\nabla_{\\mathbf{x}} x^\\top (A x) =  \\nabla_{\\mathbf{x}} x^\\top y\\\\\n&= (\\nabla_{\\mathbf{x}} x) \\nabla_{\\mathbf{x}} x^\\top y + \\nabla_{\\mathbf{x}} y^\\top \\nabla_{\\mathbf{y}} x^\\top y\\\\\n&= I y + \\nabla_{\\mathbf{x}} (x^\\top A^\\top) x\\\\\n&= (A x) + A^\\top x\\\\\n&= (A + A^\\top) x\n\\end {align*}\n\\]\nThis fits with the generalization for a scalar quadratic form where we end up with \\((cx^2)' = (c + c^\\top)x = 2cx\\) where \\(c\\) is a scalar.\n\n\n\nAnother form of interest is the hadamard product of two vectors. \\[\\phi(x) = (Ax)^2 = Ax \\odot Ax\\]\nFor this one let \\(y=Ax\\) and we can index each element of the vector \\(y\\) as \\(y_i = \\sum_j A_{ij} x_j\\). The hadamard product is a vector \\(z\\) where \\(z_i = y_i^2\\), we can compute the jacobian since now we are taking the gradient with respect to a vector.\nThe Jacobian will contain the partial derivatives:\n\\[\\frac{d\\vec{z}}{d\\vec{x}} = \\begin{bmatrix} \\frac{\\partial z_1}{\\partial x_1} & \\frac{\\partial z_1}{\\partial x_2} & \\cdots & \\frac{\\partial z_1}{\\partial x_n} \\\\\n\\frac{\\partial z_2}{\\partial x_1} & \\frac{\\partial z_2}{\\partial x_2} & \\cdots & \\frac{\\partial z_2}{\\partial x_n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial z_n}{\\partial x_1} & \\frac{\\partial z_n}{\\partial x_2} & \\cdots & \\frac{\\partial z_n}{\\partial x_n} \\end{bmatrix}\n\\]\nIf we can recover this then we have the gradient of the hadamard product.\n\\[\n\\begin{align*}\nz_i &= y_i^2 = \\left( \\sum_j A_{ij} x_j \\right)^2\\\\\n\\frac{\\partial}{\\partial x_j} y_i^2 &= 2 y_i \\frac{\\partial y_i}{\\partial x_j} = 2 y_i A_{ij}\\\\\n\\frac{d\\vec{z}}{d\\vec{x}} &= 2 \\begin{bmatrix} y_1 A_{1j} & y_1 A_{2j} & \\cdots & y_1 A_{nj} \\\\\ny_2 A_{1j} & y_2 A_{2j} & \\cdots & y_2 A_{nj} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\ny_n A_{1j} & y_n A_{2j} & \\cdots & y_n A_{nj} \\end{bmatrix}\\\\\n&= 2 \\cdot \\text{diag}(\\vec{y})A\\\\\n&= 2 \\cdot \\text{diag}(Ax)A\n\\end{align*}\n\\]\n\n\n\nWe look at taking the gradient of the expansion of least squares to find the gradient for this optimization objective.\n\\[\\phi(x) = \\frac{1}{2} ||Ax - b||^2 = \\frac{1}{2} (x^\\top A^\\top A x - 2 b^\\top A x + b^\\top b)\\]\n\\[ \\begin{align*}\n\\nabla_{\\mathbf{x}} \\phi &= \\nabla_{\\mathbf{x}} \\left( \\frac{1}{2} (x^\\top A^\\top A x - 2 b^\\top A x + b^\\top b) \\right)\\\\\n&= \\nabla_{\\mathbf{x}} \\left( \\frac{1}{2} x^\\top A^\\top A x \\right) - \\nabla_{\\mathbf{x}} \\left( b^\\top A x \\right)\\\\\n&= \\frac{1}{2} (A^\\top A + A^\\top A) x - A^\\top b\\\\\n&= A^\\top A x - A^\\top b\\\\\n\\end{align*}\n\\]\nReturning to the first-order optimality condition we have: \\[A^\\top A x = A^\\top b\\]\nAt which point it is in question if \\(A^\\top A\\) is invertible. The invertibility of \\(A^\\top A\\) is determined by the rank of \\(A\\). The rank of A for a non-square matrix is the number of independent columns. If we examine \\(A^\\top Ax = 0\\) then we see that this is only true where the range of \\(A\\) is in the nullspace of \\(A^\\top\\). But \\(N(A^\\top) = R(A)^\\perp\\) so they are orthogonal subspaces and will never coincide unless \\(Ax=0\\). So then \\(A^\\top A x = 0\\) implies that \\(Ax = 0\\) which means that if the null space of \\(A=\\{0\\}\\) then the null space of \\(A^\\top A = \\{0\\}\\) and \\(A^\\top A\\) is invertible. Since \\(A^\\top A\\) is symmetric and positive definite, it is invertible.\n\\(A^\\top A\\) is invertible \\(\\iff\\) \\(A\\) is full rank, that is all the columns are independent. For non-square matrices, an \\(m&gt;n\\) matrix that is wide will trivially not satisfy this condition. A tall matrix \\(m&lt;n\\) will satisfy the condition if the columns are independent."
  },
  {
    "objectID": "content/eosc555/lectures/lecture3/index.html#gradient-descent-analysis",
    "href": "content/eosc555/lectures/lecture3/index.html#gradient-descent-analysis",
    "title": "Lecture 3: Image Denoising with Gradient Descent and Early Stopping",
    "section": "Gradient Descent Analysis",
    "text": "Gradient Descent Analysis\nThe standard form of the gradient descent algorithm comes from the field of optimization and can be written as:\n\\[ x_{k+1} = x_k - \\alpha \\nabla_x \\phi(x_k)\\]\nWhere \\(\\alpha\\) is the learning rate, which can be dependent on the problem and the gradient. Substituting the gradient of the least squares problem we have:\n\\[ \\begin{align}\nx_{k+1} &= x_k - \\alpha (A^\\top A x_k - A^\\top b)\\\\\n\\frac{x_{k+1}-x_k}{\\alpha} &= A^\\top b - A^\\top A x_k\\\\\n\\lim_{\\alpha \\to 0} \\frac{x_{k+1}-x_k}{\\alpha} &= \\frac{dx}{dt} = A^\\top (b -A x), \\quad x(0) = x_0\n\\end{align}\n\\]\nThis ODE is the continuous version of the gradient descent algorithm, also known as the gradient flow. Since this a linear first-order ODE we can solve it analytically. The general method for a linear system ODE would be to find the homogeneous solution and the particular solution:\n\\[ \\begin{align}\nx' + A^\\top A x &= A^\\top b\\\\\n\\text{Guess:} x &= v e^{\\lambda t}\\\\\n\\lambda v e^{\\lambda t} + A^\\top A v e^{\\lambda t} &= A^\\top b e^{\\lambda t}\\\\\n\\lambda v + A^\\top A v &= 0 \\qquad \\text{Homogeneous}\\\\\n(\\lambda I + A^\\top A) v &= 0\\\\\n\\lambda &= \\text{eigenvalues of } A^\\top A, \\quad v = \\text{eigenvectors of } A^\\top A\n\\end{align}\n\\]\nBefore continuing further with this line, we can see that the solutions will be closely related to the SVD because it contains the information on these eigenvalues and vectors. So we can try to solve the ODE with the SVD.\n\nSolving the ODE with SVD\n\\[\\begin{align}\nA &= U \\Sigma V^\\top\\\\\nA^TA &= V \\Sigma^2 V^\\top\\\\\n\\frac{d}{dt}x &= V \\Sigma U^\\top b - V \\Sigma^2 V^\\top x\\\\\n\\end{align}\n\\]\nNow let \\(z = V^\\top x\\) and \\(\\hat b = U ^ \\top b\\) then we have:\n\\[\\begin{align}\n\\frac{d}{dt} (V^\\top x) &= \\Sigma \\hat b - \\Sigma^2 (V^\\top x)\\\\\n\\frac{d}{dt} z &= \\Sigma \\hat b - \\Sigma^2 z\\\\\nz' + \\Sigma^2 z &= \\Sigma \\hat b\\\\\n\\end{align}\n\\]\nAt this stage since everything has been diagonalized, all of the equations are decoupled and independent so we can solve for the \\(\\lambda_i\\) cases independently. We find the homogeneous \\(z_h\\) and particular \\(z_p\\) solutions:\n\\[\n\\begin{align}\nz_h' + \\lambda^2 z_h &= 0\\\\\nz_h &= c e^{-\\lambda^2 t}\\\\\nz_p' + \\lambda^2 z_p &= \\lambda \\hat b\\\\\nz_p &= D \\hat b \\\\\n\\lambda^2 D \\hat b &= \\lambda \\hat b\\\\\nD &= \\frac{1}{\\lambda}\\\\\nz_p &= \\frac{1}{\\lambda} \\hat b\n\\end{align}\n\\]\nSo the general solution for the \\(i^{th}\\) component is:\n\\[z_i = c_i e^{-\\lambda_i^2 t} + \\frac{1}{\\lambda_i} \\hat b_i\\]\nSupposing that we start at \\(x=0\\) then we have \\(z=0\\) at all elements and can solve the coefficients \\(c_i\\):\n\\[c_i = -\\frac{1}{\\lambda_i} \\hat b_i\\]\nThen putting it all back together with all the equations we have that\n\\[Z = \\text{diag}\\left( \\lambda_i^{-1} (1 - \\exp (-\\lambda_i t)) \\right) \\hat b\\]\nSubstituting back in for \\(x\\) and \\(b\\) we get:\n\\[x = V \\text{diag}\\left( \\lambda_i^{-1} (1 - \\exp (-\\lambda_i t)) \\right) U^\\top b\\]\nIf we stare at this long enough it begins to look a lot like the pseudoinverse of \\(A\\) from earlier:\n\\(x = V \\Sigma^{-1} U^\\top b\\) except in this case there is a time dependence. At the limit as \\(t \\rightarrow \\infty\\) we have that the exponential term goes to zero and we are left with the pseudoinverse solution. This is a nice way to see that the pseudoinverse is the limit of the gradient descent algorithm. What we may be interested in is what happens at earlier stages since each decay term is dependent on the eigenvalues.\nFor a simple matrix problem we can create a matrix and plot out the time evolution of the diagonals of the matrix that are of interest. In a sense, we have singular values that are time evolving at different rates.\n\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Seed for reproducibility\nnp.random.seed(4)\n# Create a 5x10 matrix A with random values\nA = np.random.randn(5, 10)\n# Create a vector b of size 5 with random values\nb = np.random.randn(5)\n\n# Compute the SVD of A\nU, S, Vt = np.linalg.svd(A, full_matrices=False)\n\n# Create a time dependent vector of the singular values\ndef St(t):\n    Sdim = S[:, np.newaxis]\n    return (1 - np.exp(-Sdim**2*t)) / Sdim\n\n# Compute the time evolution of the values and plot them on a log scale y axis with a linear time x axis\nt = np.linspace(0, .6, 100)\nT = t[np.newaxis, :]\n\nsingular_vals_t = St(T)\n\n# Initialize the plot\nplt.figure(figsize=(7.5, 4))\n\n# Create a color palette\npalette = sns.color_palette(\"husl\", len(S))\n\n# Plot the singular values and their asymptotes\nfor i in range(len(S)):\n    # Plot the time evolution of each singular value\n    sns.lineplot(x=t, y=singular_vals_t[i, :], color=palette[i], linewidth=2, label=f'$1/S_{i}$ ')\n    \n    Sinv = 1/S[i]\n\n    # Add a horizontal asymptote at the original singular value\n    plt.axhline(y=Sinv, color=palette[i], linestyle='--', linewidth=1)\n    \n    # Annotate the asymptote with the singular value\n    plt.text(t[-1] + 0.02, Sinv, f'{Sinv:.2f}', color=palette[i], va='center')\n\n# Configure plot aesthetics\nplt.xlabel('Time', fontsize=14)\nplt.ylabel('Inverse Singular Vals', fontsize=14)\nplt.title('Time Evolution of Pseudo Inverse in Gradient Flow', fontsize=16)\nplt.legend(title='Inverse Singular Vals', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.xlim(t[0], t[-1] + 0.1)\nplt.tight_layout()\nplt.savefig('imgs/pseudo_inverse_time_evolution.png')\nplt.show()\n\n\n\n\n\n\n\n\n\nSo we can use early stopping to prevent the flow from reaching the optimal point, a very useful technique. When it comes to inverse theory, often we are not interested in the optimal solution, but more interested in getting somewhere close that is not too noisy. This method differs from the thresholded pseudoinverse from the previous lecture, in that it allows some blending of the the smaller singular values, but their propensity for blowing up is controlled by the time exponent and early stopping.\n\n\nExample for Image Recovery using Analytic Solution\nReferring back to the problem of estimating the original image based on a noisy point spread function. We can monitor the time evolution of the estimate using gradient flow. Some code below defines the problem again, with recovery of the SVD decomposition for the 32x32 image, which will be used to solve the ODE for the gradient flow.\n\n\nShow the code\nimport matplotlib.pyplot as plt\nimport matplotlib\n#matplotlib.use('TkAgg')\nimport numpy as np\nimport torch.optim\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nimport copy\n\nimport seaborn as sns\n\nimport math\nimport os\nimport time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.fft\n\nclass gaussianConv(nn.Module):\n    \"\"\"\n    A PyTorch module that applies a Gaussian convolution to an input image using \n    a parameterized Gaussian Point Spread Function (PSF). The PSF is derived \n    from a covariance matrix and the derivatives of the Gaussian are computed \n    for edge detection.\n\n    Args:\n        C (torch.Tensor): Inverse of covariance matrix used to define the shape of the Gaussian.\n        t (float, optional): Scaling factor for the Gaussian, default is np.exp(5).\n        n0 (float, optional): Scaling factor for the original PSF, default is 1.\n        nx (float, optional): Scaling factor for the derivative along the x-axis, default is 1.\n        ny (float, optional): Scaling factor for the derivative along the y-axis, default is 1.\n    \"\"\"\n    def __init__(self, C, t=np.exp(5), n0=1, nx=1, ny=1):\n        super(gaussianConv, self).__init__()\n\n        self.C = C\n        self.t = t\n        self.n0 = n0\n        self.nx = nx\n        self.ny = ny\n\n    def forward(self, image):\n        P, center = self.psfGauss(image.shape[-1], image.device)\n        P_shifted = torch.roll(P, shifts=center, dims=[2, 3])\n        S = torch.fft.fft2(P_shifted)\n        I_fft = torch.fft.fft2(image)\n        B_fft = S * I_fft\n        B = torch.real(torch.fft.ifft2(B_fft))\n\n        return B\n\n    def psfGauss(self, dim, device='cpu'):\n        m = dim\n        n = dim\n\n        # Create a meshgrid of (X, Y) coordinates\n        x = torch.arange(-m // 2 + 1, m // 2 + 1, device=device)\n        y = torch.arange(-n // 2 + 1, n // 2 + 1, device=device)\n        X, Y = torch.meshgrid(x, y, indexing='ij')\n        X = X.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, m, n)\n        Y = Y.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, m, n)\n\n        cx, cy, cxy = self.C[0, 0], self.C[1, 1], self.C[0, 1]\n\n        PSF = torch.exp(-self.t * (cx * X ** 2 + cy * Y ** 2 + 2 * cxy * X * Y))\n        PSF0 = PSF / torch.sum(PSF.abs())\n\n        Kdx = torch.tensor([[-1, 0, 1],\n                            [-2, 0, 2],\n                            [-1, 0, 1]], dtype=PSF0.dtype, device=device) / 4\n        Kdy = torch.tensor([[-1, -2, -1],\n                            [0, 0, 0],\n                            [1, 2, 1]], dtype=PSF0.dtype, device=device) / 4\n\n        Kdx = Kdx.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, 3, 3)\n        Kdy = Kdy.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, 3, 3)\n\n        PSFdx = F.conv2d(PSF0, Kdx, padding=1)\n        PSFdy = F.conv2d(PSF0, Kdy, padding=1)\n\n        PSF_combined = self.n0 * PSF0 + self.nx * PSFdx + self.ny * PSFdy\n\n        center = [1 - m // 2, 1 - n // 2]\n\n        return PSF_combined, center\n\ndim = 32\nx = torch.zeros(1, 1, dim, dim)\nx[:,:, 12:14, 12:14] = 1.0\nx[:,:, 10:12, 10:12] = -1.0\n\nC = torch.tensor([[1, 0],[0, 1]])\nAmv = gaussianConv(C, t=0.1,n0=1, nx=0.1,  ny=0.1)\n\nn=(len(x.flatten()))\nAmat = torch.zeros(n,n)\n\nk=0\nfor i in range(x.shape[-2]):\n  for j in range(x.shape[-1]):\n    e_ij = torch.zeros_like(x)\n    e_ij[:,:, i, j] = 1.0\n    y = Amv(e_ij)\n    Amat[:, k] = y.flatten()\n    k = k+1\n\nU, S, V = torch.svd(Amat.to(torch.float64))\nb = Amv(x)\n\n\nNow that we have the matrix form of the forward operator Amat defined, along with the forward result b and the the decomposition U, S, V we can run the pseudo-inverse gradient flow method as before. So in this case we will be computing:\n\\[ x = V \\text{diag}\\left( \\lambda_i^{-1} (1 - \\exp (-\\lambda_i t)) \\right) U^\\top b\\]\nSince these represents an evolution over time, an animation can be created to show the time evolution of the image recovery, along with the effect of continuing into a region where noise is amplified and dominates.\nRecalling the original and distorted images with a small amount of noise \\(\\epsilon\\) are as follows:\n\n\nShow the code\nplt.figure(figsize=(6, 3))\nplt.subplot(1, 2, 1)\nplt.imshow(x[0, 0], cmap='viridis', vmin=-1, vmax=1)\nplt.title('Original Image')\nplt.axis('off')\nplt.subplot(1, 2, 2)\n\nb_noisy = b+ 0.01 * torch.randn_like(b)\nplt.imshow(b_noisy[0, 0], cmap='viridis', vmin=-1, vmax=1)\nplt.title('Distorted Image')\nplt.axis('off')\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nThe distorted image has had much of its intensity spread out diffusely, so it is only visible as a faint outline. The noise is also visible in the image as a grainy texture. The gradient flow method will attempt to recover the original image from this distorted image.\n\n\nShow the code\nfrom matplotlib import animation\n\nb_flat = b.flatten().to(torch.float64)\nx_flat = x.flatten().to(torch.float64)\nb_noisy = b_flat + 0.001 * torch.randn_like(b_flat)\n\ndef get_xhat(t):\n    Sinv_t = (1 - torch.exp(-S**2 * t)) / S\n    A_pinv = V @ torch.diag(Sinv_t) @ U.T\n    xhat = A_pinv @ b_noisy\n    return xhat\n\n# Time evolution parameters\nnum_frames = 50\nt_vals = np.logspace(0, 6, num_frames)\n\n# Prepare the plot\nfig, ax = plt.subplots(figsize=(6, 6))\nim = ax.imshow(np.zeros((dim, dim)), cmap='viridis', vmin=-1, vmax=1)\nax.set_title('Time Evolution of Pseudo-Inverse Gradient Flow')\nplt.axis('off')\n\n# Initialize the error text\nerror_text = ax.text(0.02, 0.95, '', transform=ax.transAxes, color='blue', fontsize=12,\n                     verticalalignment='top')\n\ntime_text = ax.text(0.5, 0.95, '', transform=ax.transAxes, color='blue', fontsize=12,\n                        verticalalignment='top')\n\n# Initialize containers to track min error and best time\ntracking = {'min_error': float('inf'), 'best_t': 0.0}\n\n# Animation update function\ndef update_frame(t):\n    # Compute time-dependent singular values\n    Sinv_t = (1 - torch.exp(-S ** 2 * t)) / S\n    # Construct the pseudoinverse of Amat at time t\n    A_pinv = V @ torch.diag(Sinv_t) @ U.t()\n    # Reconstruct the image estimate x(t)\n    xt = A_pinv @ b_noisy\n    # Compute the relative error\n    error = torch.norm(x_flat - xt) / torch.norm(x_flat)\n    \n    # Update min_error and best_t if current error is lower\n    if error.item() &lt; tracking['min_error']:\n        tracking['min_error'] = error.item()\n        tracking['best_t'] = t\n\n    # Reshape to image dimensions\n    x_image = xt.reshape(dim, dim).detach().numpy()\n\n    # Update the image data\n    im.set_data(x_image)\n\n    # Update the error text\n    error_text.set_text(f'Relative Error: {error.item():.4f}')\n    time_text.set_text(f'Time: {t:.2f}')\n\n    return [im, error_text, time_text]\n\n# Create the animation\nani = animation.FuncAnimation(fig, update_frame, frames=t_vals, blit=True, interval=100)\n\nani.save('imgs/gradient_flow.gif', writer='pillow', fps=5)\nplt.close(fig)\n\n\n\nAnd we saved the best time that was discovered for the recovery (with prior knowledge of the ground truth). So we can inspect that image, this was the best that we could do with the gradient flow method.\n\n\nShow the code\nbest_img = get_xhat(tracking['best_t']).reshape(dim, dim).detach().numpy()\n\nplt.figure(figsize=(6, 6))\nplt.imshow(best_img / np.max(np.abs(best_img)), cmap='viridis', vmin=-1, vmax=1)\nplt.title(f'Best Reconstruction at t={tracking[\"best_t\"]:.2f}\\nRelative Error: {tracking[\"min_error\"]:.4f}')\nplt.axis('off')\nplt.show()"
  },
  {
    "objectID": "content/eosc555/lectures/lecture3/index.html#recovery-of-the-adjoint-operator-using-autograd",
    "href": "content/eosc555/lectures/lecture3/index.html#recovery-of-the-adjoint-operator-using-autograd",
    "title": "Lecture 3: Image Denoising with Gradient Descent and Early Stopping",
    "section": "Recovery of the Adjoint Operator using Autograd",
    "text": "Recovery of the Adjoint Operator using Autograd\nIn this case we were able to compute the matrix form of \\(A\\) and use its transpose to compute the SVD, but in many cases this might be too expensive or there may not be a closed form analytic solution to the early stopping technique. In such cases we wish to recover the adjoint. The question then is how to recover the adjoint operator from the Amv operator? There are helpful tools available through the use of automatic differentiation to track the gradients of the forward operator and recover the adjoint operator. This is a very powerful tool that can be used to recover the adjoint operator in a very general way.\nBy definition the adjoint has the property that: \\[\\langle Ax, v \\rangle = \\langle x, A^\\top v \\rangle\\]\n\nExplicit Computation of the Adjoint\nWe can compute the adjoint explicitly for the Amv operator based on its computation from earlier. The discrete fourier transform matrix operator \\(F\\) has the property that \\(F^{-1} = F^\\top\\) so we can use this to compute the adjoint.\n\\[\n\\begin{align}\nA(x) &= \\mathcal{F}^-1 \\left( \\mathcal{F}(P) \\odot \\mathcal{F}(x) \\right)\\\\\n&= F^\\top \\left( \\text{diag} (F(P)) F(x) \\right)\\\\\nA^\\top(v) &= F^\\top \\text{diag} (F(P))^* F v\\\\\n\\end{align}\n\\]\nWhere the hadamard operation of the two vectors has been modified to a matrix form by diagonalizing the vector \\(F(P)\\) that is the Fourier transform of the point spread function. From this form it is posible to take the adjoint of the operator by taking the complex conjugate of the transpose of the entire operation.\n\n\nAutograd Computation of the Adjoint\nWe start with a new function \\(h = v^\\top A(x)\\) and we wish to compute the gradient of \\(h\\) with respect to \\(x\\).\n\\[ \\nabla_x h = \\nabla_x (v^\\top A(x)) = A^\\top(v)\\]\nThe gradient of \\(h\\) with respect to \\(x\\) is the adjoint operator \\(A^\\top(v)\\). We can use the torch.autograd.grad function to compute the gradient of \\(h\\) with respect to \\(x\\).\n\n\nShow the code\ndef Amv_adjoint(v):\n    x = torch.zeros(1, 1, dim, dim)\n    x.requires_grad = True\n    b = Amv(x)\n    # Compute the dot product of the forward operator with the input vector\n    h = torch.sum(b * v)\n    # Compute the gradient of the dot product with respect to the input image\n    adjoint = torch.autograd.grad(h, x, create_graph=True)[0]\n    return adjoint\n\n\nWe can use this to recover \\(A^\\top\\) for the general case if we run the operator on the set of basis vectors in the image space. This will give us the adjoint operator in the form of a matrix. We can also use it to confirm that it recovers the matrix transpose of the forward operator if we are working with a simple matrix, reusing the Amat matrix from earlier to take its transpose and compare it to the adjoint operator.\n\n\nShow the code\nAmat_adj = torch.zeros(n,n)\n\ndim = 32 # Same as earlier\nk=0\nfor i in range(dim):\n  for j in range(dim):\n    e_ij = torch.zeros_like(x)\n    e_ij[:,:, i, j] = 1.0\n    y = Amv_adjoint(e_ij)\n    Amat_adj[:, k] = y.flatten()\n    k = k+1\n\ndiff = torch.norm(Amat_adj - Amat.T)\nprint(f'Norm of difference between adjoint and transpose: {diff:.2e}')\n\n\nNorm of difference between adjoint and transpose: 4.43e-07\n\n\nSo the difference is within the bounds of numerical precison and the code appears to be working correctly."
  },
  {
    "objectID": "content/eosc555/lectures/lecture3/index.html#gradient-descent-with-adjoint",
    "href": "content/eosc555/lectures/lecture3/index.html#gradient-descent-with-adjoint",
    "title": "Lecture 3: Image Denoising with Gradient Descent and Early Stopping",
    "section": "Gradient Descent with Adjoint",
    "text": "Gradient Descent with Adjoint\nWe can now use the defined operators (functions) from earlier to setup a simple gradient descent algorithm with a step size and early stopping to produce a recovery image that bypasses the need to compute the SVD decomposition, which may be very expensive for large matrices.\n\n\nShow the code\nfrom tqdm import tqdm\n\ndef least_squares_sol(x0, b, Amv, Amv_adjoint, max_iter=1000, alpha=1e-3, tol=1e-6, show_progress=True):\n    \"\"\"\n    Solves the least squares problem using gradient descent with optional progress tracking.\n\n    Parameters:\n    - x0 (torch.Tensor): Initial guess for the solution.\n    - b (torch.Tensor): Observation vector.\n    - Amv (callable): Function to compute A @ x.\n    - Amv_adjoint (callable): Function to compute A^T @ v.\n    - max_iter (int): Maximum number of iterations.\n    - alpha (float): Learning rate.\n    - tol (float): Tolerance for convergence.\n    - show_progress (bool): If True, display a progress bar; otherwise, suppress output.\n\n    Returns:\n    - x (torch.Tensor): Approximated solution vector.\n    \"\"\"\n    x = x0.clone()\n    x.requires_grad = True\n    b_noisy = b.clone() + 0.01 * torch.randn_like(b)\n\n    # Initialize progress bar or a placeholder for quiet mode\n    pbar = tqdm(total=max_iter, desc='Least Squares Iteration', unit='iter', disable=not show_progress) \n    for i in range(max_iter):\n        # Gradient descent update\n        residual = Amv(x) - b_noisy\n        gradient = Amv_adjoint(residual)\n        xnext = x - alpha * gradient\n\n        # Compute relative error\n        error = torch.norm(xnext - x) \n\n        # Update the progress bar with the current error\n        if show_progress:\n            pbar.set_postfix({'Error': f'{error.item():.4e}'})\n            pbar.update(1);\n\n        # Check for convergence\n        if error &lt; tol:\n            if show_progress:\n                pbar.write(f'Converged at iteration {i+1} with error {error.item():.4e}')\n            x = xnext\n            break\n\n        x = xnext\n\n    pbar.close()\n    \n    return x\n\nb = Amv(x)\nx0 = torch.zeros_like(x)\nxhat = least_squares_sol(x0, b, Amv, Amv_adjoint, max_iter=1000, alpha=1, tol=1e-6, show_progress=False)\n\n# Display final images\nplt.figure(figsize=(6, 3))\nplt.subplot(1, 2, 1)\nplt.imshow(x[0, 0], cmap='viridis', vmin=-1, vmax=1)\nplt.title('Original Image')\nplt.axis('off')\nplt.subplot(1, 2, 2)\nplt.imshow(xhat.detach().numpy()[0, 0], cmap='viridis', vmin=-1, vmax=1)\nplt.title('Recovered Image')\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nNote that torch does have the framework to run autograd on the least squares objective itself, but for this general method we are using the adjoint to compute the gradient (and indirectly invoking autograd). This framework is the most general for when there might not be explicit analytic solutions to the least squares problem, but we have the forward operator and its adjoint."
  },
  {
    "objectID": "content/eosc555/lectures/lecture5/index.html",
    "href": "content/eosc555/lectures/lecture5/index.html",
    "title": "Lecture 5",
    "section": "",
    "text": "$$ \n$$"
  },
  {
    "objectID": "content/eosc555/lectures/lecture5/index.html#a-non-linear-dynamics-problem",
    "href": "content/eosc555/lectures/lecture5/index.html#a-non-linear-dynamics-problem",
    "title": "Lecture 5",
    "section": "A Non-Linear Dynamics Problem",
    "text": "A Non-Linear Dynamics Problem\nA well studied problem in non-linear dynamics involves the predator-prey model that is described by the Lotka-Volterra equations. The equations are given by:\n\\[\n\\begin{aligned}\n\\frac{dx}{dt} &= \\alpha x - \\beta xy \\\\\n\\frac{dy}{dt} &= \\delta xy - \\gamma y\n\\end{aligned}\n\\]\nwhere \\(x\\) and \\(y\\) are the populations of the prey and predator respectively. The parameters \\(\\alpha, \\beta, \\gamma, \\delta\\) are positive constants. The goal is to find the values of these parameters that best fit the data.\nThere is no closed form analytic solution that is known to this remarkably simple system of equations, which is why we must resort to numerical solutions to compute the model.\nMore information about the model can be found at the Wikipedia page.\n\nThe Forward Problem\nWe start with an initial time \\(t_0\\) and initial conditions \\(x_0, y_0\\), with parameters \\(\\alpha, \\beta, \\gamma, \\delta\\) to run a forward version of the problem using a variant of the forward Euler method, the RK4.\n\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\n\nclass LotkaVolterraModel(nn.Module):\n    def __init__(self, alpha, beta, gamma, delta):\n        super(LotkaVolterraModel, self).__init__()\n        # Define parameters as torch tensors that require gradients\n        self.alpha = nn.Parameter(torch.tensor(alpha, dtype=torch.float32))\n        self.beta = nn.Parameter(torch.tensor(beta, dtype=torch.float32))\n        self.gamma = nn.Parameter(torch.tensor(gamma, dtype=torch.float32))\n        self.delta = nn.Parameter(torch.tensor(delta, dtype=torch.float32))\n\n    def forward(self, x, y):\n        # Ensure x and y are tensors\n        if not isinstance(x, torch.Tensor):\n            x = torch.tensor(x, dtype=torch.float32)\n        if not isinstance(y, torch.Tensor):\n            y = torch.tensor(y, dtype=torch.float32)\n\n        # Compute dx and dy based on the current parameters\n        dx = self.alpha * x - self.beta * x * y\n        dy = self.delta * x * y - self.gamma * y\n\n        return dx, dy\n\nclass RK4Solver:\n    def __init__(self, model):\n        self.model = model\n\n    def step(self, x, y, dt):\n        \"\"\"\n        Perform a single RK4 step.\n        \"\"\"\n        # Convert x and y to tensors if they are not already\n        if not isinstance(x, torch.Tensor):\n            x = torch.tensor(x, dtype=torch.float32)\n        if not isinstance(y, torch.Tensor):\n            y = torch.tensor(y, dtype=torch.float32)\n\n        # RK4 Step calculations\n        k1_x, k1_y = self.model.forward(x, y)\n        k2_x, k2_y = self.model.forward(x + 0.5 * dt * k1_x, y + 0.5 * dt * k1_y)\n        k3_x, k3_y = self.model.forward(x + 0.5 * dt * k2_x, y + 0.5 * dt * k2_y)\n        k4_x, k4_y = self.model.forward(x + dt * k3_x, y + dt * k3_y)\n\n        # Update x and y using weighted averages of the slopes\n        x_new = x + (dt / 6) * (k1_x + 2 * k2_x + 2 * k3_x + k4_x)\n        y_new = y + (dt / 6) * (k1_y + 2 * k2_y + 2 * k3_y + k4_y)\n\n        return x_new, y_new\n\n    def solve(self, x0, y0, time_steps):\n        \"\"\"\n        Solve the system over a serie of time steps.\n        Parameters:\n            x0: Initial value of prey population\n            y0: Initial value of predator population\n            time_steps: List or numpy array of time steps to solve over\n        \"\"\"\n        x, y = x0, y0\n        DT = time_steps[1:] - time_steps[:-1]\n        trajectory = torch.zeros(len(time_steps), 2)\n        trajectory[0] = torch.tensor([x, y])\n\n        for i, dt in enumerate(DT):\n            x, y = self.step(x, y, dt)\n            trajectory[i+1] = torch.tensor([x, y])            \n\n        return trajectory\n\n# Define the model parameters\nalpha = 1.0\nbeta = .1\ngamma = 1.5\ndelta = 0.1\n\n# Create the model and solver\nmodel = LotkaVolterraModel(alpha, beta, gamma, delta)\nsolver = RK4Solver(model)\n\n# Define the initial conditions and time steps\nx0 = 5\ny0 = 1\ntime_steps = np.linspace(0, 20, 1000)\n\n# Solve the system\ntrajectory = solver.solve(x0, y0, time_steps)\n\nx_values = trajectory[:, 0].detach().numpy()\ny_values = trajectory[:, 1].detach().numpy()\n\nplt.plot(time_steps, x_values, label='Prey')\nplt.plot(time_steps, y_values, label='Predator')\nplt.xlabel('Time')\nplt.ylabel('Population')\nplt.legend()\nplt.savefig('imgs/lotka_volterra.png')\nplt.show()\n\n\n\n\n\nThe time evolution of the prey and predator populations.\n\n\n\n\nWe can additionally look at the phase space of the system for various initial conditions to see how the different solutions are periodic.\n\n\nShow the code\n# Define the initial conditions\nx0 = 5\ny0 = [.2,.5,1, 2, 3, 4, 5]\n\n# Create the model and solver\nmodel = LotkaVolterraModel(alpha, beta, gamma, delta)\nsolver = RK4Solver(model)\n\n# Define the time steps\ntime_steps = np.linspace(0, 10, 1000)\n\n# Plot the phase space\nplt.figure(figsize=(6, 4.5))\nfor y in y0:\n    trajectory = solver.solve(x0, y, time_steps)\n    x_values = trajectory[:, 0].detach().numpy()\n    y_values = trajectory[:, 1].detach().numpy()\n    plt.plot(x_values, y_values, label=f'y0={y}')\n\nplt.xlabel('Prey Population')\nplt.ylabel('Predator Population')\nplt.legend()\nplt.title('Lotka-Volterra Phase Space')\nplt.savefig('imgs/lotka_volterra_phase_space.png')\nplt.show()\n\n\n\n\n\nThe phase space of the predator-prey model."
  },
  {
    "objectID": "content/eosc555/lectures/lecture5/index.html#the-inverse-problem",
    "href": "content/eosc555/lectures/lecture5/index.html#the-inverse-problem",
    "title": "Lecture 5",
    "section": "The Inverse Problem",
    "text": "The Inverse Problem\nThe inverse problem in this case is to find the parameters \\(\\alpha, \\beta, \\gamma, \\delta\\) that best fit the data. We suppose that we have a model with parameters that takes in the initial conditions and time steps and returns the trajectory of the system. For simplicity we vectorize the previous \\(\\begin{bmatrix} x \\\\ y \\end{bmatrix}\\) into a single vector \\(\\vec{x}\\). The forward model is then a function \\(F(\\vec{x}; \\vec{p})\\) where \\(\\vec{p}\\) are the parameters and is an approximator of the true system, where\n\\[f(\\vec{x}; \\vec{p}) \\approx \\frac{d \\vec{x}}{dt} = \\begin{bmatrix} \\alpha x - \\beta xy \\\\ \\delta xy - \\gamma y \\end{bmatrix}, \\quad \\vec{x}_0 = \\vec{x}(0).\\]\nwhere \\(\\vec{x}\\) is the state of the system and \\(\\vec{p}\\) are the parameters.\nThe goal is to form an estimate of \\(\\vec{p}\\), while the data that we have collected may be sparse, noisy, or incomplete. We represent the incompleteness in the data using the \\(Q\\) sampling operator which is applied to the true underlying data to give \\(Qx\\). If \\(x\\) is fully given then \\(Q=I\\).\nA finite difference approximation of the derivative of the data can be used to approximate the derivative of the data,\n\\[f(\\vec{x}; \\vec{p}) \\cong \\frac{\\vec{x}_{n+1} - \\vec{x}_n}{\\Delta t}.\\]\nSo in this case the forward model is a time derivative, and the observed data is computed from an intial condition \\(\\vec{x}_0\\) and an ODE approximate solution such as Euler’s method or RK4. The output of the forward process is then given as \\(F\\), where \\[F(\\vec{p}, x_0) = \\hat {\\vec{x}}(t, \\vec{p}),\\]\nis the application of the system dynamics to the initial conditions and the parameter to create an estimated trajectory \\(\\hat{\\vec{x}}(t, \\vec{p})\\).\nThe observed data is \\(d = Q\\vec{x}(t)\\). We also make an assumption here that \\(F\\) does not depend on the particular solver that we are using for the forward ODE and that all of the \\(\\vec{p}\\) are physical parameters, we assume that the parameters are faithful enough.\nFor the rest of the mathematical notation ahead, the explicit marking of vectors is ommitted to simplify the equations.\n\nGoodness of Fit\nThe goodness of fit is measured by using the L2 norm of the difference between the observed data and the model output, thus forming the non-linear least squares problem:\n\\[ \\min_{p} \\frac{1}{2}\\|QF(p)-d\\|^2 = \\min_{p}\\|G(p)\\|^2.\\]\nTo find the best fit, the objective is to minimize the mean squared error (MSE) of a function of the parameters \\(p\\) and the data \\(d\\). The data is fixed for a given problem, so it is only by varying \\(p\\) that an optimal solution can be found. The entire MSE function is denoted as \\(G(p)\\)."
  },
  {
    "objectID": "content/eosc555/lectures/lecture5/index.html#minimization-of-the-objective-function",
    "href": "content/eosc555/lectures/lecture5/index.html#minimization-of-the-objective-function",
    "title": "Lecture 5",
    "section": "Minimization of the Objective Function",
    "text": "Minimization of the Objective Function\n\\[ \\min_{p \\in \\mathbb{R}^m} \\biggl\\{ \\sum_{i=1}^n (QF_i(\\mathbf{p}) - d_i) ^2\\biggr\\}\\]\nwhere \\(d_i\\) are the observed data points. This is the same as\n\\[ \\min_{p \\in \\mathbb{R}^m} \\|G(\\mathbf{p})\\|^2\\]\nwhere \\(G(\\mathbf{p}) = QF(\\mathbf{p}) - d\\) and \\(d \\in \\mathbb{R}^n\\). We are minimizing the norm of a non-linear function of the parameters. Supposing that we want to find the minimizer, one approach would be by gradient descent.\n\nThe Jacobian: A quick review\n\nThe Jacobian is a multivariate extension of the derivative that extends to functions \\(f : \\mathbb{R}^m \\to \\mathbb{R}^n\\). Because there are \\(n\\) function outputs and \\(m\\) input variables, the Jacobian is an \\(n \\times m\\) matrix that contains the information of how each of the \\(n\\) functions changes with respect to each of the \\(m\\) variables. In an abuse of Leibniz’s notation, it can be seen as:\n\\[\n\\frac{\\partial \\vec{f}}{\\partial \\vec{x}} = \\mathbf{J_f} =\n\\left[\n    \\frac{\\partial f}{\\partial x_1} \\cdots \\frac{\\partial f}{\\partial x_n}\n\\right]\n=\n\\begin{bmatrix}\n    \\nabla^\\top f_1\n    \\\\\n    \\vdots\n    \\\\\n    \\nabla^\\top f_m\n\\end{bmatrix}\n=\n\\left[\n    \\begin{array}{ccc}\n    \\frac{\\partial f_1}{\\partial x_1} & \\cdots & \\frac{\\partial f_1}{\\partial x_n} \\\\\n    \\vdots & \\ddots & \\vdots \\\\\n    \\frac{\\partial f_m}{\\partial x_1} & \\cdots & \\frac{\\partial f_m}{\\partial x_n}\n    \\end{array}\n\\right]\n\\]\nNote that like the derivative, the Jacobian is a function of the input variables \\(\\vec{x}\\). The Jacobian is a linear approximation of the function \\(f\\) at a point \\(x_0\\) and can be used to approximate the function at a point \\(x_0 + \\Delta x\\).\n\\[ f(x_0 + \\Delta x) \\approx f(x_0) + J_f(x_0) \\Delta x\\]\nNoting that we are applying matrix multiplication using \\(J_f\\) evaluated at \\(x_0\\) and the vector \\(\\Delta x = \\vec{x} - \\vec{x_0}\\). The quantity \\(J_f(x_0) \\Delta x\\) is the directional derivative of the function \\(f\\) at \\(x_0\\) in the direction of \\(\\Delta x\\).\n\nThe gradient of \\(\\|G(\\mathbf{p})\\|^2\\) can be computed as follows:\n\\[\\begin{align}\n\\nabla_p \\|G(p)\\|^2 &= \\nabla_p G(p)^T G(p)\\\\\n&= \\sum_{i=1}^n \\nabla_p G_i(p)^2\\\\\n&= \\sum_{i=1}^n 2 G_i(p) \\nabla_p G_i(p)\\\\\n&= 2 J_G(p)^T G(p)\n\\end{align}\n\\]\nFrom this stage, gradient descent can be applied to find the minimum of the function. However, the function \\(G(p)\\) is non-linear and so the gradient descent method may not converge quickly or the problem may have poor conditioning. The celebrated Newton’s Method addresses some of these issues, but requires computing the Hessian \\(\\nabla^2 \\|G(p)\\|^2\\) of the function, which can be expensive.\nTo demonstrate, the true Hessian of the function is: \\[\n\\nabla^2 \\|G(p)\\|^2 = 2 J_G(p)^T J_G(p) + 2 \\sum_{i=1}^n G_i(p) \\nabla^2 G_i(p)\n\\]\nSo we’d have to compute the Hessian \\(\\nabla^2 G_i(p)\\) of each of the \\(G_i(p)\\) functions, of which there are \\(n\\), not good in practice. If we did have this Hessian, the steps with Newton’s method would be:\n\\[ p_{k+1} = p_k - (\\nabla^2 \\|G(p_k)\\|^2)^{-1} \\nabla (\\|G(p_k)\\|^2)\\]"
  },
  {
    "objectID": "content/eosc555/lectures/lecture5/index.html#gauss-newton-optimization",
    "href": "content/eosc555/lectures/lecture5/index.html#gauss-newton-optimization",
    "title": "Lecture 5",
    "section": "Gauss-Newton Optimization",
    "text": "Gauss-Newton Optimization\nRather than solve the problem directly with Newton’s method, it can be approximated by linearizing inside of the norm and solving the linearized version using the normal equations. We approximate the function\n\\[G(p) = QF(p) - d \\approx (QF(p_k) - d) + QJ_k(p-p_k)\\]\nwhere \\(J_k\\) is the Jacobian of \\(F(p)\\) at \\(p_k\\).\n\\[ \\min_{p \\in \\mathbb{R}^m} \\|QF(p_k) - d + QJ_k(p-p_k)\\|^2\\]\nThen rearranging this we get a form that is a linear least squares problem:\n\\[ \\begin{align}\n& \\min_{p \\in \\mathbb{R}^m} \\| QJ_kp - (d + QJ_k p_k- QF(p_k) )\\|^2\\\\\n=& \\min_{p \\in \\mathbb{R}^m} \\| Ap - r_k\\|^2\\\\\nA^T A p =& A^T r_k\n\\end{align}\n\\]\nwhere \\(A = QJ_k\\) and \\(r_k = d + QJ_k p_k - QF(p_k)\\). This is the normal equations for the linear least squares problem. This gives us\n\\[\n\\begin{align}\np_{k+1} &= (A^T A)^{-1} A^T (r_k)\\\\\n&= (J_k^T Q^T Q J_k)^{-1} J_k^T Q^T (d + QJ_k p_k - QF(p_k))\\\\\n&= p_k + (J_k^T Q^T Q J_k)^{-1} J_k^T Q^T (d - QF(p_k))\\\\\np_{k+1} &= p_k - (J_k^T Q^T Q J_k)^{-1} J_k^T Q^T (QF(p_k) - d)\\\\\n\\end{align}\n\\]\nThis could be written in a more tidy and general way, reacalling that \\(G(p) = QF(p) - d\\) and let \\(J_G(p) = QJ(p)\\), then we have:\n\\[ p_{k+1} = p_k - (J_G(p_k)^TJ_G(p_k))^{-1} J_G(p_k) G(p_k)\\]\n\nComparison with Newton’s Method\nSo this resembles a scaled gradient descent. In Newton’s method we have the Hessian, in Gauss-Newton we have the Jacobian of the function. As a comparison:\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\nNewton’s Method\nStep Update\n\n\n\n\\(p_{k+1} = p_k - (\\nabla^2 \\|G(p_k)\\|^2)^{-1} \\nabla \\|G(p_k)\\|^2\\)\n\n\n\nScaling Matrix\n\n\n\n\\(\\nabla^2 \\|G(p_k)\\|^2 = 2 J_G(p_k)^T J_G(p_k) + 2 \\sum_{i=1}^n G_i(p_k) \\nabla^2 G_i(p_k)\\)\n\n\nGauss-Newton Method\nStep Update\n\n\n\n\\(p_{k+1} = p_k - (J_G(p_k)^T J_G(p_k))^{-1} J_G(p_k)^T G(p_k)\\)\n\n\n\nScaling Matrix\n\n\n\n\\(J_G(p_k)^T J_G(p_k)\\)\n\n\n\nThe direction of change between iterations in Newton’s method can be rewritten as \\[d_k = \\left(J_G(p_k)^T J(p_k) + \\sum_{i=1}^n G_i(p_k) \\nabla^2 G_i(p_k)\\right)^{-1} J_G(p_k)^T G(p_k)\\]\nWhile the direction in the case of Gauss-Newton is \\[d_k = \\left(J_G(p_k)^T J_G(p_k)\\right)^{-1} J_G(p_k)^T G(p_k)\\]\nThe difference between the two is the omission of the computationally expensive \\(\\sum_{i=1}^n G_i(p) \\nabla^2 G_i(p)\\) terms. The Gauss-Newton method is approximating the second-order approach of Newton’s method by only considering the first-order terms inside of the norm.\n\\[J_G(p_k)^T J(p_k) \\sum_{i=1}^n G_i(p_k) \\nabla^2 G_i(p_k) \\approx J_G(p_k)^T J(p_k)\\]\nRecall that \\(G(p) = QF(p) - d\\) which is the difference between the observed data and the model. If the difference is small then \\(G_i\\) is also small and the approximation is good.\n\n\nAlgorithm for Gauss-Newton\nWe have derived the algorithm for the Gauss-Newton method for solving the non-linear least squares problem. The algorithm is as follows:\n\n\n\\begin{algorithm} \\caption{Gauss-Newton Algorithm for Non-linear Least Squares}\\begin{algorithmic} \\State \\textbf{Input:} Initial guess $p_0$, maximum iterations $K$, tolerance $\\epsilon$ \\State \\textbf{Initialize} $p_0$ \\For{$k = 0, 1, 2, \\ldots$} \\State Compute the Jacobian $J_G$ of $G(p)$ at $p_k$ \\State Compute the transpose $J_G^T$ of the Jacobian \\State Compute the residual $r_k =G(p_k)$ (forward model) \\State Compute the step $s_k = (J_G(p_k)^T J_G(p_k) )^{-1} J_G(p_k)^T r_k$ \\State Update the parameters $p_{k+1} = p_k + \\mu_k s_k$ \\If{$\\|s_k\\| &lt; \\epsilon$} \\State \\textbf{Stop} \\EndIf \\EndFor \\State \\textbf{Output:} $p_{k+1}$ as the optimal solution \\end{algorithmic} \\end{algorithm}\n\n\n\n\nMatrix Inversions\nIn practice it may be computationally expensive to invert the matrix \\(J_k^T Q^T Q J_k\\). We can use a conjugate gradient method to solve the normal equations instead. \\[J_k^T Q^T Q J_k s_k = J_k^T Q^T r_k\\]\nWe developed a conjugate gradient method in the last lecture, so we can use that along with the computed values for \\(J_k^T, J_k, r_k\\) to solve the normal equations and get the step \\(s_k\\).\n\n\nSummary\n\n\n\n\n\n\n\n\nComponent\nDescription\nDimensions\n\n\n\n\n\\(d\\)\nObserved data\n\\(\\mathbb{R}^{n}\\)\n\n\n\\(p_k\\)\nParameters\n\\(\\mathbb{R}^{m}\\)\n\n\n\\(Q\\)\nWeight matrix\n\\(\\mathbb{R}^{n \\times n}\\)\n\n\n\\(J_k\\)\nJacobian of \\(F(p_k)\\)\n\\(\\mathbb{R}^{n \\times m}\\)\n\n\n\\(r_k\\)\nResidual \\(d - QF(p_k)\\)\n\\(\\mathbb{R}^{n}\\)\n\n\n\\(F(p_k)\\)\nForward model output\n\\(\\mathbb{R}^{n}\\)\n\n\n\\(s_k\\)\nStep direction\n\\(\\mathbb{R}^{m}\\)\n\n\n\\(J_k^T\\)\nTranspose of the Jacobian\n\\(\\mathbb{R}^{m \\times n}\\)\n\n\n\\(J_k^T Q^T Q J_k\\)\nNormal equations matrix\n\\(\\mathbb{R}^{m \\times m}\\)"
  },
  {
    "objectID": "content/eosc555/lectures/lecture7/index.html",
    "href": "content/eosc555/lectures/lecture7/index.html",
    "title": "Lecture 7",
    "section": "",
    "text": "$$ \n$$"
  },
  {
    "objectID": "content/eosc555/lectures/lecture7/index.html#motivation",
    "href": "content/eosc555/lectures/lecture7/index.html#motivation",
    "title": "Lecture 7",
    "section": "Motivation",
    "text": "Motivation\nSo far we have examined optimization techniques using gradient descent and the Gauss-Newton method. These methods are powerful but can be limited by the presence of local minima in the optimization landscape. In this lecture we will explore a technique called Gaussian homotopy that can be used to escape local minima in optimization problems.\nTo recap the steps used so far in optimization, we have an objective \\[\\operatorname*{argmin}f(x),\\]\nwhere \\(x \\in \\mathbb{R}^n\\) is an unconstrained optimization variable. The objective can be searched out by stepping in a direction itertively, in general: \\[x_{k+1} = x_k - \\alpha_k H \\nabla f(x_k),\\]\nwhere \\(\\alpha_k\\) is the step size. The gradient \\(\\nabla f(x_k)\\) can be computed explicitly or using automatic differentiation. The matrix \\(H\\) is a modifier that depends on the method being used: \\[H =\n\\begin{cases}\n    I & \\text{Gradient Descent} \\\\\n    (J^T J)^{-1} & \\text{Gauss-Newton}\n\\end{cases}\n\\]\nHowever, optimization is often performed on non-convex functions, in which case the path to a global minimum can be obstructed by local minima. Three categories of increasingly non-convex functions are shown below.\n\n Figure: Three categories of increasingly non-convex functions illustrating potential local minima that can obstruct the path to a global minimum.\n\nSome examples for each of the three catergories are given in the following table:\n\n\n\n\n\n\n\n\nCategory\nFunction\nLocal Minima\n\n\n\n\nConvex\n\\(f(x) = x^2\\)\nGlobal minimum at \\(x=0\\)\n\n\nNon-Convex but \\(f'(x)&lt;0\\)\n\\(f(x) = -\\mathcal{N}(x; 0, 1)\\)\nGlobal minimum at \\(x=0\\)\n\n\nNon-Convex with \\(f'(x) \\geq 0\\)\n\\(f(A,B,w) = w^T \\sigma (B \\sigma (A x))\\)\nMultiple local minima\n\n\nNon-Convex and Poorly Conditioned \\(\\nabla^2 f(x)\\)\n\\(f(t) = x(t)^T A x(t), \\quad x(t) = \\text{square wave}\\)\nMultiple local minima and discontinuous\n\n\n\nTo illustrate these functions even more we can plot them as well.\n\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(-5, 5, 100)\ny1 = x**2\ny2 = -np.exp(-x**2)\ny3 = np.sin(x) + .5*x\n\n#square wave\ndef square_wave(x):\n    return 1 if np.sin(3*x) &gt; 0 else 0\n\ny4 = [square_wave(xi)**2 for xi in x]\n\nfig, ax = plt.subplots(2, 2)\nax[0, 0].plot(x, y1)\nax[0, 0].set_title(\"Convex: $f(x) = x^2$\")\nax[0, 1].plot(x, y2)\nax[0, 1].set_title(\"Non-Convex but $f'(x)&lt;0$ \\n $f(x) = -\\mathcal{N}(x; 0, 1)$\")\nax[1, 0].plot(x, y3)\nax[1, 0].set_title(\"Non-Convex with $f'(x) \\geq 0$ \\n $f(x) = sin(x)+.5 x$\")\nax[1, 1].plot(x, y4)\nax[1, 1].set_title(\"Non-Convex and Poorly Conditioned $\\nabla^2 f(x)$\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nFunction Categories."
  },
  {
    "objectID": "content/eosc555/lectures/lecture7/index.html#direct-search-methods",
    "href": "content/eosc555/lectures/lecture7/index.html#direct-search-methods",
    "title": "Lecture 7",
    "section": "Direct Search Methods",
    "text": "Direct Search Methods\nA direct search (Wikipedia 2024) can be performed to try to find the global minimum of a non-convex function (Lewis, Torczon, and Trosset 2000).\n\\[ x_{k+1} = x_k + \\alpha_k d_k, \\quad d_k \\in \\mathbb{R}^n.\\]\nIn this case the direction does not follow the gradient descent rule, there could be a stochastic element. The general algorithms that implement this will have the property that the step size decreases over time such that\n\\[ \\| \\alpha_k d_k \\| \\to 0, \\ k \\to \\infty\\]\nThe implementation ignores seeking information about the gradient or the Hessian of the function. Instead some points in the surrounding region are computed and the most optimal decrease for the next step is selected.\nThe method has been known since the 1950s but it fell out of favour due to the slow rate of convergence. However, with parallel computing advances it has become more feasible to use again. For a large set of direct search methods, it is possible to rigorously prove that they will converge to a local minimum (Kolda, Lewis, and Torczon 2003)."
  },
  {
    "objectID": "content/eosc555/lectures/lecture7/index.html#homotopy",
    "href": "content/eosc555/lectures/lecture7/index.html#homotopy",
    "title": "Lecture 7",
    "section": "Homotopy",
    "text": "Homotopy\nIn mathematics, homotopy refers to the continuous transformation of one function into another. In optimization, homotopy—or continuation optimization—is used to transform a highly non-convex function into a simpler, often more convex surrogate function. This approach enables the optimizer to escape local minima and approach a global minimum by incrementally tackling easier, intermediate optimization problems.\nThe core idea behind homotopy optimization is to relax a difficult optimization problem into a series of smoother problems that gradually resemble the original objective function. This relaxation process spreads the gradient and Hessian information outward, making the function landscape easier to navigate and minimizing the risk of getting stuck in local minima.\nThis can be accomplished using a convolution with a simple function as a kernel. The kernel that is used can have variable width and parameterization, there are varying degrees of relaxation which can be parameterized using a \\(t\\) time variable. As \\(t \\to 0\\) the function becomes more like the original function, and as \\(t \\to 1\\) the function becomes more like the smoothing function. The homotopy between the two is parameterized by \\(t \\in [0, 1]\\).\n\n  \n\nA continuous deformation of a path. Source: Wikimedia Commons\n\n\n\nHomotopy Optimization\nIn the case of optimization, the technique is know as homotopy optimization or continuation optimization. The optimization process starts with the smoothed function and then gradually moves back to the original function using the optimization steps from the relaxed prbolem. This is known as a continuation method, and the scheduling of the homotopy parameter \\(t\\) is the continutation schedule. A summary description with more details and advanced techniques can be found in work by Lin et. al (Lin et al. 2023).\n\nExample\nLet \\(f(x)\\) be the original function and \\(g(x)\\) be the smoothing function. The homotopy function \\(h(x, t)\\) can be defined as and interpolation between the two functions:\n\\[h(x, t) = (1-t) f(x) + t g(x).\\]\nThis new function has the important property that \\(h(x,0) = f(x)\\) and \\(h(x,1) = g(x)\\) so it represents a continuous path of deformation between the two functions, beginning at \\(t=1\\) with a simpler relaxed problem and ending at \\(t=0\\) with the original problem.\nThe new minimization problem becomes:\n\\[\\operatorname*{argmin}_{\\mathcal{X}} h(x, t).\\]\nA schedule can be set up for the times so that a series of times \\(\\{t_0, t_1, \\dots t_k, \\ldots, t_n\\}\\) are used to solve the problem. We solve at \\(t_0 = 1\\) and then gradually decrease the value of \\(t\\) to \\(0\\). The solution \\(x_k\\) at \\(t_{k}\\) is used as the starting point for the next iteration \\(t_{k+1}\\) until reaching \\(t_n = 0\\).\nIn the case where the values of \\(x\\) may be constrained, this becomes similar to the Interior Point Method, where the constraints are relaxed and then gradually tightened."
  },
  {
    "objectID": "content/eosc555/lectures/lecture7/index.html#gaussian-homotopy",
    "href": "content/eosc555/lectures/lecture7/index.html#gaussian-homotopy",
    "title": "Lecture 7",
    "section": "Gaussian Homotopy",
    "text": "Gaussian Homotopy\nA common case of homotopy is the Gaussian homotopy, where the smoothing function is a Gaussian function. The Gaussian function is a widely used in signal processing and image processing due to its properties as a low-pass filter. For example, a Gaussian blur is applied to images to aid in downsampling since it preserves the lower resolution details while removing high-frequency noise that may cause aliasing.\nTo illustrate the low-pass filtering property, consider a Gaussian function \\(g(x)\\) and its Fourier transform \\(\\hat{g}(k)\\):\n\\[g(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{-\\frac{x^2}{2\\sigma^2}}, \\quad \\hat{g}(k) = e^{-\\frac{k^2 \\sigma^2}{2}}.\\]\nThe Fourier transform of the Gaussian is another Gaussian, it is an eigenfunction of the Fourier transform operator. The convolution theorem states that the convolution of two functions in the spatial domain is equivalent to the multiplication of their Fourier transforms in the frequency domain:\n\\[f(x) \\ast g(x) = \\mathcal{F}^{-1} \\left[ \\hat{f}(k) \\hat{g}(k) \\right].\\]\nThe convolution of a function \\(f(x)\\) with a Gaussian \\(g(x)\\) can be used to remove the high-frequency components of the function while allowing the low-frequency, widely spread components to remain.\nA wide Gaussian in the time domain corresponds to a narrow Gaussian in the frequency domain, and vice versa. So a wide gaussian only lets through the lowest frequencies, while a narrow Gaussian lets through the highest frequencies. At the limit as the Gaussian becomes infinitely narrow, it becomes a delta function \\(g(x) = \\delta(x)\\) in the time domain, a constant function \\(\\hat{g}(k) = 1\\) in the frequency domain. The convolution of a delta function with a function \\(f\\) is the function itself, so the delta function does not change the function. The multiplication of the function \\(\\hat f(k)\\) with the constant function \\(1\\) is the function itself, so the constant function does not change the function in the frequency domain.\n\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fftpack import fft, ifft, fftfreq, fftshift\nfrom matplotlib.animation import FuncAnimation\n\n# Generate a square wave in the time domain\ndef square_wave(t, period=1.0):\n    \"\"\"Creates a square wave with a given period.\"\"\"\n    return np.where(np.sin(2 * np.pi * t / period) &gt;= 0, 1, -1)\n\n# Time domain setup\nt = np.linspace(-1, 1, 500)\nsquare_wave_signal = square_wave(t)\nfreq = fftfreq(t.size, d=(t[1] - t[0]))\nsquare_wave_fft = fft(square_wave_signal)\n\n# Function to update the plot for each frame, based on current sigma_t\ndef update_plot(sigma_t, axs, time_text):\n    sigma_f = 1 / (2 * np.pi * sigma_t)  # Standard deviation in frequency domain\n    gaussian_time_domain = np.exp(-0.5 * (t / sigma_t)**2)\n    gaussian_filter = np.exp(-0.5 * (freq / sigma_f)**2)\n    filtered_fft = square_wave_fft * gaussian_filter\n    smoothed_signal = np.real(ifft(filtered_fft))\n\n    # Update each subplot with new data\n    axs[1, 0].clear()\n    axs[1, 0].plot(t, gaussian_time_domain, color=\"purple\")\n    axs[1, 0].set_title(\"Gaussian Filter (Time Domain)\")\n    axs[1, 0].set_xlabel(\"Time\")\n    axs[1, 0].set_ylabel(\"Amplitude\")\n    axs[1, 0].grid(True)\n\n    axs[1, 1].clear()\n    axs[1, 1].plot(fftshift(freq), fftshift(gaussian_filter), color=\"orange\")\n    axs[1, 1].set_title(\"Gaussian Low-Pass Filter (Frequency Domain)\")\n    axs[1, 1].set_xlabel(\"Frequency\")\n    axs[1, 1].set_ylabel(\"Amplitude\")\n    axs[1, 1].set_xlim(-50, 50)\n    axs[1, 1].grid(True)\n\n    axs[2, 0].clear()\n    axs[2, 0].plot(t, square_wave_signal, color=\"green\", linestyle=\"--\")\n    axs[2, 0].plot(t, smoothed_signal, color=\"red\")\n    axs[2, 0].set_title(\"Smoothed Signal (Time Domain)\")\n    axs[2, 0].set_xlabel(\"Time\")\n    axs[2, 0].set_ylabel(\"Amplitude\")\n    axs[2, 0].grid(True)\n\n    axs[2, 1].clear()\n    axs[2, 1].plot(fftshift(freq), fftshift(np.abs(square_wave_fft)), color='blue', linestyle='--')\n    axs[2, 1].plot(fftshift(freq), fftshift(np.abs(filtered_fft)), color=\"orange\")\n    axs[2, 1].set_title(\"Filtered Spectrum (Frequency Domain)\")\n    axs[2, 1].set_xlabel(\"Frequency\")\n    axs[2, 1].set_ylabel(\"Amplitude\")\n    axs[2, 1].set_xlim(-30, 30)\n    axs[2, 1].grid(True)\n\n    # Update the time text\n    time_text.set_text(f\"T = {T:.2f}\")\n\n# Initialize the figure and plot layout for animation\nfig, axs = plt.subplots(3, 2, figsize=(12, 10))  # Increased figure size for animation\naxs[0, 0].plot(t, square_wave_signal, color='green')\naxs[0, 0].set_title(\"Square Wave (Time Domain)\")\naxs[0, 0].set_xlabel(\"Time\")\naxs[0, 0].set_ylabel(\"Amplitude\")\naxs[0, 0].grid(True)\n\naxs[0, 1].plot(fftshift(freq), fftshift(np.abs(square_wave_fft)), color='blue')\naxs[0, 1].set_title(\"Fourier Transform of Square Wave (Frequency Domain)\")\naxs[0, 1].set_xlabel(\"Frequency\")\naxs[0, 1].set_ylabel(\"Amplitude\")\naxs[0, 1].set_xlim(-30, 30)\naxs[0, 1].grid(True)\n\n# Add a text annotation for time at the bottom of the figure with extra space\ntime_text = fig.text(0.5, 0.02, \"\", ha=\"center\", fontsize=12)  # Adjusted position for clarity\n\n# Adjust subplot spacing specifically for animation\nplt.tight_layout(rect=[0, 0.05, 1, 1])  # Extra space at the bottom for time text\n\n# Animation settings\nsteps = 100\ndef animate(frame):\n    global T  # Declare T as a global variable for use in update_plot\n    T = 1 - (frame / steps)  # Scale frame number to a T value between 1 and 0\n    sigma_t = 0.5 * T + 0.001 * (1 - T)  # Interpolate sigma_t\n    update_plot(sigma_t, axs, time_text)\n\n# Create and display the animation\nani = FuncAnimation(fig, animate, frames=steps, interval=100)\n\n# Save the animation as a GIF\nani.save('imgs/gaussian_homotopy.gif', writer='imagemagick', fps=8)\n\nplt.show()\n\n\n\nFor Gaussian homotopy, the continuous transformation between the original function and the relaxed version is given by a convolution with a Gaussian kernel. We let \\(\\sigma(t)\\) be the standard deviation of the Gaussian kernel at time \\(t\\). The deviation will be \\(\\sigma(0) = 0\\) and \\(\\sigma(1) = \\sigma_{\\text{max}}\\) so that the homotopy at any time \\(t\\) is given by:\n\\[h(x, t) = \\int_{-\\infty}^{\\infty} f(x-\\xi) \\exp(-\\frac{\\xi^2}{\\sigma(t)^2}) d\\xi.\\]\nThe Gaussian kernel should be divided by its partition function \\(z(t) = \\int \\exp(-\\frac{\\xi^2}{\\sigma(t)^2}) d\\xi\\) in theory so that the kernel is normalized, but for the use case where \\(h(x, t)\\) is used as a surrogate function for optimization, the partition function \\(z(t)\\) does not change the minimizer of the function.\n\nStochastic Optimization\nSince the objective is to minimize over the integral given by \\(h(x, t)\\), a stochastic method can be used to estimate the minimizer in expectation using Monte Carlo methods. The integral can be approximated by sampling \\(N\\) points from the Gaussian kernel and averaging the function values at those points:\n\\[\n\\begin{align*}\nh(x, t) &= \\int_{-\\infty}^{\\infty} f(x-\\xi) \\exp(-\\frac{\\xi^2}{\\sigma(t)^2}) d\\xi\\\\\n& = \\mathbb{E}_{\\xi \\sim \\mathcal{N}(0, \\sigma(t)^2)} f(x-\\xi) \\\\\n& \\approx \\frac{1}{N} \\sum_{i=1}^N f(x-\\xi_i), \\quad \\xi_i \\sim \\mathcal{N}(0, \\sigma(t)^2).\n\\end{align*}\n\\]\nFor a given \\(t\\) and point \\(x\\) where we want to estimate the function \\(h(x, t)\\), we can sample \\(N\\) points from a Gaussian kernel centered at \\(x\\) with standard deviation \\(\\sigma(t)\\) and evaluate the function at those points. The average of the function values at those points will be an estimate of the function value at \\(x\\).\n\n\nImplementation Choices\nThere are two ways to approach this problem when using numerical methods.\n\nDiscretize then Optimize: The integral is first discretized by choosing a set of points \\(\\{xi_1, \\xi_2, \\ldots, \\xi_N\\}\\) and then the function is evaluated using that same discrete kernel across all points:\n\n\\[ \\min_{\\mathcal{X}} \\frac{1}{N} \\sum_{i=1}^N f(x-\\xi_i).\\]\nThis sum can end up being large if there are many points that are selected.\n\nOptimize then Discretize: In this case we start with gradient descent and the continuous function \\(h(x, t)\\) and then sample the function at the points \\(\\{xi_1, \\xi_2, \\ldots, \\xi_N\\}\\) to estimate a gradient.\n\n\\[\n\\begin{align*}\nx_{k+1} &= x_k - \\alpha_k \\mathbb{E}_{\\xi} \\nabla f(x_k - \\xi)\\\\\n  &\\approx x_k - \\alpha_k \\frac{1}{N} \\sum_{i=1}^N \\nabla f(x_k - \\xi_i).\n\\end{align*}\n\\]\nThis formulation can technically converge even with \\(| i | = 1\\) but with very slow convergence.\n\nNow that the Gaussian homotopy has been introduced, we can move on to the implementation of the algorithm."
  },
  {
    "objectID": "content/eosc555/lectures/lecture7/index.html#conclusion",
    "href": "content/eosc555/lectures/lecture7/index.html#conclusion",
    "title": "Lecture 7",
    "section": "Conclusion",
    "text": "Conclusion\nThis lecture has covered the theory behind homotopy, its action in the frequency and time domain, and its purpose in optimization. A scheme for continuation scheduling for the optimization along with the homotopy is a field of active research. A more detailed analysis to implement the technique in a practical setting can be understood from Lin et. al (Lin et al. 2023)."
  },
  {
    "objectID": "content/eosc555/lectures/lecture9/index.html",
    "href": "content/eosc555/lectures/lecture9/index.html",
    "title": "Lecture 9",
    "section": "",
    "text": "$$ \n$$"
  },
  {
    "objectID": "content/eosc555/lectures/lecture9/index.html#motivation",
    "href": "content/eosc555/lectures/lecture9/index.html#motivation",
    "title": "Lecture 9",
    "section": "Motivation",
    "text": "Motivation\nIn the previous lecture, we viewed different priors or regularizers and how they can be used to help solve inverse problems. A regularizer for least squares in the most general sense is given as:\n\\[ \\min_{u} \\left\\{ \\frac{1}{2} \\left\\| Au(x) - b \\right\\|_2^2 + \\lambda R(u) \\right\\} \\]\nwhere \\(u(x)\\) is a distribution of the unknowns over the domain \\(x\\), \\(A\\) is the forward operator, \\(b\\) is the data, and \\(R(u)\\) is the regularizer. A neural network can be used as a universal approximator for the function \\(R: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\), where \\(n\\) is the number of unknowns, or values of \\(u\\)."
  },
  {
    "objectID": "content/eosc555/lectures/lecture9/index.html#neural-networks",
    "href": "content/eosc555/lectures/lecture9/index.html#neural-networks",
    "title": "Lecture 9",
    "section": "Neural Networks",
    "text": "Neural Networks\n\nA Basic Neural Network: Single-Layer Perceptron (SLP)\nA basic neural network will have parameters \\(\\theta\\) that can be trained or learned, along with the input, \\(u\\).\n\\[y = R(u; \\theta) = w^T \\sigma(Wu+a), \\quad \\theta := \\{w, W, a\\}\\]\nThe function \\(R\\) in this case is a function defined for fixed \\(\\theta\\). The term \\(\\sigma\\) is a non-linear activation function, of which there are many choices.\n\n\\(u\\): Input vector to the neural network.\n\\(y\\): Output of the neural network, parameterized by \\(\\theta\\), representing the learned function.\n\\(\\theta := \\{w, W, a\\}\\): Set of trainable parameters in the network, where:\n\n\\(w\\): Weight vector for the output layer\n\\(W\\): Weights matrix for the hidden layer\n\\(a\\): Bias vector added to the hidden layer\n\n\\(\\sigma\\): Non-linear activation function applied element-wise to the affine transformation \\(Wu + a\\).\n\nSo a single layer neural network can be seen as the affine transformation of the vector \\(u\\) followed by a non-linear activation function and a weighting metric for the resultant vector.\nThis can be used as an approximator for the true regularizer \\(R(u) \\approx R_T(u)\\) in the inverse problem.\nSuppose that we have a known set of mappings \\(u_i \\rightarrow y_i\\), where \\(i = 1, \\ldots, N\\). For example we might have some information about the regularizer \\(R(u)\\) for a set of \\(u\\) values. One possible technique is to train an SLP to approximate the true regularizer \\(R_T(u)\\).\nThe function \\(y = R(u; \\theta)\\) returns a scalar, taking its transpose will not change the output:\n\\[y = w^T \\sigma(Wu+a) = \\sigma(u^TW + a)w\\]\nThen using the squared loss function, we can define the loss function as:\n\\[\\mathcal{L}(\\theta) = \\frac{1}{2} \\sum_{i=1}^N \\left \\| \\sigma(u^TW + a)w - y_i \\right \\|^2\\]\nThe summation is reorganized to get rid of the summation term where \\(U\\) is a matrix with the \\(u_i^T\\) as the columns, A is a matrix with \\(a\\) as the columns, and \\(y\\) is the vector of \\(y_i\\) values.\n\\[\\mathcal{L}(\\theta) = \\frac{1}{2} \\left \\| \\sigma(U^TW + A)w - y \\right \\|^2\\]\nFor simplicity of this analysis, we can assume without loss of generality for the problem at hand that \\(A = 0\\) and \\(\\sigma\\) is the identity operator. Then:\n\\[\\hat\\theta = \\min_{\\theta} \\mathcal{L}(\\theta) = \\min_{\\hat w} \\frac{1}{2} \\left \\| U^T\\hat w - y \\right \\|^2.\\]\nwhere \\(\\hat w = Ww\\).\n\n\nNon-linearity Analysis\nThis least squares problem will generally be ill-posed when the activation function is not present (the case with identity activation). \\(N&gt;d\\) means that there are more equations than there are unknowns, because \\(\\hat w\\) is of dimension \\(d\\), so there could be infinite solutions.\n\\[\\hat{\\theta} = \\min_{\\theta} \\frac{1}{2} \\left\\|\n\\underbrace{\n\\begin{bmatrix}\n\\ & \\ & \\ \\\\\n\\ & U^T & \\ \\\\\n\\ & \\ & \\ \\\\\n\\end{bmatrix}\n}_{N \\times d}\n\\cdot\n\\underbrace{\n\\begin{bmatrix}\n\\ & \\ & \\ \\\\\n\\ & W & \\ \\\\\n\\ & \\ & \\ \\\\\n\\end{bmatrix}\n}_{N \\times k}\n- y \\right\\|^2\n\\]\nIdea 1:\nIf we can increase the rank of the \\(Z = U^TW\\) matrix, then perhaps it is possible to solve the problem batter. We select for there to be a larger weights matrix \\(W\\) that is \\(N \\times m\\) where \\(m &gt; d\\). In the resulting \\(z = U^TW\\) matrix, the rank will still be \\(\\text{rank}(Z) \\le d\\).\nIdea 2:\nUse a non-linear activation function \\(\\sigma\\) that operates element-wise on the matrix \\(Z = U^TW\\) to increase the rank of the matrix so that \\(\\text{rank}(\\sigma(Z)) = \\min (N,m)\\).\nIn practice the exact activation function is not important. It may be the case that \\(\\text{rank}(\\sigma(Z)) = 3\\) for example, but applying the activation function will increase the rank to the minimum dimension size of the weights matrix \\(W\\). This can give a unique solution the least squares problem.\n\\[\n\\hat{\\theta} = \\min_{\\theta} \\frac{1}{2} \\left\\|\n\\sigma \\left( \\underbrace{\n\\begin{bmatrix}\n\\ & \\ & \\ \\\\\n\\ & U^T & \\ \\\\\n\\ & \\ & \\ \\\\\n\\end{bmatrix}\n}_{N \\times d}\n\\cdot\n\\underbrace{\n\\begin{bmatrix}\n\\ & \\ & \\ & \\ & \\cdots & \\ \\\\\n\\ & W & \\ & \\ & \\ & \\ \\\\\n\\ & \\ & \\ & \\ & \\ & \\ \\\\\n\\end{bmatrix}\n}_{N \\times m}\n\\right ) w\n-\ny \\right\\|^2\n\\]\n\nNon-linear Example\nTo illustrate the rank recovery property and the improvement for finding a unique solution to the least squares problem, we consider a simple example below.\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy.linalg import lstsq, matrix_rank\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Parameters\nN = 10  # Number of samples\nd = 5   # Dimension of input u\nm = 10  # Increased dimension for W\n\n# Generate random input data U (d x N)\nU = np.random.randn(d, N)\n\n# True weight matrix W_true (d x d)\nW_true = np.random.randn(d, d)\nw_true = np.random.randn(d)\n\n# Generate nonlinear output to test with\ny_linear = (np.cos(U.T @ W_true)) @ w_true\n\n# Initialize random model weight matrix W (d x m)\nW = np.random.randn(d, m)\nZ = U.T @ W\nrank_Z = matrix_rank(Z)\n\nsigma = np.sin\nZ_nonlinear = sigma(Z)\nrank_Z_nl = matrix_rank(Z_nonlinear)\n\nw_linear, residuals_linear, _, _ = lstsq(Z, y_linear, rcond=None)\nw_nonlinear, residuals_nl, _, _ = lstsq(Z_nonlinear, y_linear, rcond=None)\n\n# Check reconstruction error for each case\nerror_linear = np.linalg.norm(Z @ w_linear - y_linear)\nerror_nonlinear = np.linalg.norm(Z_nonlinear @ w_nonlinear - y_linear)\n\n# Comparison of Reconstruction Errors\nlabels = ['Linear Least Squares', 'Non-linear Least Squares']\nerrors = [error_linear, error_nonlinear]\n\nplt.figure(figsize=(5,5))\n\nbars = plt.bar(labels, errors, color=['skyblue', 'salmon'])\nplt.ylabel('Reconstruction Error')\n\n# Annotate bars with error values\nfor bar in bars:\n    height = bar.get_height()\n    plt.annotate(f'{height:.4f}',\n                 xy=(bar.get_x() + bar.get_width() / 2, height),\n                 xytext=(0, 3),  # 3 points vertical offset\n                 textcoords=\"offset points\",\n                 ha='center', va='bottom')\n\nplt.ylim(0, max(errors)*1.2)\nplt.show()\n\nplt.figure(figsize=(5,5))\n\nranks = [rank_Z, rank_Z_nl]\nlabels_rank = ['Z (Linear)', 'Z_nonlinear (Non-linear)']\n\nbars_rank = plt.bar(labels_rank, ranks, color=['lightgreen', 'gold'])\nplt.ylabel('Matrix Rank')\n\n# Annotate bars with rank values\nfor bar in bars_rank:\n    height = bar.get_height()\n    plt.annotate(f'{int(height)}',\n                 xy=(bar.get_x() + bar.get_width() / 2, height),\n                 xytext=(0, 3),  # 3 points vertical offset\n                 textcoords=\"offset points\",\n                 ha='center', va='bottom')\n\nplt.ylim(0, m + 1)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Reconstruction Error Comparison\n\n\n\n\n\n\n\n\n\n\n\n(b) Matrix Rank Comparison\n\n\n\n\n\n\n\nFigure 1: A comparison least squares with non-linear activation function\n\n\n\n\n\nNotes on Scaling\nThe \\(W\\) matrix will scale up in \\(O(N^2)\\) so that with more data samples it can become too large to handle well. The problem however can be solved with a random \\(w\\) and with \\(W\\) alone under these conditions. A lower rank \\(W\\) could help under conditions where the size of \\(N\\) is large.\n\\[ W = Q Z^T \\]\nwhere \\(Q\\) is a matrix of orthonormal columns and \\(Z\\) is a matrix of size \\(d \\times N\\). In this case the product \\(U^TW\\) for any particular sample \\(u_i\\) will be giben by \\(\\sigma((u_i^TQ)Z^T)\\). This lower rank matrix leads to the topic of convolutional neural networks (CNNs) which make extensive use of a reduced rank matrix. The benefit is that it can improve the computational speed by exploiting a sparse structure in the matrix \\(W\\).\nThis becomes more important when the layers of a SLP are combined into a deep neural network (DNN).\n\\[y = R(u; \\theta) = w^T \\sigma(W^{(L)} \\sigma(W^{(L-1)} \\cdots \\sigma(W^{(1)}u + a^{(1)})) + a^{(L-1)}) + a^{(L)}\\]\nwhere \\(L\\) is the number of layers in the network. This is a chain of affine transformations followed by non-linear activation functions and can be expensive to compute in the case where \\(N\\) is large."
  },
  {
    "objectID": "content/eosc555/lectures/lecture9/index.html#convolutional-neural-networks-cnns",
    "href": "content/eosc555/lectures/lecture9/index.html#convolutional-neural-networks-cnns",
    "title": "Lecture 9",
    "section": "Convolutional Neural Networks (CNNs)",
    "text": "Convolutional Neural Networks (CNNs)\nA convolutional neural network makes use of a matrix operator that produces the same result as a discrete convolution.\n\nConvolution Operator\nThe 1D convolutional operator \\(\\ast\\) in the discrete case is defined as:\n\\[ (f \\ast g)[n] = \\sum_{m=-\\infty}^{\\infty} f[m]g[n-m] \\]\nIn the case of a 2D convolution, the operator is defined as:\n\\[ (f \\ast g)[n,m] = \\sum_{i=-\\infty}^{\\infty} \\sum_{j=-\\infty}^{\\infty} f[i,j]g[n-i,m-j] \\]\nIt is also an operation defined in the continuous domain as:\n\\[ (f \\ast g)(x) = \\int_{-\\infty}^{\\infty} f(y)g(x-y)dy \\]\nThe operation is one that is fundamental to mathematics and shows up in many different applications including, signal processing, image processing, control theory, probability theory, solutions to ordinary and partial differential equations where it is known as the Green’s function, and in the solution of integral equations. Another such home that is has found is in deep learning. The convolution has some intuitive properties that make it useful in any system that is linear and time/shift invariant (LTI).\nProperties of Convolution\n\nLinearity: \\(f \\ast (\\alpha g + \\beta h) = \\alpha f \\ast g + \\beta f \\ast h\\)\nCommutativity: \\(f \\ast g = g \\ast f\\)\nAssociativity: \\(f \\ast (g \\ast h) = (f \\ast g) \\ast h\\)\n\nRather than explain convolution at length here, the interested reader is encouraged to look at the Convolution Wikipedia page for some excellent properties and visual examples to build intuition.\nIn the context of image and data processing, the convolution is closely related to a correlation filter, the two only differe by a rotation of 180 in the convolutional kernel (the function being convolved with the input). This is an important consideration when it comes to working with learned convolutional kernels, since they can be equally interpreted as correlation filters.\nAnother important property to know is that the convolution operation has a close relationship with the fourier transform. The convolution in the spatial domain is equivalent to a pointwise multiplication in the frequency domain. This is known as the convolution theorem:\n\\[ \\mathcal{F}(f \\ast g) = \\mathcal{F}(f) \\cdot \\mathcal{F}(g) \\]\nWhen it comes to computing large convolutions for two function \\(f(x)\\) and \\(g(x)\\), the convolution theorem can be used to compute the convolution in the frequency domain, which is much faster than the spatial domain.\n\\[ f \\ast g = \\mathcal{F}^{-1}(\\mathcal{F}(f) \\cdot \\mathcal{F}(g)) \\]\nFor more details with visual explanations, another good resource is the UBC CPSC 425 course on Computer Vision with slides from Lecture 3b and Lecture 4.\n\n\nConvolution in CNNs\nA convolutinal neural network (CNN) is a type of neural network where the linear mapping involves a convolution operation instead of a dense weight matrix \\(W\\). The goal of this section is to define the 2D discrete convolution and show how it can be expressed as a sparse matrix.\nSingle Layer Perceptron (SLP) vs Convolutional Neural Network (CNN)\nThe single layer of a perceptron given earlier is of the form \\(y = w^T \\sigma(Wu + a)\\), where \\(W\\) is the weights matrix, \\(w\\) is the weights vector, \\(u\\) is the input, and \\(a\\) is the bias vector. A convolutional network improves the efficiency of computation by exploiting a sparse structure with fewer parameters in the weights matrix. Replacing \\(W\\) with a sparse convolutional matrix \\(C\\).\n\nDefinition: Convolutional Operation\nLet \\(\\vec{u}\\) be the flattened input image \\(\\mathcal{I}\\), and let \\(\\mathcal{K}\\) be the convolutional kernel. The convolutional operation is defined as:\n\\[ Y[s,t] = \\mathcal{K} \\ast \\mathcal{I} = \\sum_{i=-\\infty}^{\\infty} \\sum_{j=-\\infty}^{\\infty} \\mathcal{K}[i,j] \\mathcal{I}[s-i,t-j]\\]\n\n\\(Y[s,t]\\) is the output at position \\((s,t)\\)\n\\(N\\) and \\(M\\) are the dimensions of the kernel \\(\\mathcal{K}\\)\n\\(\\mathcal{K}[i,j]\\) is the element in the \\(i\\)-th row and \\(j\\)-th column of the kernel\n\nThe kernel slides across the input image, producing a weighted sum at each valid position to give output \\(Y\\). The indices are clipped from infinity to the correct size depending on the padding, size of kernel, and the stride.\nIt is a linear operation so that every element of \\(Y\\) is a linear combination of the input and weights elements, indicating that it can be expressed as a matrix multiplication with the flattened image \\(\\vec{u}\\) and the flattened kernel \\(\\vec{k}\\).\n\nExample: Convolution of a \\(2\\times 2\\) Kernel with a \\(4\\times 4\\) Image\nInput Image: \\[\n\\mathcal{I} =\n\\begin{bmatrix}\nu_{1,1} & u_{1,2} & u_{1,3} & u_{1,4} \\\\\nu_{2,1} & u_{2,2} & u_{2,3} & u_{2,4} \\\\\nu_{3,1} & u_{3,2} & u_{3,3} & u_{3,4} \\\\\nu_{4,1} & u_{4,2} & u_{4,3} & u_{4,4} \\\\\n\\end{bmatrix}\n\\]\nKernel: \\[\n\\mathcal{K} =\n\\begin{bmatrix}\nk_{1,1} & k_{1,2} \\\\\nk_{2,1} & k_{2,2} \\\\\n\\end{bmatrix}\n\\]\nOutput: The output of the convolution will be a \\(3 \\times 3\\) matrix, since the kernel slides over the \\(4 \\times 4\\) image with no padding and a stride of 1.\n\\[\nY =\n\\begin{bmatrix}\ny_{1,1} & y_{1,2} & y_{1,3} \\\\\ny_{2,1} & y_{2,2} & y_{2,3} \\\\\ny_{3,1} & y_{3,2} & y_{3,3} \\\\\n\\end{bmatrix}\n\\]\nNote that the output indexing loses the first and last row and column because there is no padding. In cases with zero padding, then all undefined indices of the input are set to zero when using the convolution formula and reaching undefined indices.\nEach element \\(y_{s,t}\\) of the output is given by: \\[\ny_{s,t} = \\sum_{i=1}^{2} \\sum_{j=1}^{2} \\mathcal{K}[i,j] \\cdot \\mathcal{I}[(s+2)-i, (t+2)-j]\n\\]\nThe addition of \\(2\\) in the indexing is due to the size of the kernel being \\(2 \\times 2\\) and the choice to index \\(y\\) starting from \\(1\\) instead of \\(3\\) for the case with no padding.\nFlatten the Input Image:\nFlatten the \\(4 \\times 4\\) image \\(\\mathcal{I}\\) into a column vector \\(\\vec{u} \\in \\mathbb{R}^{16}\\): \\[\n\\text{flatten}\\left(\\mathcal{I}\\right) = \\vec{u} =\n\\begin{bmatrix}\nu_{1,1} & u_{1,2} & u_{1,3} & u_{1,4} &\nu_{2,1} & u_{2,2} & u_{2,3} & u_{2,4} &\nu_{3,1} & u_{3,2} & u_{3,3} & u_{3,4} &\nu_{4,1} & u_{4,2} & u_{4,3} & u_{4,4}\n\\end{bmatrix}^T\n\\]\nSparse Convolution Matrix:\nThe convolution operation is expressed as a matrix multiplication: \\[\n\\text{flatten}\\left( Y \\right) = \\mathbf{C} \\vec{u}\n\\]\nHere, \\(\\mathbf{C}\\) is the sparse matrix representation of the \\(2 \\times 2\\) kernel, with size \\(9 \\times 16\\) (matching the size of the output vector and the input vector). The non-zero entries in each row of \\(\\mathbf{C}\\) correspond to the flattened values of \\(\\mathcal{K}\\).\nLooking at the first few entries of the output \\(Y\\) defines the matrix entries:\n\n\\(y_{1,1} = k_{2,2}u_{1,1} + k_{2,1}u_{1,2} + k_{1,2}u_{2,1} + k_{1,1}u_{2,2}\\)\n\\(y_{1,2} = k_{2,2}u_{1,2} + k_{2,1}u_{1,3} + k_{1,2}u_{2,2} + k_{1,1}u_{2,3}\\)\n\\(y_{1,3} = k_{2,2}u_{1,3} + k_{2,1}u_{1,4} + k_{1,2}u_{2,3} + k_{1,1}u_{2,4}\\)\n\n\\[\n\\mathbf{C} =\n\\begin{bmatrix}\nk_{2,2} & k_{2,1} & 0      & 0      & k_{1,2} & k_{1,1} & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      \\\\\n0      & k_{2,2} & k_{2,1} & 0      & 0      & k_{1,2} & k_{1,1} & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      \\\\\n0      & 0      & k_{2,2} & k_{2,1} & 0      & 0      & k_{1,2} & k_{1,1} & 0      & 0      & 0      & 0      & 0      & 0      & 0      & 0      \\\\\n0      & 0      & 0      & 0        & k_{2,2} & k_{2,1} & 0      & 0      & k_{1,2} & k_{1,1} & 0      & 0      & 0      & 0      & 0      & 0    \\\\\n0      & 0      & 0      & 0        & 0      & k_{2,2} & k_{2,1} & 0      & 0      & k_{1,2} & k_{1,1} & 0      & 0      & 0      & 0      & 0    \\\\\n\\vdots & \\vdots  & \\vdots  & \\vdots & \\vdots & \\vdots  & \\vdots  & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n\\end{bmatrix}\n\\]\nThen using this matrix and the flattened input image, a flattened output vector can be computed as $\\(\\text{flatten}\\left(Y \\right) = C \\vec{u}\\).\nSo the convolution operation gives a matrix that only has \\(4\\) parameters out of the \\(9 \\times 16 = 144\\) total elements, with most of the entries being zero. This can be highly efficient for compuations in a neural network for spatially invariant features in the input data. The sparse structure of the matrix can also be exploited for efficient computation.\n\n\nChannels in Convolutional Neural Networks\nThe data being processed in a CNN can have multiple channels, such as color images with \\(3\\) channels. The images may also be processed in batches, adding yet another dimension to the input data. For a single image that is size \\(\\{C,H,W\\}\\) where \\(C\\) is the number of channels, \\(H\\) is the height, and \\(W\\) is the width, a different convolutional kernel is applied as a mapping from \\(C_{in}\\) channels to \\(C_{out}\\) channels. To flatten the input image with channels, the flattened single channels are stacked vertically to form a single column vector.\nFor \\(k\\) input channels and \\(l\\) output channels:\n\\[ y = \\begin{bmatrix}\nW_{1,1} & W_{1,2} & \\cdots & W_{1,k} \\\\\nW_{2,1} & W_{2,2} & \\cdots & W_{2,k} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nW_{l,1} & W_{l,2} & \\cdots & W_{l,k} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nu_{c=1} \\\\\nu_{c=2} \\\\\n\\vdots \\\\\nu_{c=k} \\\\\n\\end{bmatrix}\n\\]\nThe \\(W\\) are the individual convolutional kernel maps for each input to output channel. The input is a flattened tensor of size \\(k \\times H \\times W\\), and the output is a flattened tensor of size \\(l \\times H \\times W\\).\nTo extend the CNN structure to accept batches, the input data is pooled together into a matrix of flattned input data, where each column is a flattened input image. For a batch size of \\(N\\), the input data is of size \\(N \\times k \\times H \\times W \\times N\\) and the output data is of size \\(N \\times l \\times H \\times W\\).\n\\[ Y_{\\text{batch}} = \\begin{bmatrix}\nW_{1,1} & W_{1,2} & \\cdots & W_{1,k} \\\\\nW_{2,1} & W_{2,2} & \\cdots & W_{2,k} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nW_{l,1} & W_{l,2} & \\cdots & W_{l,k} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nu_{1,c=1} & u_{2,c=1} & \\cdots & u_{N,c=1} \\\\\nu_{1,c=2} & u_{2,c=2} & \\cdots & u_{N,c=2} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nu_{1,c=k} & u_{2,c=k} & \\cdots & u_{N,c=k} \\\\\n\\end{bmatrix}\n\\]\n\n\nDeep CNNs\nA deep CNN wil chain multiple convolutional layers together, including a non-linear activation function and bias after each later:\n\\[ y = \\sigma(W^{(L)} \\sigma(W^{(L-1)} \\cdots \\sigma(W^{(1)}u + a^{(1)}) + a^{(L-1)}) + a^{(L)} \\]\nA famous implementation of a deep CNN that broke new ground in the world of image processing is the ResNet architecture (He et al. 2015). The ResNet was able to train very deep networks with hundreds of layers by using skip connections that bypassed one or more layers. Each sequential layer in the architecture is to train a change in the residual rather than the entire output to the next layer.\n\\[ u_{n+1} = u_n + h \\sigma(W_n u_n + a_n) \\]\nWhen \\(h\\) becomes small, this resembles the Euler method for solving ordinary differential equations where \\(\\frac{du}{dt} = \\sigma(W_t u + a_t)\\). Where the parameters are also time dependent."
  },
  {
    "objectID": "content/projects/projects.html",
    "href": "content/projects/projects.html",
    "title": "Project Home",
    "section": "",
    "text": "This project focuses on the development and challenges of building and controlling a reaction wheel unicycle. Performed as part of a 2-year long capstone project in the UBC Engineering Physics program, sponsored by the Engineering Physics project lab.\nExplore the Learning to Balance Project",
    "crumbs": [
      "Home",
      "Projects",
      "Project Home"
    ]
  },
  {
    "objectID": "content/projects/projects.html#learning-to-balance-a-reaction-wheel-unicycle",
    "href": "content/projects/projects.html#learning-to-balance-a-reaction-wheel-unicycle",
    "title": "Project Home",
    "section": "",
    "text": "This project focuses on the development and challenges of building and controlling a reaction wheel unicycle. Performed as part of a 2-year long capstone project in the UBC Engineering Physics program, sponsored by the Engineering Physics project lab.\nExplore the Learning to Balance Project",
    "crumbs": [
      "Home",
      "Projects",
      "Project Home"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/introduction.html",
    "href": "content/projects/RLUnicycle/introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Welcome to our self-balancing unicycle robot capstone project! We are a team of undergraduate UBC Engineering Physics students working on our final academic checkpoint as engineering students before being released into the wild. This project is directly sponsored by the UBC Engineering Physics Project Lab.\n\n\n\nTristan Lee, Julian Lapenna, Kyle Mackenzie, Jackson Fraser, and Simon Ghyselincks\n\n\n\n\nOur goal is to design and develop a self-balancing reaction wheel robot that can navigate autonomously and be used as a platform to compare traditional control methods with reinforcement learning. The spirit of the project is to explore some of the challenges in implementing advanced control strategies on a real-world system. This includes bridging the gap between simulated models and real applications, coordinating peripherals with low latency, and designing hardware for controllability. It also presents a great opportunity to apply some fundamental physics and engineering concepts in a hands-on challenge.\n\n\n\nOur work draws on previous advances made in robotics. Notably, the Max Planck Institute’s Wheelbot project has served as a significant source of inspiration, many of our design choices and control strategies are influenced by their work. We aim to build on their development with a more advanced control and motor system that can navigate autonomously and adapt to dynamic disturbances using reinforcement learning.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Introduction"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/introduction.html#project-overview",
    "href": "content/projects/RLUnicycle/introduction.html#project-overview",
    "title": "Introduction",
    "section": "",
    "text": "Welcome to our self-balancing unicycle robot capstone project! We are a team of undergraduate UBC Engineering Physics students working on our final academic checkpoint as engineering students before being released into the wild. This project is directly sponsored by the UBC Engineering Physics Project Lab.\n\n\n\nTristan Lee, Julian Lapenna, Kyle Mackenzie, Jackson Fraser, and Simon Ghyselincks\n\n\n\n\nOur goal is to design and develop a self-balancing reaction wheel robot that can navigate autonomously and be used as a platform to compare traditional control methods with reinforcement learning. The spirit of the project is to explore some of the challenges in implementing advanced control strategies on a real-world system. This includes bridging the gap between simulated models and real applications, coordinating peripherals with low latency, and designing hardware for controllability. It also presents a great opportunity to apply some fundamental physics and engineering concepts in a hands-on challenge.\n\n\n\nOur work draws on previous advances made in robotics. Notably, the Max Planck Institute’s Wheelbot project has served as a significant source of inspiration, many of our design choices and control strategies are influenced by their work. We aim to build on their development with a more advanced control and motor system that can navigate autonomously and adapt to dynamic disturbances using reinforcement learning.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Introduction"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/introduction.html#the-robot",
    "href": "content/projects/RLUnicycle/introduction.html#the-robot",
    "title": "Introduction",
    "section": "The Robot",
    "text": "The Robot\n\n\nThe robot is composed of two reaction wheels, a single drive wheel, a controller, and a battery, all mounted on a 3D printed PLA frame. It has a total height of 30cm and a weight of 1.25kg, incorporating a compact and efficient design intended to allow self-erection from a position resting on its resetting legs. The Jetson Nano acts as an autonomous controller that reads the sensors and reacts to the environment using the motors.\n\nMuch like a unicycle, it balances on one wheel, with side-to-side stability provided by the roll wheel and direction controlled by a yaw wheel. The mechanism of balancing and steering relies on a reaction torque produced by spinning the reaction wheels. When a motor applies torque to one of the flywheels, an equal and opposite torque acts on the robot’s body, with the net effect altering the angular motion of both the wheel and the robot. The unstable axes to control are roll and pitch where the robot will fall to the ground without any intervention.\n\n\n\n\nSide View Pitch Axis\n\n\n\n\n\nSide View Roll Axis",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Introduction"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/introduction.html#the-challenge",
    "href": "content/projects/RLUnicycle/introduction.html#the-challenge",
    "title": "Introduction",
    "section": "The Challenge",
    "text": "The Challenge\nRobotics often confronts complex dynamics that are difficult to model precisely. Traditional control systems, while reliable under predictable conditions, may falter with unexpected disturbances. This project explores how Reinforcement Learning can enable our unicycle robot to adapt through trial and error, improving its decision-making capabilities in a dynamic environment.\n\nPrototyping and Progress\nWe have initiated our project with a Reaction Wheel Inverted Pendulum (RWIP) model to understand and tackle the unstable roll axis dynamics. Our efforts so far have included the application of both a traditional PID controller and an RL controller, with the latter showing promising results in handling dynamic disturbances aggressively yet effectively. With the completion of a function 2-DOF underactuated model, we are now moving towards the development of a full-scale 3-axis robot prototype.\n\n\n\n\n3-Axis Partial Build\n\n\n\n\n\nWith Prototype\n\n\n\n\n\n\n\nRWIP Model",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Introduction"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/introduction.html#looking-ahead",
    "href": "content/projects/RLUnicycle/introduction.html#looking-ahead",
    "title": "Introduction",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nThe insights gained from the RWIP will guide the development of the full-scale robot, with the eventual integration of state-space models for sophisticated control strategies and enhanced point-to-point navigation.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Introduction"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/introduction.html#development-pages",
    "href": "content/projects/RLUnicycle/introduction.html#development-pages",
    "title": "Introduction",
    "section": "Development Pages",
    "text": "Development Pages\nExplore the detailed development of specific components of our project:\n\n\n\nComponent\nDescription\n\n\n\n\nReal-Time Kernel\nDive into how we handle real-time constraints on the Jetson Nano.\n\n\nTelemetry\nDiscover how our system communicates and processes real-time data.\n\n\nDynamics and Control\nLearn about the dynamic modeling and control of our robot prototype.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Introduction"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/telemetry/telemetry.html",
    "href": "content/projects/RLUnicycle/telemetry/telemetry.html",
    "title": "Telemetry and Database Systems for Capstone Projects",
    "section": "",
    "text": "This guide provides a comprehensive overview of the telemetry and database systems employed in our “Learning to Balance” reinforcement learning unicycle project. It includes hardware recommendations, a detailed explanation of the networked services used, and example code to illustrate software implementation.\n\n\n\nTelemetry Overview\n\n\nThe telemetry and database system functions as a two-way pipeline controlling the flow of data from sensors, motors, and control decisions. Data from the robot is efficiently offloaded to a server, considering limited processing power and the necessity for a stable control loop. The server further processes this data and manages control signals sent back to the robot for parameter adjustments or commands. By utilizing a central server and internet connectivity, the database, live telemetry, and control panel can be accessed from any networked computer via a browser or software API, globally.\n\n\nThis guide assumes familiarity with running commands on a Linux command line and access to a terminal on your client device (e.g., personal laptop). This could be through WSL or VSCode on Windows, or a terminal on a Mac or Linux machine.\nBasic understanding of Python is recommended, as some examples use Python. However, the same libraries are available in other languages such as C++.\n\n\n\n\nWe recommend the Lenovo M900 series of refurbished tiny PCs as an affordable option that meets the computational needs for a server. The device’s SSD was set to dual boot into Linux Ubuntu 22.04 to run the server. This type of device is capable of handling the computational load of running multiple services simultaneously, including database management, messaging, and control services. It can also serve as a workstation for the team.\nWe tested the Raspberry Pi 4B 8GB with an external SSD, but its processing power is at the limit for these requirements. Therefore, it is not recommended for use as a server, especially considering the cost-effectiveness of a refurbished Lenovo.\n\n\n\n\n\n\n\n\n\nLenovo Server\n\n\n\n\n\n\n\nWifi Dongle\n\n\n\n\n\n\n\n\nOur robot uses an NVIDIA Jetson Nano 4GB, which does not include built-in Wi-Fi. Additionally, a real-time (PREEMPT_RT) patch has been applied to our Linux kernel. Many Wi-Fi dongle drivers are incompatible with the low-level kernel changes made by the patch; for example, the rtl8188EUS driver stopped working after the patch.\nWe recommend the MT7601U chipset USB Wi-Fi dongle, which works without the need for additional drivers on Ubuntu 22.04, Ubuntu 16.04 PREEMPT-RT, and Raspbian. This dongle is reliable for use with outdated and/or patched Linux kernels, is inexpensive, and can be found on Amazon or Aliexpress.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Telemetry and Database Systems for Capstone Projects"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/telemetry/telemetry.html#prerequisites",
    "href": "content/projects/RLUnicycle/telemetry/telemetry.html#prerequisites",
    "title": "Telemetry and Database Systems for Capstone Projects",
    "section": "",
    "text": "This guide assumes familiarity with running commands on a Linux command line and access to a terminal on your client device (e.g., personal laptop). This could be through WSL or VSCode on Windows, or a terminal on a Mac or Linux machine.\nBasic understanding of Python is recommended, as some examples use Python. However, the same libraries are available in other languages such as C++.\n\n\n\n\nWe recommend the Lenovo M900 series of refurbished tiny PCs as an affordable option that meets the computational needs for a server. The device’s SSD was set to dual boot into Linux Ubuntu 22.04 to run the server. This type of device is capable of handling the computational load of running multiple services simultaneously, including database management, messaging, and control services. It can also serve as a workstation for the team.\nWe tested the Raspberry Pi 4B 8GB with an external SSD, but its processing power is at the limit for these requirements. Therefore, it is not recommended for use as a server, especially considering the cost-effectiveness of a refurbished Lenovo.\n\n\n\n\n\n\n\n\n\nLenovo Server\n\n\n\n\n\n\n\nWifi Dongle\n\n\n\n\n\n\n\n\nOur robot uses an NVIDIA Jetson Nano 4GB, which does not include built-in Wi-Fi. Additionally, a real-time (PREEMPT_RT) patch has been applied to our Linux kernel. Many Wi-Fi dongle drivers are incompatible with the low-level kernel changes made by the patch; for example, the rtl8188EUS driver stopped working after the patch.\nWe recommend the MT7601U chipset USB Wi-Fi dongle, which works without the need for additional drivers on Ubuntu 22.04, Ubuntu 16.04 PREEMPT-RT, and Raspbian. This dongle is reliable for use with outdated and/or patched Linux kernels, is inexpensive, and can be found on Amazon or Aliexpress.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Telemetry and Database Systems for Capstone Projects"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/telemetry/telemetry.html#zerotier-virtual-network",
    "href": "content/projects/RLUnicycle/telemetry/telemetry.html#zerotier-virtual-network",
    "title": "Telemetry and Database Systems for Capstone Projects",
    "section": "ZeroTier Virtual Network",
    "text": "ZeroTier Virtual Network\nZeroTier allows all authorized devices on the network to communicate directly using assigned virtual IP addresses, similar to running a local network over a Wi-Fi router.\nIP Addresses: When a website address is entered into a browser, the request is sent to a Domain Name Server (DNS), which translates the address into an IP address—a unique identifier that functions like a postal address, marking the exact location of a server on the internet. For example:\n❯ ping google.com\nPING google.com (142.251.33.78) 56(84) bytes of data.\n64 bytes from sea09s28-in-f14.1e100.net (142.251.33.78): icmp_seq=1 ttl=114 time=21.6 ms\nThe Google webpage can be accessed by typing the IP address directly into the browser. The number is a unique identifier for that server on the internet.\nPublic and Private IP Addresses: The IP protocol reserves certain ranges of IP addresses for pivate networks. For example, the entire block of addresses 192.168.0.0 – 192.168.255.255 do not point to the wider internet but is reserved for local devices. This is why home routers can all have the same common IP address of 192.168.0.1 without creating any conflicts. It acts as a local addressing system, like apartment numbers in a building.\nNetwork Ports: Ports differentiate between different services running on the same IP address. For example, a web server might run on port 80, while an email server might run on port 25. When entering a website address, the browser automatically connects to the server on port 80. To connect to a different service, you can specify the port using a colon, e.g., http://172.22.1.1:8086/ connects to port 8086 which is commonly used for InfluxDB.\nLocal Host: The IP address http://localhost s a special address that points to the local machine. It is used to access services running on the same machine without needing to know the IP address.\nThe clients on the ZeroTier network connect to the robot and server using their assigned virtual IP addresses managed by the ZeroTier service.\n\nSetting up ZeroTier Network\nTo setup a network you should first create a free account at https://my.zerotier.com/. It is advisable to set up a team email so that any team member can log in to manage the network as needed. Once you have an account, you can create a network and add devices to it. The network ID is a 16-digit number used to identify the network.\n\n\nZeroTier Client Setup\nEvery device intended to be part of the network – including laptops, the server, and the Jetson – should have the ZeroTier client installed. After installation, enter the network ID from the ZeroTier website into the client, and approve the device to join the network. Assign static IP addresses, especially for critical devices like the server. This can be managed via the ZeroTier website.\nInstallation Instructions: Download the ZeroTier client here.\n\nSteps:\n\nDownload and Install the ZeroTier client for your operating system:\nStart the ZeroTier service:\n\nOn Windows:\n\nOpen the ZeroTier client, which will add an icon to the system tray.\nRight-click on the icon and select Join Network, then enter the network ID.\nSet the client UI to launch on startup.\n\nOn Linux: Run the following commands:\nsudo systemctl enable zerotier-one\nsudo systemctl start zerotier-one\nsudo zerotier-cli join YOUR_NETWORK_ID\n\nApprove the device:\nTake note of the client ID and either log into the ZeroTier website or use the command-line interface to approve the device for network access.\nVerify the connection:\nAfter approval, you can verify the connection by pinging another connected device on the network using its assigned virtual IP address.\nAssign a static IP (optional):\nFor important devices like the server or the Jetson, assign static IP addresses through the ZeroTier web console under the Members tab. This ensures consistent IP allocation across reboots.\n\n\n\n\n\nManaging IP Addresses\nBelow is an example of a ZeroTier network where the server has been assigned the static IP address 172.22.1.1 on the network:\n\n\n\nZeroTier Network and Access",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Telemetry and Database Systems for Capstone Projects"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/telemetry/telemetry.html#connecting-to-robot-controller-using-ssh",
    "href": "content/projects/RLUnicycle/telemetry/telemetry.html#connecting-to-robot-controller-using-ssh",
    "title": "Telemetry and Database Systems for Capstone Projects",
    "section": "Connecting to Robot Controller using SSH",
    "text": "Connecting to Robot Controller using SSH\nWith the virtual network established, you can enable remote access to the robot controller via SSH. SSH is a secure shell protocol that allows you to run command-line commands on a remote device. This is very useful for managing the robot, running scripts, and updating software code. Use the virtual IP address assigned to the robot on the ZeroTier network. It is recommended to assign a static IP address using the ZeroTier UI or CLI so that the address does not change between reboots.\nFor faster access to SSH devices, consider setting up an alias or an SSH key once SSH is verified working for a device. More information on SSH can be found here\nExample: Our robot has the static ip address 172.22.0.5. To connect from a linux terminal on a computer connected to the private network with zerotier client installed, run the following command:\nssh jetson@172.22.0.5\nThis will attempt to log in to the username jetson on the robot controller, prompting for the user password (the same as if logging in directly on the robot). For a controller running Linux, we recommend setting up different users on the system so that each team member can log in to their own account and manage their own files and credentials. Software between user accounts can be shared using symbolic links to a central repository or using GitHub to manage individual software branches.\n\nVSCode Server\nThe Jetson is also able to handle VSCode Server (https://code.visualstudio.com/docs/remote/ssh), although the outdated Ubuntu 16.04 requires running an older version of the VSCode IDE to SSH in. Be aware that VSCode Server is active on the Jetson when SSHed in, which consumes some system resources; however, in practice, it has not been a performance issue. For best performance, running the robot through a simple terminal is recommended. The benefit of SSHing through VSCode is that it provides a GUI interface for software development and file management on the robot, as if you were using VSCode on your own computer.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Telemetry and Database Systems for Capstone Projects"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/telemetry/telemetry.html#mqtt-overview",
    "href": "content/projects/RLUnicycle/telemetry/telemetry.html#mqtt-overview",
    "title": "Telemetry and Database Systems for Capstone Projects",
    "section": "MQTT Overview",
    "text": "MQTT Overview\n\n\n\nMQTT is a lightweight messaging protocol that provides an efficient and cost-effective method for telemetry-based communication between devices. MQTT messages are routed through the Lenovo server acting as the broker using Mosquitto. The robot can publish data to a topic, which can be picked up by various subscribers such as Grafana or other laptops and devices connected to the broker and subscribed to the topic. Similarly, commands can be sent back to the robot via a command topic to turn it on or off or adjust parameters. The default port for MQTT is 1883.\nFor setup, installation, and maintenance of the broker, we recommend installing MQTT Explorer on any device connected to the network. This allows for monitoring all messaging and client connections across the system.\nDownload from MQTT Explorer\n\nKey Features of MQTT\n\n\n\n\n\n\n\nFeature\nDescription\n\n\n\n\nLightweight Protocol\nIdeal for constrained devices and networks with limited bandwidth.\n\n\nPublish-Subscribe Model\nAllows devices to publish messages to a topic and any client subscribed to that topic will receive the messages.\n\n\nReliable Message Delivery\nOffers various levels of Quality of Service (QoS) to guarantee message delivery.\n\n\nMinimal Overhead\nAdds only a small overhead to each message, ensuring efficient use of network resources.\n\n\n\n\n\n\nInstalling Mosquitto MQTT Broker\nFrom the server open a terminal and run the following commands to install the MQTT broker:\nsudo apt update\nsudo apt install mosquitto mosquitto-clients\nsudo systemctl enable mosquitto\nsudo systemctl start mosquitto\nAfter installation, open MQTT Explorer and connect to the broker using the IP address of the server and the default port. You should see the server as a client connected to the broker.\n\n\n\nConnecting to MQTT Broker\n\n\nOnce connected, some test messages can be sent through the GUI and verified that they are being received by the server.\nFor more detailed instructions or help, consider using additional resources or consult the Mosquitto documentation.\n\n\nInterfacing with Software\nMQTT interfaces with Python, Node-RED, and Grafana to provide a network of communication topics. The broker can be accessed by any device on the ZeroTier network; messages can be sent to a topic, or actions can be taken based on a message received from a topic.\nBelow is an example Python script for publishing messages to the MQTT broker. This script publishes a test message to the topic jetson/telemetry every second. Note that the two key components of a successful message are the topic and the message payload. The topic is the address to which the message is sent, and the payload is the data being sent. The payload can be a string, a number, or a JSON object. For our project, we use JSON objects to send data.\nThe package is installed using pip: pip install paho-mqtt\n\nimport json\nimport time\nimport paho.mqtt.client as mqtt\nimport random\n\n# Define the MQTT settings\nbroker_address = \"172.22.1.1\"  # Lenovo's IP address (replace with your broker IP)\nport = 1883\ntopic = \"jeston/telemetry\"\n\n# Create an MQTT client instance\nclient = mqtt.Client()\n\n# Define the callback for receiving messages\ndef on_message(client, userdata, message):\n    print(f\"Message received on topic {message.topic}: {message.payload.decode()}\")\n\n# Define the callback for connecting to the broker\ndef on_connect(client, userdata, flags, rc):\n    print(\"Connected to broker with result code \" + str(rc))\n    # Subscribe to the topic when connected\n    client.subscribe(topic)\n\n# Assign the callbacks\nclient.on_message = on_message\nclient.on_connect = on_connect\n\n# Connect to the broker\nclient.connect(broker_address, port)\n\n# Start the loop to process messages\nclient.loop_start()\n\n# Publish some test messages to the topic every second\ntry:\n  range(3)\n  for i in range(3):\n        message = {\"sensor\": \"temperature\", \"value\": 20 + random.random() * 5}\n        client.publish(topic, json.dumps(message))\n        print(f\"Published message: {message}\")\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    print(\"Exiting...\")\n\n# Stop the loop and disconnect\nclient.loop_stop()\nclient.disconnect()\n\nIn this demo script, the client is both publishing and subscribing to the same topic. In practice, we use multiple topics for different data streams and commands. A more advanced implementation for assigning topics and managing data can be found in our repository: RLUnicycle\nThis test script is useful for publishing test data when it comes to verifying the installation of InfluxDB and Grafana ahead.\nWe are now at this stage in the setup:\n\n\n\n\n\nflowchart TD\n  %% Customizing colors for subgraphs and nodes\n  style Robot fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Server fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px\n  style Clients fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n\n  Y[Robot]\n  Z[Server]\n\n  %% Define a class for black text\n  classDef blackText fill:none,color:#000,stroke:none;\n\n  subgraph Robot\n    E(Jetson)\n  end\n  \n  subgraph Server\n    E &lt;--&gt; F[MQTT Broker]\n  end\n\n  %% Clients section coloring applied to individual floating nodes\n    K[Python Script] --&gt;|Commands| F\n    L[Laptop] --&gt;|SSH| E\n    L --&gt;|MQTT Explorer| F\n    L --&gt; K\n  \n  %% Styling for the floating client items\n  style K fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style L fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style Y fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Z fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Telemetry and Database Systems for Capstone Projects"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/telemetry/telemetry.html#telegraf-and-influxdb",
    "href": "content/projects/RLUnicycle/telemetry/telemetry.html#telegraf-and-influxdb",
    "title": "Telemetry and Database Systems for Capstone Projects",
    "section": "Telegraf and InfluxDB",
    "text": "Telegraf and InfluxDB\n\n \n\nTelegraf and InfluxDB are free and open-source products from InfluxData. Telegraf is driven by a configuration file that organizes incoming data from multiple sources for processing and forwarding into the InfluxDB database. InfluxDB is a time-series database used to store telemetry data streamed from the robot. It features a web browser interface for data exploration and APIs in Python and other languages for database queries.\nFollow the instructions in the links above to install both services on the server.\n\nInfluxDB Configuration\nThe InfluxDB database can be accessed through a web browser by navigating to the IP address of the Lenovo server on port 8086. For example, http://172.22.1.1:8086/. A login process will establish a username, password, and organization. The organization is simply a way to group data together across users. A bucket is a way to group data together within an organization. For our database we have assigned the organization name as Capstone and the bucket name as telegraf but these are free to choose. Once the organization and bucket have been created, the database is ready to receive data.\n\n\nTelegraf Configuration\nThe Telegraf configuration file is located at /etc/telegraf/telegraf.conf by default. The default configuration is extensive, with many lines commented out. It is advisable to back up the original file and then remove unnecessary commented lines for clarity.\nTelegraf acts as a central messaging switchboard. To utilize it, we need to connect the MQTT topics into the switchboard and connect the output to the InfluxDB database for storage. The main changes suggested from the default configuration are:\n\nRemove the logging of server stats from the pool of inputs.\nAdd the MQTT input plugin to the configuration file.\nAdd the InfluxDB output plugin to the configuration file.\n\nA simplified header is shown below:\n# Default Header\n[global_tags]\n\n# Configuration for telegraf agent\n[agent]\n  ## Default data collection interval for all inputs\n  interval = \"10s\"\n  round_interval = true\n  metric_batch_size = 1000\n  metric_buffer_limit = 10000\n  collection_jitter = \"0s\"\n  flush_interval = \"10s\"\n  flush_jitter = \"0s\"\n  precision = \"\"\n\n  ## Override default hostname, if empty use os.Hostname()\n  hostname = \"\"\n  ## If set to true, do no set the \"host\" tag in the telegraf agent.\n  omit_hostname = true\n\n\n\n\n\nNow, add InfluxDB as an output plugin and MQTT as an input plugin. The MQTT plugin listens to messages on particular topics, and the InfluxDB plugin writes the data to the database. The configuration for the InfluxDB output plugin is shown below.\nNote the token above can be generated through the InfluxDB web interface.\n\n\n[[outputs.influxdb_v2]]\n  # localhost assumes telegraf and influxdb are on the same server\n  urls = [\"http://localhost:8086\"]\n  token = \"api token from InfluxDB\"\n  organization = \"Capstone\"\n  bucket = \"telegraf\"\n\n[[outputs.prometheus_client]]\n    listen = \":9273\"\n    metric_version = 2\nFinally the incoming messages from MQTT are processed. A very important consideration here is to fully automate the process of message conversion from JSON to adopt a robot-driven database. The core principle is that changes in the robot software and telemetry should not change either this configuration file or the database schema. In our case, all messages that are to be databased start with robot/ and the topic indicates the data category. For example robot/imu1 is the MQTT topic that recieves information on the imu sensor\n{ax: 0.1, ay: 0.2, az: 0.3, gx: 0.4, gy: 0.5, gz: 0.6}\nTelegraph identifies that this is to be databased, removes the robot/ prepend, records the json message _measurement as imu1 and the _field as ax, ay, az, gx, gy, gz.\n[[processors.starlark]]\n  source = '''\ndef apply(metric):\n    # Get the topic tag value (e.g., \"robot/motor\")\n    topic = metric.tags.get(\"topic\")\n    \n    # Extract the part after \"robot/\"\n    if topic.startswith(\"robot/\"):\n        measurement = topic.split(\"robot/\", 1)[1]\n        # Set the new measurement based on the tail of the topic\n        metric.name = measurement\n    \n    return metric\n'''\n\n# MQTT Consumer Input Plugin\n[[inputs.mqtt_consumer]]\n  servers = [\"tcp://localhost:1883\"]\n\n  topics = [\n    \"robot/#\"  # Subscribe to all subtopics under robot/\n  ]\n  qos = 0\n  client_id = \"telegraf_mqtt_consumer\"\n  data_format = \"json\"\n  ## Use a part of the topic or JSON structure as the measurement name.\n  json_name_key = \"measurement\"\nThis completes the configuration file. The other components that record server metrics can be removed to keep the database focused.\n\n\nTesting the Configuration with Data Explorer\nReturn to the MQTT Python script and send messages to a robot/ topic for testing. They should now be automatically processed into the database as described. Verify that the messages are passing through the MQTT broker, then confirm they are reaching the InfluxDB database using the Data Explorer.\n\nf successful, the Data Explorer will show that the bucket has new data. The measurement filter will display the topic passed to MQTT, the field will show the keys from the passed JSON, and the data will show the values. Note that InfluxDB automatically applies data operations such as aggregation to reduce the number of sample points. This can be managed using the window period on the right-hand side.\nInfluxDB has its own query language, which can be previewed by clicking the Script Editor button. This provides direct insight into how the data is processed when a query is sent and can be edited to fine-tune the settings or used as an API call from elsewhere (e.g., from a Python script to create plots).\nfrom(bucket: \"telegraf\")\n  |&gt; range(start: v.timeRangeStart, stop: v.timeRangeStop)\n  |&gt; filter(fn: (r) =&gt; r[\"_measurement\"] == \"sensors/imu\")\n  |&gt; filter(fn: (r) =&gt; r[\"_field\"] == \"accel_x\")\n  |&gt; aggregateWindow(every: 100ms, fn: mean, createEmpty: false)\n  |&gt; yield(name: \"mean\")\nThe accel_x is being aggregated into 100ms sample periods using the mean of all values in that window. This can be modified to get raw data or changed to a different aggregation function. The range values can also be set to relative times to get the last 10 minutes of data, for example.\nfrom(bucket: \"telegraf\")\n  |&gt; range(start: -10m)\n  |&gt; filter(fn: (r) =&gt; r[\"_measurement\"] == \"sensors/imu\")\n  |&gt; filter(fn: (r) =&gt; r[\"_field\"] == \"accel_x\")\nBuilding these queries through the script editor is a good way to get the correct string to use in a Python script to query the database.\n\n\nExample Python Query\nTo illustrate how this can be integrated into Python for data analysis, here is a simple example. This script queries the last one minute of data from the database and plots the acceleration data over time.\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom influxdb_client import InfluxDBClient\n\n# Server IP address with InfluxDB port\nurl = \"http://172.22.1.1:8086\"\ntoken = \"gGu-3t4Avltf6-yHamGXItRfOKBQIDLgWEfhdURE7wURQazK_yvIa8O9k0O-_doXX8Q0Acy82vVavb5AcM2Lhw==\"\norg = \"Capstone\"\nbucket = \"telegraf\"\n\nclient = InfluxDBClient(url=url, token=token, org=org)\n\n# Query for the last 10 minutes of data\nlast_mins = 1\nquery = f'''\nfrom(bucket: \"{bucket}\")\n  |&gt; range(start: -{last_mins}m)\n  |&gt; filter(fn: (r) =&gt; r[\"_measurement\"] == \"sensors/imu\")\n  |&gt; filter(fn: (r) =&gt; r[\"_field\"] == \"accel_x\")\n  |&gt; aggregateWindow(every: 1s, fn: mean, createEmpty: false)\n'''\n\n# Query the data\nquery_api = client.query_api()\ntables = query_api.query(org=org, query=query)\n\n# Extract values (accel_x) from query response\nvalues = [record.get_value() for table in tables for record in table.records]\n\n# Plot using Seaborn\nplt.figure(figsize=(5, 3))\nsns.lineplot(data=values, linewidth=2.5)\n\n# Customize plot\nplt.title('Acceleration Data (accel_x) Over Time', fontsize=16)\nplt.xlabel('Steps', fontsize=14)\nplt.ylabel('Acceleration (accel_x)', fontsize=14)\nplt.tight_layout()\n\n# Display the plot\nplt.show()\n\nThis concludes the setup of the MQTT, Telegraf, and InfluxDB services. The next step is to setup Grafana for live telemetry and database dashboards.\n\nAt this stage in the setup, the system architecture is as follows:\n\n\n\n\n\nflowchart TD\n  %% Customizing colors for subgraphs and nodes\n  style Robot fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Server fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px\n  style Clients fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n\n  Y[Robot]\n  Z[Server]\n\n  %% Define a class for black text\n  classDef blackText fill:none,color:#000,stroke:none;\n\n  subgraph Robot\n    E(Jetson)\n  end\n  \n  subgraph Server\n    E &lt;--&gt; F[MQTT Broker]\n    F --&gt;|Metrics| G[Telegraf]\n    G --&gt;|Write| H[InfluxDB]\n  end\n\n  %% Clients section coloring applied to individual floating nodes\n    K[Python Script] --&gt;|Commands| F\n    L[Laptop] --&gt;|SSH| E\n    L --&gt;|MQTT Explorer| F\n    L --&gt; K\n    H --&gt;|Data| M[Data Explorer and API]\n  \n  %% Styling for the floating client items\n  style K fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style L fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style M fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style Y fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Z fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Telemetry and Database Systems for Capstone Projects"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/telemetry/telemetry.html#grafana-live-telemetry",
    "href": "content/projects/RLUnicycle/telemetry/telemetry.html#grafana-live-telemetry",
    "title": "Telemetry and Database Systems for Capstone Projects",
    "section": "Grafana Live Telemetry",
    "text": "Grafana Live Telemetry\n\nGrafana is a powerful open-source platform for creating dashboards and visualizing time-series data. Grafana supports a wide range of data sources and can display both live and historical data. While it can refresh data from InfluxDB at a rate of every 5 seconds, this is too slow for live monitoring of a dynamic system. Instead, live telemetry is pulled directly from the MQTT broker.\nTo begin, download and install Grafana on the server. The default port for Grafana is 3000. Once installed, open up a web browser and navigate to http://localhost:3000/ to access the Grafana dashboard. The default login is admin with the password admin.\n\nAdding Data Sources\nGrafana needs to be configured with data sources:\n\nInfluxDB Data Source:\n\nThe InfluxDB data source is included by default as a plugin.\nSpecify the correct query language and provide the necessary credentials and address (http://localhost:8086).\n\nMQTT Data Source:\n\nTo view MQTT data in real time, install a plugin to connect Grafana to the Mosquitto broker: MQTT Datasource Plugin.\nIn Grafana, navigate to Configuration &gt; Data Sources &gt; Add data source.\nSelect MQTT from the list of available data sources.\nName the data source and specify the connection to the MQTT broker (tcp://localhost:1883).\nAdd a username and password if configured for the broker.\n\n\n\n\nCreating Dashboards and Panels\nNow it is time to setup a dashboard, a collection of data panels. The Grafana interface is user friendly, but we are interested in some key settings.\n\nThe window of time that is being displayed in the dashboard.\nThe MQTT topics that are being fetched for display.\nThe keys from the JSON that are being displayed.\n\nFor this stage, it is recommended to either have a robot sensor streaming data, or a surrogate Python script sending out data to the MQTT broker so that there are live streaming messages to display.\n\n\n\n\n\nStep 1: Create a New Dashboard\n\nLog into the Grafana homepage from any device connected to the private network using the server IP: http://172.22.1.1:3000/.\nNavigate to Dashboards and select New Dashboard.\nSave the new dashboard. Remember to save periodically to avoid losing changes.\nAdjust the time range of the dashboard to the last 30 seconds to see recent data streaming in. Apply the time range.\n\n\n\n\n\n\n\n\nStep 2: Add a Visualization Panel\n\nSelect the Add a visualization button to make the first panel.\nEnter the MQTT topic and verify that data is streaming using MQTT Explorer.\nThe data should begin streaming in the panel preview.\nUse the Query Inspector and Data tab to verify that data is being received and processed correctly if the visualization is not showing as expected.\n\n\n\n\nStep 3: Customize the Panel\n Select the Transform Data tab and then Filter fields by name option. Fields that are to be omitted can be removed from the identifier list and will not be displayed in the panel. Finally the right hand side of the panel configuration can be used to fully customize the display of data, panel title, etc.\nSave and apply the panel change. Now is a good time to bookmark the dashboard for easy access in the future. The live telemetry has limitations in how much data can be displayed at once, since it is sampling from a moving buffer and not storing the data like the database. Too many panels with too much data will cause the system to stutter, so the recommendation is to downsample the data to about 10Hz or less unless full sample resolution is needed.\n\n\n\nNotes on Downsampling\nAs of now, an effective way to downsample the incoming data in Grafana has not been found. Telegraf has some data processing capabilities for downsampling, but it would require rebroadcasting over a new MQTT topic. The simplest solution we have found is to downsample data on the robot side by sending full-resolution data to each of the robot/ topics and every \\(n\\) th message to a downsampled/ topic. This can be implemented with few lines of code and does not add significant overhead.\n\nAt this stage in the setup, the system architecture is as follows:\n\n\n\n\n\nflowchart TD\n  %% Customizing colors for subgraphs and nodes\n  style Robot fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Server fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px\n  style Clients fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n\n  Y[Robot]\n  Z[Server]\n\n  %% Define a class for black text\n  classDef blackText fill:none,color:#000,stroke:none;\n\n  subgraph Robot\n    E(Jetson)\n  end\n  \n  subgraph Server\n    E &lt;--&gt; F[MQTT Broker]\n    F --&gt;|Metrics| G[Telegraf]\n    G --&gt;|Write| H[InfluxDB]\n    F --&gt;|Visualization| I[Grafana]\n  end\n\n  %% Clients section coloring applied to individual floating nodes\n    I --&gt;|Live Telemetry| J[Dashboard]\n    H --&gt;|Data| M[Data Explorer and API]\n\n  \n  %% Styling for the floating client items\n  style J fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style M fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style Y fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Z fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Telemetry and Database Systems for Capstone Projects"
    ]
  }
]
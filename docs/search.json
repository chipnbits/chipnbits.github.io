[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Simon Ghyselincks Personal Website",
    "section": "",
    "text": "Welcome to my personal site! I’m Simon Ghyselincks, currently a 5th-year Engineering Physics student at the University of British Columbia (UBC), with a minor in Computer Science. I am studying a cross-disciplinary blend of engineering, computer science, and applied mathematics. What I really love is coding to solve tough problems in robotics, machine learning, signal processing, and more."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Simon Ghyselincks Personal Website",
    "section": "",
    "text": "Welcome to my personal site! I’m Simon Ghyselincks, currently a 5th-year Engineering Physics student at the University of British Columbia (UBC), with a minor in Computer Science. I am studying a cross-disciplinary blend of engineering, computer science, and applied mathematics. What I really love is coding to solve tough problems in robotics, machine learning, signal processing, and more."
  },
  {
    "objectID": "index.html#academics-and-projects",
    "href": "index.html#academics-and-projects",
    "title": "Simon Ghyselincks Personal Website",
    "section": "Academics and Projects",
    "text": "Academics and Projects\nI am currently working with Eldad Haber at UBC Earth and Ocean Sciences on generative AI for geophysical applications. Our work explores the application of recent advances in normalizing flows with stochastic interpolants to generate 3d models of the earth’s crust. I am also continuing to develop our Engineering Physics capstone project “Learning to Balance” which explores the application of reinforcement learning to a reaction wheel robot with complex dynamics. Read more about my projects here.\n\nFeel free to connect with me on LinkedIn or check out my GitHub."
  },
  {
    "objectID": "index.html#my-journey",
    "href": "index.html#my-journey",
    "title": "Simon Ghyselincks Personal Website",
    "section": "My Journey",
    "text": "My Journey\nRead more about my journey and past pursuits here."
  },
  {
    "objectID": "content/projects/RLUnicycle/rtkernel/rtpatch.html",
    "href": "content/projects/RLUnicycle/rtkernel/rtpatch.html",
    "title": "RT Kernel on Jetson Nano",
    "section": "",
    "text": "The following guide is intended to provide step-by-step instructions on how to compile a real-time (RT) Linux kernel for the NVIDIA Jetson Nano. The RT kernel is based on the PREEMPT_RT patch, which adds real-time capabilities to the Linux kernel by making it fully preemptible and reducing the latency of the kernel’s interrupt handling.\nThis guide has been modified from some valuable instructions found at: https://forums.developer.nvidia.com/t/applying-a-preempt-rt-patch-to-jetpack-4-5-on-jetson-nano/168428/4\n\n\nFirst download the BSP from the NVIDIA website. The BSP contains the kernel source code, device tree files, and other necessary files for building the kernel. The BSP also contains the sample root filesystem, which is used to create the final image for the Jetson Nano. You may wish to look up the most recent version of the Tegra for Linux, in this case we are using R32.7.4.\nYou can download all of these files onto a Linux machine specifically running Ubuntu 18.04. Another option that has been tested is compiling on the Jetson Nano itself which is running the correct version of Linux by default. For our project we installed 18.04 on a laptop and compiled the kernel there.\n\n\n\n\n\n\nNote\n\n\n\nSource Files:\nhttps://developer.nvidia.com/embedded/linux-tegra-r3274\n\n\nDownload:\n\nDriver Package (BSP)\nSample Root File System\nDriver Package (BSP) Sources\nGCC Tool Chain can also be obtained via the command line:\nwget http://releases.linaro.org/components/toolchain/binaries/7.3-2018.05/aarch64-linux-gnu/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz\n\nPile all the files into a single directory and install packages\nsudo apt-get update \nsudo apt-get install libncurses5-dev \nsudo apt-get install build-essential \nsudo apt-get install bc \nsudo apt-get install lbzip2 \nsudo apt-get install qemu-user-static \nsudo apt-get install python\n\nmkdir $HOME/jetson_nano \ncd $HOME/jetson_nano\nExtract all of the files\nsudo tar xpf jetson-210_linux_r32.7.4_aarch64.tbz2\ncd Linux_for_Tegra/rootfs/ \nsudo tar xpf ../../tegra_linux_sample-root-filesystem_r32.7.4_aarch64.tbz2\ncd ../../ \ntar -xvf gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz \nsudo tar -xjf public_sources.tbz2 \ntar -xjf Linux_for_Tegra/source/public/kernel_src.tbz2\n\n\n\nGo into extracted kernel source and apply RT patch\ncd kernel/kernel-4.9/\n./scripts/rt-patch.sh apply-patches\nConfigure and compile:\nTEGRA_KERNEL_OUT=jetson_nano_kernel \nmkdir $TEGRA_KERNEL_OUT \nexport CROSS_COMPILE=$HOME/jetson_nano/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu/bin/aarch64-linux-gnu- \nmake ARCH=arm64 O=$TEGRA_KERNEL_OUT tegra_defconfig \nmake ARCH=arm64 O=$TEGRA_KERNEL_OUT menuconfig\nThe menu config opens an old school BIOS menu. Set the proper settings for the RT kernel:\n\nGeneral setup → Timer subsystem → Timer tick handling → Full dynticks system (tickless)\nKernel Features → Preemption Model: Fully Preemptible Kernel (RT)\nKernel Features → Timer frequency: 1000 HZ\n\nAt this point you can go tamper with device tree files (.dtsi) or other things, next step is the compile stage!\n\n\nI tried to modify\ntegra210-porg-gpio-p3448-0000-b00.dtsi \nthe source file, found using a find file function in terminal. It did not fix things. In general the P3450 model requires the p3448-0000-3449-b00 series of files. This was confirmed by looking at all the source configs and scripts.\n\n\n\nmake ARCH=arm64 O=$TEGRA_KERNEL_OUT -j4\n\nsudo cp jetson_nano_kernel/arch/arm64/boot/Image $HOME/jetson_nano/Linux_for_Tegra/kernel/Image\nsudo cp -r jetson_nano_kernel/arch/arm64/boot/dts/* $HOME/jetson_nano/Linux_for_Tegra/kernel/dtb/\nsudo make ARCH=arm64 O=$TEGRA_KERNEL_OUT modules_install INSTALL_MOD_PATH=$HOME/jetson_nano/Linux_for_Tegra/rootfs/\n\ncd $HOME/jetson_nano/Linux_for_Tegra/rootfs/\nsudo tar --owner root --group root -cjf kernel_supplements.tbz2 lib/modules\nsudo mv kernel_supplements.tbz2  ../kernel/\n\ncd ..\nsudo ./apply_binaries.sh\nThe image creator requires the device model. For the 4GB Jetson nano it is -r 300. This will select the correct dtb:\ncd tools\nsudo ./jetson-disk-image-creator.sh -o jetson_nano.img -b jetson-nano -r 300\nIt is crucial to select the correct device tree since it will not boot otherwise. If you are unsure of which to select, follow through the source cocde in the jetson-disk-image-creator.sh to find what the different flags do. Or try the NVIDIA forums but good luck over there!\nUse Balena etcher to put image in $HOME/jetson_nano/Linux_for_Tegra/tools/jetson_nano.img onto the SD card",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "RT Kernel on Jetson Nano"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/rtkernel/rtpatch.html#download-source-files-and-install-packages",
    "href": "content/projects/RLUnicycle/rtkernel/rtpatch.html#download-source-files-and-install-packages",
    "title": "RT Kernel on Jetson Nano",
    "section": "",
    "text": "First download the BSP from the NVIDIA website. The BSP contains the kernel source code, device tree files, and other necessary files for building the kernel. The BSP also contains the sample root filesystem, which is used to create the final image for the Jetson Nano. You may wish to look up the most recent version of the Tegra for Linux, in this case we are using R32.7.4.\nYou can download all of these files onto a Linux machine specifically running Ubuntu 18.04. Another option that has been tested is compiling on the Jetson Nano itself which is running the correct version of Linux by default. For our project we installed 18.04 on a laptop and compiled the kernel there.\n\n\n\n\n\n\nNote\n\n\n\nSource Files:\nhttps://developer.nvidia.com/embedded/linux-tegra-r3274\n\n\nDownload:\n\nDriver Package (BSP)\nSample Root File System\nDriver Package (BSP) Sources\nGCC Tool Chain can also be obtained via the command line:\nwget http://releases.linaro.org/components/toolchain/binaries/7.3-2018.05/aarch64-linux-gnu/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz\n\nPile all the files into a single directory and install packages\nsudo apt-get update \nsudo apt-get install libncurses5-dev \nsudo apt-get install build-essential \nsudo apt-get install bc \nsudo apt-get install lbzip2 \nsudo apt-get install qemu-user-static \nsudo apt-get install python\n\nmkdir $HOME/jetson_nano \ncd $HOME/jetson_nano\nExtract all of the files\nsudo tar xpf jetson-210_linux_r32.7.4_aarch64.tbz2\ncd Linux_for_Tegra/rootfs/ \nsudo tar xpf ../../tegra_linux_sample-root-filesystem_r32.7.4_aarch64.tbz2\ncd ../../ \ntar -xvf gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz \nsudo tar -xjf public_sources.tbz2 \ntar -xjf Linux_for_Tegra/source/public/kernel_src.tbz2",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "RT Kernel on Jetson Nano"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/rtkernel/rtpatch.html#apply-rt-patch",
    "href": "content/projects/RLUnicycle/rtkernel/rtpatch.html#apply-rt-patch",
    "title": "RT Kernel on Jetson Nano",
    "section": "",
    "text": "Go into extracted kernel source and apply RT patch\ncd kernel/kernel-4.9/\n./scripts/rt-patch.sh apply-patches\nConfigure and compile:\nTEGRA_KERNEL_OUT=jetson_nano_kernel \nmkdir $TEGRA_KERNEL_OUT \nexport CROSS_COMPILE=$HOME/jetson_nano/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu/bin/aarch64-linux-gnu- \nmake ARCH=arm64 O=$TEGRA_KERNEL_OUT tegra_defconfig \nmake ARCH=arm64 O=$TEGRA_KERNEL_OUT menuconfig\nThe menu config opens an old school BIOS menu. Set the proper settings for the RT kernel:\n\nGeneral setup → Timer subsystem → Timer tick handling → Full dynticks system (tickless)\nKernel Features → Preemption Model: Fully Preemptible Kernel (RT)\nKernel Features → Timer frequency: 1000 HZ\n\nAt this point you can go tamper with device tree files (.dtsi) or other things, next step is the compile stage!\n\n\nI tried to modify\ntegra210-porg-gpio-p3448-0000-b00.dtsi \nthe source file, found using a find file function in terminal. It did not fix things. In general the P3450 model requires the p3448-0000-3449-b00 series of files. This was confirmed by looking at all the source configs and scripts.\n\n\n\nmake ARCH=arm64 O=$TEGRA_KERNEL_OUT -j4\n\nsudo cp jetson_nano_kernel/arch/arm64/boot/Image $HOME/jetson_nano/Linux_for_Tegra/kernel/Image\nsudo cp -r jetson_nano_kernel/arch/arm64/boot/dts/* $HOME/jetson_nano/Linux_for_Tegra/kernel/dtb/\nsudo make ARCH=arm64 O=$TEGRA_KERNEL_OUT modules_install INSTALL_MOD_PATH=$HOME/jetson_nano/Linux_for_Tegra/rootfs/\n\ncd $HOME/jetson_nano/Linux_for_Tegra/rootfs/\nsudo tar --owner root --group root -cjf kernel_supplements.tbz2 lib/modules\nsudo mv kernel_supplements.tbz2  ../kernel/\n\ncd ..\nsudo ./apply_binaries.sh\nThe image creator requires the device model. For the 4GB Jetson nano it is -r 300. This will select the correct dtb:\ncd tools\nsudo ./jetson-disk-image-creator.sh -o jetson_nano.img -b jetson-nano -r 300\nIt is crucial to select the correct device tree since it will not boot otherwise. If you are unsure of which to select, follow through the source cocde in the jetson-disk-image-creator.sh to find what the different flags do. Or try the NVIDIA forums but good luck over there!\nUse Balena etcher to put image in $HOME/jetson_nano/Linux_for_Tegra/tools/jetson_nano.img onto the SD card",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "RT Kernel on Jetson Nano"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/rtkernel/rtpatch.html#setting-python-scheduling-privileges",
    "href": "content/projects/RLUnicycle/rtkernel/rtpatch.html#setting-python-scheduling-privileges",
    "title": "RT Kernel on Jetson Nano",
    "section": "2.1 Setting Python Scheduling Privileges",
    "text": "2.1 Setting Python Scheduling Privileges\nNote that for this description our team is using Python 3.8 in a virtual environment, the instructions path files may change slightly if using a different version.\nThe scheduling priority is a top-level system command and is usually locked behind ‘sudo’. This is problematic when running a Python script because we don’t want to run it as sudo allowing it full access to wreak havoc on the OS. The solution is to grant only the scheduling part of ‘sudo’ to the Python interpreter:\nThis command only needs to be set once after Python 3.8 is installed (the same in use in our venv): sudo setcap 'cap_sys_nice=eip' /usr/bin/python3.8\n\nsetcap: This is a utility that sets or changes the capabilities of a file/executable. Capabilities are a Linux feature that allow for more fine-grained access control; they provide a way to grant specific privileges to executables that normally only the root user would have.\n'cap_sys_nice=eip': This argument specifies the capabilities to be set on the file, in this case, /usr/bin/python3.8. It’s composed of three parts:\n\ncap_sys_nice: This is the specific capability being set. cap_sys_nice allows the program to raise process nice values (which can deprioritize processes) and change real-time scheduling priorities and policies, without requiring full root privileges.\ne: This stands for “effective” and means the capability is “activated” and can be used by the executable.\ni: This stands for “inheritable”, meaning this capability can be inherited by child processes created by the executable.\np: This stands for “permitted”, which means the capability is allowed for the executable. It’s a part of the set of capabilities that the executable is permitted to use.\n\n/usr/bin/python3.8: This is the path to the Python 3.8 executable. The command sets the specified capabilities on this specific file.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "RT Kernel on Jetson Nano"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/rtkernel/rtpatch.html#setting-script-specific-rt",
    "href": "content/projects/RLUnicycle/rtkernel/rtpatch.html#setting-script-specific-rt",
    "title": "RT Kernel on Jetson Nano",
    "section": "2.2 Setting Script Specific RT",
    "text": "2.2 Setting Script Specific RT\nThe ‘RT’ scheduling priority is code 99. Some imported C implementation allows for resetting the scheduling for the process. The function is wrapped in try/except block to ensure it activates.\n# Define constants for the scheduling policy\nSCHED_FIFO = 1  # FIFO real-time policy\n\nclass SchedParam(ctypes.Structure):\n    _fields_ = [('sched_priority', ctypes.c_int)]\n\ndef set_realtime_priority(priority=99):\n    libc = ctypes.CDLL('libc.so.6')\n    param = SchedParam(priority)\n    # Set the scheduling policy to FIFO and priority for the entire process (0 refers to the current process)\n    if libc.sched_setscheduler(0, SCHED_FIFO, ctypes.byref(param)) != 0:\n        raise ValueError(\"Failed to set real-time priority. Check permissions.\") \nWe run this function at the start of the script which will reassign the scheduling priority to the highest level. This can be verified to work by opening the system monitor and checking the priority of the script such as with htop.\n\n\n\nRT Priority Enabled",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "RT Kernel on Jetson Nano"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html",
    "title": "Dynamics and Control",
    "section": "",
    "text": "The following is a demonstration of the derivation for the equations of motion for a single degree of freedom reaction wheel inverted pendulum. The approach used is energy methods via the Lagrangian using classical mechanics.\nAn automated derivation sequence using MATLAB is presented, which allows for parsing the equations of motion for an arbitrary system such as a 4-DOF unicycle robot. The code for the auto-derivation has been tested by hand against known solutions in the literature, as explored by (Brevik 2017), (Montoya and Gil-González 2020).",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#mass-and-center-of-mass-measurements",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#mass-and-center-of-mass-measurements",
    "title": "Dynamics and Control",
    "section": "Mass and Center of Mass Measurements",
    "text": "Mass and Center of Mass Measurements\nThe mass and center of mass (CM) were measured using a lab scale and a balancing method, respectively.\n\nFlywheel: The wheel and rings mass (denoted as \\(m_w\\)) was measured to be 346g. The CM of the wheel from the pendulum hinge (denoted as \\(l_w\\)) is 180mm. This was measured in CAD and also with a ruler.\nPendulum and Motor: The combined mass of the pendulum and motor with stator (denoted as \\(m_p\\)) was measured to be 531g. The CM of the pendulum with motor and stator (denoted as \\(l_p\\)) is 100mm. The pendulum CM is found by balancing the apparatus with removed flywheel overtop of a fulcrum and finding the stable resting point position.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#inertia-calculations",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#inertia-calculations",
    "title": "Dynamics and Control",
    "section": "Inertia Calculations",
    "text": "Inertia Calculations\nThe moment of inertia for each component was calculated using the parallel axis theorem and the physical dimensions provided by CAD models and direct measurement.\n\nWheel Inertia\nThe wheel inertia (denoted as \\(I_w\\)) was found by comparing the CAD weight to the measured weight of the flywheel to find agreement: \\[I_w = 725\\ \\text{kg}\\cdot\\text{mm}^2\\] In particular the metal rings were weighed and set to be the same weight in CAD which is the most influential part of the moment in question.\n\n\nPendulum Inertia\nThe pendulum moment of inertia (denoted as \\(I_p\\)) is a composite value derived from the inertia of individual components:\n\nBattery: The battery contributes an inertia of: \\[I_{\\text{battery}} = \\frac{1}{12} \\cdot 0.185 \\cdot (70^2 + 35^2) + 0.185 \\cdot 50^2 = 446\\ \\text{kg}\\cdot\\text{mm}^2\\]\nPendulum Arm: The corrected inertia for the pendulum arm is: \\[I_{\\text{arm}} = 346\\ \\text{kg}\\cdot\\text{mm}^2 + 0.102 \\cdot 45^2 = 552\\ \\text{kg}\\cdot\\text{mm}^2\\]\nMotor and Mount: The combined inertia for the motor and mount is: \\[I_{\\text{motor}} = 0.5 \\cdot 0.206 \\cdot 30^2 + 0.206 \\cdot 75^2 = 1251.75\\ \\text{kg}\\cdot\\text{mm}^2\\]\n\nThe total pendulum inertia is then calculated as the sum of the components: \\[I_p = I_{\\text{battery}} + I_{\\text{arm}} + I_{\\text{motor}} = 2250\\ \\text{kg}\\cdot\\text{mm}^2\\]",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#kinetic-energy",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#kinetic-energy",
    "title": "Dynamics and Control",
    "section": "Kinetic Energy",
    "text": "Kinetic Energy\n\\[\\begin{aligned}\nT &= T_p+T_w \\\\\nT_p &= \\frac{1}{2}(\\underbrace{I_p + m_pl_p^2}_{\\text{Parallel Axis Theorem}})\\dot{\\varphi}^2\\\\\nT_w&=\\frac{1}{2}m_w(\\underbrace{l_w\\dot{\\varphi}}_{\\text{Speed of CM}})^2 +  \\frac{1}{2}I_w(\\underbrace{\\dot{\\varphi}+\\dot{\\theta}}_{\\text{net rotation earth frame}})^2\\\\\nT_{net} &= \\frac{1}{2} \\left(I_p + m_p l_p^2 + I_w + m_w l_w^2\\right) \\dot{\\varphi}^2 + \\frac{1}{2} I_w (\\dot{\\varphi} + \\dot{\\theta})^2 \\\\\n&= \\frac{1}{2} \\left(I_p + m_p l_p^2\\right) \\dot{\\varphi}^2 + \\frac{1}{2} I_w \\left(\\dot{\\varphi}^2 + 2\\dot{\\varphi}\\dot{\\theta} + \\dot{\\theta}^2\\right)\\\\\nT_{net}&=\\frac{1}{2} [\\dot{\\varphi}, \\dot{\\theta}] \\begin{bmatrix}\n    I_p + m_pl_p^2 + I_w + m_wl_w^2 & I_w \\\\\n    I_w & I_w\n\\end{bmatrix} \\begin{bmatrix}\n    \\dot{\\varphi} \\\\\n\\dot{\\theta}\n\\end{bmatrix}\n\\end{aligned}\\]\nThis gives the form using the inertia matrix M, note the matrix is always symmetric.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#potential-energy",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#potential-energy",
    "title": "Dynamics and Control",
    "section": "Potential Energy",
    "text": "Potential Energy\nThe potential energy is taken by projecting the position of the center of masses onto the vertical axis using \\(\\cos(\\varphi)\\), noting that the angle \\(\\theta\\) has no impact on the potential since the wheel is radially symmetric. \\[U = (m_pl_p + m_wl_w)g \\cos (\\varphi) = m_0 \\cos (\\varphi)\\] We can simplify future equations by assigning an equivalent variable \\(m_0 = (m_p l_p + m_w l_w)g\\)\nThis gives the complete Lagrangian \\[\\mathcal{L}(\\varphi,\\theta,\\dot \\varphi,\\dot \\theta)= KE - PE = \\frac{1}{2}\\mathbf{\\dot q}^{T}\\mathbf{M}\\mathbf{\\dot q}-m_0cos(\\varphi)\\]",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#matlab-derivation",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#matlab-derivation",
    "title": "Dynamics and Control",
    "section": "Matlab Derivation",
    "text": "Matlab Derivation\nThe required files to run this code are included at https://github.com/Team-2411-RL-Unicycle/pid-control The automated E-L solver uses a modified version of a file made by (Veng 2023). It is incorporated into the RWIPpid_derivation.m file. The derivation technique is validated against the equations derived by (Brevik 2017).\nThe first step is to define symbolic variables for all of the parameters, states, and inputs\nsyms mp lp Ip mw lw Iw real\nparams = [mp, lp, Ip, mw, lw, Iw];\n% Define numerical values for the parameters\nvalues = [.531, 0.100, 0.002250, .346, 0.180, 0.000725];\ng=9.81;\n% State variables\nsyms phi theta dphi dtheta real\nq = [phi, theta];\ndq = [dphi, dtheta];\n% Input\nsyms tau real\n\n% Potential energy mass\nm0 = (mp*lp + mw*lw)*g; % Effective U=mgh for combined parts\n% Mass matrix\nM = [(Ip + mp*lp^2 + Iw +mw*lw^2), Iw;\n    Iw, Iw];\nlagrangian = (1/2)*([dphi, dtheta])*M*([dphi, dtheta]') - m0 * cos(phi);\n% Non-conservative forces in each coordinate q\nQ = [0, tau];\nThe Lagrangian and its non-conservative forces are fully defined now. The equations are solved using the modified imported library and the solution equations for each second time derivative is solved giving \\(\\frac{d}{dt}\\dot{q}\\), these solutions can be packed into a single array to form a matrix.\n[eqs, ddq] = EulerLagrange(q,dq,lagrangian,Q);\n% Explicit equations:\nexp_eqs = ddq == eqs;\n% Solve equations to isolate ddphi and ddtheta\nddqSolutions = solve(ddq == eqs, ddq);\n% Convert solutions to cell array\nddqSolutionEquations = struct2cell(ddqSolutions) ;\nddqArray = [ddqSolutionEquations{:}].';",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#derived-equations-of-motion",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#derived-equations-of-motion",
    "title": "Dynamics and Control",
    "section": "Derived Equations of Motion",
    "text": "Derived Equations of Motion\nOnce we have \\(n\\) 2nd order ODEs for \\(n\\) general coordinates and their \\(n\\) general time derivatives we have enough to make a first order system of ODEs that characterize the system. The time-domain non-linearized result from the derivation is given below.\n\\[\\frac{d}{dt}\\vec{x} = \\vec{G}(\\vec{x}, t) = \\begin{bmatrix}\nd\\varphi \\\\\nd\\theta \\\\\n\\frac{g_0 l_p m_p \\sin(\\phi) - \\tau + g_0 l_w m_w \\sin(\\phi)}{m_p l_p^2 + m_w l_w^2 + I_p} \\\\\n\\frac{m_p \\tau l_p^2 - I_w g_0 m_p \\sin(\\phi) l_p + m_w \\tau l_w^2 - I_w g_0 m_w \\sin(\\phi) l_w + I_p \\tau + I_w \\tau}{I_w (m_p l_p^2 + m_w l_w^2 + I_p)}\n\\end{bmatrix}, \\quad x = \\begin{bmatrix}\n\\varphi \\\\ \\theta \\\\ \\dot{\\varphi} \\\\ \\dot{\\theta}\n\\end{bmatrix}\\]\nNote that there is no explicit time dependence in the function \\(G\\) the inverted pendulum dynamics and rigid body characteristics are constant over time. From inspection of the solutions we see that \\(\\theta\\), the angle of the wheel does not play a role in the function \\(G\\) and can be removed entirely if desired.\nThese system dynamics can be used to create a time-domain non-linear simulation using Euler’s method to get numerical solutions. Friction can be added as a damping coefficient \\(\\beta\\) such that we superimpose \\(\\ddot{\\varphi} = - \\beta \\dot{\\varphi}\\) onto the solution for example.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#linearization",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#linearization",
    "title": "Dynamics and Control",
    "section": "Linearization",
    "text": "Linearization\nWe wish to convert \\[\\vec{G}(\\vec{x}, t) \\approx Ax + Bu\\] via linearization about the operating point. We choose the upright position as the target and note that \\(\\varphi\\) is the only variable present in \\(G\\). \\(\\hat{\\vec{x}}=0\\) is the chosen linearization point:\n\\[\\frac{d}{dt}\\vec{x} \\approx \\hat{\\vec{x}} + \\left. \\text{Jacobian}\\{\\vec{G}(\\vec{x}, t)\\} \\right|_{\\vec{x}=\\hat{\\vec{x}}} (\\vec{x}-\\hat{\\vec{x}}) = \\left. \\Big(A\\Big) \\right|_{\\vec{x}=\\hat{\\vec{x}}} \\vec{x}\\]\nWe perform a similar linearization to get the effect of the system inputs by taking the Jacobian with respect to \\(\\tau\\). The two combined give the cannonical \\(\\frac{d}{dt}x = Ax + Bu\\) of controls engineering. The final step is to take the Laplace transform of the entire equation and then solve for the transfer function between the system inputs \\(u\\) or in this case \\(\\tau\\) and the observables we want (mainly the system state \\(x\\)) but this generalizes to any observable that is a function of \\(x\\) and \\(u\\)\nState Vector \\[{\\mathbf{x}} =\n\\begin{bmatrix}\n    x_1 \\\\\n    x_2 \\\\\n    \\vdots\n\\end{bmatrix}\\] Input Vector \\[{\\mathbf{u}} =\n\\begin{bmatrix}\n    u_1 \\\\\n    u_2 \\\\\n    \\vdots\n\\end{bmatrix}\\] Output Vector \\[{\\mathbf{y}} =\n\\begin{bmatrix}\n    y_1 \\\\\n    y_2 \\\\\n    \\vdots\n\\end{bmatrix}\\]\nState Equation \\[\\dot{\\mathbf{x}} =\n\\begin{bmatrix}\n    \\dot{x}_1 \\\\\n    \\dot{x}_2 \\\\\n    \\vdots\n\\end{bmatrix}\n= \\mathbf{A}{\\mathbf{x}} + \\mathbf{B}{\\mathbf{u}}\\] Output Equation \\[{\\mathbf{y}} = \\mathbf{C}{\\mathbf{x}} + \\mathbf{D}{\\mathbf{u}}\\]\nState Transition Matrix \\[\\mathbf{\\Phi} = (s\\mathbf{I} - \\mathbf{A})^{-1}\\] Transfer Functions \\[\\frac{{\\mathbf{y}}}{{\\mathbf{u}}} = \\mathbf{C}\\mathbf{\\Phi}\\mathbf{B} + \\mathbf{D}\\]\nWe solve for the transfer matrix \\(y = Gu\\) at \\(x=0\\), noting that in our case \\(y=x\\)",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#matlab-derivation-1",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#matlab-derivation-1",
    "title": "Dynamics and Control",
    "section": "MATLAB Derivation",
    "text": "MATLAB Derivation\n% Phi, dPhi, dTheta\nX = [q(1)' ; dq']\n% The inputs are non-zero entries of Q (non-conservative forces)\nU = Q(Q ~= 0);\n% Vector functionn for the derivative of the state vector\ndX = [dphi; ddqArray]\n\n% Compute the Jacobian matrices to get nonlinear state matrices dX = Ax + Bu\nA = jacobian(dX, X);\nB = jacobian(dX, U);\n\n% Substitute or linearize about an equilibrium point\n% Define equilibrium point (for example, all zeros)\nx0 = [0; 0; 0];\n% Substitute equilibrium values x0 into A and B\nAeq = subs(A, X, x0)\nBeq = subs(B, X, x0)\n\n% U to X transfer function\n% dX = Ax + Bu implies  sX = Ax + Bu, solve for x = Gtf*u\nsyms s\nGtf = (s*eye(length(X)) - Aeq)^(-1)*Beq",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#system-transfer-function",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#system-transfer-function",
    "title": "Dynamics and Control",
    "section": "System Transfer Function",
    "text": "System Transfer Function\n\\[\\begin{pmatrix}\n\\varphi(s)\\\\\n\\dot{\\varphi}(s)\\\\\n\\dot\\theta(s)\n\\end{pmatrix}=\n\\begin{pmatrix}\n-\\frac{1}{{m_p l_p^2 s^2 - g_0 m_p l_p + m_w l_w^2 s^2 - g_0 m_w l_w + I_p s^2}} \\\\\n-\\frac{s}{{m_p l_p^2 s^2 - g_0 m_p l_p + m_w l_w^2 s^2 - g_0 m_w l_w + I_p s^2}} \\\\\n\\frac{{m_p l_p^2 + m_w l_w^2 + I_p + I_w}}{{I_w s (m_p l_p^2 + m_w l_w^2 + I_p)}} + \\frac{{g_0 l_p m_p + g_0 l_w m_w}}{{s (m_p l_p^2 + m_w l_w^2 + I_p)(m_p l_p^2 s^2 - g_0 m_p l_p + m_w l_w^2 s^2 - g_0 m_w l_w + I_p s^2)}}\n\\end{pmatrix}\n\\tau(s)\\]\nWe note that for our control problem we are trying to control the angle \\(\\varphi\\) using torque, so the function of interest is the upper row equation:\n\\[\\varphi(s) = \\Big(-\\frac{1}{{m_p l_p^2 s^2 - g_0 m_p l_p + m_w l_w^2 s^2 - g_0 m_w l_w + I_p s^2}}\\Big) \\tau(s)\\]\nOr rearranging we see that we have function of the form \\(\\frac{1}{s^2+a^2}\\): \\[\\varphi(s) = \\left(-\\frac{1}{s^2(m_p l_p^2 + m_w l_w^2 + I_p) - m_0}\\right) \\tau(s)\\]\nThis is a function with one pole in the RH plane making it unstable.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#pd-controller-for-pendulum-angle",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#pd-controller-for-pendulum-angle",
    "title": "Dynamics and Control",
    "section": "PD Controller for Pendulum Angle",
    "text": "PD Controller for Pendulum Angle\nThe PD Controller for \\(\\varphi\\) is tuned using the assumption that the torque requests have little delay before reaching the intended value. This is because the motor controller is running at 100 times faster than the main control loop frequency of 100Hz. Thus we model the feedback loop of Controller -&gt; \\(G(s)\\) -&gt; \\(H(s)\\) Sensor Fusion. The sensor fusion and torque request mechanism are modeled as a delay of one \\(100Hz\\) control cycle.\nA PD controller is selected because of the dynamic setpoint that is being controlled by the cascade arrangement. If we were to include an I term then the controller would not be memoryless and would have undesirable response characteristics to the dynamic \\(\\varphi\\) setpoint being requested by the higher level controller. The PD control model is a robust choice for a controller for this robot state parameter, (Brevik 2017).\nThe MATLAB pid tuner is used to get feasible starting values based on this loop. The experimental parameters applied to the robot were found to closely match the predicted values.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/dynamics/dynamics.html#pi-controller-for-wheel-velocity",
    "href": "content/projects/RLUnicycle/dynamics/dynamics.html#pi-controller-for-wheel-velocity",
    "title": "Dynamics and Control",
    "section": "PI Controller for Wheel Velocity",
    "text": "PI Controller for Wheel Velocity\nThe PI controller is tuned heuristically once a good underlying PD controller for the angle is found. A starting value of around \\(K_p = 0.1\\) was found to be helpful. Blending of integral term with a corresponding reduction of \\(P\\) is one approach to further tuning.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Dynamics and Control"
    ]
  },
  {
    "objectID": "content/eosc555/lectures/lecture7/index.html",
    "href": "content/eosc555/lectures/lecture7/index.html",
    "title": "Lecture 7: Applying Homotopy to Optimize Highly Non-Convex Functions",
    "section": "",
    "text": "$$ \n$$"
  },
  {
    "objectID": "content/eosc555/lectures/lecture7/index.html#direct-search-methods",
    "href": "content/eosc555/lectures/lecture7/index.html#direct-search-methods",
    "title": "Lecture 7: Applying Homotopy to Optimize Highly Non-Convex Functions",
    "section": "Direct Search Methods",
    "text": "Direct Search Methods\nA direct search (Wikipedia 2024) can be performed to try to find the global minimum of a non-convex function (Lewis, Torczon, and Trosset 2000).\n\\[ x_{k+1} = x_k + \\alpha_k d_k, \\quad d_k \\in \\mathbb{R}^n.\\]\nIn this case the direction does not follow the gradient descent rule, there could be a stochastic element. The general algorithms that implement this will have the property that the step size decreases over time such that\n\\[ \\| \\alpha_k d_k \\| \\to 0, \\ k \\to \\infty\\]\nThe implementation ignores seeking information about the gradient or the Hessian of the function. Instead some points in the surrounding region are computed and the most optimal decrease for the next step is selected.\nThe method has been known since the 1950s but it fell out of favour due to the slow rate of convergence. However, with parallel computing advances it has become more feasible to use again. For a large set of direct search methods, it is possible to rigorously prove that they will converge to a local minimum (Kolda, Lewis, and Torczon 2003)."
  },
  {
    "objectID": "content/eosc555/lectures/lecture5/index.html",
    "href": "content/eosc555/lectures/lecture5/index.html",
    "title": "Lecture 5: Gauss Newton",
    "section": "",
    "text": "$$ \n$$"
  },
  {
    "objectID": "content/eosc555/lectures/lecture5/index.html#a-non-linear-dynamics-problem",
    "href": "content/eosc555/lectures/lecture5/index.html#a-non-linear-dynamics-problem",
    "title": "Lecture 5: Gauss Newton",
    "section": "A Non-Linear Dynamics Problem",
    "text": "A Non-Linear Dynamics Problem\nA well studied problem in non-linear dynamics involves the predator-prey model that is described by the Lotka-Volterra equations. The equations are given by:\n\\[\n\\begin{aligned}\n\\frac{dx}{dt} &= \\alpha x - \\beta xy \\\\\n\\frac{dy}{dt} &= \\delta xy - \\gamma y\n\\end{aligned}\n\\]\nwhere \\(x\\) and \\(y\\) are the populations of the prey and predator respectively. The parameters \\(\\alpha, \\beta, \\gamma, \\delta\\) are positive constants. The goal is to find the values of these parameters that best fit the data.\nThere is no closed form analytic solution that is known to this remarkably simple system of equations, which is why we must resort to numerical solutions to compute the model.\nMore information about the model can be found at the Wikipedia page.\n\nThe Forward Problem\nWe start with an initial time \\(t_0\\) and initial conditions \\(x_0, y_0\\), with parameters \\(\\alpha, \\beta, \\gamma, \\delta\\) to run a forward version of the problem using a variant of the forward Euler method, the RK4.\n\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\n\nclass LotkaVolterraModel(nn.Module):\n    def __init__(self, alpha, beta, gamma, delta):\n        super(LotkaVolterraModel, self).__init__()\n        # Define parameters as torch tensors that require gradients\n        self.alpha = nn.Parameter(torch.tensor(alpha, dtype=torch.float32))\n        self.beta = nn.Parameter(torch.tensor(beta, dtype=torch.float32))\n        self.gamma = nn.Parameter(torch.tensor(gamma, dtype=torch.float32))\n        self.delta = nn.Parameter(torch.tensor(delta, dtype=torch.float32))\n\n    def forward(self, x, y):\n        # Ensure x and y are tensors\n        if not isinstance(x, torch.Tensor):\n            x = torch.tensor(x, dtype=torch.float32)\n        if not isinstance(y, torch.Tensor):\n            y = torch.tensor(y, dtype=torch.float32)\n\n        # Compute dx and dy based on the current parameters\n        dx = self.alpha * x - self.beta * x * y\n        dy = self.delta * x * y - self.gamma * y\n\n        return dx, dy\n\nclass RK4Solver:\n    def __init__(self, model):\n        self.model = model\n\n    def step(self, x, y, dt):\n        \"\"\"\n        Perform a single RK4 step.\n        \"\"\"\n        # Convert x and y to tensors if they are not already\n        if not isinstance(x, torch.Tensor):\n            x = torch.tensor(x, dtype=torch.float32)\n        if not isinstance(y, torch.Tensor):\n            y = torch.tensor(y, dtype=torch.float32)\n\n        # RK4 Step calculations\n        k1_x, k1_y = self.model.forward(x, y)\n        k2_x, k2_y = self.model.forward(x + 0.5 * dt * k1_x, y + 0.5 * dt * k1_y)\n        k3_x, k3_y = self.model.forward(x + 0.5 * dt * k2_x, y + 0.5 * dt * k2_y)\n        k4_x, k4_y = self.model.forward(x + dt * k3_x, y + dt * k3_y)\n\n        # Update x and y using weighted averages of the slopes\n        x_new = x + (dt / 6) * (k1_x + 2 * k2_x + 2 * k3_x + k4_x)\n        y_new = y + (dt / 6) * (k1_y + 2 * k2_y + 2 * k3_y + k4_y)\n\n        return x_new, y_new\n\n    def solve(self, x0, y0, time_steps):\n        \"\"\"\n        Solve the system over a serie of time steps.\n        Parameters:\n            x0: Initial value of prey population\n            y0: Initial value of predator population\n            time_steps: List or numpy array of time steps to solve over\n        \"\"\"\n        x, y = x0, y0\n        DT = time_steps[1:] - time_steps[:-1]\n        trajectory = torch.zeros(len(time_steps), 2)\n        trajectory[0] = torch.tensor([x, y])\n\n        for i, dt in enumerate(DT):\n            x, y = self.step(x, y, dt)\n            trajectory[i+1] = torch.tensor([x, y])            \n\n        return trajectory\n\n# Define the model parameters\nalpha = 1.0\nbeta = .1\ngamma = 1.5\ndelta = 0.1\n\n# Create the model and solver\nmodel = LotkaVolterraModel(alpha, beta, gamma, delta)\nsolver = RK4Solver(model)\n\n# Define the initial conditions and time steps\nx0 = 5\ny0 = 1\ntime_steps = np.linspace(0, 20, 1000)\n\n# Solve the system\ntrajectory = solver.solve(x0, y0, time_steps)\n\nx_values = trajectory[:, 0].detach().numpy()\ny_values = trajectory[:, 1].detach().numpy()\n\nplt.plot(time_steps, x_values, label='Prey')\nplt.plot(time_steps, y_values, label='Predator')\nplt.xlabel('Time')\nplt.ylabel('Population')\nplt.legend()\nplt.savefig('imgs/lotka_volterra.png')\nplt.show()\n\n\n\n\n\nThe time evolution of the prey and predator populations.\n\n\n\n\nWe can additionally look at the phase space of the system for various initial conditions to see how the different solutions are periodic.\n\n\nShow the code\n# Define the initial conditions\nx0 = 5\ny0 = [.2,.5,1, 2, 3, 4, 5]\n\n# Create the model and solver\nmodel = LotkaVolterraModel(alpha, beta, gamma, delta)\nsolver = RK4Solver(model)\n\n# Define the time steps\ntime_steps = np.linspace(0, 10, 1000)\n\n# Plot the phase space\nplt.figure(figsize=(6, 4.5))\nfor y in y0:\n    trajectory = solver.solve(x0, y, time_steps)\n    x_values = trajectory[:, 0].detach().numpy()\n    y_values = trajectory[:, 1].detach().numpy()\n    plt.plot(x_values, y_values, label=f'y0={y}')\n\nplt.xlabel('Prey Population')\nplt.ylabel('Predator Population')\nplt.legend()\nplt.title('Lotka-Volterra Phase Space')\nplt.savefig('imgs/lotka_volterra_phase_space.png')\nplt.show()\n\n\n\n\n\nThe phase space of the predator-prey model."
  },
  {
    "objectID": "content/eosc555/lectures/lecture5/index.html#the-inverse-problem",
    "href": "content/eosc555/lectures/lecture5/index.html#the-inverse-problem",
    "title": "Lecture 5: Gauss Newton",
    "section": "The Inverse Problem",
    "text": "The Inverse Problem\nThe inverse problem in this case is to find the parameters \\(\\alpha, \\beta, \\gamma, \\delta\\) that best fit the data. We suppose that we have a model with parameters that takes in the initial conditions and time steps and returns the trajectory of the system. For simplicity we vectorize the previous \\(\\begin{bmatrix} x \\\\ y \\end{bmatrix}\\) into a single vector \\(\\vec{x}\\). The forward model is then a function \\(F(\\vec{x}; \\vec{p})\\) where \\(\\vec{p}\\) are the parameters and is an approximator of the true system, where\n\\[f(\\vec{x}; \\vec{p}) \\approx \\frac{d \\vec{x}}{dt} = \\begin{bmatrix} \\alpha x - \\beta xy \\\\ \\delta xy - \\gamma y \\end{bmatrix}, \\quad \\vec{x}_0 = \\vec{x}(0).\\]\nwhere \\(\\vec{x}\\) is the state of the system and \\(\\vec{p}\\) are the parameters.\nThe goal is to form an estimate of \\(\\vec{p}\\), while the data that we have collected may be sparse, noisy, or incomplete. We represent the incompleteness in the data using the \\(Q\\) sampling operator which is applied to the true underlying data to give \\(Qx\\). If \\(x\\) is fully given then \\(Q=I\\).\nA finite difference approximation of the derivative of the data can be used to approximate the derivative of the data,\n\\[f(\\vec{x}; \\vec{p}) \\cong \\frac{\\vec{x}_{n+1} - \\vec{x}_n}{\\Delta t}.\\]\nSo in this case the forward model is a time derivative, and the observed data is computed from an intial condition \\(\\vec{x}_0\\) and an ODE approximate solution such as Euler’s method or RK4. The output of the forward process is then given as \\(F\\), where \\[F(\\vec{p}, x_0) = \\hat {\\vec{x}}(t, \\vec{p}),\\]\nis the application of the system dynamics to the initial conditions and the parameter to create an estimated trajectory \\(\\hat{\\vec{x}}(t, \\vec{p})\\).\nThe observed data is \\(d = Q\\vec{x}(t)\\). We also make an assumption here that \\(F\\) does not depend on the particular solver that we are using for the forward ODE and that all of the \\(\\vec{p}\\) are physical parameters, we assume that the parameters are faithful enough.\nFor the rest of the mathematical notation ahead, the explicit marking of vectors is ommitted to simplify the equations.\n\nGoodness of Fit\nThe goodness of fit is measured by using the L2 norm of the difference between the observed data and the model output, thus forming the non-linear least squares problem:\n\\[ \\min_{p} \\frac{1}{2}\\|QF(p)-d\\|^2 = \\min_{p}\\|G(p)\\|^2.\\]\nTo find the best fit, the objective is to minimize the mean squared error (MSE) of a function of the parameters \\(p\\) and the data \\(d\\). The data is fixed for a given problem, so it is only by varying \\(p\\) that an optimal solution can be found. The entire MSE function is denoted as \\(G(p)\\)."
  },
  {
    "objectID": "content/eosc555/lectures/lecture5/index.html#minimization-of-the-objective-function",
    "href": "content/eosc555/lectures/lecture5/index.html#minimization-of-the-objective-function",
    "title": "Lecture 5: Gauss Newton",
    "section": "Minimization of the Objective Function",
    "text": "Minimization of the Objective Function\n\\[ \\min_{p \\in \\mathbb{R}^m} \\biggl\\{ \\sum_{i=1}^n (QF_i(\\mathbf{p}) - d_i) ^2\\biggr\\}\\]\nwhere \\(d_i\\) are the observed data points. This is the same as\n\\[ \\min_{p \\in \\mathbb{R}^m} \\|G(\\mathbf{p})\\|^2\\]\nwhere \\(G(\\mathbf{p}) = QF(\\mathbf{p}) - d\\) and \\(d \\in \\mathbb{R}^n\\). We are minimizing the norm of a non-linear function of the parameters. Supposing that we want to find the minimizer, one approach would be by gradient descent.\n\nThe Jacobian: A quick review\n\nThe Jacobian is a multivariate extension of the derivative that extends to functions \\(f : \\mathbb{R}^m \\to \\mathbb{R}^n\\). Because there are \\(n\\) function outputs and \\(m\\) input variables, the Jacobian is an \\(n \\times m\\) matrix that contains the information of how each of the \\(n\\) functions changes with respect to each of the \\(m\\) variables. In an abuse of Leibniz’s notation, it can be seen as:\n\\[\n\\frac{\\partial \\vec{f}}{\\partial \\vec{x}} = \\mathbf{J_f} =\n\\left[\n    \\frac{\\partial f}{\\partial x_1} \\cdots \\frac{\\partial f}{\\partial x_n}\n\\right]\n=\n\\begin{bmatrix}\n    \\nabla^\\top f_1\n    \\\\\n    \\vdots\n    \\\\\n    \\nabla^\\top f_m\n\\end{bmatrix}\n=\n\\left[\n    \\begin{array}{ccc}\n    \\frac{\\partial f_1}{\\partial x_1} & \\cdots & \\frac{\\partial f_1}{\\partial x_n} \\\\\n    \\vdots & \\ddots & \\vdots \\\\\n    \\frac{\\partial f_m}{\\partial x_1} & \\cdots & \\frac{\\partial f_m}{\\partial x_n}\n    \\end{array}\n\\right]\n\\]\nNote that like the derivative, the Jacobian is a function of the input variables \\(\\vec{x}\\). The Jacobian is a linear approximation of the function \\(f\\) at a point \\(x_0\\) and can be used to approximate the function at a point \\(x_0 + \\Delta x\\).\n\\[ f(x_0 + \\Delta x) \\approx f(x_0) + J_f(x_0) \\Delta x\\]\nNoting that we are applying matrix multiplication using \\(J_f\\) evaluated at \\(x_0\\) and the vector \\(\\Delta x = \\vec{x} - \\vec{x_0}\\). The quantity \\(J_f(x_0) \\Delta x\\) is the directional derivative of the function \\(f\\) at \\(x_0\\) in the direction of \\(\\Delta x\\).\n\nThe gradient of \\(\\|G(\\mathbf{p})\\|^2\\) can be computed as follows:\n\\[\\begin{align}\n\\nabla_p \\|G(p)\\|^2 &= \\nabla_p G(p)^T G(p)\\\\\n&= \\sum_{i=1}^n \\nabla_p G_i(p)^2\\\\\n&= \\sum_{i=1}^n 2 G_i(p) \\nabla_p G_i(p)\\\\\n&= 2 J_G(p)^T G(p)\n\\end{align}\n\\]\nFrom this stage, gradient descent can be applied to find the minimum of the function. However, the function \\(G(p)\\) is non-linear and so the gradient descent method may not converge quickly or the problem may have poor conditioning. The celebrated Newton’s Method addresses some of these issues, but requires computing the Hessian \\(\\nabla^2 \\|G(p)\\|^2\\) of the function, which can be expensive.\nTo demonstrate, the true Hessian of the function is: \\[\n\\nabla^2 \\|G(p)\\|^2 = 2 J_G(p)^T J_G(p) + 2 \\sum_{i=1}^n G_i(p) \\nabla^2 G_i(p)\n\\]\nSo we’d have to compute the Hessian \\(\\nabla^2 G_i(p)\\) of each of the \\(G_i(p)\\) functions, of which there are \\(n\\), not good in practice. If we did have this Hessian, the steps with Newton’s method would be:\n\\[ p_{k+1} = p_k - (\\nabla^2 \\|G(p_k)\\|^2)^{-1} \\nabla (\\|G(p_k)\\|^2)\\]"
  },
  {
    "objectID": "content/eosc555/lectures/lecture5/index.html#gauss-newton-optimization",
    "href": "content/eosc555/lectures/lecture5/index.html#gauss-newton-optimization",
    "title": "Lecture 5: Gauss Newton",
    "section": "Gauss-Newton Optimization",
    "text": "Gauss-Newton Optimization\nRather than solve the problem directly with Newton’s method, it can be approximated by linearizing inside of the norm and solving the linearized version using the normal equations. We approximate the function\n\\[G(p) = QF(p) - d \\approx (QF(p_k) - d) + QJ_k(p-p_k)\\]\nwhere \\(J_k\\) is the Jacobian of \\(F(p)\\) at \\(p_k\\).\n\\[ \\min_{p \\in \\mathbb{R}^m} \\|QF(p_k) - d + QJ_k(p-p_k)\\|^2\\]\nThen rearranging this we get a form that is a linear least squares problem:\n\\[ \\begin{align}\n& \\min_{p \\in \\mathbb{R}^m} \\| QJ_kp - (d + QJ_k p_k- QF(p_k) )\\|^2\\\\\n=& \\min_{p \\in \\mathbb{R}^m} \\| Ap - r_k\\|^2\\\\\nA^T A p =& A^T r_k\n\\end{align}\n\\]\nwhere \\(A = QJ_k\\) and \\(r_k = d + QJ_k p_k - QF(p_k)\\). This is the normal equations for the linear least squares problem. This gives us\n\\[\n\\begin{align}\np_{k+1} &= (A^T A)^{-1} A^T (r_k)\\\\\n&= (J_k^T Q^T Q J_k)^{-1} J_k^T Q^T (d + QJ_k p_k - QF(p_k))\\\\\n&= p_k + (J_k^T Q^T Q J_k)^{-1} J_k^T Q^T (d - QF(p_k))\\\\\np_{k+1} &= p_k - (J_k^T Q^T Q J_k)^{-1} J_k^T Q^T (QF(p_k) - d)\\\\\n\\end{align}\n\\]\nThis could be written in a more tidy and general way, reacalling that \\(G(p) = QF(p) - d\\) and let \\(J_G(p) = QJ(p)\\), then we have:\n\\[ p_{k+1} = p_k - (J_G(p_k)^TJ_G(p_k))^{-1} J_G(p_k) G(p_k)\\]\n\nComparison with Newton’s Method\nSo this resembles a scaled gradient descent. In Newton’s method we have the Hessian, in Gauss-Newton we have the Jacobian of the function. As a comparison:\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\nNewton’s Method\nStep Update\n\n\n\n\\(p_{k+1} = p_k - (\\nabla^2 \\|G(p_k)\\|^2)^{-1} \\nabla \\|G(p_k)\\|^2\\)\n\n\n\nScaling Matrix\n\n\n\n\\(\\nabla^2 \\|G(p_k)\\|^2 = 2 J_G(p_k)^T J_G(p_k) + 2 \\sum_{i=1}^n G_i(p_k) \\nabla^2 G_i(p_k)\\)\n\n\nGauss-Newton Method\nStep Update\n\n\n\n\\(p_{k+1} = p_k - (J_G(p_k)^T J_G(p_k))^{-1} J_G(p_k)^T G(p_k)\\)\n\n\n\nScaling Matrix\n\n\n\n\\(J_G(p_k)^T J_G(p_k)\\)\n\n\n\nThe direction of change between iterations in Newton’s method can be rewritten as \\[d_k = \\left(J_G(p_k)^T J(p_k) + \\sum_{i=1}^n G_i(p_k) \\nabla^2 G_i(p_k)\\right)^{-1} J_G(p_k)^T G(p_k)\\]\nWhile the direction in the case of Gauss-Newton is \\[d_k = \\left(J_G(p_k)^T J_G(p_k)\\right)^{-1} J_G(p_k)^T G(p_k)\\]\nThe difference between the two is the omission of the computationally expensive \\(\\sum_{i=1}^n G_i(p) \\nabla^2 G_i(p)\\) terms. The Gauss-Newton method is approximating the second-order approach of Newton’s method by only considering the first-order terms inside of the norm.\n\\[J_G(p_k)^T J(p_k) \\sum_{i=1}^n G_i(p_k) \\nabla^2 G_i(p_k) \\approx J_G(p_k)^T J(p_k)\\]\nRecall that \\(G(p) = QF(p) - d\\) which is the difference between the observed data and the model. If the difference is small then \\(G_i\\) is also small and the approximation is good.\n\n\nAlgorithm for Gauss-Newton\nWe have derived the algorithm for the Gauss-Newton method for solving the non-linear least squares problem. The algorithm is as follows:\n\n\n\\begin{algorithm} \\caption{Gauss-Newton Algorithm for Non-linear Least Squares}\\begin{algorithmic} \\State \\textbf{Input:} Initial guess $p_0$, maximum iterations $K$, tolerance $\\epsilon$ \\State \\textbf{Initialize} $p_0$ \\For{$k = 0, 1, 2, \\ldots$} \\State Compute the Jacobian $J_G$ of $G(p)$ at $p_k$ \\State Compute the transpose $J_G^T$ of the Jacobian \\State Compute the residual $r_k =G(p_k)$ (forward model) \\State Compute the step $s_k = (J_G(p_k)^T J_G(p_k) )^{-1} J_G(p_k)^T r_k$ \\State Update the parameters $p_{k+1} = p_k + \\mu_k s_k$ \\If{$\\|s_k\\| &lt; \\epsilon$} \\State \\textbf{Stop} \\EndIf \\EndFor \\State \\textbf{Output:} $p_{k+1}$ as the optimal solution \\end{algorithmic} \\end{algorithm}\n\n\n\n\nMatrix Inversions\nIn practice it may be computationally expensive to invert the matrix \\(J_k^T Q^T Q J_k\\). We can use a conjugate gradient method to solve the normal equations instead. \\[J_k^T Q^T Q J_k s_k = J_k^T Q^T r_k\\]\nWe developed a conjugate gradient method in the last lecture, so we can use that along with the computed values for \\(J_k^T, J_k, r_k\\) to solve the normal equations and get the step \\(s_k\\).\n\n\nSummary\n\n\n\n\n\n\n\n\nComponent\nDescription\nDimensions\n\n\n\n\n\\(d\\)\nObserved data\n\\(\\mathbb{R}^{n}\\)\n\n\n\\(p_k\\)\nParameters\n\\(\\mathbb{R}^{m}\\)\n\n\n\\(Q\\)\nWeight matrix\n\\(\\mathbb{R}^{n \\times n}\\)\n\n\n\\(J_k\\)\nJacobian of \\(F(p_k)\\)\n\\(\\mathbb{R}^{n \\times m}\\)\n\n\n\\(r_k\\)\nResidual \\(d - QF(p_k)\\)\n\\(\\mathbb{R}^{n}\\)\n\n\n\\(F(p_k)\\)\nForward model output\n\\(\\mathbb{R}^{n}\\)\n\n\n\\(s_k\\)\nStep direction\n\\(\\mathbb{R}^{m}\\)\n\n\n\\(J_k^T\\)\nTranspose of the Jacobian\n\\(\\mathbb{R}^{m \\times n}\\)\n\n\n\\(J_k^T Q^T Q J_k\\)\nNormal equations matrix\n\\(\\mathbb{R}^{m \\times m}\\)"
  },
  {
    "objectID": "content/eosc555/lectures/lecture3/index.html",
    "href": "content/eosc555/lectures/lecture3/index.html",
    "title": "Lecture 3: Image Denoising with Gradient Descent and Early Stopping",
    "section": "",
    "text": "Often times we wish to find the gradient of a multi-variable function that is formulated as a linear algebra operation. In this case there are some useful “vector” derivatives and rules that can simplify the process of calculating more complex expressions. The gradient with respect to vector \\(\\mathbf{x}\\) is generally denoted as \\(\\nabla_{\\mathbf{x}}\\) or alternatively \\(\\partial_{\\mathbf{x}}\\), somewhat of an abuse of notation.\n\n\n\\[\\phi(x) = a^\\top x = \\sum_i a_i x_i\\]\nThis is a vector dotproduct and the gradient is simply the vector \\(a\\). There is a subtlety here in that the vector is usually transposed to be a column vector, but this is not always the case. Some people in the field of statistics prefer to use row vector, this can cause some confusion. The general convention is a column vector.\n\\[\\nabla_{\\mathbf{x}} \\phi = a\\]\n\n\n\n\\[\\phi(x) = Ax\\]\nBased on the previous process we are expecting to potentially get \\(A^\\top\\) as the gradient, however the transpose does not occur in this case because we are not returning a vector that needs to be reshaped into a column form.\n\\[\\nabla_{\\mathbf{x}} \\phi = A\\]\n\n\n\nOften we may encounter quadratic linear functions that are of the form: \\[ \\phi(x) = x^\\top A x\\]\nOne way to determine the gradient is to expand the expression and evaluate for a single \\(\\frac{\\partial}{\\partial x_i}\\) term. This method can be found at Mark Schmidt Notes Instead we can apply a chain rule for matrix differentiation that is based on the product rule for differentiation. The chain rule for matrix differentiation is as follows:\n\\[\\frac{d f(g,h)}{d x} = \\frac{d (g(x)^\\top)}{d x} \\frac{\\partial f(g,h)}{\\partial g} + \\frac{d (h(x)^\\top)}{d x} \\frac{\\partial f(g,h)}{\\partial h}\\]\n\\[ \\begin {align*}\n\\phi(x) &= x^\\top A x \\\\\n\\nabla_{\\mathbf{x}} \\phi &= \\nabla_{\\mathbf{x}} (x^\\top A x) \\\\\n&= \\nabla_{\\mathbf{x}} x^\\top (A x) =  \\nabla_{\\mathbf{x}} x^\\top y\\\\\n&= (\\nabla_{\\mathbf{x}} x) \\nabla_{\\mathbf{x}} x^\\top y + \\nabla_{\\mathbf{x}} y^\\top \\nabla_{\\mathbf{y}} x^\\top y\\\\\n&= I y + \\nabla_{\\mathbf{x}} (x^\\top A^\\top) x\\\\\n&= (A x) + A^\\top x\\\\\n&= (A + A^\\top) x\n\\end {align*}\n\\]\nThis fits with the generalization for a scalar quadratic form where we end up with \\((cx^2)' = (c + c^\\top)x = 2cx\\) where \\(c\\) is a scalar.\n\n\n\nAnother form of interest is the hadamard product of two vectors. \\[\\phi(x) = (Ax)^2 = Ax \\odot Ax\\]\nFor this one let \\(y=Ax\\) and we can index each element of the vector \\(y\\) as \\(y_i = \\sum_j A_{ij} x_j\\). The hadamard product is a vector \\(z\\) where \\(z_i = y_i^2\\), we can compute the jacobian since now we are taking the gradient with respect to a vector.\nThe Jacobian will contain the partial derivatives:\n\\[\\frac{d\\vec{z}}{d\\vec{x}} = \\begin{bmatrix} \\frac{\\partial z_1}{\\partial x_1} & \\frac{\\partial z_1}{\\partial x_2} & \\cdots & \\frac{\\partial z_1}{\\partial x_n} \\\\\n\\frac{\\partial z_2}{\\partial x_1} & \\frac{\\partial z_2}{\\partial x_2} & \\cdots & \\frac{\\partial z_2}{\\partial x_n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial z_n}{\\partial x_1} & \\frac{\\partial z_n}{\\partial x_2} & \\cdots & \\frac{\\partial z_n}{\\partial x_n} \\end{bmatrix}\n\\]\nIf we can recover this then we have the gradient of the hadamard product.\n\\[\n\\begin{align*}\nz_i &= y_i^2 = \\left( \\sum_j A_{ij} x_j \\right)^2\\\\\n\\frac{\\partial}{\\partial x_j} y_i^2 &= 2 y_i \\frac{\\partial y_i}{\\partial x_j} = 2 y_i A_{ij}\\\\\n\\frac{d\\vec{z}}{d\\vec{x}} &= 2 \\begin{bmatrix} y_1 A_{1j} & y_1 A_{2j} & \\cdots & y_1 A_{nj} \\\\\ny_2 A_{1j} & y_2 A_{2j} & \\cdots & y_2 A_{nj} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\ny_n A_{1j} & y_n A_{2j} & \\cdots & y_n A_{nj} \\end{bmatrix}\\\\\n&= 2 \\cdot \\text{diag}(\\vec{y})A\\\\\n&= 2 \\cdot \\text{diag}(Ax)A\n\\end{align*}\n\\]\n\n\n\nWe look at taking the gradient of the expansion of least squares to find the gradient for this optimization objective.\n\\[\\phi(x) = \\frac{1}{2} ||Ax - b||^2 = \\frac{1}{2} (x^\\top A^\\top A x - 2 b^\\top A x + b^\\top b)\\]\n\\[ \\begin{align*}\n\\nabla_{\\mathbf{x}} \\phi &= \\nabla_{\\mathbf{x}} \\left( \\frac{1}{2} (x^\\top A^\\top A x - 2 b^\\top A x + b^\\top b) \\right)\\\\\n&= \\nabla_{\\mathbf{x}} \\left( \\frac{1}{2} x^\\top A^\\top A x \\right) - \\nabla_{\\mathbf{x}} \\left( b^\\top A x \\right)\\\\\n&= \\frac{1}{2} (A^\\top A + A^\\top A) x - A^\\top b\\\\\n&= A^\\top A x - A^\\top b\\\\\n\\end{align*}\n\\]\nReturning to the first-order optimality condition we have: \\[A^\\top A x = A^\\top b\\]\nAt which point it is in question if \\(A^\\top A\\) is invertible. The invertibility of \\(A^\\top A\\) is determined by the rank of \\(A\\). The rank of A for a non-square matrix is the number of independent columns. If we examine \\(A^\\top Ax = 0\\) then we see that this is only true where the range of \\(A\\) is in the nullspace of \\(A^\\top\\). But \\(N(A^\\top) = R(A)^\\perp\\) so they are orthogonal subspaces and will never coincide unless \\(Ax=0\\). So then \\(A^\\top A x = 0\\) implies that \\(Ax = 0\\) which means that if the null space of \\(A=\\{0\\}\\) then the null space of \\(A^\\top A = \\{0\\}\\) and \\(A^\\top A\\) is invertible. Since \\(A^\\top A\\) is symmetric and positive definite, it is invertible.\n\\(A^\\top A\\) is invertible \\(\\iff\\) \\(A\\) is full rank, that is all the columns are independent. For non-square matrices, an \\(m&gt;n\\) matrix that is wide will trivially not satisfy this condition. A tall matrix \\(m&lt;n\\) will satisfy the condition if the columns are independent."
  },
  {
    "objectID": "content/eosc555/lectures/lecture3/index.html#derivations-of-linear-algebra-gradients",
    "href": "content/eosc555/lectures/lecture3/index.html#derivations-of-linear-algebra-gradients",
    "title": "Lecture 3: Image Denoising with Gradient Descent and Early Stopping",
    "section": "",
    "text": "Often times we wish to find the gradient of a multi-variable function that is formulated as a linear algebra operation. In this case there are some useful “vector” derivatives and rules that can simplify the process of calculating more complex expressions. The gradient with respect to vector \\(\\mathbf{x}\\) is generally denoted as \\(\\nabla_{\\mathbf{x}}\\) or alternatively \\(\\partial_{\\mathbf{x}}\\), somewhat of an abuse of notation.\n\n\n\\[\\phi(x) = a^\\top x = \\sum_i a_i x_i\\]\nThis is a vector dotproduct and the gradient is simply the vector \\(a\\). There is a subtlety here in that the vector is usually transposed to be a column vector, but this is not always the case. Some people in the field of statistics prefer to use row vector, this can cause some confusion. The general convention is a column vector.\n\\[\\nabla_{\\mathbf{x}} \\phi = a\\]\n\n\n\n\\[\\phi(x) = Ax\\]\nBased on the previous process we are expecting to potentially get \\(A^\\top\\) as the gradient, however the transpose does not occur in this case because we are not returning a vector that needs to be reshaped into a column form.\n\\[\\nabla_{\\mathbf{x}} \\phi = A\\]\n\n\n\nOften we may encounter quadratic linear functions that are of the form: \\[ \\phi(x) = x^\\top A x\\]\nOne way to determine the gradient is to expand the expression and evaluate for a single \\(\\frac{\\partial}{\\partial x_i}\\) term. This method can be found at Mark Schmidt Notes Instead we can apply a chain rule for matrix differentiation that is based on the product rule for differentiation. The chain rule for matrix differentiation is as follows:\n\\[\\frac{d f(g,h)}{d x} = \\frac{d (g(x)^\\top)}{d x} \\frac{\\partial f(g,h)}{\\partial g} + \\frac{d (h(x)^\\top)}{d x} \\frac{\\partial f(g,h)}{\\partial h}\\]\n\\[ \\begin {align*}\n\\phi(x) &= x^\\top A x \\\\\n\\nabla_{\\mathbf{x}} \\phi &= \\nabla_{\\mathbf{x}} (x^\\top A x) \\\\\n&= \\nabla_{\\mathbf{x}} x^\\top (A x) =  \\nabla_{\\mathbf{x}} x^\\top y\\\\\n&= (\\nabla_{\\mathbf{x}} x) \\nabla_{\\mathbf{x}} x^\\top y + \\nabla_{\\mathbf{x}} y^\\top \\nabla_{\\mathbf{y}} x^\\top y\\\\\n&= I y + \\nabla_{\\mathbf{x}} (x^\\top A^\\top) x\\\\\n&= (A x) + A^\\top x\\\\\n&= (A + A^\\top) x\n\\end {align*}\n\\]\nThis fits with the generalization for a scalar quadratic form where we end up with \\((cx^2)' = (c + c^\\top)x = 2cx\\) where \\(c\\) is a scalar.\n\n\n\nAnother form of interest is the hadamard product of two vectors. \\[\\phi(x) = (Ax)^2 = Ax \\odot Ax\\]\nFor this one let \\(y=Ax\\) and we can index each element of the vector \\(y\\) as \\(y_i = \\sum_j A_{ij} x_j\\). The hadamard product is a vector \\(z\\) where \\(z_i = y_i^2\\), we can compute the jacobian since now we are taking the gradient with respect to a vector.\nThe Jacobian will contain the partial derivatives:\n\\[\\frac{d\\vec{z}}{d\\vec{x}} = \\begin{bmatrix} \\frac{\\partial z_1}{\\partial x_1} & \\frac{\\partial z_1}{\\partial x_2} & \\cdots & \\frac{\\partial z_1}{\\partial x_n} \\\\\n\\frac{\\partial z_2}{\\partial x_1} & \\frac{\\partial z_2}{\\partial x_2} & \\cdots & \\frac{\\partial z_2}{\\partial x_n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial z_n}{\\partial x_1} & \\frac{\\partial z_n}{\\partial x_2} & \\cdots & \\frac{\\partial z_n}{\\partial x_n} \\end{bmatrix}\n\\]\nIf we can recover this then we have the gradient of the hadamard product.\n\\[\n\\begin{align*}\nz_i &= y_i^2 = \\left( \\sum_j A_{ij} x_j \\right)^2\\\\\n\\frac{\\partial}{\\partial x_j} y_i^2 &= 2 y_i \\frac{\\partial y_i}{\\partial x_j} = 2 y_i A_{ij}\\\\\n\\frac{d\\vec{z}}{d\\vec{x}} &= 2 \\begin{bmatrix} y_1 A_{1j} & y_1 A_{2j} & \\cdots & y_1 A_{nj} \\\\\ny_2 A_{1j} & y_2 A_{2j} & \\cdots & y_2 A_{nj} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\ny_n A_{1j} & y_n A_{2j} & \\cdots & y_n A_{nj} \\end{bmatrix}\\\\\n&= 2 \\cdot \\text{diag}(\\vec{y})A\\\\\n&= 2 \\cdot \\text{diag}(Ax)A\n\\end{align*}\n\\]\n\n\n\nWe look at taking the gradient of the expansion of least squares to find the gradient for this optimization objective.\n\\[\\phi(x) = \\frac{1}{2} ||Ax - b||^2 = \\frac{1}{2} (x^\\top A^\\top A x - 2 b^\\top A x + b^\\top b)\\]\n\\[ \\begin{align*}\n\\nabla_{\\mathbf{x}} \\phi &= \\nabla_{\\mathbf{x}} \\left( \\frac{1}{2} (x^\\top A^\\top A x - 2 b^\\top A x + b^\\top b) \\right)\\\\\n&= \\nabla_{\\mathbf{x}} \\left( \\frac{1}{2} x^\\top A^\\top A x \\right) - \\nabla_{\\mathbf{x}} \\left( b^\\top A x \\right)\\\\\n&= \\frac{1}{2} (A^\\top A + A^\\top A) x - A^\\top b\\\\\n&= A^\\top A x - A^\\top b\\\\\n\\end{align*}\n\\]\nReturning to the first-order optimality condition we have: \\[A^\\top A x = A^\\top b\\]\nAt which point it is in question if \\(A^\\top A\\) is invertible. The invertibility of \\(A^\\top A\\) is determined by the rank of \\(A\\). The rank of A for a non-square matrix is the number of independent columns. If we examine \\(A^\\top Ax = 0\\) then we see that this is only true where the range of \\(A\\) is in the nullspace of \\(A^\\top\\). But \\(N(A^\\top) = R(A)^\\perp\\) so they are orthogonal subspaces and will never coincide unless \\(Ax=0\\). So then \\(A^\\top A x = 0\\) implies that \\(Ax = 0\\) which means that if the null space of \\(A=\\{0\\}\\) then the null space of \\(A^\\top A = \\{0\\}\\) and \\(A^\\top A\\) is invertible. Since \\(A^\\top A\\) is symmetric and positive definite, it is invertible.\n\\(A^\\top A\\) is invertible \\(\\iff\\) \\(A\\) is full rank, that is all the columns are independent. For non-square matrices, an \\(m&gt;n\\) matrix that is wide will trivially not satisfy this condition. A tall matrix \\(m&lt;n\\) will satisfy the condition if the columns are independent."
  },
  {
    "objectID": "content/eosc555/lectures/lecture3/index.html#gradient-descent-analysis",
    "href": "content/eosc555/lectures/lecture3/index.html#gradient-descent-analysis",
    "title": "Lecture 3: Image Denoising with Gradient Descent and Early Stopping",
    "section": "Gradient Descent Analysis",
    "text": "Gradient Descent Analysis\nThe standard form of the gradient descent algorithm comes from the field of optimization and can be written as:\n\\[ x_{k+1} = x_k - \\alpha \\nabla_x \\phi(x_k)\\]\nWhere \\(\\alpha\\) is the learning rate, which can be dependent on the problem and the gradient. Substituting the gradient of the least squares problem we have:\n\\[ \\begin{align}\nx_{k+1} &= x_k - \\alpha (A^\\top A x_k - A^\\top b)\\\\\n\\frac{x_{k+1}-x_k}{\\alpha} &= A^\\top b - A^\\top A x_k\\\\\n\\lim_{\\alpha \\to 0} \\frac{x_{k+1}-x_k}{\\alpha} &= \\frac{dx}{dt} = A^\\top (b -A x), \\quad x(0) = x_0\n\\end{align}\n\\]\nThis ODE is the continuous version of the gradient descent algorithm, also known as the gradient flow. Since this a linear first-order ODE we can solve it analytically. The general method for a linear system ODE would be to find the homogeneous solution and the particular solution:\n\\[ \\begin{align}\nx' + A^\\top A x &= A^\\top b\\\\\n\\text{Guess:} x &= v e^{\\lambda t}\\\\\n\\lambda v e^{\\lambda t} + A^\\top A v e^{\\lambda t} &= A^\\top b e^{\\lambda t}\\\\\n\\lambda v + A^\\top A v &= 0 \\qquad \\text{Homogeneous}\\\\\n(\\lambda I + A^\\top A) v &= 0\\\\\n\\lambda &= \\text{eigenvalues of } A^\\top A, \\quad v = \\text{eigenvectors of } A^\\top A\n\\end{align}\n\\]\nBefore continuing further with this line, we can see that the solutions will be closely related to the SVD because it contains the information on these eigenvalues and vectors. So we can try to solve the ODE with the SVD.\n\nSolving the ODE with SVD\n\\[\\begin{align}\nA &= U \\Sigma V^\\top\\\\\nA^TA &= V \\Sigma^2 V^\\top\\\\\n\\frac{d}{dt}x &= V \\Sigma U^\\top b - V \\Sigma^2 V^\\top x\\\\\n\\end{align}\n\\]\nNow let \\(z = V^\\top x\\) and \\(\\hat b = U ^ \\top b\\) then we have:\n\\[\\begin{align}\n\\frac{d}{dt} (V^\\top x) &= \\Sigma \\hat b - \\Sigma^2 (V^\\top x)\\\\\n\\frac{d}{dt} z &= \\Sigma \\hat b - \\Sigma^2 z\\\\\nz' + \\Sigma^2 z &= \\Sigma \\hat b\\\\\n\\end{align}\n\\]\nAt this stage since everything has been diagonalized, all of the equations are decoupled and independent so we can solve for the \\(\\lambda_i\\) cases independently. We find the homogeneous \\(z_h\\) and particular \\(z_p\\) solutions:\n\\[\n\\begin{align}\nz_h' + \\lambda^2 z_h &= 0\\\\\nz_h &= c e^{-\\lambda^2 t}\\\\\nz_p' + \\lambda^2 z_p &= \\lambda \\hat b\\\\\nz_p &= D \\hat b \\\\\n\\lambda^2 D \\hat b &= \\lambda \\hat b\\\\\nD &= \\frac{1}{\\lambda}\\\\\nz_p &= \\frac{1}{\\lambda} \\hat b\n\\end{align}\n\\]\nSo the general solution for the \\(i^{th}\\) component is:\n\\[z_i = c_i e^{-\\lambda_i^2 t} + \\frac{1}{\\lambda_i} \\hat b_i\\]\nSupposing that we start at \\(x=0\\) then we have \\(z=0\\) at all elements and can solve the coefficients \\(c_i\\):\n\\[c_i = -\\frac{1}{\\lambda_i} \\hat b_i\\]\nThen putting it all back together with all the equations we have that\n\\[Z = \\text{diag}\\left( \\lambda_i^{-1} (1 - \\exp (-\\lambda_i t)) \\right) \\hat b\\]\nSubstituting back in for \\(x\\) and \\(b\\) we get:\n\\[x = V \\text{diag}\\left( \\lambda_i^{-1} (1 - \\exp (-\\lambda_i t)) \\right) U^\\top b\\]\nIf we stare at this long enough it begins to look a lot like the pseudoinverse of \\(A\\) from earlier:\n\\(x = V \\Sigma^{-1} U^\\top b\\) except in this case there is a time dependence. At the limit as \\(t \\rightarrow \\infty\\) we have that the exponential term goes to zero and we are left with the pseudoinverse solution. This is a nice way to see that the pseudoinverse is the limit of the gradient descent algorithm. What we may be interested in is what happens at earlier stages since each decay term is dependent on the eigenvalues.\nFor a simple matrix problem we can create a matrix and plot out the time evolution of the diagonals of the matrix that are of interest. In a sense, we have singular values that are time evolving at different rates.\n\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Seed for reproducibility\nnp.random.seed(4)\n# Create a 5x10 matrix A with random values\nA = np.random.randn(5, 10)\n# Create a vector b of size 5 with random values\nb = np.random.randn(5)\n\n# Compute the SVD of A\nU, S, Vt = np.linalg.svd(A, full_matrices=False)\n\n# Create a time dependent vector of the singular values\ndef St(t):\n    Sdim = S[:, np.newaxis]\n    return (1 - np.exp(-Sdim**2*t)) / Sdim\n\n# Compute the time evolution of the values and plot them on a log scale y axis with a linear time x axis\nt = np.linspace(0, .6, 100)\nT = t[np.newaxis, :]\n\nsingular_vals_t = St(T)\n\n# Initialize the plot\nplt.figure(figsize=(7.5, 4))\n\n# Create a color palette\npalette = sns.color_palette(\"husl\", len(S))\n\n# Plot the singular values and their asymptotes\nfor i in range(len(S)):\n    # Plot the time evolution of each singular value\n    sns.lineplot(x=t, y=singular_vals_t[i, :], color=palette[i], linewidth=2, label=f'$1/S_{i}$ ')\n    \n    Sinv = 1/S[i]\n\n    # Add a horizontal asymptote at the original singular value\n    plt.axhline(y=Sinv, color=palette[i], linestyle='--', linewidth=1)\n    \n    # Annotate the asymptote with the singular value\n    plt.text(t[-1] + 0.02, Sinv, f'{Sinv:.2f}', color=palette[i], va='center')\n\n# Configure plot aesthetics\nplt.xlabel('Time', fontsize=14)\nplt.ylabel('Inverse Singular Vals', fontsize=14)\nplt.title('Time Evolution of Pseudo Inverse in Gradient Flow', fontsize=16)\nplt.legend(title='Inverse Singular Vals', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.xlim(t[0], t[-1] + 0.1)\nplt.tight_layout()\nplt.savefig('imgs/pseudo_inverse_time_evolution.png')\nplt.show()\n\n\n\n\n\n\n\n\n\nSo we can use early stopping to prevent the flow from reaching the optimal point, a very useful technique. When it comes to inverse theory, often we are not interested in the optimal solution, but more interested in getting somewhere close that is not too noisy. This method differs from the thresholded pseudoinverse from the previous lecture, in that it allows some blending of the the smaller singular values, but their propensity for blowing up is controlled by the time exponent and early stopping.\n\n\nExample for Image Recovery using Analytic Solution\nReferring back to the problem of estimating the original image based on a noisy point spread function. We can monitor the time evolution of the estimate using gradient flow. Some code below defines the problem again, with recovery of the SVD decomposition for the 32x32 image, which will be used to solve the ODE for the gradient flow.\n\n\nShow the code\nimport matplotlib.pyplot as plt\nimport matplotlib\n#matplotlib.use('TkAgg')\nimport numpy as np\nimport torch.optim\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nimport copy\n\nimport seaborn as sns\n\nimport math\nimport os\nimport time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.fft\n\nclass gaussianConv(nn.Module):\n    \"\"\"\n    A PyTorch module that applies a Gaussian convolution to an input image using \n    a parameterized Gaussian Point Spread Function (PSF). The PSF is derived \n    from a covariance matrix and the derivatives of the Gaussian are computed \n    for edge detection.\n\n    Args:\n        C (torch.Tensor): Inverse of covariance matrix used to define the shape of the Gaussian.\n        t (float, optional): Scaling factor for the Gaussian, default is np.exp(5).\n        n0 (float, optional): Scaling factor for the original PSF, default is 1.\n        nx (float, optional): Scaling factor for the derivative along the x-axis, default is 1.\n        ny (float, optional): Scaling factor for the derivative along the y-axis, default is 1.\n    \"\"\"\n    def __init__(self, C, t=np.exp(5), n0=1, nx=1, ny=1):\n        super(gaussianConv, self).__init__()\n\n        self.C = C\n        self.t = t\n        self.n0 = n0\n        self.nx = nx\n        self.ny = ny\n\n    def forward(self, image):\n        P, center = self.psfGauss(image.shape[-1], image.device)\n        P_shifted = torch.roll(P, shifts=center, dims=[2, 3])\n        S = torch.fft.fft2(P_shifted)\n        I_fft = torch.fft.fft2(image)\n        B_fft = S * I_fft\n        B = torch.real(torch.fft.ifft2(B_fft))\n\n        return B\n\n    def psfGauss(self, dim, device='cpu'):\n        m = dim\n        n = dim\n\n        # Create a meshgrid of (X, Y) coordinates\n        x = torch.arange(-m // 2 + 1, m // 2 + 1, device=device)\n        y = torch.arange(-n // 2 + 1, n // 2 + 1, device=device)\n        X, Y = torch.meshgrid(x, y, indexing='ij')\n        X = X.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, m, n)\n        Y = Y.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, m, n)\n\n        cx, cy, cxy = self.C[0, 0], self.C[1, 1], self.C[0, 1]\n\n        PSF = torch.exp(-self.t * (cx * X ** 2 + cy * Y ** 2 + 2 * cxy * X * Y))\n        PSF0 = PSF / torch.sum(PSF.abs())\n\n        Kdx = torch.tensor([[-1, 0, 1],\n                            [-2, 0, 2],\n                            [-1, 0, 1]], dtype=PSF0.dtype, device=device) / 4\n        Kdy = torch.tensor([[-1, -2, -1],\n                            [0, 0, 0],\n                            [1, 2, 1]], dtype=PSF0.dtype, device=device) / 4\n\n        Kdx = Kdx.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, 3, 3)\n        Kdy = Kdy.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, 3, 3)\n\n        PSFdx = F.conv2d(PSF0, Kdx, padding=1)\n        PSFdy = F.conv2d(PSF0, Kdy, padding=1)\n\n        PSF_combined = self.n0 * PSF0 + self.nx * PSFdx + self.ny * PSFdy\n\n        center = [1 - m // 2, 1 - n // 2]\n\n        return PSF_combined, center\n\ndim = 32\nx = torch.zeros(1, 1, dim, dim)\nx[:,:, 12:14, 12:14] = 1.0\nx[:,:, 10:12, 10:12] = -1.0\n\nC = torch.tensor([[1, 0],[0, 1]])\nAmv = gaussianConv(C, t=0.1,n0=1, nx=0.1,  ny=0.1)\n\nn=(len(x.flatten()))\nAmat = torch.zeros(n,n)\n\nk=0\nfor i in range(x.shape[-2]):\n  for j in range(x.shape[-1]):\n    e_ij = torch.zeros_like(x)\n    e_ij[:,:, i, j] = 1.0\n    y = Amv(e_ij)\n    Amat[:, k] = y.flatten()\n    k = k+1\n\nU, S, V = torch.svd(Amat.to(torch.float64))\nb = Amv(x)\n\n\nNow that we have the matrix form of the forward operator Amat defined, along with the forward result b and the the decomposition U, S, V we can run the pseudo-inverse gradient flow method as before. So in this case we will be computing:\n\\[ x = V \\text{diag}\\left( \\lambda_i^{-1} (1 - \\exp (-\\lambda_i t)) \\right) U^\\top b\\]\nSince these represents an evolution over time, an animation can be created to show the time evolution of the image recovery, along with the effect of continuing into a region where noise is amplified and dominates.\nRecalling the original and distorted images with a small amount of noise \\(\\epsilon\\) are as follows:\n\n\nShow the code\nplt.figure(figsize=(6, 3))\nplt.subplot(1, 2, 1)\nplt.imshow(x[0, 0], cmap='viridis', vmin=-1, vmax=1)\nplt.title('Original Image')\nplt.axis('off')\nplt.subplot(1, 2, 2)\n\nb_noisy = b+ 0.01 * torch.randn_like(b)\nplt.imshow(b_noisy[0, 0], cmap='viridis', vmin=-1, vmax=1)\nplt.title('Distorted Image')\nplt.axis('off')\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nThe distorted image has had much of its intensity spread out diffusely, so it is only visible as a faint outline. The noise is also visible in the image as a grainy texture. The gradient flow method will attempt to recover the original image from this distorted image.\n\n\nShow the code\nfrom matplotlib import animation\n\nb_flat = b.flatten().to(torch.float64)\nx_flat = x.flatten().to(torch.float64)\nb_noisy = b_flat + 0.001 * torch.randn_like(b_flat)\n\ndef get_xhat(t):\n    Sinv_t = (1 - torch.exp(-S**2 * t)) / S\n    A_pinv = V @ torch.diag(Sinv_t) @ U.T\n    xhat = A_pinv @ b_noisy\n    return xhat\n\n# Time evolution parameters\nnum_frames = 50\nt_vals = np.logspace(0, 6, num_frames)\n\n# Prepare the plot\nfig, ax = plt.subplots(figsize=(6, 6))\nim = ax.imshow(np.zeros((dim, dim)), cmap='viridis', vmin=-1, vmax=1)\nax.set_title('Time Evolution of Pseudo-Inverse Gradient Flow')\nplt.axis('off')\n\n# Initialize the error text\nerror_text = ax.text(0.02, 0.95, '', transform=ax.transAxes, color='blue', fontsize=12,\n                     verticalalignment='top')\n\ntime_text = ax.text(0.5, 0.95, '', transform=ax.transAxes, color='blue', fontsize=12,\n                        verticalalignment='top')\n\n# Initialize containers to track min error and best time\ntracking = {'min_error': float('inf'), 'best_t': 0.0}\n\n# Animation update function\ndef update_frame(t):\n    # Compute time-dependent singular values\n    Sinv_t = (1 - torch.exp(-S ** 2 * t)) / S\n    # Construct the pseudoinverse of Amat at time t\n    A_pinv = V @ torch.diag(Sinv_t) @ U.t()\n    # Reconstruct the image estimate x(t)\n    xt = A_pinv @ b_noisy\n    # Compute the relative error\n    error = torch.norm(x_flat - xt) / torch.norm(x_flat)\n    \n    # Update min_error and best_t if current error is lower\n    if error.item() &lt; tracking['min_error']:\n        tracking['min_error'] = error.item()\n        tracking['best_t'] = t\n\n    # Reshape to image dimensions\n    x_image = xt.reshape(dim, dim).detach().numpy()\n\n    # Update the image data\n    im.set_data(x_image)\n\n    # Update the error text\n    error_text.set_text(f'Relative Error: {error.item():.4f}')\n    time_text.set_text(f'Time: {t:.2f}')\n\n    return [im, error_text, time_text]\n\n# Create the animation\nani = animation.FuncAnimation(fig, update_frame, frames=t_vals, blit=True, interval=100)\n\nani.save('imgs/gradient_flow.gif', writer='pillow', fps=5)\nplt.close(fig)\n\n\n\nAnd we saved the best time that was discovered for the recovery (with prior knowledge of the ground truth). So we can inspect that image, this was the best that we could do with the gradient flow method.\n\n\nShow the code\nbest_img = get_xhat(tracking['best_t']).reshape(dim, dim).detach().numpy()\n\nplt.figure(figsize=(6, 6))\nplt.imshow(best_img / np.max(np.abs(best_img)), cmap='viridis', vmin=-1, vmax=1)\nplt.title(f'Best Reconstruction at t={tracking[\"best_t\"]:.2f}\\nRelative Error: {tracking[\"min_error\"]:.4f}')\nplt.axis('off')\nplt.show()"
  },
  {
    "objectID": "content/eosc555/lectures/lecture3/index.html#recovery-of-the-adjoint-operator-using-autograd",
    "href": "content/eosc555/lectures/lecture3/index.html#recovery-of-the-adjoint-operator-using-autograd",
    "title": "Lecture 3: Image Denoising with Gradient Descent and Early Stopping",
    "section": "Recovery of the Adjoint Operator using Autograd",
    "text": "Recovery of the Adjoint Operator using Autograd\nIn this case we were able to compute the matrix form of \\(A\\) and use its transpose to compute the SVD, but in many cases this might be too expensive or there may not be a closed form analytic solution to the early stopping technique. In such cases we wish to recover the adjoint. The question then is how to recover the adjoint operator from the Amv operator? There are helpful tools available through the use of automatic differentiation to track the gradients of the forward operator and recover the adjoint operator. This is a very powerful tool that can be used to recover the adjoint operator in a very general way.\nBy definition the adjoint has the property that: \\[\\langle Ax, v \\rangle = \\langle x, A^\\top v \\rangle\\]\n\nExplicit Computation of the Adjoint\nWe can compute the adjoint explicitly for the Amv operator based on its computation from earlier. The discrete fourier transform matrix operator \\(F\\) has the property that \\(F^{-1} = F^\\top\\) so we can use this to compute the adjoint.\n\\[\n\\begin{align}\nA(x) &= \\mathcal{F}^-1 \\left( \\mathcal{F}(P) \\odot \\mathcal{F}(x) \\right)\\\\\n&= F^\\top \\left( \\text{diag} (F(P)) F(x) \\right)\\\\\nA^\\top(v) &= F^\\top \\text{diag} (F(P))^* F v\\\\\n\\end{align}\n\\]\nWhere the hadamard operation of the two vectors has been modified to a matrix form by diagonalizing the vector \\(F(P)\\) that is the Fourier transform of the point spread function. From this form it is posible to take the adjoint of the operator by taking the complex conjugate of the transpose of the entire operation.\n\n\nAutograd Computation of the Adjoint\nWe start with a new function \\(h = v^\\top A(x)\\) and we wish to compute the gradient of \\(h\\) with respect to \\(x\\).\n\\[ \\nabla_x h = \\nabla_x (v^\\top A(x)) = A^\\top(v)\\]\nThe gradient of \\(h\\) with respect to \\(x\\) is the adjoint operator \\(A^\\top(v)\\). We can use the torch.autograd.grad function to compute the gradient of \\(h\\) with respect to \\(x\\).\n\n\nShow the code\ndef Amv_adjoint(v):\n    x = torch.zeros(1, 1, dim, dim)\n    x.requires_grad = True\n    b = Amv(x)\n    # Compute the dot product of the forward operator with the input vector\n    h = torch.sum(b * v)\n    # Compute the gradient of the dot product with respect to the input image\n    adjoint = torch.autograd.grad(h, x, create_graph=True)[0]\n    return adjoint\n\n\nWe can use this to recover \\(A^\\top\\) for the general case if we run the operator on the set of basis vectors in the image space. This will give us the adjoint operator in the form of a matrix. We can also use it to confirm that it recovers the matrix transpose of the forward operator if we are working with a simple matrix, reusing the Amat matrix from earlier to take its transpose and compare it to the adjoint operator.\n\n\nShow the code\nAmat_adj = torch.zeros(n,n)\n\ndim = 32 # Same as earlier\nk=0\nfor i in range(dim):\n  for j in range(dim):\n    e_ij = torch.zeros_like(x)\n    e_ij[:,:, i, j] = 1.0\n    y = Amv_adjoint(e_ij)\n    Amat_adj[:, k] = y.flatten()\n    k = k+1\n\ndiff = torch.norm(Amat_adj - Amat.T)\nprint(f'Norm of difference between adjoint and transpose: {diff:.2e}')\n\n\nNorm of difference between adjoint and transpose: 4.43e-07\n\n\nSo the difference is within the bounds of numerical precison and the code appears to be working correctly."
  },
  {
    "objectID": "content/eosc555/lectures/lecture3/index.html#gradient-descent-with-adjoint",
    "href": "content/eosc555/lectures/lecture3/index.html#gradient-descent-with-adjoint",
    "title": "Lecture 3: Image Denoising with Gradient Descent and Early Stopping",
    "section": "Gradient Descent with Adjoint",
    "text": "Gradient Descent with Adjoint\nWe can now use the defined operators (functions) from earlier to setup a simple gradient descent algorithm with a step size and early stopping to produce a recovery image that bypasses the need to compute the SVD decomposition, which may be very expensive for large matrices.\n\n\nShow the code\nfrom tqdm import tqdm\n\ndef least_squares_sol(x0, b, Amv, Amv_adjoint, max_iter=1000, alpha=1e-3, tol=1e-6, show_progress=True):\n    \"\"\"\n    Solves the least squares problem using gradient descent with optional progress tracking.\n\n    Parameters:\n    - x0 (torch.Tensor): Initial guess for the solution.\n    - b (torch.Tensor): Observation vector.\n    - Amv (callable): Function to compute A @ x.\n    - Amv_adjoint (callable): Function to compute A^T @ v.\n    - max_iter (int): Maximum number of iterations.\n    - alpha (float): Learning rate.\n    - tol (float): Tolerance for convergence.\n    - show_progress (bool): If True, display a progress bar; otherwise, suppress output.\n\n    Returns:\n    - x (torch.Tensor): Approximated solution vector.\n    \"\"\"\n    x = x0.clone()\n    x.requires_grad = True\n    b_noisy = b.clone() + 0.01 * torch.randn_like(b)\n\n    # Initialize progress bar or a placeholder for quiet mode\n    pbar = tqdm(total=max_iter, desc='Least Squares Iteration', unit='iter', disable=not show_progress) \n    for i in range(max_iter):\n        # Gradient descent update\n        residual = Amv(x) - b_noisy\n        gradient = Amv_adjoint(residual)\n        xnext = x - alpha * gradient\n\n        # Compute relative error\n        error = torch.norm(xnext - x) \n\n        # Update the progress bar with the current error\n        if show_progress:\n            pbar.set_postfix({'Error': f'{error.item():.4e}'})\n            pbar.update(1);\n\n        # Check for convergence\n        if error &lt; tol:\n            if show_progress:\n                pbar.write(f'Converged at iteration {i+1} with error {error.item():.4e}')\n            x = xnext\n            break\n\n        x = xnext\n\n    pbar.close()\n    \n    return x\n\nb = Amv(x)\nx0 = torch.zeros_like(x)\nxhat = least_squares_sol(x0, b, Amv, Amv_adjoint, max_iter=1000, alpha=1, tol=1e-6, show_progress=False)\n\n# Display final images\nplt.figure(figsize=(6, 3))\nplt.subplot(1, 2, 1)\nplt.imshow(x[0, 0], cmap='viridis', vmin=-1, vmax=1)\nplt.title('Original Image')\nplt.axis('off')\nplt.subplot(1, 2, 2)\nplt.imshow(xhat.detach().numpy()[0, 0], cmap='viridis', vmin=-1, vmax=1)\nplt.title('Recovered Image')\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nNote that torch does have the framework to run autograd on the least squares objective itself, but for this general method we are using the adjoint to compute the gradient (and indirectly invoking autograd). This framework is the most general for when there might not be explicit analytic solutions to the least squares problem, but we have the forward operator and its adjoint."
  },
  {
    "objectID": "content/eosc555/lectures/lecture1-2/index.html",
    "href": "content/eosc555/lectures/lecture1-2/index.html",
    "title": "Lecture 1: Introduction to Inverse Theory",
    "section": "",
    "text": "Inverse theory is a set of mathematical techniques used to infer the properties of a physical system from observations of its output. It is a fundamental tool in many scientific disciplines, including geophysics, seismology, and medical imaging. Inverse theory is used to solve a wide range of problems, such as:\n\nParameter Estimation: Determining the values of unknown parameters in a model that best fit the observed data.\nSystem Identification: Identifying the structure and dynamics of a system from input-output data.\nImage Reconstruction: Reconstructing an image or object from noisy or incomplete measurements.\n\nWhat many of these tasks have in common is that we are working with incomplete information. There is a forward problem that has generated the data that we observe \\(\\vec{b}\\) from a set of input data \\(\\vec{x}\\), and we want to infer the inverse problem that generated the data. However the inverse problem is often ill-posed, meaning that there are multiple solutions that can fit the data equally well. Inverse theory provides a framework for finding the best solution to these problems.\nThe forward problem can be described for example as a differetial equation or operator \\(L\\) that takes in some measured parameters \\(u\\) with model parameters \\(x\\) :\n\\[ L(x)[u] = q \\iff u = L^{-1}(x)[q] \\]\nFor example making measurements of an electromagnetic field in correspondence to conductivity values that are underground we have:\n\\[ \\nabla \\sigma \\nabla u = q + \\text{BC}\\]\nWe measure the \\(u\\) at some points and use that to try and form an estimate of the conductivity \\(\\sigma\\). The forward problem is to solve for \\(u\\) given \\(\\sigma\\) and the inverse problem is to solve for \\(\\sigma\\) given \\(u\\). The forward problem is often well-posed and the inverse problem is often ill-posed.\nFor a computational framework we can discretize the the equation so that the operator is a matrix \\(A\\) and the data is a vector \\(\\vec{b}\\):\n\\[ \\underbrace{A}_{\\text{Forward Map}} \\underbrace{\\vec{x}}_{\\text{Model Parameters}} + \\epsilon = \\underbrace{\\vec{b}}_{\\text{Observed Data}} \\]\nIn this case we may have a sparse set of measurements \\(b\\) and a large set of \\(x\\) making the problem underdetermined. The goal of inverse theory is to find the best estimate of \\(x\\) given \\(b\\).\n\n\nTo illustrate the concept of inverse theory, consider the following example:\n\nSuppose that you have agreed to meet a friend to watch them during a triathlon race but you showed up late and missed the start. They are expecting for you to have been there at some point during the time at which they were changing from a running phase to a cycle phase. They expect you to know the time at which they made the transition. However you only know the overall start time and finish time of the race.\nIf the race starts at time \\(t=0\\) and then ends at time \\(t=b\\) how do you use this information to deduce the actual time \\(t_r \\in [0,b]\\) at which they crossed the transition zone of the race?\n\nThe first restriction on feasible solutions is the domain \\([0,b]\\) so that we know that \\(0&lt;t_r&lt;b\\).\nAfter this there are some other techniquest that we could use to better inform the probability of the occurence at different times. For example, we might have a good idea of their fitness level or average running speed from previous experience. Or in the abscence of this information there might be average times for the competitors that are available to further inform the problem and reduce the amount of error in the estimate.\n\n\n\nFor cases where the matrix \\(A\\) is not full rank, the singular value decomposition (SVD) provides a more general framework for solving the least squares problem. The SVD decomposes the matrix \\(A\\) into three matrices \\(U\\), \\(\\Sigma\\), and \\(V\\)\n\\[ A = U \\Sigma V^T \\]\nThe matrices have the following special properties:\n\nOrthogonal Subspaces: \\(U\\) and \\(V\\) are orthogonal matrices, meaning that \\(U^TU = I\\) and \\(V^TV = I\\), that is \\(U^T = U^{-1}\\) and $V^T = V^{-1}.\nOrdered Singular Values: \\(\\Sigma\\) is a diagonal matrix with non-negative values on the diagonal, known as the singular values of \\(A\\). The singular values are ordered such that \\(\\sigma_1 \\geq \\sigma_2 \\geq \\ldots \\geq \\sigma_r\\). The number of non-zero singular values is equal to the rank of \\(A\\).\n\nSupposed that we have a \\(\\text{rank}(A) = r\\) matrix \\(A\\) which maps from \\(\\mathbb{R}^m\\rightarrow \\mathbb{R}^n\\). A fundamental way to view this mapping is as a composition of three linear transformations: a rotation \\(V\\), a scaling \\(\\Sigma\\), and another rotation \\(U\\). The orthogonal matrix \\(V\\) has the property that all of its rows and columns are orthogonal to each other, and the vectors themselves are normalized to \\(1\\). To see this property of the orthogonal matrix consider that \\(V^T V = I\\) and \\(V V^T = I\\):\n\\[ \\begin{align}\nZ = V^T V &= I \\\\\nz_{ij} = \\langle v_i, v_j \\rangle &= \\delta_{ij} \\end{align} \\]\nEach of the elements of the matrix \\(V^T\\) is the dot product of the \\(i\\)th and \\(j\\)th columns of \\(V\\). The dotproduct of all vectors against themselves is \\(1\\) and the dotproduct of any two different vectors is \\(0\\). So from this we can see that all of the columns of \\(V\\) are orthogonal to each other. The same property holds for \\(U\\).\n\\(V^T\\) by our definition of \\(A\\) must accept a vector from \\(\\mathbb{R}^m\\) and the matrix is square, indicating an \\(m \\times m\\) matrix. The matrix \\(U\\) must output a vector in \\(\\mathbb{R}^n\\) and the matrix is square, indicating an \\(n \\times n\\) matrix. The matrix \\(\\Sigma\\) must be \\(n \\times m\\) to map from \\(\\mathbb{R}^m\\) to \\(\\mathbb{R}^n\\).\nIn all its glory:\n\\[\n\\begin{aligned}\nA_{n \\times m} &= U_{n \\times n} \\, \\Sigma_{n \\times m} \\, V^T_{m \\times m} \\\\\n&= \\left[ \\begin{array}{ccc|ccc}\n\\mathbf{u}_1 & \\cdots & \\mathbf{u}_r & \\mathbf{u}_{r+1} & \\cdots & \\mathbf{u}_n\n\\end{array} \\right]_{n \\times n}\n\\left[ \\begin{array}{ccc}\n\\sigma_1 &  &  \\\\\n& \\ddots &  \\\\\n&  & \\sigma_r \\\\\n0 & \\cdots & 0 \\\\\n\\vdots & \\ddots & \\vdots \\\\\n0 & \\cdots & 0\n\\end{array} \\right]_{n \\times m}\n\\left[ \\begin{array}{ccc|ccc}\n\\mathbf{v}^T_1 \\\\\n\\vdots \\\\\n\\mathbf{v}^T_r \\\\\n\\mathbf{v}^T_{r+1} \\\\\n\\vdots \\\\\n  \\mathbf{v}^T_m\n\\end{array} \\right]_{m \\times m}\n\\end{aligned}\n\\]\nIn this case the first \\(r\\) columns of \\(U\\) are the range of \\(A\\), the rest of \\(U\\) is filled with its orthogonal complement. The first \\(r\\) columns of \\(V\\) are the domain of \\(A\\), the rest of \\(V\\) is filled with its orthogonal complement. These are the four fundamental subspaces of the matrix \\(A\\), more information on this can be found at: Wikipedia: SVD\nThe matrices as shown above are for a rectangular \\(A\\) where \\(n&gt;m\\) but the same properties hold for all \\(n,m\\). Some of the singular values \\(\\sigma_i\\) may be zero, in which case the matrix \\(A\\) is not full rank.\nAnother way to decompose the SVD is to write it as a sum of outer products that are scaled by the diagonal matrix of singular values:\n\\[ A = \\sum_{i=1}^r \\sigma_i \\mathbf{u}_i \\mathbf{v}_i^T \\]\nIf \\(\\sigma_i&gt;0\\) then \\(v_i\\) is not in the null space of \\(A\\) because \\(A v_i = \\sigma_i u_i\\). If \\(\\sigma_i = 0\\) then \\(v_i\\) is in the null space of \\(A\\) because \\(A v_i = 0\\).\n\n\nBack to the task of inverting \\(Ax + \\epsilon = b\\) we can apply the SVD decomposition:\n\\[\\begin{align}\nU \\Sigma V^T x + \\epsilon &= b \\\\\n\\Sigma V^T x +&= U^T (b-\\epsilon) \\\\\nV \\Sigma^{-1} U^T (b-\\epsilon) &= x\\\\\nA^+ (b-\\epsilon) &= \\hat{x}\n\\end{align}\\]\nWhere \\(A^+ = V \\Sigma^{-1} U^T\\) is the pseudoinverse of \\(A\\). The pseudoinverse is a generalization of the matrix inverse for non-square matrices. We recover a square matrix by removing all of the absent or zero singular values from \\(\\Sigma\\) and inverting the rest, giving an \\(r \\times r\\) diagonal matrix whose inverse is simply the inverse of each element.\n\\[ \\left[ \\begin{array}{ccc}\n\\sigma_1 &  &  \\\\\n& \\ddots &  \\\\\n&  & \\sigma_r \\\\\n0 & \\cdots & 0 \\\\\n\\vdots & \\ddots & \\vdots \\\\\n0 & \\cdots & 0\n\\end{array} \\right]_{n \\times m}\n\\rightarrow \\left[ \\begin{array}{ccc}\n\\sigma_1^{-1} &  &  \\\\\n  & \\ddots &  \\\\\n  &  & \\sigma_r^{-1} \\\\\n  \\end{array} \\right]_{r \\times r}\\]\nThen \\[\\hat{x} = \\sum_i^N \\sigma_i^{-1} \\mathbf{u}_i^T (b-\\epsilon) \\mathbf{v}_i\\] is the solution to the least squares problem. This can be solved also as a truncated sum since \\(0&lt;N&lt;r\\). In actual practice with real world measurement we end up with many singular values that may be effectively \\(0\\) by nature of being very small relative to the noise in the data and the largest single value. We have that the solution \\(\\hat{x}\\) is a sum of \\(v_i\\) components that form an orthogonal basis \\(\\hat{x} = \\sum_i \\beta_i v_i\\) where \\(\\beta_i = \\frac{u_i^T (b-\\epsilon)}{\\sigma_i}\\). These small singular values blow up in size when inverted and so extra truncation is often necessary to avoid numerical instability and excessive amplification of noise \\(\\epsilon\\).\n\n\n\n\nLeast squares and matrix inversion is a classic starting point for understanding inverse theory. Suppose that we have input data \\(\\vec{x}\\) and output data \\(\\vec{b}\\) that are related by a linear system of equations: \\[Ax = b\\] where \\(A\\) is a matrix of coefficients. In many cases, the system is overdetermined, meaning that there are more equations than unknowns. In this case, there is no exact solution to the system, and we must find the best solution that minimizes the error between the observed data \\(\\vec{b}\\) and the predicted data \\(A\\vec{x}\\). In the simplest form of inversion that we can attempt, we can solve the least squares solution. In this case we reject all of the observed data that is from the null space of \\(A\\) assuming a zero value for each of those parameters.\n\n\nLet \\(A\\) be a \\(3 \\times 2\\) matrix and \\(\\vec{b}\\) be a \\(3 \\times 1\\) vector. The \\(\\vec{x}\\) that we are trying to solve for is a \\(2 \\times 1\\) vector. The system of equations is given by:\n\\[ A = \\begin{bmatrix}  \\vec{a}_1 & \\vec{a}_2 \\end{bmatrix} \\quad \\vec{x} = \\begin{bmatrix} x_1 \\\\ x_2  \\end{bmatrix}  \\quad \\vec{b} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix} \\]\nIn this case we have an overdetermined system with three equations, two unknowns, and three data samples. If the system of equations is full rank then we are trying to map from a 2D space to a 3D space: \\(A: \\mathbb{R}^2 \\rightarrow \\mathbb{R}^3\\). In this case there is no exact solution to the system for any \\(b\\) that is not in the column space of \\(A\\).\nInstead we can solve for the least squares solution \\(\\vec{x}_{LS}\\) by minimizing the error between the observed data \\(\\vec{b}\\) and the predicted data \\(A\\vec{x}\\) from the forward model.\n\\[ \\vec{x}_{LS} = \\arg \\min_{\\vec{x}} ||A\\vec{x} - \\vec{b}||_2^2 \\]\nWe want to find the argument that minimizes the function \\(f(\\vec{x}) = ||A\\vec{x} - \\vec{b}||_2^2\\). By first order optimality conditions, the gradient of the function must be zero at the minimum.\n\\[ \\begin{align}\n\\nabla f(\\vec{x}) &= 0 \\\\\n\\nabla ||A\\vec{x} - \\vec{b}||_2^2 &= 0 \\\\\n\\nabla (A\\vec{x} - \\vec{b})^T (A\\vec{x} - \\vec{b}) &= 0 \\\\\n\\nabla \\left( \\vec{x}^T A^T A \\vec{x} - 2 \\vec{b}^T A \\vec{x} + \\vec{b}^T \\vec{b} \\right) &= 0 \\\\\n2 A^T A \\vec{x} - 2 A^T \\vec{b} &= 0 \\\\\nA^T A \\vec{x} &= A^T \\vec{b} \\\\\n\\vec{x}_{LS} &= (A^T A)^{-1} A^T \\vec{b}\n\\end{align} \\]\nThis is known as the normal equations for the least squares solution. We take a note of caution here that \\(A^T A\\) must be invertible for this solution to exist. If \\(A\\) is not full rank then the matrix \\(A^T A\\) will not be invertible and other methods must be used.\nWe call the difference between the observed data and the predicted data the residual.\n\\(r = \\vec{b} - A\\vec{x}_{LS}\\)\nUsing this information, what we really want to minimize is the sum of the squares of the residuals: \\(||r||_2^2\\). This is the same as the sum of the squares of the errors in the data.\nThere is an altogether informative way to think about the minimization problem purely in terms of linear algebra and subspaces to derive the same normal equations.\n\n\n\nLeast Squares Visual\n\n\nWe have the range of \\(A\\) or image of \\(A\\) as the subspace of \\(\\mathbb{R}^3\\) that is spanned by the columns of \\(A\\). This subspace is rank \\(2\\) because there are only two columns in \\(A\\), \\(R(A) \\subset \\mathbb{R}^3\\). The inaccessible parts of \\(\\mathbb{R}^3\\) are in the orthogonal complement of \\(R(A)\\), \\(R(A)^\\perp\\). Recalling that \\(R(A)^\\perp = N(A^T)\\) we can diagram the solution to least squares as a minimization of the error vector \\(r\\) in the orthogonal complement of \\(R(A)\\).\nAs seen the \\(r\\) vector is perpendicular to the \\(x_{LS}\\) solution, the projection of \\(r\\) onto \\(R(A)\\) is zero. Since it is in a null space of \\(A^T\\) then \\(A^T r = 0\\).\n\\[ \\begin{align} A^T \\left ( Ax_{LS} - b \\right ) &= 0\\\\\nA^T A x_{LS} &= A^T b \\\\\n\\end {align} \\]\nSo we recover the normal equations without using any of the machinery of calculus.\nFor a review on the four fundamental subspaces of a matrix see the UBC Math 307 notes on the topic: Math 307"
  },
  {
    "objectID": "content/eosc555/lectures/lecture1-2/index.html#the-singular-value-decomposition",
    "href": "content/eosc555/lectures/lecture1-2/index.html#the-singular-value-decomposition",
    "title": "Lecture 1: Introduction to Inverse Theory",
    "section": "",
    "text": "For cases where the matrix \\(A\\) is not full rank, the singular value decomposition (SVD) provides a more general framework for solving the least squares problem. The SVD decomposes the matrix \\(A\\) into three matrices \\(U\\), \\(\\Sigma\\), and \\(V\\)\n\\[ A = U \\Sigma V^T \\]\nThe matrices have the following special properties:\n\nOrthogonal Subspaces: \\(U\\) and \\(V\\) are orthogonal matrices, meaning that \\(U^TU = I\\) and \\(V^TV = I\\), that is \\(U^T = U^{-1}\\) and $V^T = V^{-1}.\nOrdered Singular Values: \\(\\Sigma\\) is a diagonal matrix with non-negative values on the diagonal, known as the singular values of \\(A\\). The singular values are ordered such that \\(\\sigma_1 \\geq \\sigma_2 \\geq \\ldots \\geq \\sigma_r\\). The number of non-zero singular values is equal to the rank of \\(A\\).\n\nSupposed that we have a \\(\\text{rank}(A) = r\\) matrix \\(A\\) which maps from \\(\\mathbb{R}^m\\rightarrow \\mathbb{R}^n\\). A fundamental way to view this mapping is as a composition of three linear transformations: a rotation \\(V\\), a scaling \\(\\Sigma\\), and another rotation \\(U\\). The orthogonal matrix \\(V\\) has the property that all of its rows and columns are orthogonal to each other, and the vectors themselves are normalized to \\(1\\). To see this property of the orthogonal matrix consider that \\(V^T V = I\\) and \\(V V^T = I\\):\n\\[ \\begin{align}\nZ = V^T V &= I \\\\\nz_{ij} = \\langle v_i, v_j \\rangle &= \\delta_{ij} \\end{align} \\]\nEach of the elements of the matrix \\(V^T\\) is the dot product of the \\(i\\)th and \\(j\\)th columns of \\(V\\). The dotproduct of all vectors against themselves is \\(1\\) and the dotproduct of any two different vectors is \\(0\\). So from this we can see that all of the columns of \\(V\\) are orthogonal to each other. The same property holds for \\(U\\).\n\\(V^T\\) by our definition of \\(A\\) must accept a vector from \\(\\mathbb{R}^m\\) and the matrix is square, indicating an \\(m \\times m\\) matrix. The matrix \\(U\\) must output a vector in \\(\\mathbb{R}^n\\) and the matrix is square, indicating an \\(n \\times n\\) matrix. The matrix \\(\\Sigma\\) must be \\(n \\times m\\) to map from \\(\\mathbb{R}^m\\) to \\(\\mathbb{R}^n\\).\nIn all its glory:\n\\[\n\\begin{aligned}\nA_{n \\times m} &= U_{n \\times n} \\, \\Sigma_{n \\times m} \\, V^T_{m \\times m} \\\\\n&= \\left[ \\begin{array}{ccc|ccc}\n\\mathbf{u}_1 & \\cdots & \\mathbf{u}_r & \\mathbf{u}_{r+1} & \\cdots & \\mathbf{u}_n\n\\end{array} \\right]_{n \\times n}\n\\left[ \\begin{array}{ccc}\n\\sigma_1 &  &  \\\\\n& \\ddots &  \\\\\n&  & \\sigma_r \\\\\n0 & \\cdots & 0 \\\\\n\\vdots & \\ddots & \\vdots \\\\\n0 & \\cdots & 0\n\\end{array} \\right]_{n \\times m}\n\\left[ \\begin{array}{ccc|ccc}\n\\mathbf{v}^T_1 \\\\\n\\vdots \\\\\n\\mathbf{v}^T_r \\\\\n\\mathbf{v}^T_{r+1} \\\\\n\\vdots \\\\\n  \\mathbf{v}^T_m\n\\end{array} \\right]_{m \\times m}\n\\end{aligned}\n\\]\nIn this case the first \\(r\\) columns of \\(U\\) are the range of \\(A\\), the rest of \\(U\\) is filled with its orthogonal complement. The first \\(r\\) columns of \\(V\\) are the domain of \\(A\\), the rest of \\(V\\) is filled with its orthogonal complement. These are the four fundamental subspaces of the matrix \\(A\\), more information on this can be found at: Wikipedia: SVD\nThe matrices as shown above are for a rectangular \\(A\\) where \\(n&gt;m\\) but the same properties hold for all \\(n,m\\). Some of the singular values \\(\\sigma_i\\) may be zero, in which case the matrix \\(A\\) is not full rank.\nAnother way to decompose the SVD is to write it as a sum of outer products that are scaled by the diagonal matrix of singular values:\n\\[ A = \\sum_{i=1}^r \\sigma_i \\mathbf{u}_i \\mathbf{v}_i^T \\]\nIf \\(\\sigma_i&gt;0\\) then \\(v_i\\) is not in the null space of \\(A\\) because \\(A v_i = \\sigma_i u_i\\). If \\(\\sigma_i = 0\\) then \\(v_i\\) is in the null space of \\(A\\) because \\(A v_i = 0\\).\n\n\nBack to the task of inverting \\(Ax + \\epsilon = b\\) we can apply the SVD decomposition:\n\\[\\begin{align}\nU \\Sigma V^T x + \\epsilon &= b \\\\\n\\Sigma V^T x +&= U^T (b-\\epsilon) \\\\\nV \\Sigma^{-1} U^T (b-\\epsilon) &= x\\\\\nA^+ (b-\\epsilon) &= \\hat{x}\n\\end{align}\\]\nWhere \\(A^+ = V \\Sigma^{-1} U^T\\) is the pseudoinverse of \\(A\\). The pseudoinverse is a generalization of the matrix inverse for non-square matrices. We recover a square matrix by removing all of the absent or zero singular values from \\(\\Sigma\\) and inverting the rest, giving an \\(r \\times r\\) diagonal matrix whose inverse is simply the inverse of each element.\n\\[ \\left[ \\begin{array}{ccc}\n\\sigma_1 &  &  \\\\\n& \\ddots &  \\\\\n&  & \\sigma_r \\\\\n0 & \\cdots & 0 \\\\\n\\vdots & \\ddots & \\vdots \\\\\n0 & \\cdots & 0\n\\end{array} \\right]_{n \\times m}\n\\rightarrow \\left[ \\begin{array}{ccc}\n\\sigma_1^{-1} &  &  \\\\\n  & \\ddots &  \\\\\n  &  & \\sigma_r^{-1} \\\\\n  \\end{array} \\right]_{r \\times r}\\]\nThen \\[\\hat{x} = \\sum_i^N \\sigma_i^{-1} \\mathbf{u}_i^T (b-\\epsilon) \\mathbf{v}_i\\] is the solution to the least squares problem. This can be solved also as a truncated sum since \\(0&lt;N&lt;r\\). In actual practice with real world measurement we end up with many singular values that may be effectively \\(0\\) by nature of being very small relative to the noise in the data and the largest single value. We have that the solution \\(\\hat{x}\\) is a sum of \\(v_i\\) components that form an orthogonal basis \\(\\hat{x} = \\sum_i \\beta_i v_i\\) where \\(\\beta_i = \\frac{u_i^T (b-\\epsilon)}{\\sigma_i}\\). These small singular values blow up in size when inverted and so extra truncation is often necessary to avoid numerical instability and excessive amplification of noise \\(\\epsilon\\)."
  },
  {
    "objectID": "content/eosc555/lectures/lecture1-2/index.html#least-squares",
    "href": "content/eosc555/lectures/lecture1-2/index.html#least-squares",
    "title": "Lecture 1: Introduction to Inverse Theory",
    "section": "",
    "text": "Least squares and matrix inversion is a classic starting point for understanding inverse theory. Suppose that we have input data \\(\\vec{x}\\) and output data \\(\\vec{b}\\) that are related by a linear system of equations: \\[Ax = b\\] where \\(A\\) is a matrix of coefficients. In many cases, the system is overdetermined, meaning that there are more equations than unknowns. In this case, there is no exact solution to the system, and we must find the best solution that minimizes the error between the observed data \\(\\vec{b}\\) and the predicted data \\(A\\vec{x}\\). In the simplest form of inversion that we can attempt, we can solve the least squares solution. In this case we reject all of the observed data that is from the null space of \\(A\\) assuming a zero value for each of those parameters.\n\n\nLet \\(A\\) be a \\(3 \\times 2\\) matrix and \\(\\vec{b}\\) be a \\(3 \\times 1\\) vector. The \\(\\vec{x}\\) that we are trying to solve for is a \\(2 \\times 1\\) vector. The system of equations is given by:\n\\[ A = \\begin{bmatrix}  \\vec{a}_1 & \\vec{a}_2 \\end{bmatrix} \\quad \\vec{x} = \\begin{bmatrix} x_1 \\\\ x_2  \\end{bmatrix}  \\quad \\vec{b} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix} \\]\nIn this case we have an overdetermined system with three equations, two unknowns, and three data samples. If the system of equations is full rank then we are trying to map from a 2D space to a 3D space: \\(A: \\mathbb{R}^2 \\rightarrow \\mathbb{R}^3\\). In this case there is no exact solution to the system for any \\(b\\) that is not in the column space of \\(A\\).\nInstead we can solve for the least squares solution \\(\\vec{x}_{LS}\\) by minimizing the error between the observed data \\(\\vec{b}\\) and the predicted data \\(A\\vec{x}\\) from the forward model.\n\\[ \\vec{x}_{LS} = \\arg \\min_{\\vec{x}} ||A\\vec{x} - \\vec{b}||_2^2 \\]\nWe want to find the argument that minimizes the function \\(f(\\vec{x}) = ||A\\vec{x} - \\vec{b}||_2^2\\). By first order optimality conditions, the gradient of the function must be zero at the minimum.\n\\[ \\begin{align}\n\\nabla f(\\vec{x}) &= 0 \\\\\n\\nabla ||A\\vec{x} - \\vec{b}||_2^2 &= 0 \\\\\n\\nabla (A\\vec{x} - \\vec{b})^T (A\\vec{x} - \\vec{b}) &= 0 \\\\\n\\nabla \\left( \\vec{x}^T A^T A \\vec{x} - 2 \\vec{b}^T A \\vec{x} + \\vec{b}^T \\vec{b} \\right) &= 0 \\\\\n2 A^T A \\vec{x} - 2 A^T \\vec{b} &= 0 \\\\\nA^T A \\vec{x} &= A^T \\vec{b} \\\\\n\\vec{x}_{LS} &= (A^T A)^{-1} A^T \\vec{b}\n\\end{align} \\]\nThis is known as the normal equations for the least squares solution. We take a note of caution here that \\(A^T A\\) must be invertible for this solution to exist. If \\(A\\) is not full rank then the matrix \\(A^T A\\) will not be invertible and other methods must be used.\nWe call the difference between the observed data and the predicted data the residual.\n\\(r = \\vec{b} - A\\vec{x}_{LS}\\)\nUsing this information, what we really want to minimize is the sum of the squares of the residuals: \\(||r||_2^2\\). This is the same as the sum of the squares of the errors in the data.\nThere is an altogether informative way to think about the minimization problem purely in terms of linear algebra and subspaces to derive the same normal equations.\n\n\n\nLeast Squares Visual\n\n\nWe have the range of \\(A\\) or image of \\(A\\) as the subspace of \\(\\mathbb{R}^3\\) that is spanned by the columns of \\(A\\). This subspace is rank \\(2\\) because there are only two columns in \\(A\\), \\(R(A) \\subset \\mathbb{R}^3\\). The inaccessible parts of \\(\\mathbb{R}^3\\) are in the orthogonal complement of \\(R(A)\\), \\(R(A)^\\perp\\). Recalling that \\(R(A)^\\perp = N(A^T)\\) we can diagram the solution to least squares as a minimization of the error vector \\(r\\) in the orthogonal complement of \\(R(A)\\).\nAs seen the \\(r\\) vector is perpendicular to the \\(x_{LS}\\) solution, the projection of \\(r\\) onto \\(R(A)\\) is zero. Since it is in a null space of \\(A^T\\) then \\(A^T r = 0\\).\n\\[ \\begin{align} A^T \\left ( Ax_{LS} - b \\right ) &= 0\\\\\nA^T A x_{LS} &= A^T b \\\\\n\\end {align} \\]\nSo we recover the normal equations without using any of the machinery of calculus.\nFor a review on the four fundamental subspaces of a matrix see the UBC Math 307 notes on the topic: Math 307"
  },
  {
    "objectID": "content/CV.html",
    "href": "content/CV.html",
    "title": "CV",
    "section": "",
    "text": "This browser does not support PDFs. Please download the PDF to view it: &lt;a href=\"www/cv/CV.pdf\"&gt;Download PDF&lt;/a&gt;."
  },
  {
    "objectID": "content/about/biography.html",
    "href": "content/about/biography.html",
    "title": "Bio",
    "section": "",
    "text": "I wasn’t always so academically focused. In fact, I had a ten year career in forestry where I planted over 2 million trees along with a variety of other projects. I also spent some years living in the Peruvian Amazon working as a travel guide and translator.\nI came back to study at UBC in 2020 to revisit my interest in science and technology, after an injury required me to change lifestyles. It has been a challenging but rewarding journey, and I am excited to see where it takes me next."
  },
  {
    "objectID": "content/about/biography.html#some-past-adventures",
    "href": "content/about/biography.html#some-past-adventures",
    "title": "Bio",
    "section": "Some Past Adventures",
    "text": "Some Past Adventures\n\n\n\n\nSta. Clautilde, Rio Napo, Peru\n\n\n\n\n\nTarapoto, San Martin, Peru\n\n\n\n\n\nRemote Helicopter Forestry Work\n\n\n\n\n\nEverest Base Camp\n\n\n\n\n\nDirtbiking in Myanmar\n\n\n\n\n\nSailing to Mexico from Victoria"
  },
  {
    "objectID": "blog/posts/scorematching/index.html",
    "href": "blog/posts/scorematching/index.html",
    "title": "Score Matching for Density Estimation",
    "section": "",
    "text": "The Problem of Density Estimation\nWhen working with a set of data, one of the tasks that we often want to do is to estimate the underlying probability density function (PDF) of the data. Knowing the probability distribution is a powerful tool that allows to make predictions, generate new samples, and understand the data better. For example, we may have a coin and want to know the probability of getting heads or tails. We can flip the coin many times and count the number of heads and tails to estimate the probability of each outcome. However, when it comes to higher dimensional spaces that are continuous in distribution, the problem of estimating the PDF in this way becomes intractable.\nFor example, with a set of small images such as the CIFAR-10 dataset, the images are 32x32 pixels with 3 color channels. The number of dimensions in the data space is 32x32x3 = 3072. With 8-bit images the number of all possible unique images is \\(255^{3072}\\), which is an incomprehensibly large number. The 60,000 images that are included in CIFAR-10 represent but a tiny fraction of samples in the space of all possible images.\n Figure 1: Sample images from the CIFAR-10 dataset (Krizhevsky 2009)\nTo demonstrate the issue with random image generation in such a sparsely populated space, we can generate a random 32x32 image with 3 color channels and display it.\n\n\nShow the code\nusing Plots, Images\n\n# Generate 6 random images and display them in a grid\nplots = []\nfor i in 1:6\n    # Generate a random 32x32 3-channel image\n    im = rand(3, 32, 32)\n    im = colorview(RGB, im)\n    p = plot(im, showaxis=false, showgrid=false, title=\"Random Image $i\")\n    push!(plots, p)\nend\n\n# Create a plot with a 2x3 grid layout\nplot_grid = plot(plots..., layout=(2, 3), size=(800, 400))\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYes we have successfuly generated random 32x32 color images, but they are not very useful or interesting.\nIf there were some way to learn the underlying distribution of the data, we could generate new samples that are realistic (probable) but that have never been seen before by sampling from higher probability regions of the learned distribution. So how do recent developments in machine learning manage to generate new and plausible samples from high dimensional data sets?\nOne of the techniques that has been developed is called generative modeling. Generative models are a class of machine learning models that are trained to learn the underlying distribution of the data. Once the model has learned the distribution, it can generate new samples that are similar to the training data.\nOne of the powerful techniques that allows for learning a probability distribution is score matching.\n\n\nParameter Estimation\nLet us take a moment to consider the problem of fitting a model to data in the most simple sense. Suppose that we have a set of data points and want to fit a linear model by drawing a line through it. One of the techniques that can be used is to minimize the sum of the squared errors between the data points and the line. This is known as the method of least squares.\nWe have model \\(f(x) = \\hat y = mx + b\\) with free parameters \\(\\theta = {m, b}\\) and data points \\((x_i, y_i)\\). The objective is to find the parameters \\(\\theta\\) that minimize the sum of the squared errors \\(J\\) between the predicted values \\(\\hat y_i\\) and the true values \\(y_i\\).: \\[  \\text{arg}\\min_{m,b} J(m,b) = \\text{arg}\\min_{m,b} \\sum_{i=1}^{n} (\\hat y_i - y_i)^2 \\]\nWe could use some calculus at this point to solve the minimization problem but more general matrix methods can be used to solve the problem.\n\\[\\begin{align*}\n    X &= \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{bmatrix} , \\quad  \\vec{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} , \\quad \\vec{\\theta} &= \\begin{bmatrix} b \\\\ m \\end{bmatrix} \\\\\n    \\text{arg}\\min_{\\vec{\\theta}} J(\\vec{\\theta}) &= \\text{arg}\\min_{\\vec{\\theta}} ||\\vec{\\hat y} - \\vec{y}||^2\\\\\n    \\text{arg}\\min_{\\vec{\\theta}} J(\\vec{\\theta}) &= \\text{arg}\\min_{\\vec{\\theta}} ||X\\vec{\\theta} - \\vec{y}||^2\n\\end{align*}\\]\nThe solution to this problem is well known and can be found by solving the normal equations: \\[ X^T X \\vec{\\theta} = X^T \\vec{y} \\]\nAn example of this optimization problem is shown below where we generate some random data points and fit a line to them.\n\n\nShow the code\nusing Plots, Random\n\n# Generate some random data points with correlation along a line\nRandom.seed!(1234)\nn_points = 10\nx = rand(n_points)\nm_true = 0.8; b_true = -1\ny = .8* x .- 1 + 0.3 * randn(n_points)\n\n# Create the matrix X\nX = hcat(ones(n_points), x)\n\n# Solve the normal equations to find the parameters theta\ntheta = X \\ y\n\n# Generate x values for the complete line\nx_line = range(minimum(x) - 0.1, maximum(x) + 0.1, length=100)\nX_line = hcat(ones(length(x_line)), x_line)\n\n# Compute the y values for the line\ny_hat_line = X_line * theta\n\n# Compute the fitted values for the original data points\ny_hat = X * theta\n\n# Unpack learned parameters\nb, m = theta\n\n# Plot the data points and the fitted line\ntitle_text = \"Fitted Line: y = $(round(m, digits=2))x + $(round(b, digits=2)) vs. \\n True Line: y = $(m_true)x + $(b_true)\"\np1 = scatter(x, y, label=\"Data Points\", color=:red, ms=5, aspect_ratio=:equal, xlabel=\"x\", ylabel=\"y\", title=title_text)\nplot!(p1, x_line, y_hat_line, label=\"Fitted Line\", color=:blue)\n# Add dashed lines for residuals\nfor i in 1:n_points\n    plot!(p1, [x[i], x[i]], [y[i], y_hat[i]], color=:black, linestyle=:dash, label=\"\")\nend\n\ndisplay(p1)\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is a simple example of parameter estimation but it shows some of the important concepts that are used in more complex models. There is an underlying distribution which is a line with some error or noise added to it. We collected some random points from the distribution and then used them in an optimization problem where we minimized the squared error between the predicted values and the true values. The best solution is the parameters \\(\\theta\\) that minimize the error. In doing so we recovered a line that is close to the one that was used to generate the data.\n\n\nEstimating a Density Function\nWhen it comes to estimating denstity we are constrained by the fact that any model must sum to 1 of the entire sample space.\n\n\nDenoising Autoencoders\nDenoising Autoencoders (DAE) are a type of machine learning model that is trained to reconstruct the input data from a noisy or corrupted version of the input. The DAE is trained to take an sample such as an image with unwanted noise and restore it to the original sample.\nIn the process of learning the denoising parameters, the DAE also can learn the score function the underlying distribution of noisy samples, which is a kernel density estimate of the true distribution.\nThe score function is an operator defined as: \\[ s(f(x)) = \\nabla_x \\log f(x) \\]\nWhere \\(f(x)\\) is the density function or PDF of the distribution.\nBy learning a score function for a model, we can reverse the score operation to obtain the original density function it was derived from. This is the idea behind score matching, where we indirectly find the the pdf of a distribution by matching the score of a proposed model \\(p(x;\\theta)\\) to the score of the true distribution \\(q(x)\\).\nAnother benefit of learning the score function of a distribution is that it can be used to move from less probable regions of the distribution to more probable regions using gradient ascent. This is useful when it comes to generative models, where we want to generate new samples from the distribution that are more probable.\nHowever one of the challenges is that the score function is not always well-defined, especially in regions of low probability where there are sparse samples. This can make it difficult to learn the score function accurately in these regions.\nThis post explores some of those limitations and how increasing the bandwidth of the noise kernel in the DAE can help to stabilize the score function in regions of low probability.\n\n\nSample of Score Matching\nSuppose we have a distribution in 2D space that consists of three Gaussians as our ground truth. We can plot this pdf and its gradient field.\n\n\nShow the code\nusing Plots, Distributions\n\n# Define the ground truth distribution\nfunction p(x, y)\n    mu1, mu2, mu3 = [-1, -1], [1, 1], [1, -1]\n    sigma1, sigma2, sigma3 = [0.5 0.3; 0.3 0.5], [0.5 0.3; 0.3 0.5], [0.5 0; 0 0.5]\n\n    return 0.2 * pdf(MvNormal(mu1, sigma1), [x, y]) + 0.2 * pdf(MvNormal(mu2, sigma2), [x, y]) + 0.6 * pdf(MvNormal(mu3, sigma3), [x, y])\nend\n\n# Plot the distribution using a heatmap\nheatmap(\n    -3:0.01:3, -3:0.01:3, p,\n    c=cgrad(:davos, rev=true),\n    aspect_ratio=:equal,\n    xlabel=\"x\", ylabel=\"y\", title=\"Ground Truth PDF q(x)\",\n    xlims=(-3, 3), ylims=(-3, 3),\n    xticks=[-3, 3], yticks=[-3, 3]\n)\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\nSampling from the distribution can be done by generating 100 random points\n\n\nShow the code\nusing Random, Plots, Distributions\n\n# Define the ground truth distribution\nfunction p(x, y)\n    mu1, mu2, mu3 = [-1, -1], [1, 1], [1, -1]\n    sigma1, sigma2, sigma3 = [0.5 0.3; 0.3 0.5], [0.5 0.3; 0.3 0.5], [0.5 0; 0 0.5]\n\n    return 0.2 * pdf(MvNormal(mu1, sigma1), [x, y]) + 0.2 * pdf(MvNormal(mu2, sigma2), [x, y]) + 0.6 * pdf(MvNormal(mu3, sigma3), [x, y])\nend\n\n# Sample 200 points from the ground truth distribution\nn_points = 200\npoints = []\n\n# Set random seed for reproducibility\nRandom.seed!(1234)\n\nwhile length(points) &lt; n_points\n    x = rand() * 6 - 3\n    y = rand() * 6 - 3\n    if rand() &lt; p(x, y)\n        push!(points, (x, y))\n    end\nend\n\n# Plot the distribution using a heatmap\n# heatmap(\n#     -3:0.01:3, -3:0.01:3, p,\n#     c=cgrad(:davos, rev=true),\n#     aspect_ratio=:equal,\n#     xlabel=\"x\", ylabel=\"y\", title=\"Ground Truth PDF q(θ)\",\n\n# )\n\n# Scatter plot of the sampled points\nscatter([x for (x, y) in points], [y for (x, y) in points], label=\"Sampled Points\", color=:red, ms=2,\n     xlims=(-3, 3), ylims=(-3, 3),\n     xticks=[-3, 3], yticks=[-3, 3])\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom this sampling of points we can visualize the effect of the choice of noise bandwidth on the kernel density estimate.\n\n\nShow the code\nusing Plots, Distributions, ForwardDiff\n\n# Define the ground truth distribution\nfunction p(x, y)\n    mu1, mu2, mu3 = [-1, -1], [1, 1], [1, -1]\n    sigma1, sigma2, sigma3 = [0.5 0.3; 0.3 0.5], [0.5 0.3; 0.3 0.5], [0.5 0; 0 0.5]\n\n    return 0.2 * pdf(MvNormal(mu1, sigma1), [x, y]) + 0.2 * pdf(MvNormal(mu2, sigma2), [x, y]) + 0.6 * pdf(MvNormal(mu3, sigma3), [x, y])\nend\n\n# Define the log of the distribution\nfunction log_p(x, y)\n    val = p(x, y)\n    return val &gt; 0 ? log(val) : -Inf\nend\n\n# Function to compute the gradient using ForwardDiff\nfunction gradient_log_p(u, v)\n    grad = ForwardDiff.gradient(x -&gt; log_p(x[1], x[2]), [u, v])\n    return grad[1], grad[2]\nend\n\n# Generate a grid of points\nxs = -3:0.5:3\nys = -3:0.5:3\n\n# Create meshgrid manually\nxxs = [x for x in xs, y in ys]\nyys = [y for x in xs, y in ys]\n\n# Compute the gradients at each point\nU = []\nV = []\nfor x in xs\n    for y in ys\n        u, v = gradient_log_p(x, y)\n\n        push!(U, u)\n        push!(V, v)\n    end\nend\n\n# Convert U and V to arrays\nU = reshape(U, length(xs), length(ys))\nV = reshape(V, length(xs), length(ys))\n\n# Plot the distribution using a heatmap\nheatmap(\n    -3:0.01:3, -3:0.01:3, p,\n    c=cgrad(:davos, rev=true),\n    aspect_ratio=:equal,\n    xlabel=\"x\", ylabel=\"y\", title=\"Ground Truth PDF q(x) with score\",\n    xlims=(-3, 3), ylims=(-3, 3),\n    xticks=[-3, 3], yticks=[-3, 3]\n)\n\n# Flatten the gradients and positions for quiver plot\nxxs_flat = [x for x in xs for y in ys]\nyys_flat = [y for x in xs for y in ys]\n\n# Plot the vector field\nquiver!(xxs_flat, yys_flat, quiver=(vec(U)/20, vec(V)/20), color=:green, quiverkeyscale=0.5)\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\nNow we apply a Gaussian kernel to the sample points to create the kernel density estimate:\n\n\nShow the code\nusing Plots, Distributions, KernelDensity\n\n# Convert points to x and y vectors\nx_points = [x for (x, y) in points]\ny_points = [y for (x, y) in points]\n\n# Perform kernel density estimation using KernelDensity.jl\nparzen = kde((y_points, x_points); boundary=((-3,3),(-3,3)), bandwidth = (.3,.3))\n\n# Plot the ground truth PDF\np1 = heatmap(\n    -3:0.01:3, -3:0.01:3, p,\n    c=cgrad(:davos, rev=true),\n    aspect_ratio=:equal,\n    xlabel=\"x\", ylabel=\"y\", title=\"Ground Truth PDF q(x)\",\n    xlims=(-3, 3), ylims=(-3, 3),\n    xticks=[-3, 3], yticks=[-3, 3]\n)\n\n# Scatter plot of the sampled points on top of the ground truth PDF\nscatter!(p1, x_points, y_points, label=\"Sampled Points\", color=:red, ms=2)\n\n\n# Plot the kernel density estimate\np2 = heatmap(\n    parzen.x, parzen.y, parzen.density,\n    c=cgrad(:davos, rev=true),\n    aspect_ratio=:equal,\n    xlabel=\"x\", ylabel=\"y\", title=\"Kernel Density Estimate\",\n    xlims=(-3, 3), ylims=(-3, 3),\n    xticks=[-3, 3], yticks=[-3, 3]\n)\n\n# Scatter plot of the sampled points on top of the kernel density estimate\nscatter!(p2, x_points,  y_points, label=\"Sampled Points\", color=:red, ms=2)\n\n# Arrange the plots side by side\nplot(p1, p2, layout = @layout([a b]), size=(800, 400))\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\nNow looking at the density estimate across many bandwidths, we can see the effect on adding more and more noise to the original sampled points and our density estimate that we are learning. At very large bandwidths the estimate becomes a uniform distribution.\n\n\nShow the code\nusing Plots, Distributions, KernelDensity\n# Define the range of bandwidths for the animation\nbandwidths = [(0.01 + 0.05 * i, 0.01 + 0.05 * i) for i in 0:40]\n\n# Create the animation\nanim = @animate for bw in bandwidths\n    kde_result = kde((x_points,y_points); boundary=((-6, 6), (-6, 6)), bandwidth=bw)\n\n    p2 = heatmap(\n        kde_result.x, kde_result.y, kde_result.density',\n        c=cgrad(:davos, rev=true),\n        aspect_ratio=:equal,\n        xlabel=\"x\", ylabel=\"y\", title=\"Kernel Density Estimate,Bandwidth = $(round(bw[1],digits=2))\",\n        xlims=(-6, 6), ylims=(-6, 6),\n        xticks=[-6, 6], yticks=[-6, 6]\n    )\n\n    scatter!(p2, x_points, y_points, label=\"Sampled Points\", color=:red, ms=2)\nend\n\n# Save the animation as a GIF\ngif(anim, \"parzen_density_animation_with_gradients.gif\", fps=2,show_msg = false)\n\n\n\n\n\nNow we can compute the score of the kernel density estimate to see how it changes with the bandwidth. The score function of the distribution is numerically unstable at regions of sparse data. Recalling that the score is the gradient of the log-density funtion, when the density is very low the function approaches negative infinity. Within the limits of numerical precision, taking the log of the density function will result in a negative infinity in sparse and low probability regions. Higher bandwidths of KDE using the Gaussian kernel for example, spread out both the discrete sampling and the true distribution over space. This extends the region of numerical stability for a higher bandwidth.\nThe regions with poor numerical stability can be seen as noise artifacts and missing data in the partial derivatives of the log-density function. Some of these artifacts may also propogate from the fourier transform calculations that the kernel density estimate uses.\n\n\nShow the code\nusing Plots, Distributions, KernelDensity, ForwardDiff\n\n# Define the range of bandwidths for the animation\nbandwidths = [(0.01 + 0.05 * i, 0.01 + 0.05 * i) for i in 0:30]\n\nboundary = (-10, 10)\n# Create the animation\nanim = @animate for bw in bandwidths\n    kde_result = kde((x_points, y_points); boundary=(boundary, boundary), bandwidth=bw)\n\n        # Compute log-density\n    log_density = log.(kde_result.density)\n\n    # Compute gradients of log-density\n    grad_x = zeros(size(log_density))\n    grad_y = zeros(size(log_density))\n\n    # Compute gradients using finite difference centered difference\n    for i in 2:size(log_density, 1)-1\n        for j in 2:size(log_density, 2)-1\n            grad_x[i, j] = (log_density[i+1, j] - log_density[i-1, j]) / (kde_result.x[i+1] - kde_result.x[i-1])\n            grad_y[i, j] = (log_density[i, j+1] - log_density[i, j-1]) / (kde_result.y[j+1] - kde_result.y[j-1])\n        end\n    end\n    # Downsample the gradients and coordinates by selecting every 10th point\n    downsample_indices_x = 1:10:size(grad_x, 1)\n    downsample_indices_y = 1:10:size(grad_y, 2)\n\n    grad_x_downsampled = grad_x[downsample_indices_x, downsample_indices_y]\n    grad_y_downsampled = grad_y[downsample_indices_x, downsample_indices_y]\n\n    x_downsampled = kde_result.x[downsample_indices_x]\n    y_downsampled = kde_result.y[downsample_indices_y]\n\n    xxs_flat = repeat(x_downsampled, inner=[length(y_downsampled)])\n    yys_flat = repeat(y_downsampled, outer=[length(x_downsampled)])\n\n    grad_x_flat = grad_x_downsampled[:]\n    grad_y_flat = grad_y_downsampled[:]\n\n    # Plot heatmaps of the gradients\n    p1 = heatmap(\n        kde_result.x, kde_result.y, grad_x',\n        c=cgrad(:davos, rev=true),\n        aspect_ratio=:equal,\n        xlabel=\"x\", ylabel=\"y\", title=\"Partial Derivative of Log-Density wrt x \\n Bandwidth = $(round(bw[1],digits=2))\",\n        xlims=boundary, ylims=boundary\n    )\n\n    # Overlay the scatter plot of the sampled points\n    scatter!(p1, x_points, y_points, label=\"Sampled Points\", color=:red, ms=2)\n\n    p2 = heatmap(\n        kde_result.x, kde_result.y, grad_y',\n        c=cgrad(:davos, rev=true),\n        aspect_ratio=:equal,\n        xlabel=\"x\", ylabel=\"y\", title=\"Partial Derivative of Log-Density wrt y \\n Bandwidth = $(round(bw[1],digits=2))\",\n        xlims=boundary, ylims=boundary\n    )\n\n    # Overlay the scatter plot of the sampled points\n    scatter!(p2, x_points, y_points, label=\"Sampled Points\", color=:red, ms=2)\n\n    plot(p1, p2, layout = @layout([a b]), size=(800, 400))\nend\n# Save the animation as a GIF\ngif(anim, \"parzen_density_partials.gif\", fps=2, show_msg=false)\n\n\n\n\n\nAnd combining the gradient overtop of the ground truth distribution that is modeled with the kernel density estimate, starting with the larger bandwidths and moving to the smaller bandwidths, we can see that the region of numerical stability is extended with the larger bandwidths. The larger bandwidths also remove some of the precision in the model, with larger bandwidths the model approaches a single gaussian distribution.\n\n\nShow the code\n# Define the range of bandwidths for the animation\nbandwidths = [(0.01 + 0.2 * i, 0.01 + 0.2 * i) for i in 0:10]\nbandwidths = reverse(bandwidths)\n\nboundary = (-10, 10)\n# Create the animation\nanim = @animate for bw in bandwidths\n    kde_result = kde((x_points, y_points); boundary=(boundary, boundary), bandwidth=bw)\n\n    # Compute log-density\n    log_density = log.(kde_result.density)\n\n    # Compute gradients of log-density\n    grad_x = zeros(size(log_density))\n    grad_y = zeros(size(log_density))\n\n    # Compute gradients using finite difference centered difference\n    for i in 2:size(log_density, 1)-1\n        for j in 2:size(log_density, 2)-1\n            grad_x[i, j] = (log_density[i+1, j] - log_density[i-1, j]) / (kde_result.x[i+1] - kde_result.x[i-1])\n            grad_y[i, j] = (log_density[i, j+1] - log_density[i, j-1]) / (kde_result.y[j+1] - kde_result.y[j-1])\n        end\n    end\n    # Downsample the gradients and coordinates by selecting every 10th point\n    downsample_indices_x = 1:20:size(grad_x, 1)\n    downsample_indices_y = 1:20:size(grad_y, 2)\n\n    grad_x_downsampled = grad_x[downsample_indices_x, downsample_indices_y]\n    grad_y_downsampled = grad_y[downsample_indices_x, downsample_indices_y]\n\n    x_downsampled = kde_result.x[downsample_indices_x]\n    y_downsampled = kde_result.y[downsample_indices_y]\n\n    xxs_flat = repeat(x_downsampled, inner=[length(y_downsampled)])\n    yys_flat = repeat(y_downsampled, outer=[length(x_downsampled)])\n\n    grad_x_flat = grad_x_downsampled[:]\n    grad_y_flat = grad_y_downsampled[:]\n\n     # Plot the actual distribution\n    x_range = boundary[1]:0.01:boundary[2]\n    y_range = boundary[1]:0.01:boundary[2]\n    p1 = heatmap(\n        x_range, y_range, p,\n        c=cgrad(:davos, rev=true),\n        aspect_ratio=:equal,\n        xlabel=\"x\", ylabel=\"y\", title=\"Ground Truth PDF q(x)\\n with score of Kernel Density Estimate, \\n Bandwidth = $(round(bw[1],digits=2))\",\n        xlims=boundary, ylims=boundary,\n        size=(800, 800)\n    )\n\n    # Plot a quiver plot of the downsampled gradients\n    quiver!(yys_flat, xxs_flat, quiver=(grad_x_flat/10, grad_y_flat/10), \n    color=:green, quiverkeyscale=0.5, aspect_ratio=:equal)\nend\n# Save the animation as a GIF\ngif(anim, \"parzen_density_gradient_animation_with_gradients.gif\", fps=2, show_msg=false)\n\n\n\n\n\n\n\n\n\n\nReferences\n\nKrizhevsky, Alex. 2009. “Learning Multiple Layers of Features from Tiny Images.” https://www.cs.toronto.edu/~kriz/cifar.html."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Posts",
    "section": "",
    "text": "Generative Modeling for Structural Geology\n\n\nMaterials from the CUPC 2024 Conference\n\n\nA copy of the conference poster and presentation slides for the 2024 Canadian Association of Physicists Undegraduate Research Conference held at UBC\n\n\n\n\n\nOct 21, 2024\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nScore Matching for Density Estimation\n\n\nEstimation of the probability density function using score matching\n\n\nScore matching is a method for indirectly estimating the probability density function of a distribution. In this post, I will explain the score matching method as well as some of its limitations.\n\n\n\n\n\nJun 22, 2024\n\n\n17 min\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome\n\n\nA first post using Quarto\n\n\nFind out more about the tools I’m using to create this blog.\n\n\n\n\n\nApr 22, 2024\n\n\n4 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/CAP-conference-poster/index.html",
    "href": "blog/posts/CAP-conference-poster/index.html",
    "title": "Generative Modeling for Structural Geology",
    "section": "",
    "text": "CUPC Conference Poster\n\nThis is an embedded &lt;a target=\"_blank\" href=\"https://office.com\"&gt;Microsoft Office&lt;/a&gt; presentation, powered by &lt;a target=\"_blank\" href=\"https://office.com/webapps\"&gt;Office&lt;/a&gt;.\n\n\n\nConference PresentationThis is an embedded &lt;a target=\"_blank\" href=\"https://office.com\"&gt;Microsoft Office&lt;/a&gt; presentation, powered by &lt;a target=\"_blank\" href=\"https://office.com/webapps\"&gt;Office&lt;/a&gt;."
  },
  {
    "objectID": "blog/posts/welcome/index.html",
    "href": "blog/posts/welcome/index.html",
    "title": "Welcome",
    "section": "",
    "text": "This year, I have been expanding my knowledge of publishing and coding techniques that are designed to make sharing technical work easier, more visual, and more interactive. Michael Friedlander, who teaches CPSC 406 Computational Optimization at UBC, is an advocate for using Julia and Quarto in teaching and research. Drawing inspiration from his work along with Patrick Altmeyer’s website, I have decided to start my own blog using Quarto.\nQuarto is a scientific and technical publishing system built on Pandoc. It is designed to make it easy to write and publish technical content, such as research papers, books, and reports. One of its main features is that it allows for writing content in markdown along with code chunks in Julia, Python, R, and other languages. In addition, Quarto supports a wide range of output formats, including HTML, PDF, and Word. It has the great convenience of being able to port writing from Obsidian or in Latex to a blog post or html with minimal effort.\nI’m excited to use this new tool to share my work and ideas, especially as I continue to learn more about data science, machine learning, and optimization. I hope you find the content here useful and/or interesting."
  },
  {
    "objectID": "blog/posts/welcome/index.html#examples-of-julia-code-and-plots",
    "href": "blog/posts/welcome/index.html#examples-of-julia-code-and-plots",
    "title": "Welcome",
    "section": "Examples of Julia Code and Plots",
    "text": "Examples of Julia Code and Plots\nHere’s a parametrically defined, snail-like surface. Although it exists in 3D space, the surface is two-dimensional in that any location on it can be specified using just two coordinates—similar to how we navigate the surface of the Earth. You van see this incorporated as the two parameters \\(u\\) and \\(v\\) in the code below. These two coordinates map into 3D space that is defined by the functions \\(s1\\), \\(s2\\), and \\(s3\\) giving a vector \\[\\mathbf{s}(u,v) = \\begin{bmatrix}s1(u,v) \\\\ s2(u,v) \\\\ s3(u,v)\\end{bmatrix}\\]\nThe surface is then plotted using the surface function from the Julia Plots package.\nNote the usage of the vectorized operation of the functions \\(s1\\), \\(s2\\), and \\(s3\\) to create the vectors xs, ys, and zs. The passing of the input vectors u and v' creates the required meshgrid for the surface plot.\n\n\nShow the code\nusing Plots\n\n# Your plotting code here\nu = range(0, stop=6π, length=100)\nv = range(0, stop=2π, length=30)\ns1(u, v) = 2 * (1 - exp(u / (6 * π))) * cos(u) * cos(v / 2)^2\ns2(u, v) = 2 * (-1 + exp(u / (6 * π))) * sin(u) * cos(v / 2)^2\ns3(u, v) = 1 - 0.71 * exp(u / (3 * π)) - sin(v) + exp(u / (6 * π)) * sin(v)\n\nxs, ys, zs = s1.(u, v'), s2.(u, v'), s3.(u, v')\nsurface(xs, ys, zs, color=cgrad(:acton), alpha=0.5, legend=false)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Surface Plot Example\n\n\n\n\nThis code is an example of the animation features included in the Julia Plot library found at Julia Plots Package that can be used to create a gif. The gif below shows a parametric plot of a heart. Note just how compact the code is for creating this gif and the natural expression that the code has. This is the power of Julia.\n\n\nShow the code\nusing Plots\n\n@userplot CirclePlot\n@recipe function f(cp::CirclePlot)\n    x, y, i = cp.args\n    n = length(x)\n    inds = circshift(1:n, 1 - i)\n    linewidth --&gt; range(0, 10, length = n)\n    seriesalpha --&gt; range(0, 1, length = n)\n    aspect_ratio --&gt; 1\n    label --&gt; false\n    x[inds], y[inds]\nend\n\nn = 400\nt = range(0, 2π, length = n)\nx = 16sin.(t).^3\ny = 13cos.(t) .- 5cos.(2t) .- 2cos.(3t) .- cos.(4t)\n\nanim = @animate for i ∈ 1:n\n    circleplot(x, y, i, line_z = 1:n, cbar = false, c = :reds, framestyle = :none)\nend every 5\ngif(anim, \"anim_fps15.gif\", fps = 15, show_msg = false)\n\n\n\n\n\n\n\nFigure 2: Heart Animation Example"
  },
  {
    "objectID": "content/about/overview.html",
    "href": "content/about/overview.html",
    "title": "Simon Ghyselincks",
    "section": "",
    "text": "Welcome to my personal site! I’m Simon Ghyselincks, currently a 5th-year Engineering Physics student at the University of British Columbia (UBC), with a minor in Computer Science. I am studying a cross-disciplinary blend of engineering, computer science, and applied mathematics. What I really love is coding to solve tough problems in robotics, machine learning, signal processing, and more."
  },
  {
    "objectID": "content/about/overview.html#welcome",
    "href": "content/about/overview.html#welcome",
    "title": "Simon Ghyselincks",
    "section": "",
    "text": "Welcome to my personal site! I’m Simon Ghyselincks, currently a 5th-year Engineering Physics student at the University of British Columbia (UBC), with a minor in Computer Science. I am studying a cross-disciplinary blend of engineering, computer science, and applied mathematics. What I really love is coding to solve tough problems in robotics, machine learning, signal processing, and more."
  },
  {
    "objectID": "content/about/overview.html#academics-and-projects",
    "href": "content/about/overview.html#academics-and-projects",
    "title": "Simon Ghyselincks",
    "section": "Academics and Projects",
    "text": "Academics and Projects\nI am currently working with Eldad Haber at UBC Earth and Ocean Sciences on generative AI for geophysical applications. Our work explores the application of recent advances in normalizing flows with stochastic interpolants to generate 3d models of the earth’s crust. I am also continuing to develop our Engineering Physics capstone project “Learning to Balance” which explores the application of reinforcement learning to a reaction wheel robot with complex dynamics. Read more about my projects here.\n\nFeel free to connect with me on LinkedIn or check out my GitHub."
  },
  {
    "objectID": "content/about/overview.html#my-journey",
    "href": "content/about/overview.html#my-journey",
    "title": "Simon Ghyselincks",
    "section": "My Journey",
    "text": "My Journey\nRead more about my journey and past pursuits here."
  },
  {
    "objectID": "content/eosc555/index.html",
    "href": "content/eosc555/index.html",
    "title": "EOSC 555B: Nonlinear Inverse Theory",
    "section": "",
    "text": "Lecture notes for EOSC 555B: Nonlinear Inverse Theory taken at the University of British Columbia. Portions of template code originate from the course instrcutor Prof. Eldad Haber, while I’ve added some of my own numerical experiments and examples explored as part of self-study on the topics.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 7: Applying Homotopy to Optimize Highly Non-Convex Functions\n\n\nA look at how Gaussian homotopy can be used to escape local minima in optimization problems.\n\n\nGaussian homotopy is a technique that can be used to effectively broadcast the gradient of a non-convex function outward to help escape local minima.\n\n\n\n\n\nOct 22, 2024\n\n\n13 min\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 6: Autodiff and Implementing Gauss-Newton\n\n\nA look at some of the foundations of automatic differentiation and the Gauss-Newton optimization method.\n\n\nAutomatic differentiation is a powerful tool for solving optimization problems that can be used to automate the process of Gauss-Newton optimization. Here we put together an implementation of the Gauss-Newton method using PyTorch.\n\n\n\n\n\nOct 8, 2024\n\n\n23 min\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 5: Gauss Newton\n\n\nNon-Linear Least Squares Optimization\n\n\nThe Gauss-Newton method is a powerful optimization technique for solving non-linear least squares problems of the form \\(\\min_{p} \\frac{1}{2}\\|F(p)-d\\|^2\\). In this lecture, a derivation of the method is presented along with a comparison to Newton’s method. Finally an algorithm for solving the problem is given.\n\n\n\n\n\nSep 25, 2024\n\n\n17 min\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 4: Regularization and the Conjugate Gradient Methods\n\n\nA derivation of regularization techniques for least squares\n\n\nTikhonov regularization is a common technique used in inverse theory to stabilize ill-posed problems. In this lecture, we derive the Tikhonov regularization technique, we also have a look at a least squares solution that does not require the computation of the full SVD of the matrix \\(A\\), using the conjugate gradient method.\n\n\n\n\n\nSep 20, 2024\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 3: Image Denoising with Gradient Descent and Early Stopping\n\n\nA derivation of least squares gradient descent and ODE analysis\n\n\nIn continuation of Lecture 2, we now look at an alternative approach to image denoising using gradient descent and early stopping. We will derive the least squares gradient descent algorithm and analyze it as an ordinary differential equation.\n\n\n\n\n\nSep 17, 2024\n\n\n22 min\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 2: Image Denoising with SVD\n\n\nApplications of Least Squares and SVD\n\n\nImage denoising and deblurring are important techniques in signal processing and recovery. I this coding exercise, we will explore the application of least squares, SVD, and the pseudoinverse to denoise and deblur images.\n\n\n\n\n\nSep 15, 2024\n\n\n22 min\n\n\n\n\n\n\n\n\n\n\n\n\nLecture 1: Introduction to Inverse Theory\n\n\nLeast Squares and the SVD\n\n\nInverse theory has broad applications across many scientific disciplines. This lecture introduces the concept of least squares and the singular value decomposition (SVD) as a foundation for understanding inverse theory. We then use these properties to analyse the stability and conditioning of linear systems for solving inverse problems using the pseudoinverse and ML techniques.\n\n\n\n\n\nSep 14, 2024\n\n\n11 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/eosc555/lectures/lecture2/index.html",
    "href": "content/eosc555/lectures/lecture2/index.html",
    "title": "Lecture 2: Image Denoising with SVD",
    "section": "",
    "text": "The motivation for the exercise comes from a real world problem. The Hubble space telescope when launched had a defect in its mirror. This defect caused the images to be blurred. The problem was initially addressed by using signal processing techniques to remove the aberrations from the images.\n\n\nFor such an image processing problem, we can consider the continuous incoming light as striking a 2D mirror that distorts the light, followed by a 2D sensor that captures the light. In this context we suppose that we have a noise kernel or a point spread function (PSF) that describes the distortion of the light at the mirror. The point spread function, being a convolution kernel, behaves as a Green’s function for the system in the continuous case:\n\\[ \\vec{b}(x,y) = \\int_{\\mathcal{X}} \\int_{\\mathcal{Y}} \\vec{G}(x - x', y - y') \\vec{u}(x',y') \\, dx' dy' \\]\nwhere \\(\\vec{b}(x,y)\\) is the blurred image data that is recovered at the sensor, \\(\\vec{u}(x',y')\\) is the true image data, and \\(\\vec{G}(x,y)\\) is the point spread function.\nIn the special case that the point spread function is \\(\\delta(x-x',y-y')\\), then the image data is not distorted and the sensor captures the true image data. However our experiment is to consider cases where there could be even severe distortions and see how this impacts the proposition of recovering the true image data, \\(\\vec{u}(x',y')\\) from our sensor data, \\(\\vec{b}(x,y)\\).\n\n\nThe discrete analog of the continuous PSF can be more conveniently treated with we essentially flatten the the 2D mesh into a 1D vector, a common operation for signal processing. The unflattened case we have:\n\\[ b_{ij} = \\sum_{k=1}^{n} \\sum_{l=1}^{m} \\Delta x \\Delta y G(x_i - x_k, y_j - y_l) u_{kl} \\]\nwhere \\(b\\) is the blurred image data at the sensor, \\(u\\) is the true image data, and \\(G\\) is the discrete point spread function. If we flatten the 2D mesh into a 1D vector we can represent this as a 1D convolution operation: \\[ \\vec{b} = \\vec{G} * \\vec{u} \\]\nSince this is a convolution operation, we can process it much more quickly by leveraging the convolution theorem.\n\\[\\begin{align}\n\\mathcal{F}(\\vec{b}) &= \\mathcal{F}(\\vec{G} * \\vec{u}) \\\\\n\\mathcal{F}(\\vec{b}) &= \\mathcal{F}(\\vec{G}) \\mathcal{F}(\\vec{u}) \\\\\n\\vec{b} &= \\mathcal{F}^{-1}(\\mathcal{F}(\\vec{G}) \\odot \\mathcal{F}(\\vec{u}))\n\\end{align}\n\\]\nThe \\(\\odot\\) hadamard product is element-wise multiplication, the discrete analog of multiplication of two functions except over an array.\n\n\n\n\nIf we flatten the data down into a 1D vector then it is possible to construct a matrix operator that performs the convolution. This is a Toeplitz matrix, a matrix where each descending diagonal from left to right is constant, so that the row vectors represent a sliding window of the convolution kernel. We can flatten out the PSF and construct the matrix using it as the first row entry and then shifting the PSF to the right to fill out the rest of the rows."
  },
  {
    "objectID": "content/eosc555/lectures/lecture2/index.html#least-squares-recovery-with-svd-and-pseudoinverse",
    "href": "content/eosc555/lectures/lecture2/index.html#least-squares-recovery-with-svd-and-pseudoinverse",
    "title": "Lecture 2: Image Denoising with SVD",
    "section": "Least Squares Recovery with SVD and Pseudoinverse",
    "text": "Least Squares Recovery with SVD and Pseudoinverse\nNow that we have a matrix operator recovered we can formulate the forward problem as \\(A\\mathbf{x} = \\mathbf{b}\\) with our known \\(A\\) and \\(\\mathbf{b}\\), and we want to recover \\(\\mathbf{x}\\). To do this we use the SVD decomposition to gather the pseudo inverse. We can decide to filter out some of the singular values that are very small to improve the conditioning on the matrix as well, using a cutoff value for example.\n\nSVD Decomposition\n\n\nShow the code\nU, S, V = torch.svd(Amat.to(torch.float64))\nb = Amv(x)\n\n\nNow we make a log plot of the singular values to see how they decay, noting that we lose numerical precision around the \\(10^{-6}\\) mark. We can also asses what the frobenius norm of the difference between the original matrix and the reconstructed matrix is to get a sense of the error in the decomposition and reconstruction.\n\n\nShow the code\nplt.semilogy(S)\nplt.xlabel('Singular Value Index')\nplt.ylabel('Singular Value')\n\nloss = F.mse_loss(Amat, U @ torch.diag(S) @ V.T)\nprint(f\"The loss is {loss}\")\n\n\nThe loss is 1.812403923995022e-34\n\n\n\n\n\nSVD Decomposition of the Convolution Matrix.\n\n\n\n\nThe loss is quite small which is a good sign that the decomposition is working well within the numerical precision of the machine.\n\n\nInitial Attempt at Pseudoinverse\nTo recover the original image data we first naively try to invert the matrix to see what happens.\n\n\nShow the code\nxhat = torch.linalg.solve(Amat,b.reshape(dim**2))\nplt.subplot(1,2,1)\nplt.imshow(xhat.reshape(x.shape[-2:]))\nplt.title('Naive Inverse')\nplt.subplot(1,2,2)\nplt.imshow(x.reshape(x.shape[-2:]))\nplt.title('Original Image');\n\n\n\n\n\nNaive Pseudoinverse Recovery of the Original Image.\n\n\n\n\nWow, not even close! This is because the matrix is so ill conditioned that it is effectively low rank and not invertible. We can improve the situation by filtering out the singular values that are very small.\n\n\nPseudoinverse with Filtering\nWe can filter out the poor conditioning singular values and exclude those values from the inversion. To get an idea of what the values are doing, we can plot the first few singular values and the corresponding singular vector that they project onto. In the case of the SVD the most important information about the matrix is captured in the left-most vectors of the matrix \\(U\\).\n\n\nShow the code\nn= 5\nfor i in range(n):\n  plt.subplot(1,n,i+1)\n  plt.imshow(U[:,i+1].reshape(x.shape[-2:]))\n  plt.title(f'Mode {i}')\n\n\n\n\n\n\n\n\n\nFor the inverse problem, the most import singular values are conversely found in the left-most vectors of the matrix \\(V\\). We can also check what the right-most vectors are doing, as they will blow up in value when inverting small singular values. They are high frequency modes of the image, creating the reconstruction issues when they are subjected to error in numerical precision.\n\n\nShow the code\nn= 5\nfor i in range(n):\n  plt.subplot(1,n,i+1)\n  plt.imshow(V[:,i+1].reshape(x.shape[-2:]))\n  plt.title(f'Mode {i}')\nplt.show()\n\nfor i in range(n):\n  plt.subplot(1,n,i+1)\n  plt.imshow(V[:,-(i+1)].reshape(x.shape[-2:]))\n  plt.title(f'Mode {V.shape[1]-i}')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThese modes are the most important ones, as they contain the big-picture detail without the high frequency noise. We can now filter out the singular values that are very small and invert the matrix to recover the original image.\n\n\nShow the code\nb_flat = b.flatten().to(torch.float64)\nx_flat = x.flatten().to(torch.float64)\nthresholds = [1e-1, 1e-3, 1e-6, 1e-7, 1e-8, 1e-10]\n\nplt.figure(figsize=(7,5))  # Adjust the figure size as needed\n\nfor idx, threshold in enumerate(thresholds):\n    # Filter the singular values\n    S_filtered = S.clone()\n    S_filtered[S_filtered &lt; threshold] = 0\n\n    # Compute the reciprocal of the filtered singular values\n    S_inv = torch.zeros_like(S_filtered)\n    non_zero_mask = S_filtered &gt; 0\n    S_inv[non_zero_mask] = 1 / S_filtered[non_zero_mask]\n\n    # Construct the pseudoinverse of Amat\n    A_pinv = V @ torch.diag(S_inv) @ U.T\n\n    # Reconstruct the original image\n    xhat = A_pinv @ b_flat\n\n    # Compute the reconstruction error\n    error = torch.norm(xhat - x_flat, p='fro').item()\n\n    # Plot the reconstructed image in the appropriate subplot\n    plt.subplot(2, 3, idx + 1)  # idx + 1 because subplot indices start at 1\n    plt.imshow(xhat.reshape(x.shape[-2:]))\n    plt.title(f'Threshold {threshold}\\nError: {error:.4f}')\n    plt.colorbar()\n    plt.axis('off')  # Optionally turn off axis ticks and labels\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nPseudoinverse Recovery of the Original Image with Filtering.\n\n\n\n\nLooking at the results, around the \\(10^{-7}\\) mark we start to a peak level of recovery, as measured by the error in the Frobenius norm of the reconstruction. But what happens when we add noise to the data signal?\n\n\nAdding Noise to the Signal\nNow we add some noise to the signal and try least squares again for the direct solution\n\n\nShow the code\nb_flat = b.flatten().to(torch.float64)\nx_flat = x.flatten().to(torch.float64)\nAmat = Amat.to(torch.float64)\n\nalpha = .01\nnoise = torch.randn_like(b_flat) * alpha\n\nH = Amat.T @ Amat + alpha**2 * torch.eye(Amat.shape[0])\nxhat = torch.linalg.solve(H, Amat.T @ (b_flat + noise))\n\nplt.subplot(1,2,1)\nplt.imshow(x[0,0])\nplt.title('Original Image')\nplt.subplot(1,2,2)\nplt.imshow(xhat.reshape(x.shape[-2:]))\nplt.title('Reconstructed Image');\n\n\n\n\n\nPseudoinverse Recovery of the Original Image with Noise.\n\n\n\n\nThe reconstruction is not very good, the noise has been amplifed all over the image. We can try the pseudoinverse method again with the noise added to the signal.\n\n\nShow the code\nAmat_noisy = Amat + alpha * torch.eye(Amat.shape[0])\nUn, Sn, Vn = torch.svd(Amat_noisy)\n\nthresholds = [.5, .1, .05, .03, .005, .001]\n\nplt.figure(figsize=(7,5))  # Adjust the figure size as needed\n\nfor idx, threshold in enumerate(thresholds):\n    # Filter the singular values\n    S_filtered = Sn.clone()\n    S_filtered[S_filtered &lt; threshold] = 0\n\n    # Compute the reciprocal of the filtered singular values\n    S_inv = torch.zeros_like(S_filtered)\n    non_zero_mask = S_filtered &gt; 0\n    S_inv[non_zero_mask] = 1 / S_filtered[non_zero_mask]\n\n    # Construct the pseudoinverse of Amat\n    A_pinv = Vn @ torch.diag(S_inv) @ Un.T\n\n    # Reconstruct the original image\n    xhat = A_pinv @ (b_flat + noise)\n\n    # Compute the reconstruction error\n    error = torch.norm(xhat - x_flat, p='fro').item()\n\n    # Plot the reconstructed image in the appropriate subplot\n    plt.subplot(2, 3, idx + 1)  # idx + 1 because subplot indices start at 1\n    plt.imshow(xhat.reshape(x.shape[-2:]))\n    plt.title(f'Threshold {threshold}\\nError: {error:.4f}')\n    plt.colorbar()\n    plt.axis('off')  # Optionally turn off axis ticks and labels\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nPseudoinverse Recovery of the Original Image with Noise.\n\n\n\n\nThe small addition of noise is quite significant in the recovery threshold for reconstruction. Using a higher threshold for the singular values becomes important when dealing with noise in the signal. Previously numerical precision was the main issue, but now the measurement noise is the main issue."
  },
  {
    "objectID": "content/eosc555/lectures/lecture4/index.html",
    "href": "content/eosc555/lectures/lecture4/index.html",
    "title": "Lecture 4: Regularization and the Conjugate Gradient Methods",
    "section": "",
    "text": "$$ \n$$"
  },
  {
    "objectID": "content/eosc555/lectures/lecture4/index.html#tikhnov-regularization",
    "href": "content/eosc555/lectures/lecture4/index.html#tikhnov-regularization",
    "title": "Lecture 4: Regularization and the Conjugate Gradient Methods",
    "section": "Tikhnov Regularization",
    "text": "Tikhnov Regularization\nWe have looked at the least squares formulation for solving inverse problems:\n\\[ \\min \\frac{1}{2} \\|A x - b\\|^2 \\]\nwhere \\(A \\in \\mathbb R^{m \\times n}\\) is a linear operator, \\(x \\in \\mathbb R^n\\) is the unknown model, and \\(b \\in \\mathbb R^m\\) is the data.\nThe least squares problem is often ill-posed, meaning that the solution is not unique or stable. If there are more unknowns than equations, such as the case when \\(n &gt; m\\), then the problem is underdetermined and there are infinitely many solutions.\nWe can return to unique solutions by adding a regularization term to the selection of the \\(x\\) that we want to minimize. The Tikhonov regularization technique adds a penalty term to the least squares problem:\n\\[ \\min \\frac{1}{2} \\|A x - b\\|^2 + \\frac{1}{2}  \\lambda \\|Lx\\|^2 \\]\nwhere \\(L \\in \\mathbb R^{n \\times n}\\) is a regularization matrix. The regularization matrix \\(L\\) is often chosen to be the identity matrix, but other choices are possible.\n\nUniqueness\nTo check the uniqueness of the solution, we can rewrite the problem as a quadratic form:\n\\[ \\min \\frac{1}{2} x^T A^T A x - b^T A x + \\frac{1}{2} \\lambda x^T L^T L x \\] \\[ = \\min \\frac{1}{2} x^T H x - b^T A x + \\frac{1}{2}\\|b\\|^2\\]\nwhere \\(H = A^T A + \\lambda L^T L\\) is the Hessian matrix which is symmetric and positive semi-definite by spectral theorem. If we choose an appropriate \\(\\lambda\\), then the Hessian matrix is positive definite and the problem is well-posed. In the case where \\(L=I\\), the Hessian becomes full rank for \\(\\lambda &gt; 0\\) and the problem is well-posed. The quality that \\(H \\succ 0\\) means that the matrix is invertible.\n\n\nSolution\nThe unique solution is given by by the first order optimatility condition:\n\\[ \\begin{align}\n(A^T A + \\lambda L^T L) \\mathbf{x}_{\\text{RLS}} - A^T b&= 0 \\\\\n\\mathbf{x}_{\\text{RLS}} &= (A^T A + \\lambda L^T L)^{-1} A^T b\n\\end{align}\n\\]\n\n\nSVD Decomposition\nThe solution can be written in terms of the singular value decomposition of \\(A\\), and with the assumption that \\(L=I\\):\n\\[ \\begin{align}\nA &= U \\Sigma V^T \\\\\nA^T A &= V \\Sigma^T \\Sigma V^T \\\\\n\\mathbf{x}_{\\text{RLS}} &= \\left( V \\Sigma^2 V^T + \\lambda I \\right)^{-1} V \\Sigma^T U^T b \\\\\n&= \\left( V \\Sigma^2 V^T + \\lambda I V V^T \\right)^{-1} V \\Sigma^T U^T b\\\\\n&= V \\left( \\Sigma^2 + \\lambda I \\right)^{-1} \\Sigma^T U^T b\\\\\n&= V \\mathbf{Diag}\\left( \\frac{\\sigma_i}{\\sigma_i^2 + \\lambda} \\right) U^T b\\\\\n&= \\sum _i ^ n \\frac{\\sigma_i}{\\sigma_i^2 + \\lambda} \\langle u_i, b \\rangle v_i\n\\end{align}\n\\]\nThis form is more readily comparable to some of the other methods that we have see so far, which are presented in the table below:"
  },
  {
    "objectID": "content/eosc555/lectures/lecture4/index.html#comparison-of-least-squares-methods",
    "href": "content/eosc555/lectures/lecture4/index.html#comparison-of-least-squares-methods",
    "title": "Lecture 4: Regularization and the Conjugate Gradient Methods",
    "section": "Comparison of Least Squares Methods",
    "text": "Comparison of Least Squares Methods\n\n\n\n\n\n\n\nMethod\nSolution\n\n\n\n\nTikhonov\n\\(x_{\\text{RLS}} = \\sum _i ^ n \\frac{\\sigma_i}{\\sigma_i^2 + \\lambda} \\langle u_i, b \\rangle v_i\\)\n\n\nThresholded SVD\n\\(x_{\\text{TSVD}} = \\sum _i ^ n h(\\sigma_i) \\langle u_i, b \\rangle v_i\\)\n\n\nGradient Flow\n\\(x_{\\text{SDF}} = \\sum _i ^ n \\frac{\\exp(-\\sigma_i^2 t) - 1}{\\sigma_i} \\langle u_i, b \\rangle v_i\\)\n\n\n\nAs we can see all three methods have a similar form and offer some mechanism for controlling the noise induced by the small singular values of \\(A\\).\n\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef generate_ill_conditioned_matrix(m, n, condition_number):   \n    # Generate random orthogonal matrices U and V\n    U, _ = np.linalg.qr(np.random.randn(m, m))\n    V, _ = np.linalg.qr(np.random.randn(n, n))\n    \n    sigma = np.linspace(1, 1/condition_number, min(m, n))    \n    Sigma = np.diag(sigma)    \n    A = U @ Sigma @ V[:min(m, n), :]\n    \n    return A, sigma\n\n# Seed for reproducibility\nnp.random.seed(4)\nA, S = generate_ill_conditioned_matrix(8, 24, 1e3)\n\n# Create a vector b of size 5 with random values\nb = np.random.randn(8)\n\n# Compute the SVD of A\nU, S, Vt = np.linalg.svd(A, full_matrices=False)\nV = Vt.T\nU = U  # Already in proper shape\n\n# Number of singular values\nn = len(S)\n\n# Define parameters for each method\n# Gradient Flow\nt_values = np.linspace(0, 0.6, 100)\n\n# Tikhonov Regularization\nlambda_values = np.linspace(1e-4, 1, 100)\n\n# Thresholded SVD\nthreshold_values = np.linspace(0, max(S), 100)\n\n# Compute scaling factors for each method\n# Gradient Flow Scaling\ndef gradient_flow_scaling(sigma, t):\n    return (1 - np.exp(-sigma**2 * t)) / sigma\n\ngradient_scalings = np.array([gradient_flow_scaling(s, t_values) for s in S])\n\n# Tikhonov Scaling\ndef tikhonov_scaling(sigma, lambd):\n    return sigma / (sigma**2 + lambd)\n\ntikhonov_scalings = np.array([tikhonov_scaling(s, lambda_values) for s in S])\n\n# Thresholded SVD Scaling\ndef tsvd_scaling(sigma, threshold):\n    return np.where(sigma &gt;= threshold, 1/sigma, 0)\n\ntsvd_scalings = np.array([tsvd_scaling(s, threshold_values) for s in S])\n\n# Initialize the plot with 3 subplots\nfig, axes = plt.subplots(3, 1, figsize=(5, 15))\n\n# Define a color palette\npalette = sns.color_palette(\"husl\", n)\n\n# Plot Gradient Flow\nax = axes[0]\nfor i in range(n):\n    ax.plot(t_values, gradient_scalings[i], color=palette[i], linewidth=2, label=f'$1/\\sigma_{i}$' )\n    ax.axhline(y=1/S[i], color=palette[i], linestyle='--', linewidth=1)\nax.set_yscale('log')\nax.set_xlabel('Time (t)', fontsize=14)\nax.set_ylabel('Scaling Factor', fontsize=14)\nax.set_title('Gradient Flow', fontsize=16)\nax.legend()\nax.grid(True)\n\n# Plot Tikhonov Regularization\nax = axes[1]\nfor i in range(n):\n    ax.plot(lambda_values, tikhonov_scalings[i], color=palette[i], linewidth=2, label=f'$1/\\sigma_{i}$' )\n    ax.axhline(y=1/S[i], color=palette[i], linestyle='--', linewidth=1)\nax.set_yscale('log')\nax.set_xlabel('Regularization Parameter (λ)', fontsize=14)\nax.set_ylabel('Scaling Factor', fontsize=14)\nax.set_title('Tikhonov Regularization', fontsize=16)\nax.legend()\nax.grid(True)\n\n# Plot Thresholded SVD\nax = axes[2]\nfor i in range(n):\n    ax.plot(threshold_values, tsvd_scalings[i], color=palette[i], linewidth=2, label=f'$1/\\sigma_{i}$')\n    ax.axhline(y=1/S[i], color=palette[i], linestyle='--', linewidth=1)\nax.set_yscale('log')\nax.set_xlabel('Threshold (τ)', fontsize=14)\nax.set_ylabel('Scaling Factor', fontsize=14)\nax.set_title('Thresholded SVD', fontsize=16)\nax.legend()\nax.grid(True)\n\n# Adjust layout and add a legend\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nEvolution of scaling factors for three different methods"
  },
  {
    "objectID": "content/eosc555/lectures/lecture4/index.html#solving-least-squares-using-conjugate-gradient",
    "href": "content/eosc555/lectures/lecture4/index.html#solving-least-squares-using-conjugate-gradient",
    "title": "Lecture 4: Regularization and the Conjugate Gradient Methods",
    "section": "Solving Least Squares Using Conjugate Gradient",
    "text": "Solving Least Squares Using Conjugate Gradient\nA detailed explanation of this method can be found at Wikipedia\n\nConjugate Vectors Definition\nA set of vectors \\(\\{ p_1, p_2, \\ldots, p_n \\}\\) is said to be conjugate with respect to a matrix \\(A\\) if:\n\\[\n\\langle p_i, A p_j \\rangle = 0 \\quad \\text{for all } i \\neq j\n\\]\nThis is a generalization of the concept of orthoganality to non-symmetric matrices.\nStandard Orthogonality: When $ A = I $ (the identity matrix), the definition reduces to the standard concept of orthogonality. For a symmetric \\(A\\) we also have an orthogonal decomposition of eigenvectors by spectral theorem.\n\nBack to the problem of least squares, we can express the solution $ x $ as a linear combination of conjugate vectors:\n\\[\nx = x_0 + \\sum_{i=1}^n \\alpha_i p_i\n\\]\nwhere:\n\n\\(x_0\\) is an initial guess (can be zero).\n\\(\\alpha_i\\) are scalar coefficients.\n\\(p_i\\) are conjugate vectors with respect to \\(A\\).\n\nTo recover the coefficients of \\(\\alpha_i\\) we can use a projection in the weighted space of \\(A\\):\n\\[ \\begin{align}\nA x_0 + \\sum_{i=1}^n \\alpha_i A p_i &= b\\\\\nr &= b - A x_0\\\\\n\\sum_{i=1}^n \\alpha_i A p_i &= r\\\\\n\\langle p_i, \\sum_{i=1}^n \\alpha_i A p_i \\rangle &= \\langle p_i, r \\rangle\\\\\n\\alpha_i \\langle p_i, A p_i \\rangle &= \\langle p_i, r \\rangle\\\\\n\\alpha_i &= \\frac{\\langle p_i, r \\rangle}{\\langle p_i, A p_i \\rangle}\n\\end{align}\n\\] In the case where \\(x_0\\) is zero, then this reduces to \\[ \\alpha_i = \\frac{\\langle p_i, b \\rangle}{\\langle p_i, A p_i \\rangle} \\]\n\n\nAlgorithm Steps\nInitialize:\n\n\\(x = x_0\\)\n\\(r_0 = b - A x_0\\)\n\\(p_0 = r_0\\)\n\nFor \\(i = 0,1, 2, \\ldots\\):\n\nCompute \\(\\alpha_i\\):\n\\[\n\\alpha_i = \\frac{\\langle r_i, r_i \\rangle}{\\langle p_i, A p_i \\rangle}\n\\]\nUpdate Solution \\(x\\):\n\\[\nx_{i+1} = x_{i} + \\alpha_i p_i\n\\]\nUpdate Residual \\(r\\):\n\\[\nr_{i+1} = r_{i} - \\alpha_i A p_i\n\\]\nCheck for Convergence:\n\nIf \\(\\| r_{i+1} \\|\\) is small enough, stop.\n\nCompute \\(\\beta_i\\):\n\\[\n\\beta_i = \\frac{\\langle r_{i+1}, r_{i+1}\\rangle}{\\langle r_i,r_i \\rangle}\n\\]\nUpdate Conjugate Direction \\(p_{i+1}\\):\n\\[\np_{i+1} = r_{i+1} + \\beta_i p_i\n\\]\n\n\nThe method can be seen better if we trace through the minimization problem for fixed \\(x\\) and with variable \\(\\alpha\\):\n\\[\n\\begin{align}\n& \\min \\frac{1}{2} \\|A (x+\\alpha p) - b\\|^2  \\\\\n&= \\frac{1}{2}r^T r + \\alpha \\langle r, A p \\rangle + \\frac{1}{2} \\alpha^2 \\langle p, A^T A p \\rangle \\\\\n0 &= \\langle r, A p \\rangle + \\alpha \\langle p, A^T A p \\rangle \\\\\n\\alpha &= -\\frac{\\langle r, A p \\rangle}{\\|A p\\|^2}\n\\end{align}\n\\]\nBut we can also trace this through using the expansion of lest squares and removing the \\(\\|b\\|^2\\) term:\n\\[\n\\begin{align}\n& \\min \\frac{1}{2} \\tilde x^T A x - \\tilde x^T b  \\\\\n&= \\frac{1}{2} \\left( x^T A x + 2 \\alpha x^T A p + \\alpha^2 p^T A p \\right) - x^T b - \\alpha p^T b\\\\\n0&= x^TAp + \\alpha p^T A p - p^T b \\\\\n\\alpha &= \\frac{p^T (Ax-b)}{p^T A p}\n\\end {align}\n\\]"
  },
  {
    "objectID": "content/eosc555/lectures/lecture6/index.html",
    "href": "content/eosc555/lectures/lecture6/index.html",
    "title": "Lecture 6: Autodiff and Implementing Gauss-Newton",
    "section": "",
    "text": "$$ \n$$"
  },
  {
    "objectID": "content/eosc555/lectures/lecture6/index.html#building-the-gauss-newton-optimizer",
    "href": "content/eosc555/lectures/lecture6/index.html#building-the-gauss-newton-optimizer",
    "title": "Lecture 6: Autodiff and Implementing Gauss-Newton",
    "section": "Building the Gauss-Newton Optimizer",
    "text": "Building the Gauss-Newton Optimizer\nRecall the algorithm for the Gauss-Newton method:\n\n\n\\begin{algorithm} \\caption{Gauss-Newton Algorithm for Non-linear Least Squares}\\begin{algorithmic} \\State \\textbf{Input:} Initial guess $p_0$, maximum iterations $K$, tolerance $\\epsilon$ \\State \\textbf{Initialize} $p_0$ \\For{$k = 0, 1, 2, \\ldots$} \\State Compute the Jacobian $J_G$ of $G(p)$ at $p_k$ \\State Compute the transpose $J_G^T$ of the Jacobian \\State Compute the residual $r_k =G(p_k)$ (forward model) \\State Compute the step $s_k = (J_G(p_k)^T J_G(p_k) )^{-1} J_G(p_k)^T r_k$ \\State Update the parameters $p_{k+1} = p_k + \\mu_k s_k$ \\If{$\\|s_k\\| &lt; \\epsilon$} \\State \\textbf{Stop} \\EndIf \\EndFor \\State \\textbf{Output:} $p_{k+1}$ as the optimal solution \\end{algorithmic} \\end{algorithm}\n\n\nThen combining all the previous stages of code we have:\n\n# fix all parts of the problem except the parameters\ndef forward_model(params):\n    X = lotka_volterra(params, initial_pop, T=period, nt=n_time_steps)\n    prey = X[0, :]\n    return prey\n\n\ndef gauss_newton_solver(forward_model, p0, data, max_iter=100, tol=1e-6, mu=1, verbose=True):\n    \"\"\"\n    Solve a non-linear least squares problem using the Gauss-Newton method.\n\n    Parameters:\n        forward_model (callable): A function that computes the forward model.\n        p0 (torch.Tensor): The initial guess for the parameters.\n        data (torch.Tensor): The observed data to fit to.\n        max_iter (int): Maximum number of iterations. Defaults to 100.\n        tol (float): Tolerance for the residual. Defaults to 1e-6.\n        mu (float): Step size for the Gauss-Newton method. Defaults to 1.\n        verbose (bool): Whether to print iteration information. Defaults to True.\n    \"\"\"\n\n    predictions = []  # To store predictions at each iteration for animation\n    \n    params = p0\n    for i in range(max_iter):\n        # Compute residual\n        data_pred = forward_model(params)\n        rk = data - data_pred\n        \n        # Store the current predicted data for animation\n        predictions.append(data_pred.detach())\n        \n        # Compute parts for conjugate gradient\n        b = torch.autograd.functional.vjp(forward_model, params, rk)[1]\n        def A(sk):\n            q = torch.autograd.functional.jvp(forward_model, params, sk)[1]\n            a = torch.autograd.functional.vjp(forward_model, params, q)[1]\n            return a\n        s_k = conj_gradient(A, b, niter=20, tol=1e-2, alpha=1e-2, verbose=False)\n        \n        # Update parameters\n        params = params + mu * s_k\n        \n        # Check for convergence\n        if s_k.norm() &lt; tol:\n            print(f'Converged in {i+1} iterations')\n            break\n        if verbose:\n            print(f'Iteration {i+1}/{max_iter}: Residual = {rk.norm().item()}')\n    \n    return params, predictions\n\n\nTesting the Gauss-Newton Optimizer\nA run of the Gauss-Newton optimization method can be performed on the Lotka-Volterra model to fit the prey population data. The optimization method will be run for a maximum of \\(40\\) iterations with a tolerance that will exit early if the step size becomes small enough indicating a local minimum. The results of the optimization can be plotted against the true data, both prey and predator, to see how well the optimization method has performed to recover the missing predator population.\n\n\nShow the code\nperiod = 40.0  # Time horizon as a single float\nn_time_steps = 200\ninitial_pop = torch.rand(2)\n\n# Making a true data set to fit to\nXX, M = generate_data_set(\n    initial_pop=initial_pop, period=period, n_time_steps=n_time_steps, n_realizations=1\n)\nX = XX[0]\nd_true = X[0, :]  # Use the prey population as the data to fit\n\n# Start with an initial guess for the parameters\np0 = torch.tensor([1.7, 1.7, 0.7, 0.7], requires_grad=True)\n\n# Solve the problem\np_opt, predictions = gauss_newton_solver(\n    forward_model, p0, d_true, max_iter=45, tol=1e-4, mu=1e-1, verbose=False\n)\n\n# Make a final plot of the both pred prey true data and the predicted data\nX_hat = lotka_volterra(p_opt, initial_pop, T=period, nt=n_time_steps)\n\nplt.figure()\nplt.plot(X[0, :].detach().numpy(), label=\"True Prey Population\")\nplt.plot(X[1, :].detach().numpy(), label=\"True Predator Population\")\nplt.plot(X_hat[0, :].detach().numpy(), label=\"Predicted Prey Population\")\nplt.plot(X_hat[1, :].detach().numpy(), label=\"Predicted Predator Population\")\nplt.legend()\nplt.xlabel(\"Time Steps\")\nplt.ylabel(\"Population\")\nplt.title(\"True vs Predicted Population\")\nplt.show()\n\n\nComputing realization 1/1\n\n\n\n\n\nTesting the Gauss-Newton optimization method.\n\n\n\n\nThe plot outputs the successive iterations of the method and the data of the forward model as it is fitting in the predicitons tensor. The optimization process can be animated from the successive predictions to get a visual understanding of the optimization method.\n\n\nShow the code\nfrom matplotlib.animation import FuncAnimation\n\n\ndef create_animation(true_data, predictions, filename=\"imgs/fitting_animation.gif\"):\n    fig, ax = plt.subplots()\n    (line1,) = ax.plot([], [], \"r-\", label=\"Predicted Fit\")\n    (line2,) = ax.plot([], [], \"b--\", label=\"True Data\")\n    ax.legend()\n\n    # Set titles and labels\n    ax.set_xlabel(\"Time Steps\")\n    ax.set_ylabel(\"Population\")\n\n    def init():\n        # Set x and y limits based on true_data and predictions\n        ax.set_xlim(0, len(true_data))\n        ax.set_ylim(\n            min(true_data.min(), predictions[0].min()) - 0.1,\n            max(true_data.max(), predictions[0].max()) + 0.1,\n        )\n        line2.set_data(\n            range(len(true_data)), true_data\n        )  # Set true data once, as it remains constant\n        ax.set_title(\"Iteration: 0\")  # Initial title for iteration count\n        return line1, line2\n\n    def update(i):\n        # Update predicted data and title with the current iteration count\n        line1.set_data(range(len(predictions[i])), predictions[i])\n        ax.set_title(f\"Iteration: {i + 1}\")\n        return line1, line2\n\n    # Create animation with updated frames\n    ani = FuncAnimation(fig, update, frames=len(predictions), init_func=init, blit=True)\n    ani.save(filename, writer=\"imagemagick\")\n\n\n# Create the animation\ncreate_animation(\n    d_true.cpu().detach().numpy(),\n    [pred.cpu().numpy() for pred in predictions],\n    \"imgs/fitting_animation.gif\",\n)"
  },
  {
    "objectID": "content/eosc555/lectures/lecture6/index.html#extension-to-time-varying-parameters",
    "href": "content/eosc555/lectures/lecture6/index.html#extension-to-time-varying-parameters",
    "title": "Lecture 6: Autodiff and Implementing Gauss-Newton",
    "section": "Extension to Time Varying Parameters",
    "text": "Extension to Time Varying Parameters\nAlthough the previous examples have been for a fixed set of parameters, it is entirely possible in natural systems that the parameters of the model are time dependent. The formulation of the Lotka-Volterra model has incorporated this design from the start by expanding the initial four parameters across the time dimension. However we can pass a full tensor of time varying parameters that is size \\([nt, 4]\\) to the model and the optimization algorithm. The rest of the code does not change at all since the PyTorch library can perform the required gradient computations on a 2D tensor as well.\nThe range of possible solutions and the dimensionality of the problem expands from \\(4\\) parameters to \\(4 \\times nt\\) parameters which means more parameters than there are actual data points. This means that any set of data could be fit perfectly, but it might not be the correct fit. This issue is a hallmark of ill-posed inverse problems. The optimization algorithm will still converge to a solution, but it might not be the correct one.\nSince the ground truth of both predator and prey populations is known, the optimization algorithm can be run with time dependent parameters which will allow more overfitting. The parameters being fixed in time is a sort of regularization that can applied to the problem, and removing it will change the results of the optimization.\n\n# Start with an initial guess for the parameters\np0 = torch.tensor([1.7, 1.7, 0.7, 0.7], requires_grad=True)\n# Extend p0 to repeat over the time steps with individual gradients\np0 = p0.unsqueeze(0).expand(n_time_steps, -1)\n\n# Solve the problem\np_opt, predictions = gauss_newton_solver(\n    forward_model, p0, d_true, max_iter=45, tol=1e-4, mu=1e-1, verbose=False\n)\n\n# Make a final plot of the both pred prey true data and the predicted data\nX_hat = lotka_volterra(p_opt, initial_pop, T=period, nt=n_time_steps)\n\nplt.figure()\nplt.plot(X[0, :].detach().numpy(), label=\"True Prey Population\")\nplt.plot(X[1, :].detach().numpy(), label=\"True Predator Population\")\nplt.plot(X_hat[0, :].detach().numpy(), label=\"Predicted Prey Population\")\nplt.plot(X_hat[1, :].detach().numpy(), label=\"Predicted Predator Population\")\nplt.legend()\nplt.xlabel(\"Time Steps\")\nplt.ylabel(\"Population\")\nplt.title(\"True vs Predicted Population\")\nplt.show()\n\n\n\n\nFitting the Lotka-Volterra model with time-varying parameters."
  },
  {
    "objectID": "content/eosc555/lectures/lecture6/index.html#conclusion",
    "href": "content/eosc555/lectures/lecture6/index.html#conclusion",
    "title": "Lecture 6: Autodiff and Implementing Gauss-Newton",
    "section": "Conclusion",
    "text": "Conclusion\nThe Gauss-Newton optimization method is a powerful tool for solving non-linear least squares problems in a fast and efficient manner. It can be extended to any problem that is formulated as a vector of residuals or generally \\(\\| G(p) \\|^2\\) that is to be optimized over \\(p\\). Improved efficiency in the normal equations is done by using the Jacobian-vector product to bypass the costly need to compute a full Jacobian when all that is required is the directional derivative. The normal equtions also present a sub-problem in the optimization routine that can be solved using the conjugate gradient method to find the optimal step size \\(s_k\\). This step direction is then used to perform the gradient descent step in the outer optimization algorithm. Increasing the complexity of the problem by allowing time varying parameters can lead to overfitting and ill-posedness, but the optimization algorithm will still converge to a solution."
  },
  {
    "objectID": "content/projects/projects.html",
    "href": "content/projects/projects.html",
    "title": "Project Home",
    "section": "",
    "text": "This project focuses on the development and challenges of building and controlling a reaction wheel unicycle. Performed as part of a 2-year long capstone project in the UBC Engineering Physics program, sponsored by the Engineering Physics project lab.\nExplore the Learning to Balance Project",
    "crumbs": [
      "Home",
      "Projects",
      "Project Home"
    ]
  },
  {
    "objectID": "content/projects/projects.html#learning-to-balance-a-reaction-wheel-unicycle",
    "href": "content/projects/projects.html#learning-to-balance-a-reaction-wheel-unicycle",
    "title": "Project Home",
    "section": "",
    "text": "This project focuses on the development and challenges of building and controlling a reaction wheel unicycle. Performed as part of a 2-year long capstone project in the UBC Engineering Physics program, sponsored by the Engineering Physics project lab.\nExplore the Learning to Balance Project",
    "crumbs": [
      "Home",
      "Projects",
      "Project Home"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/introduction.html",
    "href": "content/projects/RLUnicycle/introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Welcome to our self-balancing unicycle robot capstone project! We are a team of undergraduate UBC Engineering Physics students working on our final academic checkpoint as engineering students before being released into the wild. This project is directly sponsored by the UBC Engineering Physics Project Lab.\n\n\n\nTristan Lee, Julian Lapenna, Kyle Mackenzie, Jackson Fraser, and Simon Ghyselincks\n\n\n\n\nOur goal is to design and develop a self-balancing reaction wheel robot that can navigate autonomously and be used as a platform to compare traditional control methods with reinforcement learning. The spirit of the project is to explore some of the challenges in implementing advanced control strategies on a real-world system. This includes bridging the gap between simulated models and real applications, coordinating peripherals with low latency, and designing hardware for controllability. It also presents a great opportunity to apply some fundamental physics and engineering concepts in a hands-on challenge.\n\n\n\nOur work draws on previous advances made in robotics. Notably, the Max Planck Institute’s Wheelbot project has served as a significant source of inspiration, many of our design choices and control strategies are influenced by their work. We aim to build on their development with a more advanced control and motor system that can navigate autonomously and adapt to dynamic disturbances using reinforcement learning.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Introduction"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/introduction.html#project-overview",
    "href": "content/projects/RLUnicycle/introduction.html#project-overview",
    "title": "Introduction",
    "section": "",
    "text": "Welcome to our self-balancing unicycle robot capstone project! We are a team of undergraduate UBC Engineering Physics students working on our final academic checkpoint as engineering students before being released into the wild. This project is directly sponsored by the UBC Engineering Physics Project Lab.\n\n\n\nTristan Lee, Julian Lapenna, Kyle Mackenzie, Jackson Fraser, and Simon Ghyselincks\n\n\n\n\nOur goal is to design and develop a self-balancing reaction wheel robot that can navigate autonomously and be used as a platform to compare traditional control methods with reinforcement learning. The spirit of the project is to explore some of the challenges in implementing advanced control strategies on a real-world system. This includes bridging the gap between simulated models and real applications, coordinating peripherals with low latency, and designing hardware for controllability. It also presents a great opportunity to apply some fundamental physics and engineering concepts in a hands-on challenge.\n\n\n\nOur work draws on previous advances made in robotics. Notably, the Max Planck Institute’s Wheelbot project has served as a significant source of inspiration, many of our design choices and control strategies are influenced by their work. We aim to build on their development with a more advanced control and motor system that can navigate autonomously and adapt to dynamic disturbances using reinforcement learning.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Introduction"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/introduction.html#the-robot",
    "href": "content/projects/RLUnicycle/introduction.html#the-robot",
    "title": "Introduction",
    "section": "The Robot",
    "text": "The Robot\n\n\nThe robot is composed of two reaction wheels, a single drive wheel, a controller, and a battery, all mounted on a 3D printed PLA frame. It has a total height of 30cm and a weight of 1.25kg, incorporating a compact and efficient design intended to allow self-erection from a position resting on its resetting legs. The Jetson Nano acts as an autonomous controller that reads the sensors and reacts to the environment using the motors.\n\nMuch like a unicycle, it balances on one wheel, with side-to-side stability provided by the roll wheel and direction controlled by a yaw wheel. The mechanism of balancing and steering relies on a reaction torque produced by spinning the reaction wheels. When a motor applies torque to one of the flywheels, an equal and opposite torque acts on the robot’s body, with the net effect altering the angular motion of both the wheel and the robot. The unstable axes to control are roll and pitch where the robot will fall to the ground without any intervention.\n\n\n\n\nSide View Pitch Axis\n\n\n\n\n\nSide View Roll Axis",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Introduction"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/introduction.html#the-challenge",
    "href": "content/projects/RLUnicycle/introduction.html#the-challenge",
    "title": "Introduction",
    "section": "The Challenge",
    "text": "The Challenge\nRobotics often confronts complex dynamics that are difficult to model precisely. Traditional control systems, while reliable under predictable conditions, may falter with unexpected disturbances. This project explores how Reinforcement Learning can enable our unicycle robot to adapt through trial and error, improving its decision-making capabilities in a dynamic environment.\n\nPrototyping and Progress\nWe have initiated our project with a Reaction Wheel Inverted Pendulum (RWIP) model to understand and tackle the unstable roll axis dynamics. Our efforts so far have included the application of both a traditional PID controller and an RL controller, with the latter showing promising results in handling dynamic disturbances aggressively yet effectively. With the completion of a function 2-DOF underactuated model, we are now moving towards the development of a full-scale 3-axis robot prototype.\n\n\n\n\n3-Axis Partial Build\n\n\n\n\n\nWith Prototype\n\n\n\n\n\n\n\nRWIP Model",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Introduction"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/introduction.html#looking-ahead",
    "href": "content/projects/RLUnicycle/introduction.html#looking-ahead",
    "title": "Introduction",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nThe insights gained from the RWIP will guide the development of the full-scale robot, with the eventual integration of state-space models for sophisticated control strategies and enhanced point-to-point navigation.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Introduction"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/introduction.html#development-pages",
    "href": "content/projects/RLUnicycle/introduction.html#development-pages",
    "title": "Introduction",
    "section": "Development Pages",
    "text": "Development Pages\nExplore the detailed development of specific components of our project:\n\n\n\nComponent\nDescription\n\n\n\n\nReal-Time Kernel\nDive into how we handle real-time constraints on the Jetson Nano.\n\n\nTelemetry\nDiscover how our system communicates and processes real-time data.\n\n\nDynamics and Control\nLearn about the dynamic modeling and control of our robot prototype.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Introduction"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/telemetry/telemetry.html",
    "href": "content/projects/RLUnicycle/telemetry/telemetry.html",
    "title": "Telemetry and Database Systems for Capstone Projects",
    "section": "",
    "text": "This guide provides a comprehensive overview of the telemetry and database systems employed in our “Learning to Balance” reinforcement learning unicycle project. It includes hardware recommendations, a detailed explanation of the networked services used, and example code to illustrate software implementation.\n\n\n\nTelemetry Overview\n\n\nThe telemetry and database system functions as a two-way pipeline controlling the flow of data from sensors, motors, and control decisions. Data from the robot is efficiently offloaded to a server, considering limited processing power and the necessity for a stable control loop. The server further processes this data and manages control signals sent back to the robot for parameter adjustments or commands. By utilizing a central server and internet connectivity, the database, live telemetry, and control panel can be accessed from any networked computer via a browser or software API, globally.\n\n\nThis guide assumes familiarity with running commands on a Linux command line and access to a terminal on your client device (e.g., personal laptop). This could be through WSL or VSCode on Windows, or a terminal on a Mac or Linux machine.\nBasic understanding of Python is recommended, as some examples use Python. However, the same libraries are available in other languages such as C++.\n\n\n\n\nWe recommend the Lenovo M900 series of refurbished tiny PCs as an affordable option that meets the computational needs for a server. The device’s SSD was set to dual boot into Linux Ubuntu 22.04 to run the server. This type of device is capable of handling the computational load of running multiple services simultaneously, including database management, messaging, and control services. It can also serve as a workstation for the team.\nWe tested the Raspberry Pi 4B 8GB with an external SSD, but its processing power is at the limit for these requirements. Therefore, it is not recommended for use as a server, especially considering the cost-effectiveness of a refurbished Lenovo.\n\n\n\n\n\n\n\n\n\nLenovo Server\n\n\n\n\n\n\n\nWifi Dongle\n\n\n\n\n\n\n\n\nOur robot uses an NVIDIA Jetson Nano 4GB, which does not include built-in Wi-Fi. Additionally, a real-time (PREEMPT_RT) patch has been applied to our Linux kernel. Many Wi-Fi dongle drivers are incompatible with the low-level kernel changes made by the patch; for example, the rtl8188EUS driver stopped working after the patch.\nWe recommend the MT7601U chipset USB Wi-Fi dongle, which works without the need for additional drivers on Ubuntu 22.04, Ubuntu 16.04 PREEMPT-RT, and Raspbian. This dongle is reliable for use with outdated and/or patched Linux kernels, is inexpensive, and can be found on Amazon or Aliexpress.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Telemetry and Database Systems for Capstone Projects"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/telemetry/telemetry.html#prerequisites",
    "href": "content/projects/RLUnicycle/telemetry/telemetry.html#prerequisites",
    "title": "Telemetry and Database Systems for Capstone Projects",
    "section": "",
    "text": "This guide assumes familiarity with running commands on a Linux command line and access to a terminal on your client device (e.g., personal laptop). This could be through WSL or VSCode on Windows, or a terminal on a Mac or Linux machine.\nBasic understanding of Python is recommended, as some examples use Python. However, the same libraries are available in other languages such as C++.\n\n\n\n\nWe recommend the Lenovo M900 series of refurbished tiny PCs as an affordable option that meets the computational needs for a server. The device’s SSD was set to dual boot into Linux Ubuntu 22.04 to run the server. This type of device is capable of handling the computational load of running multiple services simultaneously, including database management, messaging, and control services. It can also serve as a workstation for the team.\nWe tested the Raspberry Pi 4B 8GB with an external SSD, but its processing power is at the limit for these requirements. Therefore, it is not recommended for use as a server, especially considering the cost-effectiveness of a refurbished Lenovo.\n\n\n\n\n\n\n\n\n\nLenovo Server\n\n\n\n\n\n\n\nWifi Dongle\n\n\n\n\n\n\n\n\nOur robot uses an NVIDIA Jetson Nano 4GB, which does not include built-in Wi-Fi. Additionally, a real-time (PREEMPT_RT) patch has been applied to our Linux kernel. Many Wi-Fi dongle drivers are incompatible with the low-level kernel changes made by the patch; for example, the rtl8188EUS driver stopped working after the patch.\nWe recommend the MT7601U chipset USB Wi-Fi dongle, which works without the need for additional drivers on Ubuntu 22.04, Ubuntu 16.04 PREEMPT-RT, and Raspbian. This dongle is reliable for use with outdated and/or patched Linux kernels, is inexpensive, and can be found on Amazon or Aliexpress.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Telemetry and Database Systems for Capstone Projects"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/telemetry/telemetry.html#zerotier-virtual-network",
    "href": "content/projects/RLUnicycle/telemetry/telemetry.html#zerotier-virtual-network",
    "title": "Telemetry and Database Systems for Capstone Projects",
    "section": "ZeroTier Virtual Network",
    "text": "ZeroTier Virtual Network\nZeroTier allows all authorized devices on the network to communicate directly using assigned virtual IP addresses, similar to running a local network over a Wi-Fi router.\nIP Addresses: When a website address is entered into a browser, the request is sent to a Domain Name Server (DNS), which translates the address into an IP address—a unique identifier that functions like a postal address, marking the exact location of a server on the internet. For example:\n❯ ping google.com\nPING google.com (142.251.33.78) 56(84) bytes of data.\n64 bytes from sea09s28-in-f14.1e100.net (142.251.33.78): icmp_seq=1 ttl=114 time=21.6 ms\nThe Google webpage can be accessed by typing the IP address directly into the browser. The number is a unique identifier for that server on the internet.\nPublic and Private IP Addresses: The IP protocol reserves certain ranges of IP addresses for pivate networks. For example, the entire block of addresses 192.168.0.0 – 192.168.255.255 do not point to the wider internet but is reserved for local devices. This is why home routers can all have the same common IP address of 192.168.0.1 without creating any conflicts. It acts as a local addressing system, like apartment numbers in a building.\nNetwork Ports: Ports differentiate between different services running on the same IP address. For example, a web server might run on port 80, while an email server might run on port 25. When entering a website address, the browser automatically connects to the server on port 80. To connect to a different service, you can specify the port using a colon, e.g., http://172.22.1.1:8086/ connects to port 8086 which is commonly used for InfluxDB.\nLocal Host: The IP address http://localhost s a special address that points to the local machine. It is used to access services running on the same machine without needing to know the IP address.\nThe clients on the ZeroTier network connect to the robot and server using their assigned virtual IP addresses managed by the ZeroTier service.\n\nSetting up ZeroTier Network\nTo setup a network you should first create a free account at https://my.zerotier.com/. It is advisable to set up a team email so that any team member can log in to manage the network as needed. Once you have an account, you can create a network and add devices to it. The network ID is a 16-digit number used to identify the network.\n\n\nZeroTier Client Setup\nEvery device intended to be part of the network – including laptops, the server, and the Jetson – should have the ZeroTier client installed. After installation, enter the network ID from the ZeroTier website into the client, and approve the device to join the network. Assign static IP addresses, especially for critical devices like the server. This can be managed via the ZeroTier website.\nInstallation Instructions: Download the ZeroTier client here.\n\nSteps:\n\nDownload and Install the ZeroTier client for your operating system:\nStart the ZeroTier service:\n\nOn Windows:\n\nOpen the ZeroTier client, which will add an icon to the system tray.\nRight-click on the icon and select Join Network, then enter the network ID.\nSet the client UI to launch on startup.\n\nOn Linux: Run the following commands:\nsudo systemctl enable zerotier-one\nsudo systemctl start zerotier-one\nsudo zerotier-cli join YOUR_NETWORK_ID\n\nApprove the device:\nTake note of the client ID and either log into the ZeroTier website or use the command-line interface to approve the device for network access.\nVerify the connection:\nAfter approval, you can verify the connection by pinging another connected device on the network using its assigned virtual IP address.\nAssign a static IP (optional):\nFor important devices like the server or the Jetson, assign static IP addresses through the ZeroTier web console under the Members tab. This ensures consistent IP allocation across reboots.\n\n\n\n\n\nManaging IP Addresses\nBelow is an example of a ZeroTier network where the server has been assigned the static IP address 172.22.1.1 on the network:\n\n\n\nZeroTier Network and Access",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Telemetry and Database Systems for Capstone Projects"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/telemetry/telemetry.html#connecting-to-robot-controller-using-ssh",
    "href": "content/projects/RLUnicycle/telemetry/telemetry.html#connecting-to-robot-controller-using-ssh",
    "title": "Telemetry and Database Systems for Capstone Projects",
    "section": "Connecting to Robot Controller using SSH",
    "text": "Connecting to Robot Controller using SSH\nWith the virtual network established, you can enable remote access to the robot controller via SSH. SSH is a secure shell protocol that allows you to run command-line commands on a remote device. This is very useful for managing the robot, running scripts, and updating software code. Use the virtual IP address assigned to the robot on the ZeroTier network. It is recommended to assign a static IP address using the ZeroTier UI or CLI so that the address does not change between reboots.\nFor faster access to SSH devices, consider setting up an alias or an SSH key once SSH is verified working for a device. More information on SSH can be found here\nExample: Our robot has the static ip address 172.22.0.5. To connect from a linux terminal on a computer connected to the private network with zerotier client installed, run the following command:\nssh jetson@172.22.0.5\nThis will attempt to log in to the username jetson on the robot controller, prompting for the user password (the same as if logging in directly on the robot). For a controller running Linux, we recommend setting up different users on the system so that each team member can log in to their own account and manage their own files and credentials. Software between user accounts can be shared using symbolic links to a central repository or using GitHub to manage individual software branches.\n\nVSCode Server\nThe Jetson is also able to handle VSCode Server (https://code.visualstudio.com/docs/remote/ssh), although the outdated Ubuntu 16.04 requires running an older version of the VSCode IDE to SSH in. Be aware that VSCode Server is active on the Jetson when SSHed in, which consumes some system resources; however, in practice, it has not been a performance issue. For best performance, running the robot through a simple terminal is recommended. The benefit of SSHing through VSCode is that it provides a GUI interface for software development and file management on the robot, as if you were using VSCode on your own computer.",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Telemetry and Database Systems for Capstone Projects"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/telemetry/telemetry.html#mqtt-overview",
    "href": "content/projects/RLUnicycle/telemetry/telemetry.html#mqtt-overview",
    "title": "Telemetry and Database Systems for Capstone Projects",
    "section": "MQTT Overview",
    "text": "MQTT Overview\n\n\n\nMQTT is a lightweight messaging protocol that provides an efficient and cost-effective method for telemetry-based communication between devices. MQTT messages are routed through the Lenovo server acting as the broker using Mosquitto. The robot can publish data to a topic, which can be picked up by various subscribers such as Grafana or other laptops and devices connected to the broker and subscribed to the topic. Similarly, commands can be sent back to the robot via a command topic to turn it on or off or adjust parameters. The default port for MQTT is 1883.\nFor setup, installation, and maintenance of the broker, we recommend installing MQTT Explorer on any device connected to the network. This allows for monitoring all messaging and client connections across the system.\nDownload from MQTT Explorer\n\nKey Features of MQTT\n\n\n\n\n\n\n\nFeature\nDescription\n\n\n\n\nLightweight Protocol\nIdeal for constrained devices and networks with limited bandwidth.\n\n\nPublish-Subscribe Model\nAllows devices to publish messages to a topic and any client subscribed to that topic will receive the messages.\n\n\nReliable Message Delivery\nOffers various levels of Quality of Service (QoS) to guarantee message delivery.\n\n\nMinimal Overhead\nAdds only a small overhead to each message, ensuring efficient use of network resources.\n\n\n\n\n\n\nInstalling Mosquitto MQTT Broker\nFrom the server open a terminal and run the following commands to install the MQTT broker:\nsudo apt update\nsudo apt install mosquitto mosquitto-clients\nsudo systemctl enable mosquitto\nsudo systemctl start mosquitto\nAfter installation, open MQTT Explorer and connect to the broker using the IP address of the server and the default port. You should see the server as a client connected to the broker.\n\n\n\nConnecting to MQTT Broker\n\n\nOnce connected, some test messages can be sent through the GUI and verified that they are being received by the server.\nFor more detailed instructions or help, consider using additional resources or consult the Mosquitto documentation.\n\n\nInterfacing with Software\nMQTT interfaces with Python, Node-RED, and Grafana to provide a network of communication topics. The broker can be accessed by any device on the ZeroTier network; messages can be sent to a topic, or actions can be taken based on a message received from a topic.\nBelow is an example Python script for publishing messages to the MQTT broker. This script publishes a test message to the topic jetson/telemetry every second. Note that the two key components of a successful message are the topic and the message payload. The topic is the address to which the message is sent, and the payload is the data being sent. The payload can be a string, a number, or a JSON object. For our project, we use JSON objects to send data.\nThe package is installed using pip: pip install paho-mqtt\n\nimport json\nimport time\nimport paho.mqtt.client as mqtt\nimport random\n\n# Define the MQTT settings\nbroker_address = \"172.22.1.1\"  # Lenovo's IP address (replace with your broker IP)\nport = 1883\ntopic = \"jeston/telemetry\"\n\n# Create an MQTT client instance\nclient = mqtt.Client()\n\n# Define the callback for receiving messages\ndef on_message(client, userdata, message):\n    print(f\"Message received on topic {message.topic}: {message.payload.decode()}\")\n\n# Define the callback for connecting to the broker\ndef on_connect(client, userdata, flags, rc):\n    print(\"Connected to broker with result code \" + str(rc))\n    # Subscribe to the topic when connected\n    client.subscribe(topic)\n\n# Assign the callbacks\nclient.on_message = on_message\nclient.on_connect = on_connect\n\n# Connect to the broker\nclient.connect(broker_address, port)\n\n# Start the loop to process messages\nclient.loop_start()\n\n# Publish some test messages to the topic every second\ntry:\n  range(3)\n  for i in range(3):\n        message = {\"sensor\": \"temperature\", \"value\": 20 + random.random() * 5}\n        client.publish(topic, json.dumps(message))\n        print(f\"Published message: {message}\")\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    print(\"Exiting...\")\n\n# Stop the loop and disconnect\nclient.loop_stop()\nclient.disconnect()\n\nPublished message: {'sensor': 'temperature', 'value': 20.3095790384297}\n\n\nC:\\Users\\sghys\\AppData\\Local\\Temp\\ipykernel_15800\\406674647.py:12: DeprecationWarning: Callback API version 1 is deprecated, update to latest version\n  client = mqtt.Client()\n\n\nConnected to broker with result code 0\nPublished message: {'sensor': 'temperature', 'value': 23.604692472457177}\nMessage received on topic jeston/telemetry: {\"sensor\": \"temperature\", \"value\": 23.604692472457177}\nPublished message: {'sensor': 'temperature', 'value': 22.55116248680919}\nMessage received on topic jeston/telemetry: {\"sensor\": \"temperature\", \"value\": 22.55116248680919}\n\n\n&lt;MQTTErrorCode.MQTT_ERR_SUCCESS: 0&gt;\n\n\nIn this demo script, the client is both publishing and subscribing to the same topic. In practice, we use multiple topics for different data streams and commands. A more advanced implementation for assigning topics and managing data can be found in our repository: RLUnicycle\nThis test script is useful for publishing test data when it comes to verifying the installation of InfluxDB and Grafana ahead.\nWe are now at this stage in the setup:\n\n\n\n\n\nflowchart TD\n  %% Customizing colors for subgraphs and nodes\n  style Robot fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Server fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px\n  style Clients fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n\n  Y[Robot]\n  Z[Server]\n\n  %% Define a class for black text\n  classDef blackText fill:none,color:#000,stroke:none;\n\n  subgraph Robot\n    E(Jetson)\n  end\n  \n  subgraph Server\n    E &lt;--&gt; F[MQTT Broker]\n  end\n\n  %% Clients section coloring applied to individual floating nodes\n    K[Python Script] --&gt;|Commands| F\n    L[Laptop] --&gt;|SSH| E\n    L --&gt;|MQTT Explorer| F\n    L --&gt; K\n  \n  %% Styling for the floating client items\n  style K fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style L fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style Y fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Z fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Telemetry and Database Systems for Capstone Projects"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/telemetry/telemetry.html#telegraf-and-influxdb",
    "href": "content/projects/RLUnicycle/telemetry/telemetry.html#telegraf-and-influxdb",
    "title": "Telemetry and Database Systems for Capstone Projects",
    "section": "Telegraf and InfluxDB",
    "text": "Telegraf and InfluxDB\n\n \n\nTelegraf and InfluxDB are free and open-source products from InfluxData. Telegraf is driven by a configuration file that organizes incoming data from multiple sources for processing and forwarding into the InfluxDB database. InfluxDB is a time-series database used to store telemetry data streamed from the robot. It features a web browser interface for data exploration and APIs in Python and other languages for database queries.\nFollow the instructions in the links above to install both services on the server.\n\nInfluxDB Configuration\nThe InfluxDB database can be accessed through a web browser by navigating to the IP address of the Lenovo server on port 8086. For example, http://172.22.1.1:8086/. A login process will establish a username, password, and organization. The organization is simply a way to group data together across users. A bucket is a way to group data together within an organization. For our database we have assigned the organization name as Capstone and the bucket name as telegraf but these are free to choose. Once the organization and bucket have been created, the database is ready to receive data.\n\n\nTelegraf Configuration\nThe Telegraf configuration file is located at /etc/telegraf/telegraf.conf by default. The default configuration is extensive, with many lines commented out. It is advisable to back up the original file and then remove unnecessary commented lines for clarity.\nTelegraf acts as a central messaging switchboard. To utilize it, we need to connect the MQTT topics into the switchboard and connect the output to the InfluxDB database for storage. The main changes suggested from the default configuration are:\n\nRemove the logging of server stats from the pool of inputs.\nAdd the MQTT input plugin to the configuration file.\nAdd the InfluxDB output plugin to the configuration file.\n\nA simplified header is shown below:\n# Default Header\n[global_tags]\n\n# Configuration for telegraf agent\n[agent]\n  ## Default data collection interval for all inputs\n  interval = \"10s\"\n  round_interval = true\n  metric_batch_size = 1000\n  metric_buffer_limit = 10000\n  collection_jitter = \"0s\"\n  flush_interval = \"10s\"\n  flush_jitter = \"0s\"\n  precision = \"\"\n\n  ## Override default hostname, if empty use os.Hostname()\n  hostname = \"\"\n  ## If set to true, do no set the \"host\" tag in the telegraf agent.\n  omit_hostname = true\n\n\n\n\n\nNow, add InfluxDB as an output plugin and MQTT as an input plugin. The MQTT plugin listens to messages on particular topics, and the InfluxDB plugin writes the data to the database. The configuration for the InfluxDB output plugin is shown below.\nNote the token above can be generated through the InfluxDB web interface.\n\n\n[[outputs.influxdb_v2]]\n  # localhost assumes telegraf and influxdb are on the same server\n  urls = [\"http://localhost:8086\"]\n  token = \"api token from InfluxDB\"\n  organization = \"Capstone\"\n  bucket = \"telegraf\"\n\n[[outputs.prometheus_client]]\n    listen = \":9273\"\n    metric_version = 2\nFinally the incoming messages from MQTT are processed. A very important consideration here is to fully automate the process of message conversion from JSON to adopt a robot-driven database. The core principle is that changes in the robot software and telemetry should not change either this configuration file or the database schema. In our case, all messages that are to be databased start with robot/ and the topic indicates the data category. For example robot/imu1 is the MQTT topic that recieves information on the imu sensor\n{ax: 0.1, ay: 0.2, az: 0.3, gx: 0.4, gy: 0.5, gz: 0.6}\nTelegraph identifies that this is to be databased, removes the robot/ prepend, records the json message _measurement as imu1 and the _field as ax, ay, az, gx, gy, gz.\n[[processors.starlark]]\n  source = '''\ndef apply(metric):\n    # Get the topic tag value (e.g., \"robot/motor\")\n    topic = metric.tags.get(\"topic\")\n    \n    # Extract the part after \"robot/\"\n    if topic.startswith(\"robot/\"):\n        measurement = topic.split(\"robot/\", 1)[1]\n        # Set the new measurement based on the tail of the topic\n        metric.name = measurement\n    \n    return metric\n'''\n\n# MQTT Consumer Input Plugin\n[[inputs.mqtt_consumer]]\n  servers = [\"tcp://localhost:1883\"]\n\n  topics = [\n    \"robot/#\"  # Subscribe to all subtopics under robot/\n  ]\n  qos = 0\n  client_id = \"telegraf_mqtt_consumer\"\n  data_format = \"json\"\n  ## Use a part of the topic or JSON structure as the measurement name.\n  json_name_key = \"measurement\"\nThis completes the configuration file. The other components that record server metrics can be removed to keep the database focused.\n\n\nTesting the Configuration with Data Explorer\nReturn to the MQTT Python script and send messages to a robot/ topic for testing. They should now be automatically processed into the database as described. Verify that the messages are passing through the MQTT broker, then confirm they are reaching the InfluxDB database using the Data Explorer.\n\nf successful, the Data Explorer will show that the bucket has new data. The measurement filter will display the topic passed to MQTT, the field will show the keys from the passed JSON, and the data will show the values. Note that InfluxDB automatically applies data operations such as aggregation to reduce the number of sample points. This can be managed using the window period on the right-hand side.\nInfluxDB has its own query language, which can be previewed by clicking the Script Editor button. This provides direct insight into how the data is processed when a query is sent and can be edited to fine-tune the settings or used as an API call from elsewhere (e.g., from a Python script to create plots).\nfrom(bucket: \"telegraf\")\n  |&gt; range(start: v.timeRangeStart, stop: v.timeRangeStop)\n  |&gt; filter(fn: (r) =&gt; r[\"_measurement\"] == \"sensors/imu\")\n  |&gt; filter(fn: (r) =&gt; r[\"_field\"] == \"accel_x\")\n  |&gt; aggregateWindow(every: 100ms, fn: mean, createEmpty: false)\n  |&gt; yield(name: \"mean\")\nThe accel_x is being aggregated into 100ms sample periods using the mean of all values in that window. This can be modified to get raw data or changed to a different aggregation function. The range values can also be set to relative times to get the last 10 minutes of data, for example.\nfrom(bucket: \"telegraf\")\n  |&gt; range(start: -10m)\n  |&gt; filter(fn: (r) =&gt; r[\"_measurement\"] == \"sensors/imu\")\n  |&gt; filter(fn: (r) =&gt; r[\"_field\"] == \"accel_x\")\nBuilding these queries through the script editor is a good way to get the correct string to use in a Python script to query the database.\n\n\nExample Python Query\nTo illustrate how this can be integrated into Python for data analysis, here is a simple example. This script queries the last one minute of data from the database and plots the acceleration data over time.\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom influxdb_client import InfluxDBClient\n\n# Server IP address with InfluxDB port\nurl = \"http://172.22.1.1:8086\"\ntoken = \"gGu-3t4Avltf6-yHamGXItRfOKBQIDLgWEfhdURE7wURQazK_yvIa8O9k0O-_doXX8Q0Acy82vVavb5AcM2Lhw==\"\norg = \"Capstone\"\nbucket = \"telegraf\"\n\nclient = InfluxDBClient(url=url, token=token, org=org)\n\n# Query for the last 10 minutes of data\nlast_mins = 1\nquery = f'''\nfrom(bucket: \"{bucket}\")\n  |&gt; range(start: -{last_mins}m)\n  |&gt; filter(fn: (r) =&gt; r[\"_measurement\"] == \"sensors/imu\")\n  |&gt; filter(fn: (r) =&gt; r[\"_field\"] == \"accel_x\")\n  |&gt; aggregateWindow(every: 1s, fn: mean, createEmpty: false)\n'''\n\n# Query the data\nquery_api = client.query_api()\ntables = query_api.query(org=org, query=query)\n\n# Extract values (accel_x) from query response\nvalues = [record.get_value() for table in tables for record in table.records]\n\n# Plot using Seaborn\nplt.figure(figsize=(5, 3))\nsns.lineplot(data=values, linewidth=2.5)\n\n# Customize plot\nplt.title('Acceleration Data (accel_x) Over Time', fontsize=16)\nplt.xlabel('Steps', fontsize=14)\nplt.ylabel('Acceleration (accel_x)', fontsize=14)\nplt.tight_layout()\n\n# Display the plot\nplt.show()\n\n\n\n\n\n\n\n\nThis concludes the setup of the MQTT, Telegraf, and InfluxDB services. The next step is to setup Grafana for live telemetry and database dashboards.\n\nAt this stage in the setup, the system architecture is as follows:\n\n\n\n\n\nflowchart TD\n  %% Customizing colors for subgraphs and nodes\n  style Robot fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Server fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px\n  style Clients fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n\n  Y[Robot]\n  Z[Server]\n\n  %% Define a class for black text\n  classDef blackText fill:none,color:#000,stroke:none;\n\n  subgraph Robot\n    E(Jetson)\n  end\n  \n  subgraph Server\n    E &lt;--&gt; F[MQTT Broker]\n    F --&gt;|Metrics| G[Telegraf]\n    G --&gt;|Write| H[InfluxDB]\n  end\n\n  %% Clients section coloring applied to individual floating nodes\n    K[Python Script] --&gt;|Commands| F\n    L[Laptop] --&gt;|SSH| E\n    L --&gt;|MQTT Explorer| F\n    L --&gt; K\n    H --&gt;|Data| M[Data Explorer and API]\n  \n  %% Styling for the floating client items\n  style K fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style L fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style M fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style Y fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Z fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Telemetry and Database Systems for Capstone Projects"
    ]
  },
  {
    "objectID": "content/projects/RLUnicycle/telemetry/telemetry.html#grafana-live-telemetry",
    "href": "content/projects/RLUnicycle/telemetry/telemetry.html#grafana-live-telemetry",
    "title": "Telemetry and Database Systems for Capstone Projects",
    "section": "Grafana Live Telemetry",
    "text": "Grafana Live Telemetry\n\nGrafana is a powerful open-source platform for creating dashboards and visualizing time-series data. Grafana supports a wide range of data sources and can display both live and historical data. While it can refresh data from InfluxDB at a rate of every 5 seconds, this is too slow for live monitoring of a dynamic system. Instead, live telemetry is pulled directly from the MQTT broker.\nTo begin, download and install Grafana on the server. The default port for Grafana is 3000. Once installed, open up a web browser and navigate to http://localhost:3000/ to access the Grafana dashboard. The default login is admin with the password admin.\n\nAdding Data Sources\nGrafana needs to be configured with data sources:\n\nInfluxDB Data Source:\n\nThe InfluxDB data source is included by default as a plugin.\nSpecify the correct query language and provide the necessary credentials and address (http://localhost:8086).\n\nMQTT Data Source:\n\nTo view MQTT data in real time, install a plugin to connect Grafana to the Mosquitto broker: MQTT Datasource Plugin.\nIn Grafana, navigate to Configuration &gt; Data Sources &gt; Add data source.\nSelect MQTT from the list of available data sources.\nName the data source and specify the connection to the MQTT broker (tcp://localhost:1883).\nAdd a username and password if configured for the broker.\n\n\n\n\nCreating Dashboards and Panels\nNow it is time to setup a dashboard, a collection of data panels. The Grafana interface is user friendly, but we are interested in some key settings.\n\nThe window of time that is being displayed in the dashboard.\nThe MQTT topics that are being fetched for display.\nThe keys from the JSON that are being displayed.\n\nFor this stage, it is recommended to either have a robot sensor streaming data, or a surrogate Python script sending out data to the MQTT broker so that there are live streaming messages to display.\n\n\n\n\n\nStep 1: Create a New Dashboard\n\nLog into the Grafana homepage from any device connected to the private network using the server IP: http://172.22.1.1:3000/.\nNavigate to Dashboards and select New Dashboard.\nSave the new dashboard. Remember to save periodically to avoid losing changes.\nAdjust the time range of the dashboard to the last 30 seconds to see recent data streaming in. Apply the time range.\n\n\n\n\n\n\n\n\nStep 2: Add a Visualization Panel\n\nSelect the Add a visualization button to make the first panel.\nEnter the MQTT topic and verify that data is streaming using MQTT Explorer.\nThe data should begin streaming in the panel preview.\nUse the Query Inspector and Data tab to verify that data is being received and processed correctly if the visualization is not showing as expected.\n\n\n\n\nStep 3: Customize the Panel\n Select the Transform Data tab and then Filter fields by name option. Fields that are to be omitted can be removed from the identifier list and will not be displayed in the panel. Finally the right hand side of the panel configuration can be used to fully customize the display of data, panel title, etc.\nSave and apply the panel change. Now is a good time to bookmark the dashboard for easy access in the future. The live telemetry has limitations in how much data can be displayed at once, since it is sampling from a moving buffer and not storing the data like the database. Too many panels with too much data will cause the system to stutter, so the recommendation is to downsample the data to about 10Hz or less unless full sample resolution is needed.\n\n\n\nNotes on Downsampling\nAs of now, an effective way to downsample the incoming data in Grafana has not been found. Telegraf has some data processing capabilities for downsampling, but it would require rebroadcasting over a new MQTT topic. The simplest solution we have found is to downsample data on the robot side by sending full-resolution data to each of the robot/ topics and every \\(n\\) th message to a downsampled/ topic. This can be implemented with few lines of code and does not add significant overhead.\n\nAt this stage in the setup, the system architecture is as follows:\n\n\n\n\n\nflowchart TD\n  %% Customizing colors for subgraphs and nodes\n  style Robot fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Server fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px\n  style Clients fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n\n  Y[Robot]\n  Z[Server]\n\n  %% Define a class for black text\n  classDef blackText fill:none,color:#000,stroke:none;\n\n  subgraph Robot\n    E(Jetson)\n  end\n  \n  subgraph Server\n    E &lt;--&gt; F[MQTT Broker]\n    F --&gt;|Metrics| G[Telegraf]\n    G --&gt;|Write| H[InfluxDB]\n    F --&gt;|Visualization| I[Grafana]\n  end\n\n  %% Clients section coloring applied to individual floating nodes\n    I --&gt;|Live Telemetry| J[Dashboard]\n    H --&gt;|Data| M[Data Explorer and API]\n\n  \n  %% Styling for the floating client items\n  style J fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style M fill:#F1F8E9,stroke:#A5D6A7,stroke-width:2px\n  style Y fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px\n  style Z fill:#FFF8E1,stroke:#FFCC80,stroke-width:2px",
    "crumbs": [
      "Home",
      "Projects",
      "Learning to Balance",
      "Telemetry and Database Systems for Capstone Projects"
    ]
  },
  {
    "objectID": "content/eosc555/lectures/lecture7/index.html#motivation",
    "href": "content/eosc555/lectures/lecture7/index.html#motivation",
    "title": "Lecture 7: Applying Homotopy to Optimize Highly Non-Convex Functions",
    "section": "Motivation",
    "text": "Motivation\nSo far we have examined optimization techniques using gradient descent and the Gauss-Newton method. These methods are powerful but can be limited by the presence of local minima in the optimization landscape. In this lecture we will explore a technique called Gaussian homotopy that can be used to escape local minima in optimization problems.\nTo recap the steps used so far in optimization, we have an objective \\[\\operatorname*{argmin}f(x),\\]\nwhere \\(x \\in \\mathbb{R}^n\\) is an unconstrained optimization variable. The objective can be searched out by stepping in a direction itertively, in general: \\[x_{k+1} = x_k - \\alpha_k H \\nabla f(x_k),\\]\nwhere \\(\\alpha_k\\) is the step size. The gradient \\(\\nabla f(x_k)\\) can be computed explicitly or using automatic differentiation. The matrix \\(H\\) is a modifier that depends on the method being used: \\[H =\n\\begin{cases}\n    I & \\text{Gradient Descent} \\\\\n    (J^T J)^{-1} & \\text{Gauss-Newton}\n\\end{cases}\n\\]\nHowever, optimization is often performed on non-convex functions, in which case the path to a global minimum can be obstructed by local minima. Three categories of increasingly non-convex functions are shown below.\n\n Figure: Three categories of increasingly non-convex functions illustrating potential local minima that can obstruct the path to a global minimum.\n\nSome examples for each of the three catergories are given in the following table:\n\n\n\n\n\n\n\n\nCategory\nFunction\nLocal Minima\n\n\n\n\nConvex\n\\(f(x) = x^2\\)\nGlobal minimum at \\(x=0\\)\n\n\nNon-Convex but \\(f'(x)&lt;0\\)\n\\(f(x) = -\\mathcal{N}(x; 0, 1)\\)\nGlobal minimum at \\(x=0\\)\n\n\nNon-Convex with \\(f'(x) \\geq 0\\)\n\\(f(A,B,w) = w^T \\sigma (B \\sigma (A x))\\)\nMultiple local minima\n\n\nNon-Convex and Poorly Conditioned \\(\\nabla^2 f(x)\\)\n\\(f(t) = x(t)^T A x(t), \\quad x(t) = \\text{square wave}\\)\nMultiple local minima and discontinuous\n\n\n\nTo illustrate these functions even more we can plot them as well.\n\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(-5, 5, 100)\ny1 = x**2\ny2 = -np.exp(-x**2)\ny3 = np.sin(x) + .5*x\n\n#square wave\ndef square_wave(x):\n    return 1 if np.sin(3*x) &gt; 0 else 0\n\ny4 = [square_wave(xi)**2 for xi in x]\n\nfig, ax = plt.subplots(2, 2)\nax[0, 0].plot(x, y1)\nax[0, 0].set_title(\"Convex: $f(x) = x^2$\")\nax[0, 1].plot(x, y2)\nax[0, 1].set_title(\"Non-Convex but $f'(x)&lt;0$ \\n $f(x) = -\\mathcal{N}(x; 0, 1)$\")\nax[1, 0].plot(x, y3)\nax[1, 0].set_title(\"Non-Convex with $f'(x) \\geq 0$ \\n $f(x) = sin(x)+.5 x$\")\nax[1, 1].plot(x, y4)\nax[1, 1].set_title(\"Non-Convex and Poorly Conditioned $\\nabla^2 f(x)$\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nFunction Categories."
  },
  {
    "objectID": "content/eosc555/lectures/lecture7/index.html#gaussian-homotopy",
    "href": "content/eosc555/lectures/lecture7/index.html#gaussian-homotopy",
    "title": "Lecture 7: Applying Homotopy to Optimize Highly Non-Convex Functions",
    "section": "Gaussian Homotopy",
    "text": "Gaussian Homotopy\nA common case of homotopy is the Gaussian homotopy, where the smoothing function is a Gaussian function. The Gaussian function is a widely used in signal processing and image processing due to its properties as a low-pass filter. For example, a Gaussian blur is applied to images to aid in downsampling since it preserves the lower resolution details while removing high-frequency noise that may cause aliasing.\nTo illustrate the low-pass filtering property, consider a Gaussian function \\(g(x)\\) and its Fourier transform \\(\\hat{g}(k)\\):\n\\[g(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{-\\frac{x^2}{2\\sigma^2}}, \\quad \\hat{g}(k) = e^{-\\frac{k^2 \\sigma^2}{2}}.\\]\nThe Fourier transform of the Gaussian is another Gaussian, it is an eigenfunction of the Fourier transform operator. The convolution theorem states that the convolution of two functions in the spatial domain is equivalent to the multiplication of their Fourier transforms in the frequency domain:\n\\[f(x) \\ast g(x) = \\mathcal{F}^{-1} \\left[ \\hat{f}(k) \\hat{g}(k) \\right].\\]\nThe convolution of a function \\(f(x)\\) with a Gaussian \\(g(x)\\) can be used to remove the high-frequency components of the function while allowing the low-frequency, widely spread components to remain.\nA wide Gaussian in the time domain corresponds to a narrow Gaussian in the frequency domain, and vice versa. So a wide gaussian only lets through the lowest frequencies, while a narrow Gaussian lets through the highest frequencies. At the limit as the Gaussian becomes infinitely narrow, it becomes a delta function \\(g(x) = \\delta(x)\\) in the time domain, a constant function $ (k) = 1$ in the frequency domain. The convolution of a delta function with a function \\(f\\) is the function itself, so the delta function does not change the function. The multiplication of the function \\(\\hat f(k)\\) with the constant function \\(1\\) is the function itself, so the constant function does not change the function in the frequency domain.\n\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fftpack import fft, ifft, fftfreq, fftshift\nfrom matplotlib.animation import FuncAnimation\n\n# Generate a square wave in the time domain\ndef square_wave(t, period=1.0):\n    \"\"\"Creates a square wave with a given period.\"\"\"\n    return np.where(np.sin(2 * np.pi * t / period) &gt;= 0, 1, -1)\n\n# Time domain setup\nt = np.linspace(-1, 1, 500)\nsquare_wave_signal = square_wave(t)\nfreq = fftfreq(t.size, d=(t[1] - t[0]))\nsquare_wave_fft = fft(square_wave_signal)\n\n# Function to update the plot for each frame, based on current sigma_t\ndef update_plot(sigma_t, axs, time_text):\n    sigma_f = 1 / (2 * np.pi * sigma_t)  # Standard deviation in frequency domain\n    gaussian_time_domain = np.exp(-0.5 * (t / sigma_t)**2)\n    gaussian_filter = np.exp(-0.5 * (freq / sigma_f)**2)\n    filtered_fft = square_wave_fft * gaussian_filter\n    smoothed_signal = np.real(ifft(filtered_fft))\n\n    # Update each subplot with new data\n    axs[1, 0].clear()\n    axs[1, 0].plot(t, gaussian_time_domain, color=\"purple\")\n    axs[1, 0].set_title(\"Gaussian Filter (Time Domain)\")\n    axs[1, 0].set_xlabel(\"Time\")\n    axs[1, 0].set_ylabel(\"Amplitude\")\n    axs[1, 0].grid(True)\n\n    axs[1, 1].clear()\n    axs[1, 1].plot(fftshift(freq), fftshift(gaussian_filter), color=\"orange\")\n    axs[1, 1].set_title(\"Gaussian Low-Pass Filter (Frequency Domain)\")\n    axs[1, 1].set_xlabel(\"Frequency\")\n    axs[1, 1].set_ylabel(\"Amplitude\")\n    axs[1, 1].set_xlim(-50, 50)\n    axs[1, 1].grid(True)\n\n    axs[2, 0].clear()\n    axs[2, 0].plot(t, square_wave_signal, color=\"green\", linestyle=\"--\")\n    axs[2, 0].plot(t, smoothed_signal, color=\"red\")\n    axs[2, 0].set_title(\"Smoothed Signal (Time Domain)\")\n    axs[2, 0].set_xlabel(\"Time\")\n    axs[2, 0].set_ylabel(\"Amplitude\")\n    axs[2, 0].grid(True)\n\n    axs[2, 1].clear()\n    axs[2, 1].plot(fftshift(freq), fftshift(np.abs(square_wave_fft)), color='blue', linestyle='--')\n    axs[2, 1].plot(fftshift(freq), fftshift(np.abs(filtered_fft)), color=\"orange\")\n    axs[2, 1].set_title(\"Filtered Spectrum (Frequency Domain)\")\n    axs[2, 1].set_xlabel(\"Frequency\")\n    axs[2, 1].set_ylabel(\"Amplitude\")\n    axs[2, 1].set_xlim(-30, 30)\n    axs[2, 1].grid(True)\n\n    # Update the time text\n    time_text.set_text(f\"T = {T:.2f}\")\n\n# Initialize the figure and plot layout for animation\nfig, axs = plt.subplots(3, 2, figsize=(12, 10))  # Increased figure size for animation\naxs[0, 0].plot(t, square_wave_signal, color='green')\naxs[0, 0].set_title(\"Square Wave (Time Domain)\")\naxs[0, 0].set_xlabel(\"Time\")\naxs[0, 0].set_ylabel(\"Amplitude\")\naxs[0, 0].grid(True)\n\naxs[0, 1].plot(fftshift(freq), fftshift(np.abs(square_wave_fft)), color='blue')\naxs[0, 1].set_title(\"Fourier Transform of Square Wave (Frequency Domain)\")\naxs[0, 1].set_xlabel(\"Frequency\")\naxs[0, 1].set_ylabel(\"Amplitude\")\naxs[0, 1].set_xlim(-30, 30)\naxs[0, 1].grid(True)\n\n# Add a text annotation for time at the bottom of the figure with extra space\ntime_text = fig.text(0.5, 0.02, \"\", ha=\"center\", fontsize=12)  # Adjusted position for clarity\n\n# Adjust subplot spacing specifically for animation\nplt.tight_layout(rect=[0, 0.05, 1, 1])  # Extra space at the bottom for time text\n\n# Animation settings\nsteps = 100\ndef animate(frame):\n    global T  # Declare T as a global variable for use in update_plot\n    T = 1 - (frame / steps)  # Scale frame number to a T value between 1 and 0\n    sigma_t = 0.5 * T + 0.001 * (1 - T)  # Interpolate sigma_t\n    update_plot(sigma_t, axs, time_text)\n\n# Create and display the animation\nani = FuncAnimation(fig, animate, frames=steps, interval=100)\n\n# Save the animation as a GIF\nani.save('imgs/gaussian_homotopy.gif', writer='imagemagick', fps=8)\n\nplt.show()\n\n\n\nFor Gaussian homotopy, the continuous transformation between the original function and the relaxed version is given by a convolution with a Gaussian kernel. We let \\(\\sigma(t)\\) be the standard deviation of the Gaussian kernel at time \\(t\\). The deviation will be \\(\\sigma(0) = 0\\) and \\(\\sigma(1) = \\sigma_{\\text{max}}\\) so that the homotopy at any time \\(t\\) is given by:\n\\[h(x, t) = \\int_{-\\infty}^{\\infty} f(x-\\xi) \\exp(-\\frac{\\xi^2}{\\sigma(t)^2}) d\\xi.\\]\nThe Gaussian kernel should be divided by its partition function \\(z(t) = \\int \\exp(-\\frac{\\xi^2}{\\sigma(t)^2}) d\\xi\\) in theory so that the kernel is normalized, but for the use case where \\(h(x, t)\\) is used as a surrogate function for optimization, the partition function \\(z(t)\\) does not change the minimizer of the function.\n\nStochastic Optimization\nSince the objective is to minimize over the integral given by \\(h(x, t)\\), a stochastic method can be used to estimate the minimizer in expectation using Monte Carlo methods. The integral can be approximated by sampling \\(N\\) points from the Gaussian kernel and averaging the function values at those points:\n\\[\n\\begin{align*}\nh(x, t) &= \\int_{-\\infty}^{\\infty} f(x-\\xi) \\exp(-\\frac{\\xi^2}{\\sigma(t)^2}) d\\xi\\\\\n& = \\mathbb{E}_{\\xi \\sim \\mathcal{N}(0, \\sigma(t)^2)} f(x-\\xi) \\\\\n& \\approx \\frac{1}{N} \\sum_{i=1}^N f(x-\\xi_i), \\quad \\xi_i \\sim \\mathcal{N}(0, \\sigma(t)^2).\n\\end{align*}\n\\]\nFor a given \\(t\\) and point \\(x\\) where we want to estimate the function \\(h(x, t)\\), we can sample \\(N\\) points from a Gaussian kernel centered at \\(x\\) with standard deviation \\(\\sigma(t)\\) and evaluate the function at those points. The average of the function values at those points will be an estimate of the function value at \\(x\\).\n\n\nImplementation Choices\nThere are two ways to approach this problem when using numerical methods.\n\nDiscretize then Optimize: The integral is first discretized by choosing a set of points \\(\\{xi_1, \\xi_2, \\ldots, \\xi_N\\}\\) and then the function is evaluated using that same discrete kernel across all points:\n\n\\[ \\min_{\\mathcal{X}} \\frac{1}{N} \\sum_{i=1}^N f(x-\\xi_i).\\]\nThis sum can end up being large if there are many points that are selected.\n\nOptimize then Discretize: In this case we start with gradient descent and the continuous function \\(h(x, t)\\) and then sample the function at the points \\(\\{xi_1, \\xi_2, \\ldots, \\xi_N\\}\\) to estimate a gradient.\n\n\\[\n\\begin{align*}\nx_{k+1} &= x_k - \\alpha_k \\mathbb{E}_{\\xi} \\nabla f(x_k - \\xi)\\\\\n  &\\approx x_k - \\alpha_k \\frac{1}{N} \\sum_{i=1}^N \\nabla f(x_k - \\xi_i).\n\\end{align*}\n\\]\nThis formulation can technically converge even with \\(| i | = 1\\) but with very slow convergence.\n\nNow that the Gaussian homotopy has been introduced, we can move on to the implementation of the algorithm."
  },
  {
    "objectID": "content/eosc555/lectures/lecture7/index.html#homotopy",
    "href": "content/eosc555/lectures/lecture7/index.html#homotopy",
    "title": "Lecture 7: Applying Homotopy to Optimize Highly Non-Convex Functions",
    "section": "Homotopy",
    "text": "Homotopy\nIn mathematics, homotopy refers to the continuous transformation of one function into another. In optimization, homotopy—or continuation optimization—is used to transform a highly non-convex function into a simpler, often more convex surrogate function. This approach enables the optimizer to escape local minima and approach a global minimum by incrementally tackling easier, intermediate optimization problems.\nThe core idea behind homotopy optimization is to relax a difficult optimization problem into a series of smoother problems that gradually resemble the original objective function. This relaxation process spreads the gradient and Hessian information outward, making the function landscape easier to navigate and minimizing the risk of getting stuck in local minima.\nThis can be accomplished using a convolution with a simple function as a kernel. The kernel that is used can have variable width and parameterization, there are varying degrees of relaxation which can be parameterized using a \\(t\\) time variable. As \\(t \\to 0\\) the function becomes more like the original function, and as \\(t \\to 1\\) the function becomes more like the smoothing function. The homotopy between the two is parameterized by \\(t \\in [0, 1]\\).\n\n  \n\nA continuous deformation of a path. Source: Wikimedia Commons\n\n\n\nHomotopy Optimization\nIn the case of optimization, the technique is know as homotopy optimization or continuation optimization. The optimization process starts with the smoothed function and then gradually moves back to the original function using the optimization steps from the relaxed prbolem. This is known as a continuation method, and the scheduling of the homotopy parameter \\(t\\) is the continutation schedule. A summary description with more details and advanced techniques can be found in work by Lin et. al (Lin et al. 2023).\n\nExample\nLet \\(f(x)\\) be the original function and \\(g(x)\\) be the smoothing function. The homotopy function \\(h(x, t)\\) can be defined as and interpolation between the two functions:\n\\[h(x, t) = (1-t) f(x) + t g(x).\\]\nThis new function has the important property that \\(h(x,0) = f(x)\\) and \\(h(x,1) = g(x)\\) so it represents a continuous path of deformation between the two functions, beginning at \\(t=1\\) with a simpler relaxed problem and ending at \\(t=0\\) with the original problem.\nThe new minimization problem becomes:\n\\[\\operatorname*{argmin}_{\\mathcal{X}} h(x, t).\\]\nA schedule can be set up for the times so that a series of times \\(\\{t_0, t_1, \\dots t_k, \\ldots, t_n\\}\\) are used to solve the problem. We solve at \\(t_0 = 1\\) and then gradually decrease the value of \\(t\\) to \\(0\\). The solution \\(x_k\\) at \\(t_{k}\\) is used as the starting point for the next iteration \\(t_{k+1}\\) until reaching \\(t_n = 0\\).\nIn the case where the values of \\(x\\) may be constrained, this becomes similar to the Interior Point Method, where the constraints are relaxed and then gradually tightened."
  }
]
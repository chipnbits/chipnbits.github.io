<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Simon Ghyselincks</title>
<link>https://chipnbits.github.io/content/eosc555/</link>
<atom:link href="https://chipnbits.github.io/content/eosc555/index.xml" rel="self" type="application/rss+xml"/>
<description>A personal page for Simon Ghyselincks</description>
<generator>quarto-1.5.57</generator>
<lastBuildDate>Wed, 25 Sep 2024 07:00:00 GMT</lastBuildDate>
<item>
  <title>Lecture 5: Autodiff and Gauss Newton Optimization</title>
  <dc:creator>Simon Ghyselincks</dc:creator>
  <link>https://chipnbits.github.io/content/eosc555/lectures/lecture5/</link>
  <description><![CDATA[ 




<div class="hidden">
<p>$$ </p>
<p>$$</p>
</div>
<section id="a-non-linear-dynamics-problem" class="level2">
<h2 class="anchored" data-anchor-id="a-non-linear-dynamics-problem">A Non-Linear Dynamics Problem</h2>
<p>A well studied problem in non-linear dynamics involves the predator-prey model that is described by the Lotka-Volterra equations. The equations are given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Cfrac%7Bdx%7D%7Bdt%7D%20&amp;=%20%5Calpha%20x%20-%20%5Cbeta%20xy%20%5C%5C%0A%5Cfrac%7Bdy%7D%7Bdt%7D%20&amp;=%20%5Cdelta%20xy%20-%20%5Cgamma%20y%0A%5Cend%7Baligned%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?x"> and <img src="https://latex.codecogs.com/png.latex?y"> are the populations of the prey and predator respectively. The parameters <img src="https://latex.codecogs.com/png.latex?%5Calpha,%20%5Cbeta,%20%5Cgamma,%20%5Cdelta"> are positive constants. The goal is to find the values of these parameters that best fit the data.</p>
<p>There is no closed form analytic solution that is known to this remarkably simple system of equations, which is why we must resort to numerical solutions to compute the model.</p>
<p>More information about the model can be found at the <a href="https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations">Wikipedia</a> page.</p>
<section id="the-forward-problem" class="level3">
<h3 class="anchored" data-anchor-id="the-forward-problem">The Forward Problem</h3>
<p>We start with an initial time <img src="https://latex.codecogs.com/png.latex?t_0"> and initial conditions <img src="https://latex.codecogs.com/png.latex?x_0,%20y_0">, with parameters <img src="https://latex.codecogs.com/png.latex?%5Calpha,%20%5Cbeta,%20%5Cgamma,%20%5Cdelta"> to run a forward version of the problem using a variant of the forward Euler method, the RK4.</p>
<div id="cell-pred-prey-forward" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nn</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> LotkaVolterraModel(nn.Module):</span>
<span id="cb1-7">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, alpha, beta, gamma, delta):</span>
<span id="cb1-8">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(LotkaVolterraModel, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb1-9">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define parameters as torch tensors that require gradients</span></span>
<span id="cb1-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Parameter(torch.tensor(alpha, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32))</span>
<span id="cb1-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.beta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Parameter(torch.tensor(beta, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32))</span>
<span id="cb1-12">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.gamma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Parameter(torch.tensor(gamma, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32))</span>
<span id="cb1-13">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.delta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.Parameter(torch.tensor(delta, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32))</span>
<span id="cb1-14"></span>
<span id="cb1-15">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x, y):</span>
<span id="cb1-16">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Ensure x and y are tensors</span></span>
<span id="cb1-17">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(x, torch.Tensor):</span>
<span id="cb1-18">            x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(x, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32)</span>
<span id="cb1-19">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(y, torch.Tensor):</span>
<span id="cb1-20">            y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(y, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32)</span>
<span id="cb1-21"></span>
<span id="cb1-22">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute dx and dy based on the current parameters</span></span>
<span id="cb1-23">        dx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.beta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> y</span>
<span id="cb1-24">        dy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.delta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.gamma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> y</span>
<span id="cb1-25"></span>
<span id="cb1-26">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> dx, dy</span>
<span id="cb1-27"></span>
<span id="cb1-28"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> RK4Solver:</span>
<span id="cb1-29">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, model):</span>
<span id="cb1-30">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model</span>
<span id="cb1-31"></span>
<span id="cb1-32">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> step(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x, y, dt):</span>
<span id="cb1-33">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Perform a single RK4 step.</span></span>
<span id="cb1-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb1-36">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert x and y to tensors if they are not already</span></span>
<span id="cb1-37">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(x, torch.Tensor):</span>
<span id="cb1-38">            x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(x, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32)</span>
<span id="cb1-39">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(y, torch.Tensor):</span>
<span id="cb1-40">            y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(y, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float32)</span>
<span id="cb1-41"></span>
<span id="cb1-42">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># RK4 Step calculations</span></span>
<span id="cb1-43">        k1_x, k1_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.forward(x, y)</span>
<span id="cb1-44">        k2_x, k2_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.forward(x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> dt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> k1_x, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> dt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> k1_y)</span>
<span id="cb1-45">        k3_x, k3_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.forward(x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> dt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> k2_x, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> dt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> k2_y)</span>
<span id="cb1-46">        k4_x, k4_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.forward(x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> dt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> k3_x, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> dt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> k3_y)</span>
<span id="cb1-47"></span>
<span id="cb1-48">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update x and y using weighted averages of the slopes</span></span>
<span id="cb1-49">        x_new <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (dt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (k1_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> k2_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> k3_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> k4_x)</span>
<span id="cb1-50">        y_new <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (dt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (k1_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> k2_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> k3_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> k4_y)</span>
<span id="cb1-51"></span>
<span id="cb1-52">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> x_new, y_new</span>
<span id="cb1-53"></span>
<span id="cb1-54">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> solve(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x0, y0, time_steps):</span>
<span id="cb1-55">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-56"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Solve the system over a serie of time steps.</span></span>
<span id="cb1-57"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Parameters:</span></span>
<span id="cb1-58"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            x0: Initial value of prey population</span></span>
<span id="cb1-59"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            y0: Initial value of predator population</span></span>
<span id="cb1-60"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            time_steps: List or numpy array of time steps to solve over</span></span>
<span id="cb1-61"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb1-62">        x, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x0, y0</span>
<span id="cb1-63">        DT <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time_steps[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> time_steps[:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb1-64">        trajectory <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(time_steps), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb1-65">        trajectory[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([x, y])</span>
<span id="cb1-66"></span>
<span id="cb1-67">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, dt <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(DT):</span>
<span id="cb1-68">            x, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.step(x, y, dt)</span>
<span id="cb1-69">            trajectory[i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([x, y])            </span>
<span id="cb1-70"></span>
<span id="cb1-71">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> trajectory</span>
<span id="cb1-72"></span>
<span id="cb1-73"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the model parameters</span></span>
<span id="cb1-74">alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb1-75">beta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.1</span></span>
<span id="cb1-76">gamma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span></span>
<span id="cb1-77">delta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span></span>
<span id="cb1-78"></span>
<span id="cb1-79"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the model and solver</span></span>
<span id="cb1-80">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LotkaVolterraModel(alpha, beta, gamma, delta)</span>
<span id="cb1-81">solver <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RK4Solver(model)</span>
<span id="cb1-82"></span>
<span id="cb1-83"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the initial conditions and time steps</span></span>
<span id="cb1-84">x0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span>
<span id="cb1-85">y0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb1-86">time_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb1-87"></span>
<span id="cb1-88"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Solve the system</span></span>
<span id="cb1-89">trajectory <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> solver.solve(x0, y0, time_steps)</span>
<span id="cb1-90"></span>
<span id="cb1-91">x_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> trajectory[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].detach().numpy()</span>
<span id="cb1-92">y_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> trajectory[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].detach().numpy()</span>
<span id="cb1-93"></span>
<span id="cb1-94">plt.plot(time_steps, x_values, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Prey'</span>)</span>
<span id="cb1-95">plt.plot(time_steps, y_values, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predator'</span>)</span>
<span id="cb1-96">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Time'</span>)</span>
<span id="cb1-97">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Population'</span>)</span>
<span id="cb1-98">plt.legend()</span>
<span id="cb1-99">plt.savefig(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'imgs/lotka_volterra.png'</span>)</span>
<span id="cb1-100">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="pred-prey-forward" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture5/index_files/figure-html/pred-prey-forward-output-1.png" width="585" height="429" class="figure-img"></p>
<figcaption>The time evolution of the prey and predator populations.</figcaption>
</figure>
</div>
</div>
</div>
<p>We can additionally look at the phase space of the system for various initial conditions to see how the different solutions are periodic.</p>
<div id="cell-pred-prey-phase-space" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the initial conditions</span></span>
<span id="cb2-2">x0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span>
<span id="cb2-3">y0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.2</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.5</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]</span>
<span id="cb2-4"></span>
<span id="cb2-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the model and solver</span></span>
<span id="cb2-6">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LotkaVolterraModel(alpha, beta, gamma, delta)</span>
<span id="cb2-7">solver <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RK4Solver(model)</span>
<span id="cb2-8"></span>
<span id="cb2-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the time steps</span></span>
<span id="cb2-10">time_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb2-11"></span>
<span id="cb2-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the phase space</span></span>
<span id="cb2-13">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb2-14"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> y <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> y0:</span>
<span id="cb2-15">    trajectory <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> solver.solve(x0, y, time_steps)</span>
<span id="cb2-16">    x_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> trajectory[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].detach().numpy()</span>
<span id="cb2-17">    y_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> trajectory[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].detach().numpy()</span>
<span id="cb2-18">    plt.plot(x_values, y_values, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'y0=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>y<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb2-19"></span>
<span id="cb2-20">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Prey Population'</span>)</span>
<span id="cb2-21">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predator Population'</span>)</span>
<span id="cb2-22">plt.legend()</span>
<span id="cb2-23">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Lotka-Volterra Phase Space'</span>)</span>
<span id="cb2-24">plt.savefig(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'imgs/lotka_volterra_phase_space.png'</span>)</span>
<span id="cb2-25">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="pred-prey-phase-space" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture5/index_files/figure-html/pred-prey-phase-space-output-1.png" width="659" height="523" class="figure-img"></p>
<figcaption>The phase space of the predator-prey model.</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="the-inverse-problem" class="level2">
<h2 class="anchored" data-anchor-id="the-inverse-problem">The Inverse Problem</h2>
<p>The inverse problem in this case is to find the parameters <img src="https://latex.codecogs.com/png.latex?%5Calpha,%20%5Cbeta,%20%5Cgamma,%20%5Cdelta"> that best fit the data. We suppose that we have a model with parameters that takes in the initial conditions and time steps and returns the trajectory of the system.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bd%20%5Cvec%7Bx%7D%7D%7Bdt%7D%20=%20f(%5Cvec%7Bx%7D;%20%5Cvec%7Bp%7D),%20%5Cquad%20%5Cvec%7Bx%7D_0%20=%20%5Cvec%7Bx%7D(0)"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bx%7D"> is the state of the system and <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bp%7D"> are the parameters. The goal is to form an esimate of <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bp%7D">, while the data that we have collected may be sparse, noisy, or incomplete. We represent the incompleteness in the data using the <img src="https://latex.codecogs.com/png.latex?Q"> <em>sampling operator</em> which is applied to the true underlying data to give <img src="https://latex.codecogs.com/png.latex?Qx">. If <img src="https://latex.codecogs.com/png.latex?x"> is fully given then <img src="https://latex.codecogs.com/png.latex?Q=I">.</p>
<p><img src="https://latex.codecogs.com/png.latex?f(%5Cvec%7Bx%7D;%20%5Cvec%7Bp%7D)%20%5Ccong%20%5Cfrac%7Bx_%7Bn+1%7D%20-%20x_n%7D%7B%5CDelta%20t%7D"></p>
<p>and we can apply non-linear least squares to try and produce a fit. <img src="https://latex.codecogs.com/png.latex?F(%5Cvec%7Bp%7D,%20x_0)%20=%20x(t,%20%5Cvec%7Bp%7D)"> and the observed data is <img src="https://latex.codecogs.com/png.latex?Qx(t)">. We also make an assumption here that <img src="https://latex.codecogs.com/png.latex?F"> does not depend on the particular solver that we are using for the forward ODE and that all of the <img src="https://latex.codecogs.com/png.latex?p"> are physical parameters, we assume that the parameters are faithful enough.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cmin_%7B%5Cvec%7Bp%7D%7D%20%5Cfrac%7B1%7D%7B2%7D%5C%7CQF(p)-d%5C%7C%5E2%20=%20%5Cmin_%7Bp%7D%5C%7C%5Cphi(%5Cvec%7Bp%7D)%5C%7C%5E2"></p>
<p>So what we have is a non-linear least squares problem, where we are trying to minimize some mean squared error of a function of the parameters <img src="https://latex.codecogs.com/png.latex?p"> and the data. The data is fixed for a given problem, so it is only the optimal <img src="https://latex.codecogs.com/png.latex?p"> that we are trying to find.</p>
</section>
<section id="minimization-of-the-objective-function" class="level2">
<h2 class="anchored" data-anchor-id="minimization-of-the-objective-function">Minimization of the Objective Function</h2>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cmin_%7Bp%20%5Cin%20%5Cmathbb%7BR%7D%5Em%7D%20%5Cbiggl%5C%7B%20%5Csum_%7Bi=1%7D%5En%20(QF_i(%5Cmathbf%7Bp%7D)%20-%20d_i)%20%5E2%5Cbiggr%5C%7D"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?d_i"> is the observed data. This is the same as</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cmin_%7Bp%20%5Cin%20%5Cmathbb%7BR%7D%5Em%7D%20%5C%7CG(%5Cmathbf%7Bp%7D)%5C%7C%5E2"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?G(%5Cmathbf%7Bp%7D)%20=%20QF(%5Cmathbf%7Bp%7D)%20-%20d"> and <img src="https://latex.codecogs.com/png.latex?d%20%5Cin%20%5Cmathbb%7BR%7D%5En">. We are minimizing the norm of a non-linear function of the parameters. Supposing that we want to find the minimizer, one approach would be by gradient descent.</p>
<section id="the-jacobian-a-quick-review" class="level4">
<h4 class="anchored" data-anchor-id="the-jacobian-a-quick-review">The Jacobian: A quick review</h4>
<hr>
<p>The Jacobian is a multivariate extension of the derivative that extends to functions <img src="https://latex.codecogs.com/png.latex?f%20:%20%5Cmathbb%7BR%7D%5Em%20%5Cto%20%5Cmathbb%7BR%7D%5En">. Because there are <img src="https://latex.codecogs.com/png.latex?n"> function outputs and <img src="https://latex.codecogs.com/png.latex?m"> input variables, the Jacobian is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20m"> matrix that contains the information of how each of the <img src="https://latex.codecogs.com/png.latex?n"> functions changes with respect to each of the <img src="https://latex.codecogs.com/png.latex?m"> variables. In an abuse of notation, it can be seen as <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Cpartial%20%5Cvec%7Bf%7D%7D%7B%5Cpartial%20%5Cvec%7Bx%7D%7D">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BJ_f%7D%20=%0A%5Cleft%5B%0A%20%20%20%20%5Cfrac%7B%5Cpartial%20f%7D%7B%5Cpartial%20x_1%7D%20%5Ccdots%20%5Cfrac%7B%5Cpartial%20f%7D%7B%5Cpartial%20x_n%7D%0A%5Cright%5D%0A=%0A%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%5Cnabla%5E%5Ctop%20f_1%0A%20%20%20%20%5C%5C%0A%20%20%20%20%5Cvdots%0A%20%20%20%20%5C%5C%0A%20%20%20%20%5Cnabla%5E%5Ctop%20f_m%0A%5Cend%7Bbmatrix%7D%0A=%0A%5Cleft%5B%0A%20%20%20%20%5Cbegin%7Barray%7D%7Bccc%7D%0A%20%20%20%20%5Cfrac%7B%5Cpartial%20f_1%7D%7B%5Cpartial%20x_1%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cfrac%7B%5Cpartial%20f_1%7D%7B%5Cpartial%20x_n%7D%20%5C%5C%0A%20%20%20%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20%20%20%5Cfrac%7B%5Cpartial%20f_m%7D%7B%5Cpartial%20x_1%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cfrac%7B%5Cpartial%20f_m%7D%7B%5Cpartial%20x_n%7D%0A%20%20%20%20%5Cend%7Barray%7D%0A%5Cright%5D%0A"></p>
<p>Note that like the derivative, the Jacobian is a function of the input variables. The Jacobian is a linear approximation of the function <img src="https://latex.codecogs.com/png.latex?f"> at a point <img src="https://latex.codecogs.com/png.latex?x_0"> and can be used to approximate the function at a point <img src="https://latex.codecogs.com/png.latex?x_0%20+%20%5CDelta%20x">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20f(x_0%20+%20%5CDelta%20x)%20%5Capprox%20f(x_0)%20+%20J_f(x_0)%20%5CDelta%20x"></p>
<p>Noting that we are applying matrix multiplication using <img src="https://latex.codecogs.com/png.latex?J_f"> evaluated at <img src="https://latex.codecogs.com/png.latex?x_0"> and the vector <img src="https://latex.codecogs.com/png.latex?%5CDelta%20x%20=%20%5Cvec%7Bx%7D%20-%20%5Cvec%7Bx_0%7D">.</p>
<hr>
<p>We can compute the gradient of <img src="https://latex.codecogs.com/png.latex?%5C%7CG(%5Cmathbf%7Bp%7D)%5C%7C%5E2"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign%7D%0A%5Cnabla_p%20%5C%7CG(p)%5C%7C%5E2%20&amp;=%20%5Cnabla_p%20G(p)%5ET%20G(p)%5C%5C%0A&amp;=%20%5Csum_%7Bi=1%7D%5En%20%5Cnabla_p%20G_i(p)%5E2%5C%5C%0A&amp;=%20%5Csum_%7Bi=1%7D%5En%202%20G_i(p)%20%5Cnabla_p%20G_i(p)%5C%5C%0A&amp;=%202%20J_G(p)%5ET%20G(p)%0A%5Cend%7Balign%7D%0A"></p>
<p>From this stage we could apply gradient descent to find the minimum of the function. However, the function <img src="https://latex.codecogs.com/png.latex?G(p)"> is non-linear and so the gradient descent method may not converge quickly or the problem may have poor conditioning. The celebrated (Newton’s Method)[https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization#Higher_dimensions] addresses some of these issues, but requires computing the Hessian <img src="https://latex.codecogs.com/png.latex?%5Cnabla%5E2%20%5C%7CG(p)%5C%7C%5E2"> of the function, which can be expensive.</p>
<p>The true Hessian of the function is: <img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla%5E2%20%5C%7CG(p)%5C%7C%5E2%20=%202%20J_G(p)%5ET%20J_G(p)%20+%202%20%5Csum_%7Bi=1%7D%5En%20G_i(p)%20%5Cnabla%5E2%20G_i(p)%0A"></p>
<p>So we’d have to compute the Hessian of each of the <img src="https://latex.codecogs.com/png.latex?G_i(p)"> functions, of which there are <img src="https://latex.codecogs.com/png.latex?n">, not good in practice. If we did have this Hessian, then the steps with Newton’s method would be:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20p_%7Bk+1%7D%20=%20p_k%20-%20(%5Cnabla%5E2%20%5C%7CG(p_k)%5C%7C)%5E%7B-1%7D%20%5Cnabla%20(%5C%7CG(p_k)%5C%7C%5E2)"></p>
</section>
</section>
<section id="gauss-newton-optimization" class="level2">
<h2 class="anchored" data-anchor-id="gauss-newton-optimization">Gauss-Newton Optimization</h2>
<p>Rather than solve this problem directly we can linearize inside of the norm and solve the linearized problem using the normal equations. We approximate the function <img src="https://latex.codecogs.com/png.latex?G(p)%20=%20QF(p)%20-%20d"> by a linear function <img src="https://latex.codecogs.com/png.latex?G(p)%20%5Capprox%20(QF(p_k)%20-%20d)%20+%20QJ_k(p-p_k)"> where <img src="https://latex.codecogs.com/png.latex?J_k"> is the Jacobian of <img src="https://latex.codecogs.com/png.latex?F(p)"> at <img src="https://latex.codecogs.com/png.latex?p_k">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cmin_%7Bp%20%5Cin%20%5Cmathbb%7BR%7D%5Em%7D%20%5C%7CQF(p_k)%20-%20d%20+%20QJ_k(p-p_k)%5C%7C%5E2"></p>
<p>Then rearranging this we get a form that is a linear least squares problem:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Balign%7D%0A&amp;%20%5Cmin_%7Bp%20%5Cin%20%5Cmathbb%7BR%7D%5Em%7D%20%5C%7C%20QJ_kp%20-%20(d%20+%20QJ_k%20p_k-%20QF(p_k)%20)%5C%7C%5E2%5C%5C%0A=&amp;%20%5Cmin_%7Bp%20%5Cin%20%5Cmathbb%7BR%7D%5Em%7D%20%5C%7C%20Ap%20-%20r_k%5C%7C%5E2%5C%5C%0AA%5ET%20A%20p%20=&amp;%20A%5ET%20r_k%0A%5Cend%7Balign%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?A%20=%20QJ_k"> and <img src="https://latex.codecogs.com/png.latex?r_k%20=%20d%20+%20QJ_k%20p_k%20-%20QF(p_k)">. This is the normal equations for the linear least squares problem. This gives us</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0Ap_%7Bk+1%7D%20&amp;=%20(A%5ET%20A)%5E%7B-1%7D%20A%5ET%20(r_k)%5C%5C%0A&amp;=%20(J_k%5ET%20Q%5ET%20Q%20J_k)%5E%7B-1%7D%20J_k%5ET%20Q%5ET%20(d%20+%20QJ_k%20p_k%20-%20QF(p_k))%5C%5C%0A&amp;=%20p_k%20+%20(J_k%5ET%20Q%5ET%20Q%20J_k)%5E%7B-1%7D%20J_k%5ET%20Q%5ET%20(d%20-%20QF(p_k))%5C%5C%0Ap_%7Bk+1%7D%20&amp;=%20p_k%20-%20(J_k%5ET%20Q%5ET%20Q%20J_k)%5E%7B-1%7D%20J_k%5ET%20Q%5ET%20(QF(p_k)%20-%20d)%5C%5C%0A%5Cend%7Balign%7D%0A"></p>
<p>This could be written in a more tidy and general way, reacalling that <img src="https://latex.codecogs.com/png.latex?G(p)%20=%20QF(p)%20-%20d"> and let <img src="https://latex.codecogs.com/png.latex?J_G(p)%20=%20QJ(p)">, then we have:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20p_%7Bk+1%7D%20=%20p_k%20-%20(J_G%7Bp_k%7D%5ETJ_G%7Bp_k%7D)%5E%7B-1%7D%20J_G%7Bp_k%7D%20G(p_k)"></p>
<section id="comparison-with-newtons-method" class="level4">
<h4 class="anchored" data-anchor-id="comparison-with-newtons-method">Comparison with Newton’s Method</h4>
<p>So this resembles a scaled gradient descent. In Newton’s method we have the Hessian, in Gauss-Newton we have the Jacobian of the function. As a comparison:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 28%">
<col style="width: 71%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Method</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Newton’s Method</strong></td>
<td><strong>Step Update</strong></td>
</tr>
<tr class="even">
<td></td>
<td><img src="https://latex.codecogs.com/png.latex?p_%7Bk+1%7D%20=%20p_k%20-%20(%5Cnabla%5E2%20%5C%7CG(p_k)%5C%7C%5E2)%5E%7B-1%7D%20%5Cnabla%20%5C%7CG(p_k)%5C%7C%5E2"></td>
</tr>
<tr class="odd">
<td></td>
<td><strong>Scaling Matrix</strong></td>
</tr>
<tr class="even">
<td></td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cnabla%5E2%20%5C%7CG(p_k)%5C%7C%5E2%20=%202%20J_G(p_k)%5ET%20J(p_k)%20+%202%20%5Csum_%7Bi=1%7D%5En%20G_i(p_k)%20%5Cnabla%5E2%20G_i(p_k)"></td>
</tr>
<tr class="odd">
<td><strong>Gauss-Newton Method</strong></td>
<td><strong>Step Update</strong></td>
</tr>
<tr class="even">
<td></td>
<td><img src="https://latex.codecogs.com/png.latex?p_%7Bk+1%7D%20=%20p_k%20-%20(J_G(p_k)%5ET%20J_G(p_k))%5E%7B-1%7D%20J_G(p_k)%5ET%20G(p_k)"></td>
</tr>
<tr class="odd">
<td></td>
<td><strong>Scaling Matrix</strong></td>
</tr>
<tr class="even">
<td></td>
<td><img src="https://latex.codecogs.com/png.latex?J_G(p_k)%5ET%20J_G(p_k)"></td>
</tr>
</tbody>
</table>
<p>The direction in Newton’s method can be rewritten as <img src="https://latex.codecogs.com/png.latex?d_k%20=%20%5Cleft(J_G(p_k)%5ET%20J(p_k)%20+%20%5Csum_%7Bi=1%7D%5En%20G_i(p_k)%20%5Cnabla%5E2%20G_i(p_k)%5Cright)%5E%7B-1%7D%20J_G(p_k)%5ET%20G(p_k)"></p>
<p>So we can see that the difference between the two is the omission of the computationally expensive <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bi=1%7D%5En%20G_i(p)%20%5Cnabla%5E2%20G_i(p)"> terms. The Gauss-Newton method is approximating the second-order approach of Newton’s method by only considering the first-order terms inside of the norm.</p>
<p><img src="https://latex.codecogs.com/png.latex?J_G(p_k)%5ET%20J(p_k)%20%5Csum_%7Bi=1%7D%5En%20G_i(p_k)%20%5Cnabla%5E2%20G_i(p_k)%20%5Capprox%20J_G(p_k)%5ET%20J(p_k)"></p>
<p>Recall that <img src="https://latex.codecogs.com/png.latex?G(p)%20=%20QF(p)%20-%20d"> which is the difference between the observed data and the model. If the difference is small then <img src="https://latex.codecogs.com/png.latex?G_i"> is also small and the approximation is good.</p>
</section>
<section id="algorithm-for-gauss-newton" class="level3">
<h3 class="anchored" data-anchor-id="algorithm-for-gauss-newton">Algorithm for Gauss-Newton</h3>
<p>We have derived the algorithm for the Gauss-Newton method for solving the non-linear least squares problem. The algorithm is as follows:</p>
<div class="pseudocode-container quarto-float" data-indent-size="1.2em" data-caption-prefix="Algorithm" data-no-end="false" data-line-number="true" data-pseudocode-number="1" data-line-number-punc=":" data-comment-delimiter="//">
<div class="pseudocode">
\begin{algorithm} \caption{Gauss-Newton Algorithm for Non-linear Least Squares}\begin{algorithmic} \State \textbf{Input:} Initial guess $p_0$, maximum iterations $K$, tolerance $\epsilon$ \State \textbf{Initialize} $p_0$ \For{$k = 0, 1, 2, \ldots$} \State Compute the Jacobian $J_k$ of $F(p_k)$ \State Compute the transpose $J_k^T$ of the Jacobian \State Compute the residual $r_k = d - QF(p_k)$ (forward model) \State Compute the step $s_k = (J_k^T Q^T Q J_k)^{-1} J_k^T Q^T r_k$ \State Update the parameters $p_{k+1} = p_k + \mu_k s_k$ \If{$\|s_k\| &lt; \epsilon$} \State \textbf{Stop} \EndIf \EndFor \State \textbf{Output:} $p_{k+1}$ as the optimal solution \end{algorithmic} \end{algorithm}
</div>
</div>
</section>
<section id="matrix-inversions" class="level3">
<h3 class="anchored" data-anchor-id="matrix-inversions">Matrix Inversions</h3>
<p>In practice it may be computationally expensive to invert the matrix <img src="https://latex.codecogs.com/png.latex?J_k%5ET%20Q%5ET%20Q%20J_k">. We can use a conjugate gradient method to solve the normal equations instead. <img src="https://latex.codecogs.com/png.latex?J_k%5ET%20Q%5ET%20Q%20J_k%20s_k%20=%20J_k%5ET%20Q%5ET%20r_k"></p>
<p>We developed a conjugate gradient method in the last lecture, so we can use that along with the computed values for <img src="https://latex.codecogs.com/png.latex?J_k%5ET,%20J_k,%20r_k"> to solve the normal equations and get the step <img src="https://latex.codecogs.com/png.latex?s_k">.</p>
</section>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 40%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Component</strong></th>
<th><strong>Description</strong></th>
<th><strong>Dimensions</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?d"></td>
<td>Observed data</td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E%7Bn%7D"></td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?p_k"></td>
<td>Parameters</td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E%7Bm%7D"></td>
</tr>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?Q"></td>
<td>Weight matrix</td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E%7Bn%20%5Ctimes%20n%7D"></td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?J_k"></td>
<td>Jacobian of <img src="https://latex.codecogs.com/png.latex?F(p_k)"></td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E%7Bn%20%5Ctimes%20m%7D"></td>
</tr>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?r_k"></td>
<td>Residual <img src="https://latex.codecogs.com/png.latex?d%20-%20QF(p_k)"></td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E%7Bn%7D"></td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?F(p_k)"></td>
<td>Forward model output</td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E%7Bn%7D"></td>
</tr>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?s_k"></td>
<td>Step direction</td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E%7Bm%7D"></td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?J_k%5ET"></td>
<td>Transpose of the Jacobian</td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20n%7D"></td>
</tr>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?J_k%5ET%20Q%5ET%20Q%20J_k"></td>
<td>Normal equations matrix</td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20m%7D"></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="automatic-differentiation" class="level2">
<h2 class="anchored" data-anchor-id="automatic-differentiation">Automatic Differentiation</h2>
<p>In practice the Jacobian and its transpose can be computed using automatic differentiation.</p>
<p>Take the forward model <img src="https://latex.codecogs.com/png.latex?F(p)"> for which we want a Jacobian matrix at <img src="https://latex.codecogs.com/png.latex?p_k">. We can write the Taylor expansion of the forward model as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20F(p_k%20+%20%5Cepsilon%20v)%20=%20F(p_k)%20+%20J_k%20%5Cepsilon%20v%20+%20%5Cmathcal%7BO%7D(%5Cepsilon%5E2)"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?J_k"> is the Jacobian of <img src="https://latex.codecogs.com/png.latex?F(p_k)">. If we take the derivative of both sides in this expansion with respect to <img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> we get:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cfrac%7Bd%7D%7Bd%20%5Cepsilon%7D%20F(p_k%20+%20%5Cepsilon%20v)%20=%20J_k%20v%20+%20%5Cmathcal%7BO%7D(%5Cepsilon)"></p>
<p>If we make <img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> very small then the Jacobian of the forward problem can be numerically approximated and bounded by a small <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BO%7D(%5Cepsilon)">. The next step to fully recover the Jacobian is to take the gradient with respect to <img src="https://latex.codecogs.com/png.latex?v"> of the left-hand side of the equation.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cnabla_v%20%5Cfrac%7Bd%7D%7Bd%20%5Cepsilon%7D%20F(p_k%20+%20%5Cepsilon%20v)%20=%20J_k"></p>
<p>The gradient with respect to <img src="https://latex.codecogs.com/png.latex?v"> can be traced through with automatic differentiation. So we apply a chain of operations, the <code>pytorch</code> Jacobian vector product, followed by backpropagation on a surrogate <img src="https://latex.codecogs.com/png.latex?v"> that was passed to the function to get the Jacobian of the forward model. The same principles can be used to recover <img src="https://latex.codecogs.com/png.latex?J_k%5ET">.</p>
<p>There is also the direct method that is avaible for computing the Jacobian matrix using the torch library. Both cases are shown below. Note that the tensors have a <code>requires_grad=True</code> flag set to allow for the gradients to be computed, it indicates that the tensor is part of the computational graph for backpropagation and tracing by how much each element of <img src="https://latex.codecogs.com/png.latex?v"> contributed to the <code>jvp</code> result.</p>
<div id="jacobian-vector-product" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.autograd.functional <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> jvp</span>
<span id="cb3-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.autograd.functional <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> jacobian</span>
<span id="cb3-4"></span>
<span id="cb3-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define a simple forward function</span></span>
<span id="cb3-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> F(p):</span>
<span id="cb3-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> torch.stack([p[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> p[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], p[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> p[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]])</span>
<span id="cb3-8"></span>
<span id="cb3-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Input point p_k</span></span>
<span id="cb3-10">p_k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>])</span>
<span id="cb3-11"></span>
<span id="cb3-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Arbitrary vector v, same size as p_k</span></span>
<span id="cb3-13">v <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>], requires_grad<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb3-14"></span>
<span id="cb3-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the Jacobian-vector product (J(p) * v)</span></span>
<span id="cb3-16">F_output, jvp_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jvp(F, (p_k,), v, create_graph<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb3-17"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Function output:"</span>)</span>
<span id="cb3-18"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(F_output)</span>
<span id="cb3-19"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Jacobian-vector product:"</span>)</span>
<span id="cb3-20"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(jvp_result)</span>
<span id="cb3-21"></span>
<span id="cb3-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize a list to store each row of the Jacobian</span></span>
<span id="cb3-23">jacobian_rows <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb3-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the gradient of each component of the JVP result separately, retaining the graph to avoid re-computation</span></span>
<span id="cb3-25"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(F_output.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]):</span>
<span id="cb3-26">    v.grad <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Clear the gradient</span></span>
<span id="cb3-27">    jvp_result.backward(torch.tensor([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> j <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(F_output.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])]), retain_graph<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb3-28">    jacobian_rows.append(v.grad.clone())  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Append the gradient (row of the Jacobian)</span></span>
<span id="cb3-29"></span>
<span id="cb3-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Stack the rows to get the full Jacobian matrix</span></span>
<span id="cb3-31">jacobian_matrix <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.stack(jacobian_rows, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb3-32"></span>
<span id="cb3-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the Jacobian matrix</span></span>
<span id="cb3-34"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Jacobian matrix at p_k:"</span>)</span>
<span id="cb3-35"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(jacobian_matrix)</span>
<span id="cb3-36"></span>
<span id="cb3-37"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the full Jacobian matrix directly</span></span>
<span id="cb3-38">jacobian_matrix <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jacobian(F, p_k)</span>
<span id="cb3-39"></span>
<span id="cb3-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the Jacobian matrix</span></span>
<span id="cb3-41"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Jacobian matrix at p_k:"</span>)</span>
<span id="cb3-42"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(jacobian_matrix)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Function output:
tensor([2., 2.], grad_fn=&lt;StackBackward0&gt;)
Jacobian-vector product:
tensor([3., 4.], grad_fn=&lt;AddBackward0&gt;)
Jacobian matrix at p_k:
tensor([[2., 1.],
        [1., 3.]])
Jacobian matrix at p_k:
tensor([[2., 1.],
        [1., 3.]])</code></pre>
</div>
</div>


</section>

 ]]></description>
  <category>Optimization</category>
  <category>Automatic Differentiation</category>
  <category>Gauss-Newton</category>
  <guid>https://chipnbits.github.io/content/eosc555/lectures/lecture5/</guid>
  <pubDate>Wed, 25 Sep 2024 07:00:00 GMT</pubDate>
  <media:content url="https://chipnbits.github.io/content/eosc555/lectures/lecture5/imgs/lotka_volterra.png" medium="image" type="image/png" height="103" width="144"/>
</item>
<item>
  <title>Lecture 4: Regularization and the Conjugate Gradient Methods</title>
  <dc:creator>Simon Ghyselincks</dc:creator>
  <link>https://chipnbits.github.io/content/eosc555/lectures/lecture4/</link>
  <description><![CDATA[ 




<div class="hidden">
<p>$$ </p>
<p>$$</p>
</div>
<section id="tikhnov-regularization" class="level2">
<h2 class="anchored" data-anchor-id="tikhnov-regularization">Tikhnov Regularization</h2>
<p>We have looked at the least squares formulation for solving inverse problems:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cmin%20%5Cfrac%7B1%7D%7B2%7D%20%5C%7CA%20x%20-%20b%5C%7C%5E2%20"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?A%20%5Cin%20%5Cmathbb%20R%5E%7Bm%20%5Ctimes%20n%7D"> is a linear operator, <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20%5Cmathbb%20R%5En"> is the unknown model, and <img src="https://latex.codecogs.com/png.latex?b%20%5Cin%20%5Cmathbb%20R%5Em"> is the data.</p>
<p>The least squares problem is often ill-posed, meaning that the solution is not unique or stable. If there are more unknowns than equations, such as the case when <img src="https://latex.codecogs.com/png.latex?n%20%3E%20m">, then the problem is underdetermined and there are infinitely many solutions.</p>
<p>We can return to unique solutions by adding a regularization term to the selection of the <img src="https://latex.codecogs.com/png.latex?x"> that we want to minimize. The Tikhonov regularization technique adds a penalty term to the least squares problem:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cmin%20%5Cfrac%7B1%7D%7B2%7D%20%5C%7CA%20x%20-%20b%5C%7C%5E2%20+%20%5Cfrac%7B1%7D%7B2%7D%20%20%5Clambda%20%5C%7CLx%5C%7C%5E2%20"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?L%20%5Cin%20%5Cmathbb%20R%5E%7Bn%20%5Ctimes%20n%7D"> is a regularization matrix. The regularization matrix <img src="https://latex.codecogs.com/png.latex?L"> is often chosen to be the identity matrix, but other choices are possible.</p>
<section id="uniqueness" class="level4">
<h4 class="anchored" data-anchor-id="uniqueness">Uniqueness</h4>
<p>To check the uniqueness of the solution, we can rewrite the problem as a quadratic form:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cmin%20%5Cfrac%7B1%7D%7B2%7D%20x%5ET%20A%5ET%20A%20x%20-%20b%5ET%20A%20x%20+%20%5Cfrac%7B1%7D%7B2%7D%20%5Clambda%20x%5ET%20L%5ET%20L%20x%20"> <img src="https://latex.codecogs.com/png.latex?%20=%20%5Cmin%20%5Cfrac%7B1%7D%7B2%7D%20x%5ET%20H%20x%20-%20b%5ET%20A%20x%20+%20%5Cfrac%7B1%7D%7B2%7D%5C%7Cb%5C%7C%5E2"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?H%20=%20A%5ET%20A%20+%20%5Clambda%20L%5ET%20L"> is the Hessian matrix which is symmetric and positive semi-definite by spectral theorem. If we choose an appropriate <img src="https://latex.codecogs.com/png.latex?%5Clambda">, then the Hessian matrix is positive definite and the problem is well-posed. In the case where <img src="https://latex.codecogs.com/png.latex?L=I">, the Hessian becomes full rank for <img src="https://latex.codecogs.com/png.latex?%5Clambda%20%3E%200"> and the problem is well-posed. The quality that <img src="https://latex.codecogs.com/png.latex?H%20%5Csucc%200"> means that the matrix is invertible.</p>
</section>
<section id="solution" class="level4">
<h4 class="anchored" data-anchor-id="solution">Solution</h4>
<p>The unique solution is given by by the first order optimatility condition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Balign%7D%0A(A%5ET%20A%20+%20%5Clambda%20L%5ET%20L)%20%5Cmathbf%7Bx%7D_%7B%5Ctext%7BRLS%7D%7D%20-%20A%5ET%20b&amp;=%200%20%5C%5C%0A%5Cmathbf%7Bx%7D_%7B%5Ctext%7BRLS%7D%7D%20&amp;=%20(A%5ET%20A%20+%20%5Clambda%20L%5ET%20L)%5E%7B-1%7D%20A%5ET%20b%0A%5Cend%7Balign%7D%0A"></p>
</section>
<section id="svd-decomposition" class="level4">
<h4 class="anchored" data-anchor-id="svd-decomposition">SVD Decomposition</h4>
<p>The solution can be written in terms of the singular value decomposition of <img src="https://latex.codecogs.com/png.latex?A">, and with the assumption that <img src="https://latex.codecogs.com/png.latex?L=I">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Balign%7D%0AA%20&amp;=%20U%20%5CSigma%20V%5ET%20%5C%5C%0AA%5ET%20A%20&amp;=%20V%20%5CSigma%5ET%20%5CSigma%20V%5ET%20%5C%5C%0A%5Cmathbf%7Bx%7D_%7B%5Ctext%7BRLS%7D%7D%20&amp;=%20%5Cleft(%20V%20%5CSigma%5E2%20V%5ET%20+%20%5Clambda%20I%20%5Cright)%5E%7B-1%7D%20V%20%5CSigma%5ET%20U%5ET%20b%20%5C%5C%0A&amp;=%20%5Cleft(%20V%20%5CSigma%5E2%20V%5ET%20+%20%5Clambda%20I%20V%20V%5ET%20%5Cright)%5E%7B-1%7D%20V%20%5CSigma%5ET%20U%5ET%20b%5C%5C%0A&amp;=%20V%20%5Cleft(%20%5CSigma%5E2%20+%20%5Clambda%20I%20%5Cright)%5E%7B-1%7D%20%5CSigma%5ET%20U%5ET%20b%5C%5C%0A&amp;=%20V%20%5Cmathbf%7BDiag%7D%5Cleft(%20%5Cfrac%7B%5Csigma_i%7D%7B%5Csigma_i%5E2%20+%20%5Clambda%7D%20%5Cright)%20U%5ET%20b%5C%5C%0A&amp;=%20%5Csum%20_i%20%5E%20n%20%5Cfrac%7B%5Csigma_i%7D%7B%5Csigma_i%5E2%20+%20%5Clambda%7D%20%5Clangle%20u_i,%20b%20%5Crangle%20v_i%0A%5Cend%7Balign%7D%0A"></p>
<p>This form is more readily comparable to some of the other methods that we have see so far, which are presented in the table below:</p>
</section>
</section>
<section id="comparison-of-least-squares-methods" class="level2">
<h2 class="anchored" data-anchor-id="comparison-of-least-squares-methods">Comparison of Least Squares Methods</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Tikhonov</td>
<td><img src="https://latex.codecogs.com/png.latex?x_%7B%5Ctext%7BRLS%7D%7D%20=%20%5Csum%20_i%20%5E%20n%20%5Cfrac%7B%5Csigma_i%7D%7B%5Csigma_i%5E2%20+%20%5Clambda%7D%20%5Clangle%20u_i,%20b%20%5Crangle%20v_i"></td>
</tr>
<tr class="even">
<td>Thresholded SVD</td>
<td><img src="https://latex.codecogs.com/png.latex?x_%7B%5Ctext%7BTSVD%7D%7D%20=%20%5Csum%20_i%20%5E%20n%20h(%5Csigma_i)%20%5Clangle%20u_i,%20b%20%5Crangle%20v_i"></td>
</tr>
<tr class="odd">
<td>Gradient Flow</td>
<td><img src="https://latex.codecogs.com/png.latex?x_%7B%5Ctext%7BSDF%7D%7D%20=%20%5Csum%20_i%20%5E%20n%20%5Cfrac%7B%5Cexp(-%5Csigma_i%5E2%20t)%20-%201%7D%7B%5Csigma_i%7D%20%5Clangle%20u_i,%20b%20%5Crangle%20v_i"></td>
</tr>
</tbody>
</table>
<p>As we can see all three methods have a similar form and offer some mechanism for controlling the noise induced by the small singular values of <img src="https://latex.codecogs.com/png.latex?A">.</p>
<div id="cell-comp-plot" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> generate_ill_conditioned_matrix(m, n, condition_number):   </span>
<span id="cb1-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate random orthogonal matrices U and V</span></span>
<span id="cb1-7">    U, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linalg.qr(np.random.randn(m, m))</span>
<span id="cb1-8">    V, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linalg.qr(np.random.randn(n, n))</span>
<span id="cb1-9">    </span>
<span id="cb1-10">    sigma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>condition_number, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(m, n))    </span>
<span id="cb1-11">    Sigma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.diag(sigma)    </span>
<span id="cb1-12">    A <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> U <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> Sigma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> V[:<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(m, n), :]</span>
<span id="cb1-13">    </span>
<span id="cb1-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> A, sigma</span>
<span id="cb1-15"></span>
<span id="cb1-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Seed for reproducibility</span></span>
<span id="cb1-17">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb1-18">A, S <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> generate_ill_conditioned_matrix(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e3</span>)</span>
<span id="cb1-19"></span>
<span id="cb1-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a vector b of size 5 with random values</span></span>
<span id="cb1-21">b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>)</span>
<span id="cb1-22"></span>
<span id="cb1-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the SVD of A</span></span>
<span id="cb1-24">U, S, Vt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linalg.svd(A, full_matrices<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb1-25">V <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Vt.T</span>
<span id="cb1-26">U <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> U  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Already in proper shape</span></span>
<span id="cb1-27"></span>
<span id="cb1-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Number of singular values</span></span>
<span id="cb1-29">n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(S)</span>
<span id="cb1-30"></span>
<span id="cb1-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define parameters for each method</span></span>
<span id="cb1-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Gradient Flow</span></span>
<span id="cb1-33">t_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb1-34"></span>
<span id="cb1-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Tikhonov Regularization</span></span>
<span id="cb1-36">lambda_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb1-37"></span>
<span id="cb1-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Thresholded SVD</span></span>
<span id="cb1-39">threshold_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(S), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb1-40"></span>
<span id="cb1-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute scaling factors for each method</span></span>
<span id="cb1-42"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Gradient Flow Scaling</span></span>
<span id="cb1-43"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> gradient_flow_scaling(sigma, t):</span>
<span id="cb1-44">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> np.exp(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> t)) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> sigma</span>
<span id="cb1-45"></span>
<span id="cb1-46">gradient_scalings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([gradient_flow_scaling(s, t_values) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> s <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> S])</span>
<span id="cb1-47"></span>
<span id="cb1-48"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Tikhonov Scaling</span></span>
<span id="cb1-49"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> tikhonov_scaling(sigma, lambd):</span>
<span id="cb1-50">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> sigma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (sigma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> lambd)</span>
<span id="cb1-51"></span>
<span id="cb1-52">tikhonov_scalings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([tikhonov_scaling(s, lambda_values) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> s <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> S])</span>
<span id="cb1-53"></span>
<span id="cb1-54"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Thresholded SVD Scaling</span></span>
<span id="cb1-55"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> tsvd_scaling(sigma, threshold):</span>
<span id="cb1-56">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> np.where(sigma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> threshold, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>sigma, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb1-57"></span>
<span id="cb1-58">tsvd_scalings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([tsvd_scaling(s, threshold_values) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> s <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> S])</span>
<span id="cb1-59"></span>
<span id="cb1-60"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize the plot with 3 subplots</span></span>
<span id="cb1-61">fig, axes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>))</span>
<span id="cb1-62"></span>
<span id="cb1-63"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define a color palette</span></span>
<span id="cb1-64">palette <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sns.color_palette(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"husl"</span>, n)</span>
<span id="cb1-65"></span>
<span id="cb1-66"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot Gradient Flow</span></span>
<span id="cb1-67">ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb1-68"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n):</span>
<span id="cb1-69">    ax.plot(t_values, gradient_scalings[i], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>palette[i], linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'$1/\sigma_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">$'</span> )</span>
<span id="cb1-70">    ax.axhline(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>S[i], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>palette[i], linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-71">ax.set_yscale(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'log'</span>)</span>
<span id="cb1-72">ax.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Time (t)'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>)</span>
<span id="cb1-73">ax.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Scaling Factor'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>)</span>
<span id="cb1-74">ax.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Gradient Flow'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>)</span>
<span id="cb1-75">ax.legend()</span>
<span id="cb1-76">ax.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb1-77"></span>
<span id="cb1-78"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot Tikhonov Regularization</span></span>
<span id="cb1-79">ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb1-80"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n):</span>
<span id="cb1-81">    ax.plot(lambda_values, tikhonov_scalings[i], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>palette[i], linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'$1/\sigma_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">$'</span> )</span>
<span id="cb1-82">    ax.axhline(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>S[i], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>palette[i], linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-83">ax.set_yscale(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'log'</span>)</span>
<span id="cb1-84">ax.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Regularization Parameter (λ)'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>)</span>
<span id="cb1-85">ax.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Scaling Factor'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>)</span>
<span id="cb1-86">ax.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tikhonov Regularization'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>)</span>
<span id="cb1-87">ax.legend()</span>
<span id="cb1-88">ax.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb1-89"></span>
<span id="cb1-90"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot Thresholded SVD</span></span>
<span id="cb1-91">ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb1-92"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n):</span>
<span id="cb1-93">    ax.plot(threshold_values, tsvd_scalings[i], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>palette[i], linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'$1/\sigma_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">$'</span>)</span>
<span id="cb1-94">    ax.axhline(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>S[i], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>palette[i], linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-95">ax.set_yscale(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'log'</span>)</span>
<span id="cb1-96">ax.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Threshold (τ)'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>)</span>
<span id="cb1-97">ax.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Scaling Factor'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>)</span>
<span id="cb1-98">ax.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Thresholded SVD'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>)</span>
<span id="cb1-99">ax.legend()</span>
<span id="cb1-100">ax.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb1-101"></span>
<span id="cb1-102"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adjust layout and add a legend</span></span>
<span id="cb1-103">plt.tight_layout()</span>
<span id="cb1-104">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>&lt;&gt;:69: SyntaxWarning: invalid escape sequence '\s'
&lt;&gt;:81: SyntaxWarning: invalid escape sequence '\s'
&lt;&gt;:93: SyntaxWarning: invalid escape sequence '\s'
&lt;&gt;:69: SyntaxWarning: invalid escape sequence '\s'
&lt;&gt;:81: SyntaxWarning: invalid escape sequence '\s'
&lt;&gt;:93: SyntaxWarning: invalid escape sequence '\s'
C:\Users\sghys\AppData\Local\Temp\ipykernel_10828\1786010090.py:69: SyntaxWarning: invalid escape sequence '\s'
  ax.plot(t_values, gradient_scalings[i], color=palette[i], linewidth=2, label=f'$1/\sigma_{i}$' )
C:\Users\sghys\AppData\Local\Temp\ipykernel_10828\1786010090.py:81: SyntaxWarning: invalid escape sequence '\s'
  ax.plot(lambda_values, tikhonov_scalings[i], color=palette[i], linewidth=2, label=f'$1/\sigma_{i}$' )
C:\Users\sghys\AppData\Local\Temp\ipykernel_10828\1786010090.py:93: SyntaxWarning: invalid escape sequence '\s'
  ax.plot(threshold_values, tsvd_scalings[i], color=palette[i], linewidth=2, label=f'$1/\sigma_{i}$')</code></pre>
</div>
<div class="cell-output cell-output-display">
<div id="comp-plot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture4/index_files/figure-html/comp-plot-output-2.png" width="469" height="1430" class="figure-img"></p>
<figcaption>Evolution of scaling factors for three different methods</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="solving-least-squares-using-conjugate-gradient" class="level2">
<h2 class="anchored" data-anchor-id="solving-least-squares-using-conjugate-gradient">Solving Least Squares Using Conjugate Gradient</h2>
<p>A detailed explanation of this method can be found at <a href="https://en.wikipedia.org/wiki/Conjugate_gradient_method">Wikipedia</a></p>
<section id="conjugate-vectors-definition" class="level4">
<h4 class="anchored" data-anchor-id="conjugate-vectors-definition">Conjugate Vectors Definition</h4>
<p>A set of vectors <img src="https://latex.codecogs.com/png.latex?%5C%7B%20p_1,%20p_2,%20%5Cldots,%20p_n%20%5C%7D"> is said to be <strong>conjugate with respect to</strong> a matrix <img src="https://latex.codecogs.com/png.latex?A"> if:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clangle%20p_i,%20A%20p_j%20%5Crangle%20=%200%20%5Cquad%20%5Ctext%7Bfor%20all%20%7D%20i%20%5Cneq%20j%0A"></p>
<p>This is a generalization of the concept of orthoganality to non-symmetric matrices.</p>
<p><strong>Standard Orthogonality:</strong> When $ A = I $ (the identity matrix), the definition reduces to the standard concept of orthogonality. For a symmetric <img src="https://latex.codecogs.com/png.latex?A"> we also have an orthogonal decomposition of eigenvectors by spectral theorem.</p>
<hr>
<p>Back to the problem of least squares, we can express the solution $ x $ as a linear combination of conjugate vectors:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax%20=%20x_0%20+%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20p_i%0A"></p>
<p>where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?x_0"> is an initial guess (can be zero).</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Calpha_i"> are scalar coefficients.</li>
<li><img src="https://latex.codecogs.com/png.latex?p_i"> are conjugate vectors with respect to <img src="https://latex.codecogs.com/png.latex?A">.</li>
</ul>
<p>To recover the coefficients of <img src="https://latex.codecogs.com/png.latex?%5Calpha_i"> we can use a projection in the weighted space of <img src="https://latex.codecogs.com/png.latex?A">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Balign%7D%0AA%20x_0%20+%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20A%20p_i%20&amp;=%20b%5C%5C%0Ar%20&amp;=%20b%20-%20A%20x_0%5C%5C%0A%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20A%20p_i%20&amp;=%20r%5C%5C%0A%5Clangle%20p_i,%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20A%20p_i%20%5Crangle%20&amp;=%20%5Clangle%20p_i,%20r%20%5Crangle%5C%5C%0A%5Calpha_i%20%5Clangle%20p_i,%20A%20p_i%20%5Crangle%20&amp;=%20%5Clangle%20p_i,%20r%20%5Crangle%5C%5C%0A%5Calpha_i%20&amp;=%20%5Cfrac%7B%5Clangle%20p_i,%20r%20%5Crangle%7D%7B%5Clangle%20p_i,%20A%20p_i%20%5Crangle%7D%0A%5Cend%7Balign%7D%0A"> In the case where <img src="https://latex.codecogs.com/png.latex?x_0"> is zero, then this reduces to <img src="https://latex.codecogs.com/png.latex?%20%5Calpha_i%20=%20%5Cfrac%7B%5Clangle%20p_i,%20b%20%5Crangle%7D%7B%5Clangle%20p_i,%20A%20p_i%20%5Crangle%7D%20"></p>
</section>
<section id="algorithm-steps" class="level3">
<h3 class="anchored" data-anchor-id="algorithm-steps">Algorithm Steps</h3>
<p><strong>Initialize:</strong></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?x%20=%20x_0"></li>
<li><img src="https://latex.codecogs.com/png.latex?r_0%20=%20b%20-%20A%20x_0"></li>
<li><img src="https://latex.codecogs.com/png.latex?p_0%20=%20r_0"></li>
</ul>
<p><strong>For <img src="https://latex.codecogs.com/png.latex?i%20=%200,1,%202,%20%5Cldots">:</strong></p>
<ol type="1">
<li><p><strong>Compute <img src="https://latex.codecogs.com/png.latex?%5Calpha_i">:</strong></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Calpha_i%20=%20%5Cfrac%7B%5Clangle%20r_i,%20r_i%20%5Crangle%7D%7B%5Clangle%20p_i,%20A%20p_i%20%5Crangle%7D%0A"></p></li>
<li><p><strong>Update Solution <img src="https://latex.codecogs.com/png.latex?x">:</strong></p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax_%7Bi+1%7D%20=%20x_%7Bi%7D%20+%20%5Calpha_i%20p_i%0A"></p></li>
<li><p><strong>Update Residual <img src="https://latex.codecogs.com/png.latex?r">:</strong></p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ar_%7Bi+1%7D%20=%20r_%7Bi%7D%20-%20%5Calpha_i%20A%20p_i%0A"></p></li>
<li><p><strong>Check for Convergence:</strong></p>
<ul>
<li>If <img src="https://latex.codecogs.com/png.latex?%5C%7C%20r_%7Bi+1%7D%20%5C%7C"> is small enough, stop.</li>
</ul></li>
<li><p><strong>Compute <img src="https://latex.codecogs.com/png.latex?%5Cbeta_i">:</strong></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta_i%20=%20%5Cfrac%7B%5Clangle%20r_%7Bi+1%7D,%20r_%7Bi+1%7D%5Crangle%7D%7B%5Clangle%20r_i,r_i%20%5Crangle%7D%0A"></p></li>
<li><p><strong>Update Conjugate Direction <img src="https://latex.codecogs.com/png.latex?p_%7Bi+1%7D">:</strong></p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap_%7Bi+1%7D%20=%20r_%7Bi+1%7D%20+%20%5Cbeta_i%20p_i%0A"></p></li>
</ol>
<hr>
<p>The method can be seen better if we trace through the minimization problem for fixed <img src="https://latex.codecogs.com/png.latex?x"> and with variable <img src="https://latex.codecogs.com/png.latex?%5Calpha">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0A&amp;%20%5Cmin%20%5Cfrac%7B1%7D%7B2%7D%20%5C%7CA%20(x+%5Calpha%20p)%20-%20b%5C%7C%5E2%20%20%5C%5C%0A&amp;=%20%5Cfrac%7B1%7D%7B2%7Dr%5ET%20r%20+%20%5Calpha%20%5Clangle%20r,%20A%20p%20%5Crangle%20+%20%5Cfrac%7B1%7D%7B2%7D%20%5Calpha%5E2%20%5Clangle%20p,%20A%5ET%20A%20p%20%5Crangle%20%5C%5C%0A0%20&amp;=%20%5Clangle%20r,%20A%20p%20%5Crangle%20+%20%5Calpha%20%5Clangle%20p,%20A%5ET%20A%20p%20%5Crangle%20%5C%5C%0A%5Calpha%20&amp;=%20-%5Cfrac%7B%5Clangle%20r,%20A%20p%20%5Crangle%7D%7B%5C%7CA%20p%5C%7C%5E2%7D%0A%5Cend%7Balign%7D%0A"></p>
<p>But we can also trace this through using the expansion of lest squares and removing the <img src="https://latex.codecogs.com/png.latex?%5C%7Cb%5C%7C%5E2"> term:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0A&amp;%20%5Cmin%20%5Cfrac%7B1%7D%7B2%7D%20%5Ctilde%20x%5ET%20A%20x%20-%20%5Ctilde%20x%5ET%20b%20%20%5C%5C%0A&amp;=%20%5Cfrac%7B1%7D%7B2%7D%20%5Cleft(%20x%5ET%20A%20x%20+%202%20%5Calpha%20x%5ET%20A%20p%20+%20%5Calpha%5E2%20p%5ET%20A%20p%20%5Cright)%20-%20x%5ET%20b%20-%20%5Calpha%20p%5ET%20b%5C%5C%0A0&amp;=%20x%5ETAp%20+%20%5Calpha%20p%5ET%20A%20p%20-%20p%5ET%20b%20%5C%5C%0A%5Calpha%20&amp;=%20%5Cfrac%7Bp%5ET%20(Ax-b)%7D%7Bp%5ET%20A%20p%7D%0A%5Cend%20%7Balign%7D%0A"></p>


</section>
</section>

 ]]></description>
  <category>Optimization</category>
  <category>Inverse Theory</category>
  <category>Python</category>
  <guid>https://chipnbits.github.io/content/eosc555/lectures/lecture4/</guid>
  <pubDate>Fri, 20 Sep 2024 07:00:00 GMT</pubDate>
  <media:content url="https://chipnbits.github.io/content/eosc555/lectures/lecture4/imgs/tikhonov_regularization.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Lecture 3: Image Denoising with Gradient Descent and Early Stopping</title>
  <dc:creator>Simon Ghyselincks</dc:creator>
  <link>https://chipnbits.github.io/content/eosc555/lectures/lecture3/</link>
  <description><![CDATA[ 




<section id="derivations-of-linear-algebra-gradients" class="level2">
<h2 class="anchored" data-anchor-id="derivations-of-linear-algebra-gradients">Derivations of Linear Algebra Gradients</h2>
<p>Often times we wish to find the gradient of a multi-variable function that is formulated as a linear algebra operation. In this case there are some useful “vector” derivatives and rules that can simplify the process of calculating more complex expressions. The gradient with respect to vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> is generally denoted as <img src="https://latex.codecogs.com/png.latex?%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D"> or alternatively <img src="https://latex.codecogs.com/png.latex?%5Cpartial_%7B%5Cmathbf%7Bx%7D%7D">, somewhat of an abuse of notation.</p>
<section id="a-warmup" class="level4">
<h4 class="anchored" data-anchor-id="a-warmup">1. A Warmup</h4>
<p><img src="https://latex.codecogs.com/png.latex?%5Cphi(x)%20=%20a%5E%5Ctop%20x%20=%20%5Csum_i%20a_i%20x_i"></p>
<p>This is a vector dotproduct and the gradient is simply the vector <img src="https://latex.codecogs.com/png.latex?a">. There is a subtlety here in that the vector is usually transposed to be a column vector, but this is not always the case. Some people in the field of statistics prefer to use row vector, this can cause some confusion. The general convention is a column vector.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20%5Cphi%20=%20a"></p>
</section>
<section id="matrix-vector-multiplication" class="level4">
<h4 class="anchored" data-anchor-id="matrix-vector-multiplication">2. Matrix Vector Multiplication</h4>
<p><img src="https://latex.codecogs.com/png.latex?%5Cphi(x)%20=%20Ax"></p>
<p>Based on the previous process we are expecting to potentially get <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop"> as the gradient, however the transpose does not occur in this case because we are not returning a vector that needs to be reshaped into a column form.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20%5Cphi%20=%20A"></p>
</section>
<section id="quadratic-forms" class="level4">
<h4 class="anchored" data-anchor-id="quadratic-forms">3. Quadratic Forms</h4>
<p>Often we may encounter quadratic linear functions that are of the form: <img src="https://latex.codecogs.com/png.latex?%20%5Cphi(x)%20=%20x%5E%5Ctop%20A%20x"></p>
<p>One way to determine the gradient is to expand the expression and evaluate for a single <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20x_i%7D"> term. This method can be found at <a href="https://www.cs.ubc.ca/~schmidtm/Courses/340-F16/linearQuadraticGradients.pdf">Mark Schmidt Notes</a> Instead we can apply a chain rule for matrix differentiation that is based on the product rule for differentiation. The chain rule for matrix differentiation is as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bd%20f(g,h)%7D%7Bd%20x%7D%20=%20%5Cfrac%7Bd%20(g(x)%5E%5Ctop)%7D%7Bd%20x%7D%20%5Cfrac%7B%5Cpartial%20f(g,h)%7D%7B%5Cpartial%20g%7D%20+%20%5Cfrac%7Bd%20(h(x)%5E%5Ctop)%7D%7Bd%20x%7D%20%5Cfrac%7B%5Cpartial%20f(g,h)%7D%7B%5Cpartial%20h%7D"></p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%20%7Balign*%7D%0A%5Cphi(x)%20&amp;=%20x%5E%5Ctop%20A%20x%20%5C%5C%0A%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20%5Cphi%20&amp;=%20%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20(x%5E%5Ctop%20A%20x)%20%5C%5C%0A&amp;=%20%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20x%5E%5Ctop%20(A%20x)%20=%20%20%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20x%5E%5Ctop%20y%5C%5C%0A&amp;=%20(%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20x)%20%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20x%5E%5Ctop%20y%20+%20%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20y%5E%5Ctop%20%5Cnabla_%7B%5Cmathbf%7By%7D%7D%20x%5E%5Ctop%20y%5C%5C%0A&amp;=%20I%20y%20+%20%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20(x%5E%5Ctop%20A%5E%5Ctop)%20x%5C%5C%0A&amp;=%20(A%20x)%20+%20A%5E%5Ctop%20x%5C%5C%0A&amp;=%20(A%20+%20A%5E%5Ctop)%20x%0A%5Cend%20%7Balign*%7D%0A"></p>
<p>This fits with the generalization for a scalar quadratic form where we end up with <img src="https://latex.codecogs.com/png.latex?(cx%5E2)'%20=%20(c%20+%20c%5E%5Ctop)x%20=%202cx"> where <img src="https://latex.codecogs.com/png.latex?c"> is a scalar.</p>
</section>
<section id="hadamard-product" class="level4">
<h4 class="anchored" data-anchor-id="hadamard-product">4. Hadamard Product</h4>
<p>Another form of interest is the hadamard product of two vectors. <img src="https://latex.codecogs.com/png.latex?%5Cphi(x)%20=%20(Ax)%5E2%20=%20Ax%20%5Codot%20Ax"></p>
<p>For this one let <img src="https://latex.codecogs.com/png.latex?y=Ax"> and we can index each element of the vector <img src="https://latex.codecogs.com/png.latex?y"> as <img src="https://latex.codecogs.com/png.latex?y_i%20=%20%5Csum_j%20A_%7Bij%7D%20x_j">. The hadamard product is a vector <img src="https://latex.codecogs.com/png.latex?z"> where <img src="https://latex.codecogs.com/png.latex?z_i%20=%20y_i%5E2">, we can compute the jacobian since now we are taking the gradient with respect to a vector.</p>
<p>The Jacobian will contain the partial derivatives:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bd%5Cvec%7Bz%7D%7D%7Bd%5Cvec%7Bx%7D%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cfrac%7B%5Cpartial%20z_1%7D%7B%5Cpartial%20x_1%7D%20&amp;%20%5Cfrac%7B%5Cpartial%20z_1%7D%7B%5Cpartial%20x_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cfrac%7B%5Cpartial%20z_1%7D%7B%5Cpartial%20x_n%7D%20%5C%5C%0A%5Cfrac%7B%5Cpartial%20z_2%7D%7B%5Cpartial%20x_1%7D%20&amp;%20%5Cfrac%7B%5Cpartial%20z_2%7D%7B%5Cpartial%20x_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cfrac%7B%5Cpartial%20z_2%7D%7B%5Cpartial%20x_n%7D%20%5C%5C%0A%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%5Cfrac%7B%5Cpartial%20z_n%7D%7B%5Cpartial%20x_1%7D%20&amp;%20%5Cfrac%7B%5Cpartial%20z_n%7D%7B%5Cpartial%20x_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cfrac%7B%5Cpartial%20z_n%7D%7B%5Cpartial%20x_n%7D%20%5Cend%7Bbmatrix%7D%0A"></p>
<p>If we can recover this then we have the gradient of the hadamard product.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0Az_i%20&amp;=%20y_i%5E2%20=%20%5Cleft(%20%5Csum_j%20A_%7Bij%7D%20x_j%20%5Cright)%5E2%5C%5C%0A%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20x_j%7D%20y_i%5E2%20&amp;=%202%20y_i%20%5Cfrac%7B%5Cpartial%20y_i%7D%7B%5Cpartial%20x_j%7D%20=%202%20y_i%20A_%7Bij%7D%5C%5C%0A%5Cfrac%7Bd%5Cvec%7Bz%7D%7D%7Bd%5Cvec%7Bx%7D%7D%20&amp;=%202%20%5Cbegin%7Bbmatrix%7D%20y_1%20A_%7B1j%7D%20&amp;%20y_1%20A_%7B2j%7D%20&amp;%20%5Ccdots%20&amp;%20y_1%20A_%7Bnj%7D%20%5C%5C%0Ay_2%20A_%7B1j%7D%20&amp;%20y_2%20A_%7B2j%7D%20&amp;%20%5Ccdots%20&amp;%20y_2%20A_%7Bnj%7D%20%5C%5C%0A%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0Ay_n%20A_%7B1j%7D%20&amp;%20y_n%20A_%7B2j%7D%20&amp;%20%5Ccdots%20&amp;%20y_n%20A_%7Bnj%7D%20%5Cend%7Bbmatrix%7D%5C%5C%0A&amp;=%202%20%5Ccdot%20%5Ctext%7Bdiag%7D(%5Cvec%7By%7D)A%5C%5C%0A&amp;=%202%20%5Ccdot%20%5Ctext%7Bdiag%7D(Ax)A%0A%5Cend%7Balign*%7D%0A"></p>
</section>
<section id="least-squares-gradient" class="level4">
<h4 class="anchored" data-anchor-id="least-squares-gradient">5. Least Squares Gradient</h4>
<p>We look at taking the gradient of the expansion of least squares to find the gradient for this optimization objective.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cphi(x)%20=%20%5Cfrac%7B1%7D%7B2%7D%20%7C%7CAx%20-%20b%7C%7C%5E2%20=%20%5Cfrac%7B1%7D%7B2%7D%20(x%5E%5Ctop%20A%5E%5Ctop%20A%20x%20-%202%20b%5E%5Ctop%20A%20x%20+%20b%5E%5Ctop%20b)"></p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Balign*%7D%0A%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20%5Cphi%20&amp;=%20%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20%5Cleft(%20%5Cfrac%7B1%7D%7B2%7D%20(x%5E%5Ctop%20A%5E%5Ctop%20A%20x%20-%202%20b%5E%5Ctop%20A%20x%20+%20b%5E%5Ctop%20b)%20%5Cright)%5C%5C%0A&amp;=%20%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20%5Cleft(%20%5Cfrac%7B1%7D%7B2%7D%20x%5E%5Ctop%20A%5E%5Ctop%20A%20x%20%5Cright)%20-%20%5Cnabla_%7B%5Cmathbf%7Bx%7D%7D%20%5Cleft(%20b%5E%5Ctop%20A%20x%20%5Cright)%5C%5C%0A&amp;=%20%5Cfrac%7B1%7D%7B2%7D%20(A%5E%5Ctop%20A%20+%20A%5E%5Ctop%20A)%20x%20-%20A%5E%5Ctop%20b%5C%5C%0A&amp;=%20A%5E%5Ctop%20A%20x%20-%20A%5E%5Ctop%20b%5C%5C%0A%5Cend%7Balign*%7D%0A"></p>
<p>Returning to the first-order optimality condition we have: <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A%20x%20=%20A%5E%5Ctop%20b"></p>
<p>At which point it is in question if <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A"> is invertible. The invertibility of <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A"> is determined by the rank of <img src="https://latex.codecogs.com/png.latex?A">. The rank of A for a non-square matrix is the number of independent columns. If we examine <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20Ax%20=%200"> then we see that this is only true where the range of <img src="https://latex.codecogs.com/png.latex?A"> is in the nullspace of <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop">. But <img src="https://latex.codecogs.com/png.latex?N(A%5E%5Ctop)%20=%20R(A)%5E%5Cperp"> so they are orthogonal subspaces and will never coincide unless <img src="https://latex.codecogs.com/png.latex?Ax=0">. So then <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A%20x%20=%200"> implies that <img src="https://latex.codecogs.com/png.latex?Ax%20=%200"> which means that if the null space of <img src="https://latex.codecogs.com/png.latex?A=%5C%7B0%5C%7D"> then the null space of <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A%20=%20%5C%7B0%5C%7D"> and <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A"> is invertible. Since <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A"> is symmetric and positive definite, it is invertible.</p>
<p><img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop%20A"> is invertible <img src="https://latex.codecogs.com/png.latex?%5Ciff"> <img src="https://latex.codecogs.com/png.latex?A"> is full rank, that is all the columns are independent. For non-square matrices, an <img src="https://latex.codecogs.com/png.latex?m%3En"> matrix that is wide will trivially not satisfy this condition. A tall matrix <img src="https://latex.codecogs.com/png.latex?m%3Cn"> will satisfy the condition if the columns are independent.</p>
</section>
</section>
<section id="gradient-descent-analysis" class="level2">
<h2 class="anchored" data-anchor-id="gradient-descent-analysis">Gradient Descent Analysis</h2>
<p>The standard form of the gradient descent algorithm comes from the field of optimization and can be written as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20x_%7Bk+1%7D%20=%20x_k%20-%20%5Calpha%20%5Cnabla_x%20%5Cphi(x_k)"></p>
<p>Where <img src="https://latex.codecogs.com/png.latex?%5Calpha"> is the learning rate, which can be dependent on the problem and the gradient. Substituting the gradient of the least squares problem we have:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Balign%7D%0Ax_%7Bk+1%7D%20&amp;=%20x_k%20-%20%5Calpha%20(A%5E%5Ctop%20A%20x_k%20-%20A%5E%5Ctop%20b)%5C%5C%0A%5Cfrac%7Bx_%7Bk+1%7D-x_k%7D%7B%5Calpha%7D%20&amp;=%20A%5E%5Ctop%20b%20-%20A%5E%5Ctop%20A%20x_k%5C%5C%0A%5Clim_%7B%5Calpha%20%5Cto%200%7D%20%5Cfrac%7Bx_%7Bk+1%7D-x_k%7D%7B%5Calpha%7D%20&amp;=%20%5Cfrac%7Bdx%7D%7Bdt%7D%20=%20A%5E%5Ctop%20(b%20-A%20x),%20%5Cquad%20x(0)%20=%20x_0%0A%5Cend%7Balign%7D%0A"></p>
<p>This ODE is the continuous version of the gradient descent algorithm, also known as the <em>gradient flow</em>. Since this a linear first-order ODE we can solve it analytically. The general method for a linear system ODE would be to find the homogeneous solution and the particular solution:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Balign%7D%0Ax'%20+%20A%5E%5Ctop%20A%20x%20&amp;=%20A%5E%5Ctop%20b%5C%5C%0A%5Ctext%7BGuess:%7D%20x%20&amp;=%20v%20e%5E%7B%5Clambda%20t%7D%5C%5C%0A%5Clambda%20v%20e%5E%7B%5Clambda%20t%7D%20+%20A%5E%5Ctop%20A%20v%20e%5E%7B%5Clambda%20t%7D%20&amp;=%20A%5E%5Ctop%20b%20e%5E%7B%5Clambda%20t%7D%5C%5C%0A%5Clambda%20v%20+%20A%5E%5Ctop%20A%20v%20&amp;=%200%20%5Cqquad%20%5Ctext%7BHomogeneous%7D%5C%5C%0A(%5Clambda%20I%20+%20A%5E%5Ctop%20A)%20v%20&amp;=%200%5C%5C%0A%5Clambda%20&amp;=%20%5Ctext%7Beigenvalues%20of%20%7D%20A%5E%5Ctop%20A,%20%5Cquad%20v%20=%20%5Ctext%7Beigenvectors%20of%20%7D%20A%5E%5Ctop%20A%0A%5Cend%7Balign%7D%0A"></p>
<p>Before continuing further with this line, we can see that the solutions will be closely related to the SVD because it contains the information on these eigenvalues and vectors. So we can try to solve the ODE with the SVD.</p>
<section id="solving-the-ode-with-svd" class="level4">
<h4 class="anchored" data-anchor-id="solving-the-ode-with-svd">Solving the ODE with SVD</h4>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign%7D%0AA%20&amp;=%20U%20%5CSigma%20V%5E%5Ctop%5C%5C%0AA%5ETA%20&amp;=%20V%20%5CSigma%5E2%20V%5E%5Ctop%5C%5C%0A%5Cfrac%7Bd%7D%7Bdt%7Dx%20&amp;=%20V%20%5CSigma%20U%5E%5Ctop%20b%20-%20V%20%5CSigma%5E2%20V%5E%5Ctop%20x%5C%5C%0A%5Cend%7Balign%7D%0A"></p>
<p>Now let <img src="https://latex.codecogs.com/png.latex?z%20=%20V%5E%5Ctop%20x"> and <img src="https://latex.codecogs.com/png.latex?%5Chat%20b%20=%20U%20%5E%20%5Ctop%20b"> then we have:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign%7D%0A%5Cfrac%7Bd%7D%7Bdt%7D%20(V%5E%5Ctop%20x)%20&amp;=%20%5CSigma%20%5Chat%20b%20-%20%5CSigma%5E2%20(V%5E%5Ctop%20x)%5C%5C%0A%5Cfrac%7Bd%7D%7Bdt%7D%20z%20&amp;=%20%5CSigma%20%5Chat%20b%20-%20%5CSigma%5E2%20z%5C%5C%0Az'%20+%20%5CSigma%5E2%20z%20&amp;=%20%5CSigma%20%5Chat%20b%5C%5C%0A%5Cend%7Balign%7D%0A"></p>
<p>At this stage since everything has been diagonalized, all of the equations are decoupled and independent so we can solve for the <img src="https://latex.codecogs.com/png.latex?%5Clambda_i"> cases independently. We find the homogeneous <img src="https://latex.codecogs.com/png.latex?z_h"> and particular <img src="https://latex.codecogs.com/png.latex?z_p"> solutions:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0Az_h'%20+%20%5Clambda%5E2%20z_h%20&amp;=%200%5C%5C%0Az_h%20&amp;=%20c%20e%5E%7B-%5Clambda%5E2%20t%7D%5C%5C%0Az_p'%20+%20%5Clambda%5E2%20z_p%20&amp;=%20%5Clambda%20%5Chat%20b%5C%5C%0Az_p%20&amp;=%20D%20%5Chat%20b%20%5C%5C%0A%5Clambda%5E2%20D%20%5Chat%20b%20&amp;=%20%5Clambda%20%5Chat%20b%5C%5C%0AD%20&amp;=%20%5Cfrac%7B1%7D%7B%5Clambda%7D%5C%5C%0Az_p%20&amp;=%20%5Cfrac%7B1%7D%7B%5Clambda%7D%20%5Chat%20b%0A%5Cend%7Balign%7D%0A"></p>
<p>So the general solution for the <img src="https://latex.codecogs.com/png.latex?i%5E%7Bth%7D"> component is:</p>
<p><img src="https://latex.codecogs.com/png.latex?z_i%20=%20c_i%20e%5E%7B-%5Clambda_i%5E2%20t%7D%20+%20%5Cfrac%7B1%7D%7B%5Clambda_i%7D%20%5Chat%20b_i"></p>
<p>Supposing that we start at <img src="https://latex.codecogs.com/png.latex?x=0"> then we have <img src="https://latex.codecogs.com/png.latex?z=0"> at all elements and can solve the coefficients <img src="https://latex.codecogs.com/png.latex?c_i">:</p>
<p><img src="https://latex.codecogs.com/png.latex?c_i%20=%20-%5Cfrac%7B1%7D%7B%5Clambda_i%7D%20%5Chat%20b_i"></p>
<p>Then putting it all back together with all the equations we have that</p>
<p><img src="https://latex.codecogs.com/png.latex?Z%20=%20%5Ctext%7Bdiag%7D%5Cleft(%20%5Clambda_i%5E%7B-1%7D%20(1%20-%20%5Cexp%20(-%5Clambda_i%20t))%20%5Cright)%20%5Chat%20b"></p>
<p>Substituting back in for <img src="https://latex.codecogs.com/png.latex?x"> and <img src="https://latex.codecogs.com/png.latex?b"> we get:</p>
<p><img src="https://latex.codecogs.com/png.latex?x%20=%20V%20%5Ctext%7Bdiag%7D%5Cleft(%20%5Clambda_i%5E%7B-1%7D%20(1%20-%20%5Cexp%20(-%5Clambda_i%20t))%20%5Cright)%20U%5E%5Ctop%20b"></p>
<p>If we stare at this long enough it begins to look a lot like the pseudoinverse of <img src="https://latex.codecogs.com/png.latex?A"> from earlier:</p>
<p><img src="https://latex.codecogs.com/png.latex?x%20=%20V%20%5CSigma%5E%7B-1%7D%20U%5E%5Ctop%20b"> except in this case there is a time dependence. At the limit as <img src="https://latex.codecogs.com/png.latex?t%20%5Crightarrow%20%5Cinfty"> we have that the exponential term goes to zero and we are left with the pseudoinverse solution. This is a nice way to see that the pseudoinverse is the limit of the gradient descent algorithm. What we may be interested in is what happens at earlier stages since each decay term is dependent on the eigenvalues.</p>
<p>For a simple matrix problem we can create a matrix and plot out the time evolution of the diagonals of the matrix that are of interest. In a sense, we have singular values that are time evolving at different rates.</p>
<div id="1bb305e6" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Seed for reproducibility</span></span>
<span id="cb1-6">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a 5x10 matrix A with random values</span></span>
<span id="cb1-8">A <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a vector b of size 5 with random values</span></span>
<span id="cb1-10">b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb1-11"></span>
<span id="cb1-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the SVD of A</span></span>
<span id="cb1-13">U, S, Vt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linalg.svd(A, full_matrices<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb1-14"></span>
<span id="cb1-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a time dependent vector of the singular values</span></span>
<span id="cb1-16"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> St(t):</span>
<span id="cb1-17">    Sdim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> S[:, np.newaxis]</span>
<span id="cb1-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> np.exp(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>Sdim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>t)) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> Sdim</span>
<span id="cb1-19"></span>
<span id="cb1-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the time evolution of the values and plot them on a log scale y axis with a linear time x axis</span></span>
<span id="cb1-21">t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb1-22">T <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t[np.newaxis, :]</span>
<span id="cb1-23"></span>
<span id="cb1-24">singular_vals_t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> St(T)</span>
<span id="cb1-25"></span>
<span id="cb1-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize the plot</span></span>
<span id="cb1-27">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>))</span>
<span id="cb1-28"></span>
<span id="cb1-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a color palette</span></span>
<span id="cb1-30">palette <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sns.color_palette(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"husl"</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(S))</span>
<span id="cb1-31"></span>
<span id="cb1-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the singular values and their asymptotes</span></span>
<span id="cb1-33"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(S)):</span>
<span id="cb1-34">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the time evolution of each singular value</span></span>
<span id="cb1-35">    sns.lineplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>t, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>singular_vals_t[i, :], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>palette[i], linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'$1/S_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">$ '</span>)</span>
<span id="cb1-36">    </span>
<span id="cb1-37">    Sinv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>S[i]</span>
<span id="cb1-38"></span>
<span id="cb1-39">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add a horizontal asymptote at the original singular value</span></span>
<span id="cb1-40">    plt.axhline(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Sinv, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>palette[i], linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-41">    </span>
<span id="cb1-42">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Annotate the asymptote with the singular value</span></span>
<span id="cb1-43">    plt.text(t[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.02</span>, Sinv, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>Sinv<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>palette[i], va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>)</span>
<span id="cb1-44"></span>
<span id="cb1-45"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Configure plot aesthetics</span></span>
<span id="cb1-46">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Time'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>)</span>
<span id="cb1-47">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Inverse Singular Vals'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>)</span>
<span id="cb1-48">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Time Evolution of Pseudo Inverse in Gradient Flow'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>)</span>
<span id="cb1-49">plt.legend(title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Inverse Singular Vals'</span>, bbox_to_anchor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.05</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'upper left'</span>)</span>
<span id="cb1-50">plt.xlim(t[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], t[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span>
<span id="cb1-51">plt.tight_layout()</span>
<span id="cb1-52">plt.savefig(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'imgs/pseudo_inverse_time_evolution.png'</span>)</span>
<span id="cb1-53">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture3/index_files/figure-html/cell-2-output-1.png" width="703" height="374" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>So we can use early stopping to prevent the flow from reaching the optimal point, a very useful technique. When it comes to inverse theory, often we are not interested in the optimal solution, but more interested in getting somewhere close that is not too noisy. This method differs from the thresholded pseudoinverse from the previous lecture, in that it allows some blending of the the smaller singular values, but their propensity for blowing up is controlled by the time exponent and early stopping.</p>
</section>
<section id="example-for-image-recovery-using-analytic-solution" class="level3">
<h3 class="anchored" data-anchor-id="example-for-image-recovery-using-analytic-solution">Example for Image Recovery using Analytic Solution</h3>
<p>Referring back to the problem of estimating the original image based on a noisy point spread function. We can monitor the time evolution of the estimate using gradient flow. Some code below defines the problem again, with recovery of the SVD decomposition for the 32x32 image, which will be used to solve the ODE for the gradient flow.</p>
<div id="efc349f9" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib</span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#matplotlib.use('TkAgg')</span></span>
<span id="cb2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb2-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.optim</span>
<span id="cb2-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb2-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nn</span>
<span id="cb2-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn.functional <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> F</span>
<span id="cb2-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.optim <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Adam</span>
<span id="cb2-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> copy</span>
<span id="cb2-11"></span>
<span id="cb2-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb2-13"></span>
<span id="cb2-14"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> math</span>
<span id="cb2-15"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb2-16"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> time</span>
<span id="cb2-17"></span>
<span id="cb2-18"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb2-19"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb2-20"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.fft</span>
<span id="cb2-21"></span>
<span id="cb2-22"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> gaussianConv(nn.Module):</span>
<span id="cb2-23">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb2-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    A PyTorch module that applies a Gaussian convolution to an input image using </span></span>
<span id="cb2-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    a parameterized Gaussian Point Spread Function (PSF). The PSF is derived </span></span>
<span id="cb2-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    from a covariance matrix and the derivatives of the Gaussian are computed </span></span>
<span id="cb2-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    for edge detection.</span></span>
<span id="cb2-28"></span>
<span id="cb2-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb2-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        C (torch.Tensor): Inverse of covariance matrix used to define the shape of the Gaussian.</span></span>
<span id="cb2-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        t (float, optional): Scaling factor for the Gaussian, default is np.exp(5).</span></span>
<span id="cb2-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n0 (float, optional): Scaling factor for the original PSF, default is 1.</span></span>
<span id="cb2-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        nx (float, optional): Scaling factor for the derivative along the x-axis, default is 1.</span></span>
<span id="cb2-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        ny (float, optional): Scaling factor for the derivative along the y-axis, default is 1.</span></span>
<span id="cb2-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb2-36">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, C, t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.exp(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>), n0<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, nx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, ny<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>):</span>
<span id="cb2-37">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(gaussianConv, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb2-38"></span>
<span id="cb2-39">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.C <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> C</span>
<span id="cb2-40">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t</span>
<span id="cb2-41">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n0</span>
<span id="cb2-42">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.nx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nx</span>
<span id="cb2-43">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.ny <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ny</span>
<span id="cb2-44"></span>
<span id="cb2-45">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, image):</span>
<span id="cb2-46">        P, center <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.psfGauss(image.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], image.device)</span>
<span id="cb2-47">        P_shifted <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.roll(P, shifts<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>center, dims<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>])</span>
<span id="cb2-48">        S <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.fft.fft2(P_shifted)</span>
<span id="cb2-49">        I_fft <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.fft.fft2(image)</span>
<span id="cb2-50">        B_fft <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> S <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> I_fft</span>
<span id="cb2-51">        B <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.real(torch.fft.ifft2(B_fft))</span>
<span id="cb2-52"></span>
<span id="cb2-53">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> B</span>
<span id="cb2-54"></span>
<span id="cb2-55">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> psfGauss(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, dim, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>):</span>
<span id="cb2-56">        m <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dim</span>
<span id="cb2-57">        n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dim</span>
<span id="cb2-58"></span>
<span id="cb2-59">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a meshgrid of (X, Y) coordinates</span></span>
<span id="cb2-60">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.arange(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>m <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, m <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>device)</span>
<span id="cb2-61">        y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.arange(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>device)</span>
<span id="cb2-62">        X, Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.meshgrid(x, y, indexing<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ij'</span>)</span>
<span id="cb2-63">        X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (1, 1, m, n)</span></span>
<span id="cb2-64">        Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (1, 1, m, n)</span></span>
<span id="cb2-65"></span>
<span id="cb2-66">        cx, cy, cxy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.C[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.C[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.C[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb2-67"></span>
<span id="cb2-68">        PSF <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (cx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> cy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> cxy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> Y))</span>
<span id="cb2-69">        PSF0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PSF <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(PSF.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>())</span>
<span id="cb2-70"></span>
<span id="cb2-71">        Kdx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb2-72">                            [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>],</span>
<span id="cb2-73">                            [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]], dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>PSF0.dtype, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>device) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb2-74">        Kdy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb2-75">                            [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],</span>
<span id="cb2-76">                            [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]], dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>PSF0.dtype, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>device) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb2-77"></span>
<span id="cb2-78">        Kdx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Kdx.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (1, 1, 3, 3)</span></span>
<span id="cb2-79">        Kdy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Kdy.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (1, 1, 3, 3)</span></span>
<span id="cb2-80"></span>
<span id="cb2-81">        PSFdx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> F.conv2d(PSF0, Kdx, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-82">        PSFdy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> F.conv2d(PSF0, Kdy, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-83"></span>
<span id="cb2-84">        PSF_combined <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> PSF0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.nx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> PSFdx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.ny <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> PSFdy</span>
<span id="cb2-85"></span>
<span id="cb2-86">        center <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> m <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb2-87"></span>
<span id="cb2-88">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> PSF_combined, center</span>
<span id="cb2-89"></span>
<span id="cb2-90">dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span></span>
<span id="cb2-91">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, dim, dim)</span>
<span id="cb2-92">x[:,:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb2-93">x[:,:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb2-94"></span>
<span id="cb2-95">C <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]])</span>
<span id="cb2-96">Amv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gaussianConv(C, t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,n0<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, nx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,  ny<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span>
<span id="cb2-97"></span>
<span id="cb2-98">n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(x.flatten()))</span>
<span id="cb2-99">Amat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(n,n)</span>
<span id="cb2-100"></span>
<span id="cb2-101">k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb2-102"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(x.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]):</span>
<span id="cb2-103">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(x.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]):</span>
<span id="cb2-104">    e_ij <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros_like(x)</span>
<span id="cb2-105">    e_ij[:,:, i, j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb2-106">    y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Amv(e_ij)</span>
<span id="cb2-107">    Amat[:, k] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y.flatten()</span>
<span id="cb2-108">    k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb2-109"></span>
<span id="cb2-110">U, S, V <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.svd(Amat.to(torch.float64))</span>
<span id="cb2-111">b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Amv(x)</span></code></pre></div>
</details>
</div>
<p>Now that we have the matrix form of the forward operator <code>Amat</code> defined, along with the forward result <code>b</code> and the the decomposition <code>U, S, V</code> we can run the pseudo-inverse gradient flow method as before. So in this case we will be computing:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20x%20=%20V%20%5Ctext%7Bdiag%7D%5Cleft(%20%5Clambda_i%5E%7B-1%7D%20(1%20-%20%5Cexp%20(-%5Clambda_i%20t))%20%5Cright)%20U%5E%5Ctop%20b"></p>
<p>Since these represents an evolution over time, an animation can be created to show the time evolution of the image recovery, along with the effect of continuing into a region where noise is amplified and dominates.</p>
<p>Recalling the original and distorted images with a small amount of noise <img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> are as follows:</p>
<div id="f0f63cb5" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))</span>
<span id="cb3-2">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-3">plt.imshow(x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>, vmin<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, vmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-4">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Original Image'</span>)</span>
<span id="cb3-5">plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'off'</span>)</span>
<span id="cb3-6">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb3-7"></span>
<span id="cb3-8">b_noisy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> b<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> torch.randn_like(b)</span>
<span id="cb3-9">plt.imshow(b_noisy[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>, vmin<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, vmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-10">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Distorted Image'</span>)</span>
<span id="cb3-11">plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'off'</span>)</span>
<span id="cb3-12">plt.tight_layout()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture3/index_files/figure-html/cell-4-output-1.png" width="549" height="288" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The distorted image has had much of its intensity spread out diffusely, so it is only visible as a faint outline. The noise is also visible in the image as a grainy texture. The gradient flow method will attempt to recover the original image from this distorted image.</p>
<div id="95a813ee" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> matplotlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> animation</span>
<span id="cb4-2"></span>
<span id="cb4-3">b_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> b.flatten().to(torch.float64)</span>
<span id="cb4-4">x_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.flatten().to(torch.float64)</span>
<span id="cb4-5">b_noisy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> b_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.001</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> torch.randn_like(b_flat)</span>
<span id="cb4-6"></span>
<span id="cb4-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_xhat(t):</span>
<span id="cb4-8">    Sinv_t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> torch.exp(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>S<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> t)) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> S</span>
<span id="cb4-9">    A_pinv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> V <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> torch.diag(Sinv_t) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> U.T</span>
<span id="cb4-10">    xhat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> A_pinv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> b_noisy</span>
<span id="cb4-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> xhat</span>
<span id="cb4-12"></span>
<span id="cb4-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Time evolution parameters</span></span>
<span id="cb4-14">num_frames <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span></span>
<span id="cb4-15">t_vals <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.logspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, num_frames)</span>
<span id="cb4-16"></span>
<span id="cb4-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare the plot</span></span>
<span id="cb4-18">fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb4-19">im <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ax.imshow(np.zeros((dim, dim)), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>, vmin<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, vmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-20">ax.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Time Evolution of Pseudo-Inverse Gradient Flow'</span>)</span>
<span id="cb4-21">plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'off'</span>)</span>
<span id="cb4-22"></span>
<span id="cb4-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize the error text</span></span>
<span id="cb4-24">error_text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.02</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.95</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax.transAxes, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>,</span>
<span id="cb4-25">                     verticalalignment<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'top'</span>)</span>
<span id="cb4-26"></span>
<span id="cb4-27">time_text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.95</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax.transAxes, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>,</span>
<span id="cb4-28">                        verticalalignment<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'top'</span>)</span>
<span id="cb4-29"></span>
<span id="cb4-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize containers to track min error and best time</span></span>
<span id="cb4-31">tracking <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_error'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'inf'</span>), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'best_t'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>}</span>
<span id="cb4-32"></span>
<span id="cb4-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Animation update function</span></span>
<span id="cb4-34"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> update_frame(t):</span>
<span id="cb4-35">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute time-dependent singular values</span></span>
<span id="cb4-36">    Sinv_t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> torch.exp(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>S <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> t)) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> S</span>
<span id="cb4-37">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the pseudoinverse of Amat at time t</span></span>
<span id="cb4-38">    A_pinv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> V <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> torch.diag(Sinv_t) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> U.t()</span>
<span id="cb4-39">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Reconstruct the image estimate x(t)</span></span>
<span id="cb4-40">    xt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> A_pinv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> b_noisy</span>
<span id="cb4-41">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the relative error</span></span>
<span id="cb4-42">    error <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.norm(x_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> xt) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> torch.norm(x_flat)</span>
<span id="cb4-43">    </span>
<span id="cb4-44">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update min_error and best_t if current error is lower</span></span>
<span id="cb4-45">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> error.item() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> tracking[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_error'</span>]:</span>
<span id="cb4-46">        tracking[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_error'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> error.item()</span>
<span id="cb4-47">        tracking[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'best_t'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t</span>
<span id="cb4-48"></span>
<span id="cb4-49">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Reshape to image dimensions</span></span>
<span id="cb4-50">    x_image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> xt.reshape(dim, dim).detach().numpy()</span>
<span id="cb4-51"></span>
<span id="cb4-52">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update the image data</span></span>
<span id="cb4-53">    im.set_data(x_image)</span>
<span id="cb4-54"></span>
<span id="cb4-55">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update the error text</span></span>
<span id="cb4-56">    error_text.set_text(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Relative Error: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>error<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>item()<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb4-57">    time_text.set_text(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Time: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>t<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb4-58"></span>
<span id="cb4-59">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> [im, error_text, time_text]</span>
<span id="cb4-60"></span>
<span id="cb4-61"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the animation</span></span>
<span id="cb4-62">ani <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> animation.FuncAnimation(fig, update_frame, frames<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>t_vals, blit<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, interval<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb4-63"></span>
<span id="cb4-64">ani.save(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'imgs/gradient_flow.gif'</span>, writer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pillow'</span>, fps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb4-65">plt.close(fig)</span></code></pre></div>
</details>
</div>
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture3/imgs/gradient_flow.gif" class="img-fluid" width="600"></p>
<p>And we saved the best time that was discovered for the recovery (with prior knowledge of the ground truth). So we can inspect that image, this was the best that we could do with the gradient flow method.</p>
<div id="99cfb0cb" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">best_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_xhat(tracking[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'best_t'</span>]).reshape(dim, dim).detach().numpy()</span>
<span id="cb5-2"></span>
<span id="cb5-3">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb5-4">plt.imshow(best_img <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>(best_img)), cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>, vmin<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, vmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb5-5">plt.title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Best Reconstruction at t=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>tracking[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"best_t"</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Relative Error: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>tracking[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"min_error"</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb5-6">plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'off'</span>)</span>
<span id="cb5-7">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture3/index_files/figure-html/cell-6-output-1.png" width="463" height="501" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="recovery-of-the-adjoint-operator-using-autograd" class="level2">
<h2 class="anchored" data-anchor-id="recovery-of-the-adjoint-operator-using-autograd">Recovery of the Adjoint Operator using Autograd</h2>
<p>In this case we were able to compute the matrix form of <img src="https://latex.codecogs.com/png.latex?A"> and use its transpose to compute the SVD, but in many cases this might be too expensive or there may not be a closed form analytic solution to the early stopping technique. In such cases we wish to recover the adjoint. The question then is how to recover the adjoint operator from the <code>Amv</code> operator? There are helpful tools available through the use of automatic differentiation to track the gradients of the forward operator and recover the adjoint operator. This is a very powerful tool that can be used to recover the adjoint operator in a very general way.</p>
<p>By definition the adjoint has the property that: <img src="https://latex.codecogs.com/png.latex?%5Clangle%20Ax,%20v%20%5Crangle%20=%20%5Clangle%20x,%20A%5E%5Ctop%20v%20%5Crangle"></p>
<section id="explicit-computation-of-the-adjoint" class="level3">
<h3 class="anchored" data-anchor-id="explicit-computation-of-the-adjoint">Explicit Computation of the Adjoint</h3>
<p>We can compute the adjoint explicitly for the <code>Amv</code> operator based on its computation from earlier. The discrete fourier transform matrix operator <img src="https://latex.codecogs.com/png.latex?F"> has the property that <img src="https://latex.codecogs.com/png.latex?F%5E%7B-1%7D%20=%20F%5E%5Ctop"> so we can use this to compute the adjoint.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0AA(x)%20&amp;=%20%5Cmathcal%7BF%7D%5E-1%20%5Cleft(%20%5Cmathcal%7BF%7D(P)%20%5Codot%20%5Cmathcal%7BF%7D(x)%20%5Cright)%5C%5C%0A&amp;=%20F%5E%5Ctop%20%5Cleft(%20%5Ctext%7Bdiag%7D%20(F(P))%20F(x)%20%5Cright)%5C%5C%0AA%5E%5Ctop(v)%20&amp;=%20F%5E%5Ctop%20%5Ctext%7Bdiag%7D%20(F(P))%5E*%20F%20v%5C%5C%0A%5Cend%7Balign%7D%0A"></p>
<p>Where the hadamard operation of the two vectors has been modified to a matrix form by diagonalizing the vector <img src="https://latex.codecogs.com/png.latex?F(P)"> that is the Fourier transform of the point spread function. From this form it is posible to take the adjoint of the operator by taking the complex conjugate of the transpose of the entire operation.</p>
</section>
<section id="autograd-computation-of-the-adjoint" class="level3">
<h3 class="anchored" data-anchor-id="autograd-computation-of-the-adjoint">Autograd Computation of the Adjoint</h3>
<p>We start with a new function <img src="https://latex.codecogs.com/png.latex?h%20=%20v%5E%5Ctop%20A(x)"> and we wish to compute the gradient of <img src="https://latex.codecogs.com/png.latex?h"> with respect to <img src="https://latex.codecogs.com/png.latex?x">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cnabla_x%20h%20=%20%5Cnabla_x%20(v%5E%5Ctop%20A(x))%20=%20A%5E%5Ctop(v)"></p>
<p>The gradient of <img src="https://latex.codecogs.com/png.latex?h"> with respect to <img src="https://latex.codecogs.com/png.latex?x"> is the adjoint operator <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop(v)">. We can use the <code>torch.autograd.grad</code> function to compute the gradient of <img src="https://latex.codecogs.com/png.latex?h"> with respect to <img src="https://latex.codecogs.com/png.latex?x">.</p>
<div id="16c7d667" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> Amv_adjoint(v):</span>
<span id="cb6-2">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, dim, dim)</span>
<span id="cb6-3">    x.requires_grad <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb6-4">    b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Amv(x)</span>
<span id="cb6-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the dot product of the forward operator with the input vector</span></span>
<span id="cb6-6">    h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> v)</span>
<span id="cb6-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the gradient of the dot product with respect to the input image</span></span>
<span id="cb6-8">    adjoint <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.autograd.grad(h, x, create_graph<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb6-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> adjoint</span></code></pre></div>
</details>
</div>
<p>We can use this to recover <img src="https://latex.codecogs.com/png.latex?A%5E%5Ctop"> for the general case if we run the operator on the set of basis vectors in the image space. This will give us the adjoint operator in the form of a matrix. We can also use it to confirm that it recovers the matrix transpose of the forward operator if we are working with a simple matrix, reusing the <code>Amat</code> matrix from earlier to take its transpose and compare it to the adjoint operator.</p>
<div id="89eb340d" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">Amat_adj <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(n,n)</span>
<span id="cb7-2"></span>
<span id="cb7-3">dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Same as earlier</span></span>
<span id="cb7-4">k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb7-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(dim):</span>
<span id="cb7-6">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(dim):</span>
<span id="cb7-7">    e_ij <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros_like(x)</span>
<span id="cb7-8">    e_ij[:,:, i, j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb7-9">    y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Amv_adjoint(e_ij)</span>
<span id="cb7-10">    Amat_adj[:, k] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y.flatten()</span>
<span id="cb7-11">    k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb7-12"></span>
<span id="cb7-13">diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.norm(Amat_adj <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Amat.T)</span>
<span id="cb7-14"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Norm of difference between adjoint and transpose: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>diff<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2e}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Norm of difference between adjoint and transpose: 4.43e-07</code></pre>
</div>
</div>
<p>So the difference is within the bounds of numerical precison and the code appears to be working correctly.</p>
</section>
</section>
<section id="gradient-descent-with-adjoint" class="level2">
<h2 class="anchored" data-anchor-id="gradient-descent-with-adjoint">Gradient Descent with Adjoint</h2>
<p>We can now use the defined operators (functions) from earlier to setup a simple gradient descent algorithm with a step size and early stopping to produce a recovery image that bypasses the need to compute the SVD decomposition, which may be very expensive for large matrices.</p>
<div id="a462796b" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tqdm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span>
<span id="cb9-2"></span>
<span id="cb9-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> least_squares_sol(x0, b, Amv, Amv_adjoint, max_iter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span>, tol<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-6</span>):</span>
<span id="cb9-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb9-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Solves the least squares problem using gradient descent with progress tracking.</span></span>
<span id="cb9-6"></span>
<span id="cb9-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Parameters:</span></span>
<span id="cb9-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - x0 (torch.Tensor): Initial guess for the solution.</span></span>
<span id="cb9-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - b (torch.Tensor): Observation vector.</span></span>
<span id="cb9-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - Amv (callable): Function to compute A @ x.</span></span>
<span id="cb9-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - Amv_adjoint (callable): Function to compute A^T @ v.</span></span>
<span id="cb9-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - max_iter (int): Maximum number of iterations.</span></span>
<span id="cb9-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - alpha (float): Learning rate.</span></span>
<span id="cb9-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - tol (float): Tolerance for convergence.</span></span>
<span id="cb9-15"></span>
<span id="cb9-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb9-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    - x (torch.Tensor): Approximated solution vector.</span></span>
<span id="cb9-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb9-19">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x0.clone()</span>
<span id="cb9-20">    x.requires_grad <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb9-21">    b_noisy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> b.clone() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> torch.randn_like(b)</span>
<span id="cb9-22"></span>
<span id="cb9-23">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize the progress bar</span></span>
<span id="cb9-24">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> tqdm(total<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>max_iter, desc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Least Squares Iteration'</span>, unit<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'iter'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pbar:</span>
<span id="cb9-25">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(max_iter):</span>
<span id="cb9-26">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Gradient descent update</span></span>
<span id="cb9-27">            residual <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Amv(x) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> b_noisy</span>
<span id="cb9-28">            gradient <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Amv_adjoint(residual)</span>
<span id="cb9-29">            xnext <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> gradient</span>
<span id="cb9-30"></span>
<span id="cb9-31">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute relative error</span></span>
<span id="cb9-32">            error <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.norm(xnext <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> x) </span>
<span id="cb9-33"></span>
<span id="cb9-34">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update the progress bar with the current error</span></span>
<span id="cb9-35">            pbar.set_postfix({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Error'</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>error<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>item()<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4e}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>})</span>
<span id="cb9-36">            pbar.update(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb9-37"></span>
<span id="cb9-38">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check for convergence</span></span>
<span id="cb9-39">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> error <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> tol:</span>
<span id="cb9-40">                pbar.write(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Converged at iteration </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> with error </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>error<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>item()<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4e}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb9-41">                x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> xnext</span>
<span id="cb9-42">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">break</span></span>
<span id="cb9-43"></span>
<span id="cb9-44">            x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> xnext</span>
<span id="cb9-45"></span>
<span id="cb9-46">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> x</span>
<span id="cb9-47"></span>
<span id="cb9-48">b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Amv(x)</span>
<span id="cb9-49">x0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros_like(x)</span>
<span id="cb9-50">xhat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> least_squares_sol(x0, b, Amv, Amv_adjoint, max_iter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, tol<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-6</span>)</span>
<span id="cb9-51"></span>
<span id="cb9-52">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))</span>
<span id="cb9-53">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb9-54">plt.imshow(x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>, vmin<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, vmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb9-55">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Original Image'</span>)</span>
<span id="cb9-56">plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'off'</span>)</span>
<span id="cb9-57">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb9-58">plt.imshow(xhat.detach().numpy()[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>, vmin<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, vmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb9-59">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Recovered Image'</span>)</span>
<span id="cb9-60">plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'off'</span>)</span>
<span id="cb9-61">plt.tight_layout()</span>
<span id="cb9-62">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Least Squares Iteration:   0%|          | 0/1000 [00:00&lt;?, ?iter/s]Least Squares Iteration:   0%|          | 0/1000 [00:00&lt;?, ?iter/s, Error=2.1563e-01]Least Squares Iteration:   0%|          | 1/1000 [00:00&lt;00:04, 219.83iter/s, Error=1.2599e-01]Least Squares Iteration:   0%|          | 2/1000 [00:00&lt;00:03, 303.86iter/s, Error=9.0033e-02]Least Squares Iteration:   0%|          | 3/1000 [00:00&lt;00:02, 345.11iter/s, Error=7.0516e-02]Least Squares Iteration:   0%|          | 4/1000 [00:00&lt;00:02, 392.76iter/s, Error=5.8476e-02]Least Squares Iteration:   0%|          | 5/1000 [00:00&lt;00:02, 410.06iter/s, Error=5.0304e-02]Least Squares Iteration:   1%|          | 6/1000 [00:00&lt;00:02, 422.22iter/s, Error=4.4323e-02]Least Squares Iteration:   1%|          | 7/1000 [00:00&lt;00:02, 406.40iter/s, Error=3.9702e-02]Least Squares Iteration:   1%|          | 8/1000 [00:00&lt;00:02, 409.52iter/s, Error=3.6006e-02]Least Squares Iteration:   1%|          | 9/1000 [00:00&lt;00:02, 433.07iter/s, Error=3.2978e-02]Least Squares Iteration:   1%|          | 10/1000 [00:00&lt;00:02, 438.77iter/s, Error=3.0457e-02]Least Squares Iteration:   1%|          | 11/1000 [00:00&lt;00:02, 443.66iter/s, Error=2.8329e-02]Least Squares Iteration:   1%|          | 12/1000 [00:00&lt;00:02, 450.71iter/s, Error=2.6512e-02]Least Squares Iteration:   1%|▏         | 13/1000 [00:00&lt;00:02, 452.52iter/s, Error=2.4943e-02]Least Squares Iteration:   1%|▏         | 14/1000 [00:00&lt;00:02, 455.73iter/s, Error=2.3576e-02]Least Squares Iteration:   2%|▏         | 15/1000 [00:00&lt;00:02, 454.41iter/s, Error=2.2371e-02]Least Squares Iteration:   2%|▏         | 16/1000 [00:00&lt;00:02, 439.31iter/s, Error=2.1301e-02]Least Squares Iteration:   2%|▏         | 17/1000 [00:00&lt;00:02, 451.96iter/s, Error=2.0342e-02]Least Squares Iteration:   2%|▏         | 18/1000 [00:00&lt;00:02, 453.20iter/s, Error=1.9476e-02]Least Squares Iteration:   2%|▏         | 19/1000 [00:00&lt;00:02, 455.17iter/s, Error=1.8689e-02]Least Squares Iteration:   2%|▏         | 20/1000 [00:00&lt;00:02, 447.02iter/s, Error=1.7969e-02]Least Squares Iteration:   2%|▏         | 21/1000 [00:00&lt;00:02, 449.30iter/s, Error=1.7307e-02]Least Squares Iteration:   2%|▏         | 22/1000 [00:00&lt;00:02, 455.90iter/s, Error=1.6694e-02]Least Squares Iteration:   2%|▏         | 23/1000 [00:00&lt;00:02, 443.75iter/s, Error=1.6126e-02]Least Squares Iteration:   2%|▏         | 24/1000 [00:00&lt;00:02, 442.15iter/s, Error=1.5596e-02]Least Squares Iteration:   2%|▎         | 25/1000 [00:00&lt;00:02, 451.48iter/s, Error=1.5101e-02]Least Squares Iteration:   3%|▎         | 26/1000 [00:00&lt;00:02, 443.46iter/s, Error=1.4636e-02]Least Squares Iteration:   3%|▎         | 27/1000 [00:00&lt;00:02, 445.37iter/s, Error=1.4200e-02]Least Squares Iteration:   3%|▎         | 28/1000 [00:00&lt;00:02, 444.71iter/s, Error=1.3788e-02]Least Squares Iteration:   3%|▎         | 29/1000 [00:00&lt;00:02, 444.69iter/s, Error=1.3399e-02]Least Squares Iteration:   3%|▎         | 30/1000 [00:00&lt;00:02, 435.33iter/s, Error=1.3031e-02]Least Squares Iteration:   3%|▎         | 31/1000 [00:00&lt;00:02, 437.11iter/s, Error=1.2682e-02]Least Squares Iteration:   3%|▎         | 32/1000 [00:00&lt;00:02, 438.84iter/s, Error=1.2351e-02]Least Squares Iteration:   3%|▎         | 33/1000 [00:00&lt;00:02, 440.48iter/s, Error=1.2036e-02]Least Squares Iteration:   3%|▎         | 34/1000 [00:00&lt;00:02, 442.02iter/s, Error=1.1737e-02]Least Squares Iteration:   4%|▎         | 35/1000 [00:00&lt;00:02, 443.34iter/s, Error=1.1451e-02]Least Squares Iteration:   4%|▎         | 36/1000 [00:00&lt;00:02, 449.26iter/s, Error=1.1179e-02]Least Squares Iteration:   4%|▎         | 37/1000 [00:00&lt;00:02, 445.03iter/s, Error=1.0919e-02]Least Squares Iteration:   4%|▍         | 38/1000 [00:00&lt;00:02, 443.92iter/s, Error=1.0670e-02]Least Squares Iteration:   4%|▍         | 39/1000 [00:00&lt;00:02, 443.44iter/s, Error=1.0433e-02]Least Squares Iteration:   4%|▍         | 40/1000 [00:00&lt;00:02, 444.69iter/s, Error=1.0205e-02]Least Squares Iteration:   4%|▍         | 41/1000 [00:00&lt;00:02, 445.82iter/s, Error=9.9872e-03]Least Squares Iteration:   4%|▍         | 42/1000 [00:00&lt;00:02, 446.98iter/s, Error=9.7783e-03]Least Squares Iteration:   4%|▍         | 43/1000 [00:00&lt;00:02, 446.45iter/s, Error=9.5779e-03]Least Squares Iteration:   4%|▍         | 44/1000 [00:00&lt;00:02, 447.52iter/s, Error=9.3856e-03]Least Squares Iteration:   4%|▍         | 45/1000 [00:00&lt;00:02, 444.15iter/s, Error=9.2009e-03]Least Squares Iteration:   5%|▍         | 46/1000 [00:00&lt;00:02, 454.02iter/s, Error=9.2009e-03]Least Squares Iteration:   5%|▍         | 46/1000 [00:00&lt;00:02, 454.02iter/s, Error=9.0235e-03]Least Squares Iteration:   5%|▍         | 47/1000 [00:00&lt;00:02, 454.02iter/s, Error=8.8529e-03]Least Squares Iteration:   5%|▍         | 48/1000 [00:00&lt;00:02, 454.02iter/s, Error=8.6888e-03]Least Squares Iteration:   5%|▍         | 49/1000 [00:00&lt;00:02, 454.02iter/s, Error=8.5310e-03]Least Squares Iteration:   5%|▌         | 50/1000 [00:00&lt;00:02, 454.02iter/s, Error=8.3790e-03]Least Squares Iteration:   5%|▌         | 51/1000 [00:00&lt;00:02, 454.02iter/s, Error=8.2326e-03]Least Squares Iteration:   5%|▌         | 52/1000 [00:00&lt;00:02, 454.02iter/s, Error=8.0915e-03]Least Squares Iteration:   5%|▌         | 53/1000 [00:00&lt;00:02, 454.02iter/s, Error=7.9555e-03]Least Squares Iteration:   5%|▌         | 54/1000 [00:00&lt;00:02, 454.02iter/s, Error=7.8244e-03]Least Squares Iteration:   6%|▌         | 55/1000 [00:00&lt;00:02, 454.02iter/s, Error=7.6978e-03]Least Squares Iteration:   6%|▌         | 56/1000 [00:00&lt;00:02, 454.02iter/s, Error=7.5757e-03]Least Squares Iteration:   6%|▌         | 57/1000 [00:00&lt;00:02, 454.02iter/s, Error=7.4578e-03]Least Squares Iteration:   6%|▌         | 58/1000 [00:00&lt;00:02, 454.02iter/s, Error=7.3438e-03]Least Squares Iteration:   6%|▌         | 59/1000 [00:00&lt;00:02, 454.02iter/s, Error=7.2337e-03]Least Squares Iteration:   6%|▌         | 60/1000 [00:00&lt;00:02, 454.02iter/s, Error=7.1272e-03]Least Squares Iteration:   6%|▌         | 61/1000 [00:00&lt;00:02, 454.02iter/s, Error=7.0243e-03]Least Squares Iteration:   6%|▌         | 62/1000 [00:00&lt;00:02, 454.02iter/s, Error=6.9246e-03]Least Squares Iteration:   6%|▋         | 63/1000 [00:00&lt;00:02, 454.02iter/s, Error=6.8282e-03]Least Squares Iteration:   6%|▋         | 64/1000 [00:00&lt;00:02, 454.02iter/s, Error=6.7348e-03]Least Squares Iteration:   6%|▋         | 65/1000 [00:00&lt;00:02, 454.02iter/s, Error=6.6443e-03]Least Squares Iteration:   7%|▋         | 66/1000 [00:00&lt;00:02, 454.02iter/s, Error=6.5567e-03]Least Squares Iteration:   7%|▋         | 67/1000 [00:00&lt;00:02, 454.02iter/s, Error=6.4717e-03]Least Squares Iteration:   7%|▋         | 68/1000 [00:00&lt;00:02, 454.02iter/s, Error=6.3893e-03]Least Squares Iteration:   7%|▋         | 69/1000 [00:00&lt;00:02, 454.02iter/s, Error=6.3093e-03]Least Squares Iteration:   7%|▋         | 70/1000 [00:00&lt;00:02, 454.02iter/s, Error=6.2316e-03]Least Squares Iteration:   7%|▋         | 71/1000 [00:00&lt;00:02, 454.02iter/s, Error=6.1563e-03]Least Squares Iteration:   7%|▋         | 72/1000 [00:00&lt;00:02, 454.02iter/s, Error=6.0830e-03]Least Squares Iteration:   7%|▋         | 73/1000 [00:00&lt;00:02, 454.02iter/s, Error=6.0119e-03]Least Squares Iteration:   7%|▋         | 74/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.9427e-03]Least Squares Iteration:   8%|▊         | 75/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.8755e-03]Least Squares Iteration:   8%|▊         | 76/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.8100e-03]Least Squares Iteration:   8%|▊         | 77/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.7463e-03]Least Squares Iteration:   8%|▊         | 78/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.6843e-03]Least Squares Iteration:   8%|▊         | 79/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.6240e-03]Least Squares Iteration:   8%|▊         | 80/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.5651e-03]Least Squares Iteration:   8%|▊         | 81/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.5078e-03]Least Squares Iteration:   8%|▊         | 82/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.4519e-03]Least Squares Iteration:   8%|▊         | 83/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.3974e-03]Least Squares Iteration:   8%|▊         | 84/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.3442e-03]Least Squares Iteration:   8%|▊         | 85/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.2923e-03]Least Squares Iteration:   9%|▊         | 86/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.2416e-03]Least Squares Iteration:   9%|▊         | 87/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.1921e-03]Least Squares Iteration:   9%|▉         | 88/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.1437e-03]Least Squares Iteration:   9%|▉         | 89/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.0964e-03]Least Squares Iteration:   9%|▉         | 90/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.0502e-03]Least Squares Iteration:   9%|▉         | 91/1000 [00:00&lt;00:02, 454.02iter/s, Error=5.0050e-03]Least Squares Iteration:   9%|▉         | 92/1000 [00:00&lt;00:02, 424.05iter/s, Error=5.0050e-03]Least Squares Iteration:   9%|▉         | 92/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.9608e-03]Least Squares Iteration:   9%|▉         | 93/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.9175e-03]Least Squares Iteration:   9%|▉         | 94/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.8751e-03]Least Squares Iteration:  10%|▉         | 95/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.8337e-03]Least Squares Iteration:  10%|▉         | 96/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.7930e-03]Least Squares Iteration:  10%|▉         | 97/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.7532e-03]Least Squares Iteration:  10%|▉         | 98/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.7142e-03]Least Squares Iteration:  10%|▉         | 99/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.6760e-03]Least Squares Iteration:  10%|█         | 100/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.6385e-03]Least Squares Iteration:  10%|█         | 101/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.6017e-03]Least Squares Iteration:  10%|█         | 102/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.5656e-03]Least Squares Iteration:  10%|█         | 103/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.5302e-03]Least Squares Iteration:  10%|█         | 104/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.4955e-03]Least Squares Iteration:  10%|█         | 105/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.4614e-03]Least Squares Iteration:  11%|█         | 106/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.4279e-03]Least Squares Iteration:  11%|█         | 107/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.3949e-03]Least Squares Iteration:  11%|█         | 108/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.3626e-03]Least Squares Iteration:  11%|█         | 109/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.3308e-03]Least Squares Iteration:  11%|█         | 110/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.2996e-03]Least Squares Iteration:  11%|█         | 111/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.2688e-03]Least Squares Iteration:  11%|█         | 112/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.2386e-03]Least Squares Iteration:  11%|█▏        | 113/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.2089e-03]Least Squares Iteration:  11%|█▏        | 114/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.1797e-03]Least Squares Iteration:  12%|█▏        | 115/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.1509e-03]Least Squares Iteration:  12%|█▏        | 116/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.1226e-03]Least Squares Iteration:  12%|█▏        | 117/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.0948e-03]Least Squares Iteration:  12%|█▏        | 118/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.0673e-03]Least Squares Iteration:  12%|█▏        | 119/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.0403e-03]Least Squares Iteration:  12%|█▏        | 120/1000 [00:00&lt;00:02, 424.05iter/s, Error=4.0137e-03]Least Squares Iteration:  12%|█▏        | 121/1000 [00:00&lt;00:02, 424.05iter/s, Error=3.9875e-03]Least Squares Iteration:  12%|█▏        | 122/1000 [00:00&lt;00:02, 424.05iter/s, Error=3.9617e-03]Least Squares Iteration:  12%|█▏        | 123/1000 [00:00&lt;00:02, 424.05iter/s, Error=3.9362e-03]Least Squares Iteration:  12%|█▏        | 124/1000 [00:00&lt;00:02, 424.05iter/s, Error=3.9112e-03]Least Squares Iteration:  12%|█▎        | 125/1000 [00:00&lt;00:02, 424.05iter/s, Error=3.8865e-03]Least Squares Iteration:  13%|█▎        | 126/1000 [00:00&lt;00:02, 424.05iter/s, Error=3.8621e-03]Least Squares Iteration:  13%|█▎        | 127/1000 [00:00&lt;00:02, 424.05iter/s, Error=3.8381e-03]Least Squares Iteration:  13%|█▎        | 128/1000 [00:00&lt;00:02, 424.05iter/s, Error=3.8144e-03]Least Squares Iteration:  13%|█▎        | 129/1000 [00:00&lt;00:02, 424.05iter/s, Error=3.7910e-03]Least Squares Iteration:  13%|█▎        | 130/1000 [00:00&lt;00:02, 424.05iter/s, Error=3.7680e-03]Least Squares Iteration:  13%|█▎        | 131/1000 [00:00&lt;00:02, 424.05iter/s, Error=3.7453e-03]Least Squares Iteration:  13%|█▎        | 132/1000 [00:00&lt;00:02, 424.05iter/s, Error=3.7228e-03]Least Squares Iteration:  13%|█▎        | 133/1000 [00:00&lt;00:02, 424.05iter/s, Error=3.7007e-03]Least Squares Iteration:  13%|█▎        | 134/1000 [00:00&lt;00:02, 424.05iter/s, Error=3.6789e-03]Least Squares Iteration:  14%|█▎        | 135/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.6789e-03]Least Squares Iteration:  14%|█▎        | 135/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.6573e-03]Least Squares Iteration:  14%|█▎        | 136/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.6361e-03]Least Squares Iteration:  14%|█▎        | 137/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.6151e-03]Least Squares Iteration:  14%|█▍        | 138/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.5943e-03]Least Squares Iteration:  14%|█▍        | 139/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.5739e-03]Least Squares Iteration:  14%|█▍        | 140/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.5537e-03]Least Squares Iteration:  14%|█▍        | 141/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.5337e-03]Least Squares Iteration:  14%|█▍        | 142/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.5140e-03]Least Squares Iteration:  14%|█▍        | 143/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.4945e-03]Least Squares Iteration:  14%|█▍        | 144/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.4753e-03]Least Squares Iteration:  14%|█▍        | 145/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.4563e-03]Least Squares Iteration:  15%|█▍        | 146/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.4375e-03]Least Squares Iteration:  15%|█▍        | 147/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.4190e-03]Least Squares Iteration:  15%|█▍        | 148/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.4006e-03]Least Squares Iteration:  15%|█▍        | 149/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.3825e-03]Least Squares Iteration:  15%|█▌        | 150/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.3646e-03]Least Squares Iteration:  15%|█▌        | 151/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.3469e-03]Least Squares Iteration:  15%|█▌        | 152/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.3295e-03]Least Squares Iteration:  15%|█▌        | 153/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.3122e-03]Least Squares Iteration:  15%|█▌        | 154/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.2951e-03]Least Squares Iteration:  16%|█▌        | 155/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.2782e-03]Least Squares Iteration:  16%|█▌        | 156/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.2615e-03]Least Squares Iteration:  16%|█▌        | 157/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.2450e-03]Least Squares Iteration:  16%|█▌        | 158/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.2286e-03]Least Squares Iteration:  16%|█▌        | 159/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.2125e-03]Least Squares Iteration:  16%|█▌        | 160/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.1965e-03]Least Squares Iteration:  16%|█▌        | 161/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.1807e-03]Least Squares Iteration:  16%|█▌        | 162/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.1651e-03]Least Squares Iteration:  16%|█▋        | 163/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.1496e-03]Least Squares Iteration:  16%|█▋        | 164/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.1344e-03]Least Squares Iteration:  16%|█▋        | 165/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.1192e-03]Least Squares Iteration:  17%|█▋        | 166/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.1043e-03]Least Squares Iteration:  17%|█▋        | 167/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.0895e-03]Least Squares Iteration:  17%|█▋        | 168/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.0748e-03]Least Squares Iteration:  17%|█▋        | 169/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.0604e-03]Least Squares Iteration:  17%|█▋        | 170/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.0460e-03]Least Squares Iteration:  17%|█▋        | 171/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.0319e-03]Least Squares Iteration:  17%|█▋        | 172/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.0178e-03]Least Squares Iteration:  17%|█▋        | 173/1000 [00:00&lt;00:02, 393.64iter/s, Error=3.0039e-03]Least Squares Iteration:  17%|█▋        | 174/1000 [00:00&lt;00:02, 393.64iter/s, Error=2.9902e-03]Least Squares Iteration:  18%|█▊        | 175/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.9902e-03]Least Squares Iteration:  18%|█▊        | 175/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.9766e-03]Least Squares Iteration:  18%|█▊        | 176/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.9632e-03]Least Squares Iteration:  18%|█▊        | 177/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.9499e-03]Least Squares Iteration:  18%|█▊        | 178/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.9367e-03]Least Squares Iteration:  18%|█▊        | 179/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.9236e-03]Least Squares Iteration:  18%|█▊        | 180/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.9107e-03]Least Squares Iteration:  18%|█▊        | 181/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.8979e-03]Least Squares Iteration:  18%|█▊        | 182/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.8853e-03]Least Squares Iteration:  18%|█▊        | 183/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.8728e-03]Least Squares Iteration:  18%|█▊        | 184/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.8604e-03]Least Squares Iteration:  18%|█▊        | 185/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.8481e-03]Least Squares Iteration:  19%|█▊        | 186/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.8360e-03]Least Squares Iteration:  19%|█▊        | 187/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.8240e-03]Least Squares Iteration:  19%|█▉        | 188/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.8121e-03]Least Squares Iteration:  19%|█▉        | 189/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.8003e-03]Least Squares Iteration:  19%|█▉        | 190/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.7886e-03]Least Squares Iteration:  19%|█▉        | 191/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.7771e-03]Least Squares Iteration:  19%|█▉        | 192/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.7656e-03]Least Squares Iteration:  19%|█▉        | 193/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.7543e-03]Least Squares Iteration:  19%|█▉        | 194/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.7431e-03]Least Squares Iteration:  20%|█▉        | 195/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.7320e-03]Least Squares Iteration:  20%|█▉        | 196/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.7210e-03]Least Squares Iteration:  20%|█▉        | 197/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.7101e-03]Least Squares Iteration:  20%|█▉        | 198/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.6994e-03]Least Squares Iteration:  20%|█▉        | 199/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.6887e-03]Least Squares Iteration:  20%|██        | 200/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.6781e-03]Least Squares Iteration:  20%|██        | 201/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.6676e-03]Least Squares Iteration:  20%|██        | 202/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.6573e-03]Least Squares Iteration:  20%|██        | 203/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.6470e-03]Least Squares Iteration:  20%|██        | 204/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.6369e-03]Least Squares Iteration:  20%|██        | 205/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.6268e-03]Least Squares Iteration:  21%|██        | 206/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.6168e-03]Least Squares Iteration:  21%|██        | 207/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.6069e-03]Least Squares Iteration:  21%|██        | 208/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.5972e-03]Least Squares Iteration:  21%|██        | 209/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.5875e-03]Least Squares Iteration:  21%|██        | 210/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.5779e-03]Least Squares Iteration:  21%|██        | 211/1000 [00:00&lt;00:02, 359.51iter/s, Error=2.5684e-03]Least Squares Iteration:  21%|██        | 212/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.5684e-03]Least Squares Iteration:  21%|██        | 212/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.5590e-03]Least Squares Iteration:  21%|██▏       | 213/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.5496e-03]Least Squares Iteration:  21%|██▏       | 214/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.5404e-03]Least Squares Iteration:  22%|██▏       | 215/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.5313e-03]Least Squares Iteration:  22%|██▏       | 216/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.5222e-03]Least Squares Iteration:  22%|██▏       | 217/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.5132e-03]Least Squares Iteration:  22%|██▏       | 218/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.5043e-03]Least Squares Iteration:  22%|██▏       | 219/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.4955e-03]Least Squares Iteration:  22%|██▏       | 220/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.4868e-03]Least Squares Iteration:  22%|██▏       | 221/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.4782e-03]Least Squares Iteration:  22%|██▏       | 222/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.4696e-03]Least Squares Iteration:  22%|██▏       | 223/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.4611e-03]Least Squares Iteration:  22%|██▏       | 224/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.4527e-03]Least Squares Iteration:  22%|██▎       | 225/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.4444e-03]Least Squares Iteration:  23%|██▎       | 226/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.4361e-03]Least Squares Iteration:  23%|██▎       | 227/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.4280e-03]Least Squares Iteration:  23%|██▎       | 228/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.4199e-03]Least Squares Iteration:  23%|██▎       | 229/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.4118e-03]Least Squares Iteration:  23%|██▎       | 230/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.4039e-03]Least Squares Iteration:  23%|██▎       | 231/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.3960e-03]Least Squares Iteration:  23%|██▎       | 232/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.3882e-03]Least Squares Iteration:  23%|██▎       | 233/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.3805e-03]Least Squares Iteration:  23%|██▎       | 234/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.3728e-03]Least Squares Iteration:  24%|██▎       | 235/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.3652e-03]Least Squares Iteration:  24%|██▎       | 236/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.3577e-03]Least Squares Iteration:  24%|██▎       | 237/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.3503e-03]Least Squares Iteration:  24%|██▍       | 238/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.3429e-03]Least Squares Iteration:  24%|██▍       | 239/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.3355e-03]Least Squares Iteration:  24%|██▍       | 240/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.3283e-03]Least Squares Iteration:  24%|██▍       | 241/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.3211e-03]Least Squares Iteration:  24%|██▍       | 242/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.3140e-03]Least Squares Iteration:  24%|██▍       | 243/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.3069e-03]Least Squares Iteration:  24%|██▍       | 244/1000 [00:00&lt;00:02, 315.15iter/s, Error=2.2999e-03]Least Squares Iteration:  24%|██▍       | 245/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.2999e-03]Least Squares Iteration:  24%|██▍       | 245/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.2930e-03]Least Squares Iteration:  25%|██▍       | 246/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.2861e-03]Least Squares Iteration:  25%|██▍       | 247/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.2793e-03]Least Squares Iteration:  25%|██▍       | 248/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.2726e-03]Least Squares Iteration:  25%|██▍       | 249/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.2659e-03]Least Squares Iteration:  25%|██▌       | 250/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.2592e-03]Least Squares Iteration:  25%|██▌       | 251/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.2527e-03]Least Squares Iteration:  25%|██▌       | 252/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.2462e-03]Least Squares Iteration:  25%|██▌       | 253/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.2397e-03]Least Squares Iteration:  25%|██▌       | 254/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.2333e-03]Least Squares Iteration:  26%|██▌       | 255/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.2270e-03]Least Squares Iteration:  26%|██▌       | 256/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.2207e-03]Least Squares Iteration:  26%|██▌       | 257/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.2145e-03]Least Squares Iteration:  26%|██▌       | 258/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.2083e-03]Least Squares Iteration:  26%|██▌       | 259/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.2022e-03]Least Squares Iteration:  26%|██▌       | 260/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.1961e-03]Least Squares Iteration:  26%|██▌       | 261/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.1901e-03]Least Squares Iteration:  26%|██▌       | 262/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.1841e-03]Least Squares Iteration:  26%|██▋       | 263/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.1782e-03]Least Squares Iteration:  26%|██▋       | 264/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.1723e-03]Least Squares Iteration:  26%|██▋       | 265/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.1665e-03]Least Squares Iteration:  27%|██▋       | 266/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.1608e-03]Least Squares Iteration:  27%|██▋       | 267/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.1551e-03]Least Squares Iteration:  27%|██▋       | 268/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.1494e-03]Least Squares Iteration:  27%|██▋       | 269/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.1438e-03]Least Squares Iteration:  27%|██▋       | 270/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.1382e-03]Least Squares Iteration:  27%|██▋       | 271/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.1327e-03]Least Squares Iteration:  27%|██▋       | 272/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.1272e-03]Least Squares Iteration:  27%|██▋       | 273/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.1218e-03]Least Squares Iteration:  27%|██▋       | 274/1000 [00:00&lt;00:02, 290.22iter/s, Error=2.1164e-03]Least Squares Iteration:  28%|██▊       | 275/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.1164e-03]Least Squares Iteration:  28%|██▊       | 275/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.1111e-03]Least Squares Iteration:  28%|██▊       | 276/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.1058e-03]Least Squares Iteration:  28%|██▊       | 277/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.1006e-03]Least Squares Iteration:  28%|██▊       | 278/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0954e-03]Least Squares Iteration:  28%|██▊       | 279/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0902e-03]Least Squares Iteration:  28%|██▊       | 280/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0851e-03]Least Squares Iteration:  28%|██▊       | 281/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0800e-03]Least Squares Iteration:  28%|██▊       | 282/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0750e-03]Least Squares Iteration:  28%|██▊       | 283/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0700e-03]Least Squares Iteration:  28%|██▊       | 284/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0651e-03]Least Squares Iteration:  28%|██▊       | 285/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0602e-03]Least Squares Iteration:  29%|██▊       | 286/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0553e-03]Least Squares Iteration:  29%|██▊       | 287/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0505e-03]Least Squares Iteration:  29%|██▉       | 288/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0457e-03]Least Squares Iteration:  29%|██▉       | 289/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0409e-03]Least Squares Iteration:  29%|██▉       | 290/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0362e-03]Least Squares Iteration:  29%|██▉       | 291/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0315e-03]Least Squares Iteration:  29%|██▉       | 292/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0269e-03]Least Squares Iteration:  29%|██▉       | 293/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0223e-03]Least Squares Iteration:  29%|██▉       | 294/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0178e-03]Least Squares Iteration:  30%|██▉       | 295/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0132e-03]Least Squares Iteration:  30%|██▉       | 296/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0087e-03]Least Squares Iteration:  30%|██▉       | 297/1000 [00:00&lt;00:02, 272.42iter/s, Error=2.0043e-03]Least Squares Iteration:  30%|██▉       | 298/1000 [00:00&lt;00:02, 272.42iter/s, Error=1.9999e-03]Least Squares Iteration:  30%|██▉       | 299/1000 [00:00&lt;00:02, 272.42iter/s, Error=1.9955e-03]Least Squares Iteration:  30%|███       | 300/1000 [00:00&lt;00:02, 272.42iter/s, Error=1.9912e-03]Least Squares Iteration:  30%|███       | 301/1000 [00:00&lt;00:02, 272.42iter/s, Error=1.9868e-03]Least Squares Iteration:  30%|███       | 302/1000 [00:00&lt;00:02, 272.42iter/s, Error=1.9826e-03]Least Squares Iteration:  30%|███       | 303/1000 [00:00&lt;00:02, 258.60iter/s, Error=1.9826e-03]Least Squares Iteration:  30%|███       | 303/1000 [00:00&lt;00:02, 258.60iter/s, Error=1.9783e-03]Least Squares Iteration:  30%|███       | 304/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9741e-03]Least Squares Iteration:  30%|███       | 305/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9699e-03]Least Squares Iteration:  31%|███       | 306/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9658e-03]Least Squares Iteration:  31%|███       | 307/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9617e-03]Least Squares Iteration:  31%|███       | 308/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9576e-03]Least Squares Iteration:  31%|███       | 309/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9535e-03]Least Squares Iteration:  31%|███       | 310/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9495e-03]Least Squares Iteration:  31%|███       | 311/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9455e-03]Least Squares Iteration:  31%|███       | 312/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9416e-03]Least Squares Iteration:  31%|███▏      | 313/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9377e-03]Least Squares Iteration:  31%|███▏      | 314/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9338e-03]Least Squares Iteration:  32%|███▏      | 315/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9299e-03]Least Squares Iteration:  32%|███▏      | 316/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9260e-03]Least Squares Iteration:  32%|███▏      | 317/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9222e-03]Least Squares Iteration:  32%|███▏      | 318/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9185e-03]Least Squares Iteration:  32%|███▏      | 319/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9147e-03]Least Squares Iteration:  32%|███▏      | 320/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9110e-03]Least Squares Iteration:  32%|███▏      | 321/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9073e-03]Least Squares Iteration:  32%|███▏      | 322/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9036e-03]Least Squares Iteration:  32%|███▏      | 323/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.9000e-03]Least Squares Iteration:  32%|███▏      | 324/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.8963e-03]Least Squares Iteration:  32%|███▎      | 325/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.8928e-03]Least Squares Iteration:  33%|███▎      | 326/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.8892e-03]Least Squares Iteration:  33%|███▎      | 327/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.8856e-03]Least Squares Iteration:  33%|███▎      | 328/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.8821e-03]Least Squares Iteration:  33%|███▎      | 329/1000 [00:01&lt;00:02, 258.60iter/s, Error=1.8786e-03]Least Squares Iteration:  33%|███▎      | 330/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8786e-03]Least Squares Iteration:  33%|███▎      | 330/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8752e-03]Least Squares Iteration:  33%|███▎      | 331/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8717e-03]Least Squares Iteration:  33%|███▎      | 332/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8683e-03]Least Squares Iteration:  33%|███▎      | 333/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8649e-03]Least Squares Iteration:  33%|███▎      | 334/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8616e-03]Least Squares Iteration:  34%|███▎      | 335/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8582e-03]Least Squares Iteration:  34%|███▎      | 336/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8549e-03]Least Squares Iteration:  34%|███▎      | 337/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8516e-03]Least Squares Iteration:  34%|███▍      | 338/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8483e-03]Least Squares Iteration:  34%|███▍      | 339/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8451e-03]Least Squares Iteration:  34%|███▍      | 340/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8419e-03]Least Squares Iteration:  34%|███▍      | 341/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8387e-03]Least Squares Iteration:  34%|███▍      | 342/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8355e-03]Least Squares Iteration:  34%|███▍      | 343/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8323e-03]Least Squares Iteration:  34%|███▍      | 344/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8292e-03]Least Squares Iteration:  34%|███▍      | 345/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8261e-03]Least Squares Iteration:  35%|███▍      | 346/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8230e-03]Least Squares Iteration:  35%|███▍      | 347/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8199e-03]Least Squares Iteration:  35%|███▍      | 348/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8168e-03]Least Squares Iteration:  35%|███▍      | 349/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8138e-03]Least Squares Iteration:  35%|███▌      | 350/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8108e-03]Least Squares Iteration:  35%|███▌      | 351/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8078e-03]Least Squares Iteration:  35%|███▌      | 352/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8048e-03]Least Squares Iteration:  35%|███▌      | 353/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.8018e-03]Least Squares Iteration:  35%|███▌      | 354/1000 [00:01&lt;00:02, 239.94iter/s, Error=1.7989e-03]Least Squares Iteration:  36%|███▌      | 355/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7989e-03]Least Squares Iteration:  36%|███▌      | 355/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7960e-03]Least Squares Iteration:  36%|███▌      | 356/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7931e-03]Least Squares Iteration:  36%|███▌      | 357/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7902e-03]Least Squares Iteration:  36%|███▌      | 358/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7873e-03]Least Squares Iteration:  36%|███▌      | 359/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7845e-03]Least Squares Iteration:  36%|███▌      | 360/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7817e-03]Least Squares Iteration:  36%|███▌      | 361/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7789e-03]Least Squares Iteration:  36%|███▌      | 362/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7761e-03]Least Squares Iteration:  36%|███▋      | 363/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7733e-03]Least Squares Iteration:  36%|███▋      | 364/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7706e-03]Least Squares Iteration:  36%|███▋      | 365/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7678e-03]Least Squares Iteration:  37%|███▋      | 366/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7651e-03]Least Squares Iteration:  37%|███▋      | 367/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7624e-03]Least Squares Iteration:  37%|███▋      | 368/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7597e-03]Least Squares Iteration:  37%|███▋      | 369/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7570e-03]Least Squares Iteration:  37%|███▋      | 370/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7544e-03]Least Squares Iteration:  37%|███▋      | 371/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7517e-03]Least Squares Iteration:  37%|███▋      | 372/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7491e-03]Least Squares Iteration:  37%|███▋      | 373/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7465e-03]Least Squares Iteration:  37%|███▋      | 374/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7439e-03]Least Squares Iteration:  38%|███▊      | 375/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7414e-03]Least Squares Iteration:  38%|███▊      | 376/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7388e-03]Least Squares Iteration:  38%|███▊      | 377/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7362e-03]Least Squares Iteration:  38%|███▊      | 378/1000 [00:01&lt;00:02, 230.78iter/s, Error=1.7337e-03]Least Squares Iteration:  38%|███▊      | 379/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.7337e-03]Least Squares Iteration:  38%|███▊      | 379/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.7312e-03]Least Squares Iteration:  38%|███▊      | 380/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.7287e-03]Least Squares Iteration:  38%|███▊      | 381/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.7262e-03]Least Squares Iteration:  38%|███▊      | 382/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.7237e-03]Least Squares Iteration:  38%|███▊      | 383/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.7213e-03]Least Squares Iteration:  38%|███▊      | 384/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.7189e-03]Least Squares Iteration:  38%|███▊      | 385/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.7164e-03]Least Squares Iteration:  39%|███▊      | 386/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.7140e-03]Least Squares Iteration:  39%|███▊      | 387/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.7116e-03]Least Squares Iteration:  39%|███▉      | 388/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.7092e-03]Least Squares Iteration:  39%|███▉      | 389/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.7069e-03]Least Squares Iteration:  39%|███▉      | 390/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.7045e-03]Least Squares Iteration:  39%|███▉      | 391/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.7021e-03]Least Squares Iteration:  39%|███▉      | 392/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.6998e-03]Least Squares Iteration:  39%|███▉      | 393/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.6975e-03]Least Squares Iteration:  39%|███▉      | 394/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.6952e-03]Least Squares Iteration:  40%|███▉      | 395/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.6929e-03]Least Squares Iteration:  40%|███▉      | 396/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.6906e-03]Least Squares Iteration:  40%|███▉      | 397/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.6883e-03]Least Squares Iteration:  40%|███▉      | 398/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.6861e-03]Least Squares Iteration:  40%|███▉      | 399/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.6838e-03]Least Squares Iteration:  40%|████      | 400/1000 [00:01&lt;00:02, 218.88iter/s, Error=1.6816e-03]Least Squares Iteration:  40%|████      | 401/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6816e-03]Least Squares Iteration:  40%|████      | 401/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6794e-03]Least Squares Iteration:  40%|████      | 402/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6771e-03]Least Squares Iteration:  40%|████      | 403/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6750e-03]Least Squares Iteration:  40%|████      | 404/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6728e-03]Least Squares Iteration:  40%|████      | 405/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6706e-03]Least Squares Iteration:  41%|████      | 406/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6684e-03]Least Squares Iteration:  41%|████      | 407/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6663e-03]Least Squares Iteration:  41%|████      | 408/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6641e-03]Least Squares Iteration:  41%|████      | 409/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6620e-03]Least Squares Iteration:  41%|████      | 410/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6599e-03]Least Squares Iteration:  41%|████      | 411/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6578e-03]Least Squares Iteration:  41%|████      | 412/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6557e-03]Least Squares Iteration:  41%|████▏     | 413/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6536e-03]Least Squares Iteration:  41%|████▏     | 414/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6515e-03]Least Squares Iteration:  42%|████▏     | 415/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6494e-03]Least Squares Iteration:  42%|████▏     | 416/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6474e-03]Least Squares Iteration:  42%|████▏     | 417/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6453e-03]Least Squares Iteration:  42%|████▏     | 418/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6433e-03]Least Squares Iteration:  42%|████▏     | 419/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6413e-03]Least Squares Iteration:  42%|████▏     | 420/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6392e-03]Least Squares Iteration:  42%|████▏     | 421/1000 [00:01&lt;00:02, 209.68iter/s, Error=1.6372e-03]Least Squares Iteration:  42%|████▏     | 422/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6372e-03]Least Squares Iteration:  42%|████▏     | 422/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6352e-03]Least Squares Iteration:  42%|████▏     | 423/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6332e-03]Least Squares Iteration:  42%|████▏     | 424/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6313e-03]Least Squares Iteration:  42%|████▎     | 425/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6293e-03]Least Squares Iteration:  43%|████▎     | 426/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6273e-03]Least Squares Iteration:  43%|████▎     | 427/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6254e-03]Least Squares Iteration:  43%|████▎     | 428/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6234e-03]Least Squares Iteration:  43%|████▎     | 429/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6215e-03]Least Squares Iteration:  43%|████▎     | 430/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6196e-03]Least Squares Iteration:  43%|████▎     | 431/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6177e-03]Least Squares Iteration:  43%|████▎     | 432/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6158e-03]Least Squares Iteration:  43%|████▎     | 433/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6139e-03]Least Squares Iteration:  43%|████▎     | 434/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6120e-03]Least Squares Iteration:  44%|████▎     | 435/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6101e-03]Least Squares Iteration:  44%|████▎     | 436/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6082e-03]Least Squares Iteration:  44%|████▎     | 437/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6064e-03]Least Squares Iteration:  44%|████▍     | 438/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6045e-03]Least Squares Iteration:  44%|████▍     | 439/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6026e-03]Least Squares Iteration:  44%|████▍     | 440/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.6008e-03]Least Squares Iteration:  44%|████▍     | 441/1000 [00:01&lt;00:02, 195.58iter/s, Error=1.5990e-03]Least Squares Iteration:  44%|████▍     | 442/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5990e-03]Least Squares Iteration:  44%|████▍     | 442/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5971e-03]Least Squares Iteration:  44%|████▍     | 443/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5953e-03]Least Squares Iteration:  44%|████▍     | 444/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5935e-03]Least Squares Iteration:  44%|████▍     | 445/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5917e-03]Least Squares Iteration:  45%|████▍     | 446/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5899e-03]Least Squares Iteration:  45%|████▍     | 447/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5882e-03]Least Squares Iteration:  45%|████▍     | 448/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5864e-03]Least Squares Iteration:  45%|████▍     | 449/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5846e-03]Least Squares Iteration:  45%|████▌     | 450/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5828e-03]Least Squares Iteration:  45%|████▌     | 451/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5811e-03]Least Squares Iteration:  45%|████▌     | 452/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5793e-03]Least Squares Iteration:  45%|████▌     | 453/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5776e-03]Least Squares Iteration:  45%|████▌     | 454/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5759e-03]Least Squares Iteration:  46%|████▌     | 455/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5741e-03]Least Squares Iteration:  46%|████▌     | 456/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5724e-03]Least Squares Iteration:  46%|████▌     | 457/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5707e-03]Least Squares Iteration:  46%|████▌     | 458/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5690e-03]Least Squares Iteration:  46%|████▌     | 459/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5673e-03]Least Squares Iteration:  46%|████▌     | 460/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5656e-03]Least Squares Iteration:  46%|████▌     | 461/1000 [00:01&lt;00:02, 190.77iter/s, Error=1.5639e-03]Least Squares Iteration:  46%|████▌     | 462/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5639e-03]Least Squares Iteration:  46%|████▌     | 462/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5623e-03]Least Squares Iteration:  46%|████▋     | 463/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5606e-03]Least Squares Iteration:  46%|████▋     | 464/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5589e-03]Least Squares Iteration:  46%|████▋     | 465/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5573e-03]Least Squares Iteration:  47%|████▋     | 466/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5556e-03]Least Squares Iteration:  47%|████▋     | 467/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5540e-03]Least Squares Iteration:  47%|████▋     | 468/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5523e-03]Least Squares Iteration:  47%|████▋     | 469/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5507e-03]Least Squares Iteration:  47%|████▋     | 470/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5491e-03]Least Squares Iteration:  47%|████▋     | 471/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5474e-03]Least Squares Iteration:  47%|████▋     | 472/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5458e-03]Least Squares Iteration:  47%|████▋     | 473/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5442e-03]Least Squares Iteration:  47%|████▋     | 474/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5426e-03]Least Squares Iteration:  48%|████▊     | 475/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5410e-03]Least Squares Iteration:  48%|████▊     | 476/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5394e-03]Least Squares Iteration:  48%|████▊     | 477/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5378e-03]Least Squares Iteration:  48%|████▊     | 478/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5363e-03]Least Squares Iteration:  48%|████▊     | 479/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5347e-03]Least Squares Iteration:  48%|████▊     | 480/1000 [00:01&lt;00:02, 186.80iter/s, Error=1.5331e-03]Least Squares Iteration:  48%|████▊     | 481/1000 [00:01&lt;00:02, 173.50iter/s, Error=1.5331e-03]Least Squares Iteration:  48%|████▊     | 481/1000 [00:01&lt;00:02, 173.50iter/s, Error=1.5316e-03]Least Squares Iteration:  48%|████▊     | 482/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5300e-03]Least Squares Iteration:  48%|████▊     | 483/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5285e-03]Least Squares Iteration:  48%|████▊     | 484/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5269e-03]Least Squares Iteration:  48%|████▊     | 485/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5254e-03]Least Squares Iteration:  49%|████▊     | 486/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5238e-03]Least Squares Iteration:  49%|████▊     | 487/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5223e-03]Least Squares Iteration:  49%|████▉     | 488/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5208e-03]Least Squares Iteration:  49%|████▉     | 489/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5193e-03]Least Squares Iteration:  49%|████▉     | 490/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5178e-03]Least Squares Iteration:  49%|████▉     | 491/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5162e-03]Least Squares Iteration:  49%|████▉     | 492/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5148e-03]Least Squares Iteration:  49%|████▉     | 493/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5133e-03]Least Squares Iteration:  49%|████▉     | 494/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5118e-03]Least Squares Iteration:  50%|████▉     | 495/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5103e-03]Least Squares Iteration:  50%|████▉     | 496/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5088e-03]Least Squares Iteration:  50%|████▉     | 497/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5073e-03]Least Squares Iteration:  50%|████▉     | 498/1000 [00:02&lt;00:02, 173.50iter/s, Error=1.5058e-03]Least Squares Iteration:  50%|████▉     | 499/1000 [00:02&lt;00:03, 140.89iter/s, Error=1.5058e-03]Least Squares Iteration:  50%|████▉     | 499/1000 [00:02&lt;00:03, 140.89iter/s, Error=1.5044e-03]Least Squares Iteration:  50%|█████     | 500/1000 [00:02&lt;00:03, 140.89iter/s, Error=1.5029e-03]Least Squares Iteration:  50%|█████     | 501/1000 [00:02&lt;00:03, 140.89iter/s, Error=1.5015e-03]Least Squares Iteration:  50%|█████     | 502/1000 [00:02&lt;00:03, 140.89iter/s, Error=1.5000e-03]Least Squares Iteration:  50%|█████     | 503/1000 [00:02&lt;00:03, 140.89iter/s, Error=1.4986e-03]Least Squares Iteration:  50%|█████     | 504/1000 [00:02&lt;00:03, 140.89iter/s, Error=1.4971e-03]Least Squares Iteration:  50%|█████     | 505/1000 [00:02&lt;00:03, 140.89iter/s, Error=1.4957e-03]Least Squares Iteration:  51%|█████     | 506/1000 [00:02&lt;00:03, 140.89iter/s, Error=1.4943e-03]Least Squares Iteration:  51%|█████     | 507/1000 [00:02&lt;00:03, 140.89iter/s, Error=1.4928e-03]Least Squares Iteration:  51%|█████     | 508/1000 [00:02&lt;00:03, 140.89iter/s, Error=1.4914e-03]Least Squares Iteration:  51%|█████     | 509/1000 [00:02&lt;00:03, 140.89iter/s, Error=1.4900e-03]Least Squares Iteration:  51%|█████     | 510/1000 [00:02&lt;00:03, 140.89iter/s, Error=1.4886e-03]Least Squares Iteration:  51%|█████     | 511/1000 [00:02&lt;00:03, 140.89iter/s, Error=1.4872e-03]Least Squares Iteration:  51%|█████     | 512/1000 [00:02&lt;00:03, 140.89iter/s, Error=1.4857e-03]Least Squares Iteration:  51%|█████▏    | 513/1000 [00:02&lt;00:03, 140.89iter/s, Error=1.4843e-03]Least Squares Iteration:  51%|█████▏    | 514/1000 [00:02&lt;00:03, 139.40iter/s, Error=1.4843e-03]Least Squares Iteration:  51%|█████▏    | 514/1000 [00:02&lt;00:03, 139.40iter/s, Error=1.4829e-03]Least Squares Iteration:  52%|█████▏    | 515/1000 [00:02&lt;00:03, 139.40iter/s, Error=1.4815e-03]Least Squares Iteration:  52%|█████▏    | 516/1000 [00:02&lt;00:03, 139.40iter/s, Error=1.4802e-03]Least Squares Iteration:  52%|█████▏    | 517/1000 [00:02&lt;00:03, 139.40iter/s, Error=1.4788e-03]Least Squares Iteration:  52%|█████▏    | 518/1000 [00:02&lt;00:03, 139.40iter/s, Error=1.4774e-03]Least Squares Iteration:  52%|█████▏    | 519/1000 [00:02&lt;00:03, 139.40iter/s, Error=1.4760e-03]Least Squares Iteration:  52%|█████▏    | 520/1000 [00:02&lt;00:03, 139.40iter/s, Error=1.4747e-03]Least Squares Iteration:  52%|█████▏    | 521/1000 [00:02&lt;00:03, 139.40iter/s, Error=1.4733e-03]Least Squares Iteration:  52%|█████▏    | 522/1000 [00:02&lt;00:03, 139.40iter/s, Error=1.4719e-03]Least Squares Iteration:  52%|█████▏    | 523/1000 [00:02&lt;00:03, 139.40iter/s, Error=1.4706e-03]Least Squares Iteration:  52%|█████▏    | 524/1000 [00:02&lt;00:03, 139.40iter/s, Error=1.4692e-03]Least Squares Iteration:  52%|█████▎    | 525/1000 [00:02&lt;00:03, 139.40iter/s, Error=1.4679e-03]Least Squares Iteration:  53%|█████▎    | 526/1000 [00:02&lt;00:03, 139.40iter/s, Error=1.4665e-03]Least Squares Iteration:  53%|█████▎    | 527/1000 [00:02&lt;00:03, 139.40iter/s, Error=1.4652e-03]Least Squares Iteration:  53%|█████▎    | 528/1000 [00:02&lt;00:03, 139.40iter/s, Error=1.4638e-03]Least Squares Iteration:  53%|█████▎    | 529/1000 [00:02&lt;00:03, 135.16iter/s, Error=1.4638e-03]Least Squares Iteration:  53%|█████▎    | 529/1000 [00:02&lt;00:03, 135.16iter/s, Error=1.4625e-03]Least Squares Iteration:  53%|█████▎    | 530/1000 [00:02&lt;00:03, 135.16iter/s, Error=1.4612e-03]Least Squares Iteration:  53%|█████▎    | 531/1000 [00:02&lt;00:03, 135.16iter/s, Error=1.4598e-03]Least Squares Iteration:  53%|█████▎    | 532/1000 [00:02&lt;00:03, 135.16iter/s, Error=1.4585e-03]Least Squares Iteration:  53%|█████▎    | 533/1000 [00:02&lt;00:03, 135.16iter/s, Error=1.4572e-03]Least Squares Iteration:  53%|█████▎    | 534/1000 [00:02&lt;00:03, 135.16iter/s, Error=1.4559e-03]Least Squares Iteration:  54%|█████▎    | 535/1000 [00:02&lt;00:03, 135.16iter/s, Error=1.4546e-03]Least Squares Iteration:  54%|█████▎    | 536/1000 [00:02&lt;00:03, 135.16iter/s, Error=1.4533e-03]Least Squares Iteration:  54%|█████▎    | 537/1000 [00:02&lt;00:03, 135.16iter/s, Error=1.4519e-03]Least Squares Iteration:  54%|█████▍    | 538/1000 [00:02&lt;00:03, 135.16iter/s, Error=1.4506e-03]Least Squares Iteration:  54%|█████▍    | 539/1000 [00:02&lt;00:03, 135.16iter/s, Error=1.4493e-03]Least Squares Iteration:  54%|█████▍    | 540/1000 [00:02&lt;00:03, 135.16iter/s, Error=1.4480e-03]Least Squares Iteration:  54%|█████▍    | 541/1000 [00:02&lt;00:03, 135.16iter/s, Error=1.4468e-03]Least Squares Iteration:  54%|█████▍    | 542/1000 [00:02&lt;00:03, 135.16iter/s, Error=1.4455e-03]Least Squares Iteration:  54%|█████▍    | 543/1000 [00:02&lt;00:03, 135.18iter/s, Error=1.4455e-03]Least Squares Iteration:  54%|█████▍    | 543/1000 [00:02&lt;00:03, 135.18iter/s, Error=1.4442e-03]Least Squares Iteration:  54%|█████▍    | 544/1000 [00:02&lt;00:03, 135.18iter/s, Error=1.4429e-03]Least Squares Iteration:  55%|█████▍    | 545/1000 [00:02&lt;00:03, 135.18iter/s, Error=1.4416e-03]Least Squares Iteration:  55%|█████▍    | 546/1000 [00:02&lt;00:03, 135.18iter/s, Error=1.4404e-03]Least Squares Iteration:  55%|█████▍    | 547/1000 [00:02&lt;00:03, 135.18iter/s, Error=1.4391e-03]Least Squares Iteration:  55%|█████▍    | 548/1000 [00:02&lt;00:03, 135.18iter/s, Error=1.4378e-03]Least Squares Iteration:  55%|█████▍    | 549/1000 [00:02&lt;00:03, 135.18iter/s, Error=1.4366e-03]Least Squares Iteration:  55%|█████▌    | 550/1000 [00:02&lt;00:03, 135.18iter/s, Error=1.4353e-03]Least Squares Iteration:  55%|█████▌    | 551/1000 [00:02&lt;00:03, 135.18iter/s, Error=1.4340e-03]Least Squares Iteration:  55%|█████▌    | 552/1000 [00:02&lt;00:03, 135.18iter/s, Error=1.4328e-03]Least Squares Iteration:  55%|█████▌    | 553/1000 [00:02&lt;00:03, 135.18iter/s, Error=1.4315e-03]Least Squares Iteration:  55%|█████▌    | 554/1000 [00:02&lt;00:03, 135.18iter/s, Error=1.4303e-03]Least Squares Iteration:  56%|█████▌    | 555/1000 [00:02&lt;00:03, 135.18iter/s, Error=1.4291e-03]Least Squares Iteration:  56%|█████▌    | 556/1000 [00:02&lt;00:03, 135.18iter/s, Error=1.4278e-03]Least Squares Iteration:  56%|█████▌    | 557/1000 [00:02&lt;00:03, 133.50iter/s, Error=1.4278e-03]Least Squares Iteration:  56%|█████▌    | 557/1000 [00:02&lt;00:03, 133.50iter/s, Error=1.4266e-03]Least Squares Iteration:  56%|█████▌    | 558/1000 [00:02&lt;00:03, 133.50iter/s, Error=1.4254e-03]Least Squares Iteration:  56%|█████▌    | 559/1000 [00:02&lt;00:03, 133.50iter/s, Error=1.4241e-03]Least Squares Iteration:  56%|█████▌    | 560/1000 [00:02&lt;00:03, 133.50iter/s, Error=1.4229e-03]Least Squares Iteration:  56%|█████▌    | 561/1000 [00:02&lt;00:03, 133.50iter/s, Error=1.4217e-03]Least Squares Iteration:  56%|█████▌    | 562/1000 [00:02&lt;00:03, 133.50iter/s, Error=1.4205e-03]Least Squares Iteration:  56%|█████▋    | 563/1000 [00:02&lt;00:03, 133.50iter/s, Error=1.4192e-03]Least Squares Iteration:  56%|█████▋    | 564/1000 [00:02&lt;00:03, 133.50iter/s, Error=1.4180e-03]Least Squares Iteration:  56%|█████▋    | 565/1000 [00:02&lt;00:03, 133.50iter/s, Error=1.4168e-03]Least Squares Iteration:  57%|█████▋    | 566/1000 [00:02&lt;00:03, 133.50iter/s, Error=1.4156e-03]Least Squares Iteration:  57%|█████▋    | 567/1000 [00:02&lt;00:03, 133.50iter/s, Error=1.4144e-03]Least Squares Iteration:  57%|█████▋    | 568/1000 [00:02&lt;00:03, 133.50iter/s, Error=1.4132e-03]Least Squares Iteration:  57%|█████▋    | 569/1000 [00:02&lt;00:03, 133.50iter/s, Error=1.4120e-03]Least Squares Iteration:  57%|█████▋    | 570/1000 [00:02&lt;00:03, 133.50iter/s, Error=1.4108e-03]Least Squares Iteration:  57%|█████▋    | 571/1000 [00:02&lt;00:03, 123.71iter/s, Error=1.4108e-03]Least Squares Iteration:  57%|█████▋    | 571/1000 [00:02&lt;00:03, 123.71iter/s, Error=1.4096e-03]Least Squares Iteration:  57%|█████▋    | 572/1000 [00:02&lt;00:03, 123.71iter/s, Error=1.4084e-03]Least Squares Iteration:  57%|█████▋    | 573/1000 [00:02&lt;00:03, 123.71iter/s, Error=1.4072e-03]Least Squares Iteration:  57%|█████▋    | 574/1000 [00:02&lt;00:03, 123.71iter/s, Error=1.4061e-03]Least Squares Iteration:  57%|█████▊    | 575/1000 [00:02&lt;00:03, 123.71iter/s, Error=1.4049e-03]Least Squares Iteration:  58%|█████▊    | 576/1000 [00:02&lt;00:03, 123.71iter/s, Error=1.4037e-03]Least Squares Iteration:  58%|█████▊    | 577/1000 [00:02&lt;00:03, 123.71iter/s, Error=1.4025e-03]Least Squares Iteration:  58%|█████▊    | 578/1000 [00:02&lt;00:03, 123.71iter/s, Error=1.4014e-03]Least Squares Iteration:  58%|█████▊    | 579/1000 [00:02&lt;00:03, 123.71iter/s, Error=1.4002e-03]Least Squares Iteration:  58%|█████▊    | 580/1000 [00:02&lt;00:03, 123.71iter/s, Error=1.3990e-03]Least Squares Iteration:  58%|█████▊    | 581/1000 [00:02&lt;00:03, 123.71iter/s, Error=1.3979e-03]Least Squares Iteration:  58%|█████▊    | 582/1000 [00:02&lt;00:03, 123.71iter/s, Error=1.3967e-03]Least Squares Iteration:  58%|█████▊    | 583/1000 [00:02&lt;00:03, 123.71iter/s, Error=1.3955e-03]Least Squares Iteration:  58%|█████▊    | 584/1000 [00:02&lt;00:03, 119.24iter/s, Error=1.3955e-03]Least Squares Iteration:  58%|█████▊    | 584/1000 [00:02&lt;00:03, 119.24iter/s, Error=1.3944e-03]Least Squares Iteration:  58%|█████▊    | 585/1000 [00:02&lt;00:03, 119.24iter/s, Error=1.3932e-03]Least Squares Iteration:  59%|█████▊    | 586/1000 [00:02&lt;00:03, 119.24iter/s, Error=1.3921e-03]Least Squares Iteration:  59%|█████▊    | 587/1000 [00:02&lt;00:03, 119.24iter/s, Error=1.3909e-03]Least Squares Iteration:  59%|█████▉    | 588/1000 [00:02&lt;00:03, 119.24iter/s, Error=1.3898e-03]Least Squares Iteration:  59%|█████▉    | 589/1000 [00:02&lt;00:03, 119.24iter/s, Error=1.3887e-03]Least Squares Iteration:  59%|█████▉    | 590/1000 [00:02&lt;00:03, 119.24iter/s, Error=1.3875e-03]Least Squares Iteration:  59%|█████▉    | 591/1000 [00:02&lt;00:03, 119.24iter/s, Error=1.3864e-03]Least Squares Iteration:  59%|█████▉    | 592/1000 [00:02&lt;00:03, 119.24iter/s, Error=1.3852e-03]Least Squares Iteration:  59%|█████▉    | 593/1000 [00:02&lt;00:03, 119.24iter/s, Error=1.3841e-03]Least Squares Iteration:  59%|█████▉    | 594/1000 [00:02&lt;00:03, 119.24iter/s, Error=1.3830e-03]Least Squares Iteration:  60%|█████▉    | 595/1000 [00:02&lt;00:03, 119.24iter/s, Error=1.3819e-03]Least Squares Iteration:  60%|█████▉    | 596/1000 [00:02&lt;00:03, 119.24iter/s, Error=1.3807e-03]Least Squares Iteration:  60%|█████▉    | 597/1000 [00:02&lt;00:03, 117.81iter/s, Error=1.3807e-03]Least Squares Iteration:  60%|█████▉    | 597/1000 [00:02&lt;00:03, 117.81iter/s, Error=1.3796e-03]Least Squares Iteration:  60%|█████▉    | 598/1000 [00:02&lt;00:03, 117.81iter/s, Error=1.3785e-03]Least Squares Iteration:  60%|█████▉    | 599/1000 [00:03&lt;00:03, 117.81iter/s, Error=1.3774e-03]Least Squares Iteration:  60%|██████    | 600/1000 [00:03&lt;00:03, 117.81iter/s, Error=1.3763e-03]Least Squares Iteration:  60%|██████    | 601/1000 [00:03&lt;00:03, 117.81iter/s, Error=1.3752e-03]Least Squares Iteration:  60%|██████    | 602/1000 [00:03&lt;00:03, 117.81iter/s, Error=1.3741e-03]Least Squares Iteration:  60%|██████    | 603/1000 [00:03&lt;00:03, 117.81iter/s, Error=1.3729e-03]Least Squares Iteration:  60%|██████    | 604/1000 [00:03&lt;00:03, 117.81iter/s, Error=1.3718e-03]Least Squares Iteration:  60%|██████    | 605/1000 [00:03&lt;00:03, 117.81iter/s, Error=1.3707e-03]Least Squares Iteration:  61%|██████    | 606/1000 [00:03&lt;00:03, 117.81iter/s, Error=1.3696e-03]Least Squares Iteration:  61%|██████    | 607/1000 [00:03&lt;00:03, 117.81iter/s, Error=1.3686e-03]Least Squares Iteration:  61%|██████    | 608/1000 [00:03&lt;00:03, 117.81iter/s, Error=1.3675e-03]Least Squares Iteration:  61%|██████    | 609/1000 [00:03&lt;00:03, 114.98iter/s, Error=1.3675e-03]Least Squares Iteration:  61%|██████    | 609/1000 [00:03&lt;00:03, 114.98iter/s, Error=1.3664e-03]Least Squares Iteration:  61%|██████    | 610/1000 [00:03&lt;00:03, 114.98iter/s, Error=1.3653e-03]Least Squares Iteration:  61%|██████    | 611/1000 [00:03&lt;00:03, 114.98iter/s, Error=1.3642e-03]Least Squares Iteration:  61%|██████    | 612/1000 [00:03&lt;00:03, 114.98iter/s, Error=1.3631e-03]Least Squares Iteration:  61%|██████▏   | 613/1000 [00:03&lt;00:03, 114.98iter/s, Error=1.3620e-03]Least Squares Iteration:  61%|██████▏   | 614/1000 [00:03&lt;00:03, 114.98iter/s, Error=1.3610e-03]Least Squares Iteration:  62%|██████▏   | 615/1000 [00:03&lt;00:03, 114.98iter/s, Error=1.3599e-03]Least Squares Iteration:  62%|██████▏   | 616/1000 [00:03&lt;00:03, 114.98iter/s, Error=1.3588e-03]Least Squares Iteration:  62%|██████▏   | 617/1000 [00:03&lt;00:03, 114.98iter/s, Error=1.3577e-03]Least Squares Iteration:  62%|██████▏   | 618/1000 [00:03&lt;00:03, 114.98iter/s, Error=1.3567e-03]Least Squares Iteration:  62%|██████▏   | 619/1000 [00:03&lt;00:03, 114.98iter/s, Error=1.3556e-03]Least Squares Iteration:  62%|██████▏   | 620/1000 [00:03&lt;00:03, 114.98iter/s, Error=1.3545e-03]Least Squares Iteration:  62%|██████▏   | 621/1000 [00:03&lt;00:03, 114.98iter/s, Error=1.3535e-03]Least Squares Iteration:  62%|██████▏   | 622/1000 [00:03&lt;00:03, 116.77iter/s, Error=1.3535e-03]Least Squares Iteration:  62%|██████▏   | 622/1000 [00:03&lt;00:03, 116.77iter/s, Error=1.3524e-03]Least Squares Iteration:  62%|██████▏   | 623/1000 [00:03&lt;00:03, 116.77iter/s, Error=1.3514e-03]Least Squares Iteration:  62%|██████▏   | 624/1000 [00:03&lt;00:03, 116.77iter/s, Error=1.3503e-03]Least Squares Iteration:  62%|██████▎   | 625/1000 [00:03&lt;00:03, 116.77iter/s, Error=1.3492e-03]Least Squares Iteration:  63%|██████▎   | 626/1000 [00:03&lt;00:03, 116.77iter/s, Error=1.3482e-03]Least Squares Iteration:  63%|██████▎   | 627/1000 [00:03&lt;00:03, 116.77iter/s, Error=1.3471e-03]Least Squares Iteration:  63%|██████▎   | 628/1000 [00:03&lt;00:03, 116.77iter/s, Error=1.3461e-03]Least Squares Iteration:  63%|██████▎   | 629/1000 [00:03&lt;00:03, 116.77iter/s, Error=1.3450e-03]Least Squares Iteration:  63%|██████▎   | 630/1000 [00:03&lt;00:03, 116.77iter/s, Error=1.3440e-03]Least Squares Iteration:  63%|██████▎   | 631/1000 [00:03&lt;00:03, 116.77iter/s, Error=1.3430e-03]Least Squares Iteration:  63%|██████▎   | 632/1000 [00:03&lt;00:03, 116.77iter/s, Error=1.3419e-03]Least Squares Iteration:  63%|██████▎   | 633/1000 [00:03&lt;00:03, 116.77iter/s, Error=1.3409e-03]Least Squares Iteration:  63%|██████▎   | 634/1000 [00:03&lt;00:03, 116.77iter/s, Error=1.3399e-03]Least Squares Iteration:  64%|██████▎   | 635/1000 [00:03&lt;00:03, 118.85iter/s, Error=1.3399e-03]Least Squares Iteration:  64%|██████▎   | 635/1000 [00:03&lt;00:03, 118.85iter/s, Error=1.3388e-03]Least Squares Iteration:  64%|██████▎   | 636/1000 [00:03&lt;00:03, 118.85iter/s, Error=1.3378e-03]Least Squares Iteration:  64%|██████▎   | 637/1000 [00:03&lt;00:03, 118.85iter/s, Error=1.3368e-03]Least Squares Iteration:  64%|██████▍   | 638/1000 [00:03&lt;00:03, 118.85iter/s, Error=1.3357e-03]Least Squares Iteration:  64%|██████▍   | 639/1000 [00:03&lt;00:03, 118.85iter/s, Error=1.3347e-03]Least Squares Iteration:  64%|██████▍   | 640/1000 [00:03&lt;00:03, 118.85iter/s, Error=1.3337e-03]Least Squares Iteration:  64%|██████▍   | 641/1000 [00:03&lt;00:03, 118.85iter/s, Error=1.3327e-03]Least Squares Iteration:  64%|██████▍   | 642/1000 [00:03&lt;00:03, 118.85iter/s, Error=1.3317e-03]Least Squares Iteration:  64%|██████▍   | 643/1000 [00:03&lt;00:03, 118.85iter/s, Error=1.3306e-03]Least Squares Iteration:  64%|██████▍   | 644/1000 [00:03&lt;00:02, 118.85iter/s, Error=1.3296e-03]Least Squares Iteration:  64%|██████▍   | 645/1000 [00:03&lt;00:02, 118.85iter/s, Error=1.3286e-03]Least Squares Iteration:  65%|██████▍   | 646/1000 [00:03&lt;00:02, 118.85iter/s, Error=1.3276e-03]Least Squares Iteration:  65%|██████▍   | 647/1000 [00:03&lt;00:03, 107.70iter/s, Error=1.3276e-03]Least Squares Iteration:  65%|██████▍   | 647/1000 [00:03&lt;00:03, 107.70iter/s, Error=1.3266e-03]Least Squares Iteration:  65%|██████▍   | 648/1000 [00:03&lt;00:03, 107.70iter/s, Error=1.3256e-03]Least Squares Iteration:  65%|██████▍   | 649/1000 [00:03&lt;00:03, 107.70iter/s, Error=1.3246e-03]Least Squares Iteration:  65%|██████▌   | 650/1000 [00:03&lt;00:03, 107.70iter/s, Error=1.3236e-03]Least Squares Iteration:  65%|██████▌   | 651/1000 [00:03&lt;00:03, 107.70iter/s, Error=1.3226e-03]Least Squares Iteration:  65%|██████▌   | 652/1000 [00:03&lt;00:03, 107.70iter/s, Error=1.3216e-03]Least Squares Iteration:  65%|██████▌   | 653/1000 [00:03&lt;00:03, 107.70iter/s, Error=1.3206e-03]Least Squares Iteration:  65%|██████▌   | 654/1000 [00:03&lt;00:03, 107.70iter/s, Error=1.3196e-03]Least Squares Iteration:  66%|██████▌   | 655/1000 [00:03&lt;00:03, 107.70iter/s, Error=1.3186e-03]Least Squares Iteration:  66%|██████▌   | 656/1000 [00:03&lt;00:03, 107.70iter/s, Error=1.3176e-03]Least Squares Iteration:  66%|██████▌   | 657/1000 [00:03&lt;00:03, 107.70iter/s, Error=1.3166e-03]Least Squares Iteration:  66%|██████▌   | 658/1000 [00:03&lt;00:03, 104.94iter/s, Error=1.3166e-03]Least Squares Iteration:  66%|██████▌   | 658/1000 [00:03&lt;00:03, 104.94iter/s, Error=1.3156e-03]Least Squares Iteration:  66%|██████▌   | 659/1000 [00:03&lt;00:03, 104.94iter/s, Error=1.3147e-03]Least Squares Iteration:  66%|██████▌   | 660/1000 [00:03&lt;00:03, 104.94iter/s, Error=1.3137e-03]Least Squares Iteration:  66%|██████▌   | 661/1000 [00:03&lt;00:03, 104.94iter/s, Error=1.3127e-03]Least Squares Iteration:  66%|██████▌   | 662/1000 [00:03&lt;00:03, 104.94iter/s, Error=1.3117e-03]Least Squares Iteration:  66%|██████▋   | 663/1000 [00:03&lt;00:03, 104.94iter/s, Error=1.3108e-03]Least Squares Iteration:  66%|██████▋   | 664/1000 [00:03&lt;00:03, 104.94iter/s, Error=1.3098e-03]Least Squares Iteration:  66%|██████▋   | 665/1000 [00:03&lt;00:03, 104.94iter/s, Error=1.3088e-03]Least Squares Iteration:  67%|██████▋   | 666/1000 [00:03&lt;00:03, 104.94iter/s, Error=1.3078e-03]Least Squares Iteration:  67%|██████▋   | 667/1000 [00:03&lt;00:03, 104.94iter/s, Error=1.3069e-03]Least Squares Iteration:  67%|██████▋   | 668/1000 [00:03&lt;00:03, 104.94iter/s, Error=1.3059e-03]Least Squares Iteration:  67%|██████▋   | 669/1000 [00:03&lt;00:03, 97.30iter/s, Error=1.3059e-03] Least Squares Iteration:  67%|██████▋   | 669/1000 [00:03&lt;00:03, 97.30iter/s, Error=1.3049e-03]Least Squares Iteration:  67%|██████▋   | 670/1000 [00:03&lt;00:03, 97.30iter/s, Error=1.3040e-03]Least Squares Iteration:  67%|██████▋   | 671/1000 [00:03&lt;00:03, 97.30iter/s, Error=1.3030e-03]Least Squares Iteration:  67%|██████▋   | 672/1000 [00:03&lt;00:03, 97.30iter/s, Error=1.3020e-03]Least Squares Iteration:  67%|██████▋   | 673/1000 [00:03&lt;00:03, 97.30iter/s, Error=1.3011e-03]Least Squares Iteration:  67%|██████▋   | 674/1000 [00:03&lt;00:03, 97.30iter/s, Error=1.3001e-03]Least Squares Iteration:  68%|██████▊   | 675/1000 [00:03&lt;00:03, 97.30iter/s, Error=1.2992e-03]Least Squares Iteration:  68%|██████▊   | 676/1000 [00:03&lt;00:03, 97.30iter/s, Error=1.2982e-03]Least Squares Iteration:  68%|██████▊   | 677/1000 [00:03&lt;00:03, 97.30iter/s, Error=1.2973e-03]Least Squares Iteration:  68%|██████▊   | 678/1000 [00:03&lt;00:03, 97.30iter/s, Error=1.2963e-03]Least Squares Iteration:  68%|██████▊   | 679/1000 [00:03&lt;00:03, 94.90iter/s, Error=1.2963e-03]Least Squares Iteration:  68%|██████▊   | 679/1000 [00:03&lt;00:03, 94.90iter/s, Error=1.2954e-03]Least Squares Iteration:  68%|██████▊   | 680/1000 [00:03&lt;00:03, 94.90iter/s, Error=1.2944e-03]Least Squares Iteration:  68%|██████▊   | 681/1000 [00:03&lt;00:03, 94.90iter/s, Error=1.2935e-03]Least Squares Iteration:  68%|██████▊   | 682/1000 [00:03&lt;00:03, 94.90iter/s, Error=1.2925e-03]Least Squares Iteration:  68%|██████▊   | 683/1000 [00:03&lt;00:03, 94.90iter/s, Error=1.2916e-03]Least Squares Iteration:  68%|██████▊   | 684/1000 [00:03&lt;00:03, 94.90iter/s, Error=1.2907e-03]Least Squares Iteration:  68%|██████▊   | 685/1000 [00:03&lt;00:03, 94.90iter/s, Error=1.2897e-03]Least Squares Iteration:  69%|██████▊   | 686/1000 [00:03&lt;00:03, 94.90iter/s, Error=1.2888e-03]Least Squares Iteration:  69%|██████▊   | 687/1000 [00:03&lt;00:03, 94.90iter/s, Error=1.2879e-03]Least Squares Iteration:  69%|██████▉   | 688/1000 [00:03&lt;00:03, 94.90iter/s, Error=1.2869e-03]Least Squares Iteration:  69%|██████▉   | 689/1000 [00:03&lt;00:03, 92.93iter/s, Error=1.2869e-03]Least Squares Iteration:  69%|██████▉   | 689/1000 [00:03&lt;00:03, 92.93iter/s, Error=1.2860e-03]Least Squares Iteration:  69%|██████▉   | 690/1000 [00:03&lt;00:03, 92.93iter/s, Error=1.2851e-03]Least Squares Iteration:  69%|██████▉   | 691/1000 [00:03&lt;00:03, 92.93iter/s, Error=1.2841e-03]Least Squares Iteration:  69%|██████▉   | 692/1000 [00:03&lt;00:03, 92.93iter/s, Error=1.2832e-03]Least Squares Iteration:  69%|██████▉   | 693/1000 [00:03&lt;00:03, 92.93iter/s, Error=1.2823e-03]Least Squares Iteration:  69%|██████▉   | 694/1000 [00:03&lt;00:03, 92.93iter/s, Error=1.2814e-03]Least Squares Iteration:  70%|██████▉   | 695/1000 [00:03&lt;00:03, 92.93iter/s, Error=1.2805e-03]Least Squares Iteration:  70%|██████▉   | 696/1000 [00:03&lt;00:03, 92.93iter/s, Error=1.2795e-03]Least Squares Iteration:  70%|██████▉   | 697/1000 [00:03&lt;00:03, 92.93iter/s, Error=1.2786e-03]Least Squares Iteration:  70%|██████▉   | 698/1000 [00:03&lt;00:03, 92.93iter/s, Error=1.2777e-03]Least Squares Iteration:  70%|██████▉   | 699/1000 [00:04&lt;00:03, 92.93iter/s, Error=1.2768e-03]Least Squares Iteration:  70%|███████   | 700/1000 [00:04&lt;00:03, 92.93iter/s, Error=1.2759e-03]Least Squares Iteration:  70%|███████   | 701/1000 [00:04&lt;00:03, 98.64iter/s, Error=1.2759e-03]Least Squares Iteration:  70%|███████   | 701/1000 [00:04&lt;00:03, 98.64iter/s, Error=1.2750e-03]Least Squares Iteration:  70%|███████   | 702/1000 [00:04&lt;00:03, 98.64iter/s, Error=1.2741e-03]Least Squares Iteration:  70%|███████   | 703/1000 [00:04&lt;00:03, 98.64iter/s, Error=1.2731e-03]Least Squares Iteration:  70%|███████   | 704/1000 [00:04&lt;00:03, 98.64iter/s, Error=1.2722e-03]Least Squares Iteration:  70%|███████   | 705/1000 [00:04&lt;00:02, 98.64iter/s, Error=1.2713e-03]Least Squares Iteration:  71%|███████   | 706/1000 [00:04&lt;00:02, 98.64iter/s, Error=1.2704e-03]Least Squares Iteration:  71%|███████   | 707/1000 [00:04&lt;00:02, 98.64iter/s, Error=1.2695e-03]Least Squares Iteration:  71%|███████   | 708/1000 [00:04&lt;00:02, 98.64iter/s, Error=1.2686e-03]Least Squares Iteration:  71%|███████   | 709/1000 [00:04&lt;00:02, 98.64iter/s, Error=1.2677e-03]Least Squares Iteration:  71%|███████   | 710/1000 [00:04&lt;00:02, 98.64iter/s, Error=1.2668e-03]Least Squares Iteration:  71%|███████   | 711/1000 [00:04&lt;00:02, 98.64iter/s, Error=1.2659e-03]Least Squares Iteration:  71%|███████   | 712/1000 [00:04&lt;00:02, 98.64iter/s, Error=1.2651e-03]Least Squares Iteration:  71%|███████▏  | 713/1000 [00:04&lt;00:02, 104.15iter/s, Error=1.2651e-03]Least Squares Iteration:  71%|███████▏  | 713/1000 [00:04&lt;00:02, 104.15iter/s, Error=1.2642e-03]Least Squares Iteration:  71%|███████▏  | 714/1000 [00:04&lt;00:02, 104.15iter/s, Error=1.2633e-03]Least Squares Iteration:  72%|███████▏  | 715/1000 [00:04&lt;00:02, 104.15iter/s, Error=1.2624e-03]Least Squares Iteration:  72%|███████▏  | 716/1000 [00:04&lt;00:02, 104.15iter/s, Error=1.2615e-03]Least Squares Iteration:  72%|███████▏  | 717/1000 [00:04&lt;00:02, 104.15iter/s, Error=1.2606e-03]Least Squares Iteration:  72%|███████▏  | 718/1000 [00:04&lt;00:02, 104.15iter/s, Error=1.2597e-03]Least Squares Iteration:  72%|███████▏  | 719/1000 [00:04&lt;00:02, 104.15iter/s, Error=1.2588e-03]Least Squares Iteration:  72%|███████▏  | 720/1000 [00:04&lt;00:02, 104.15iter/s, Error=1.2580e-03]Least Squares Iteration:  72%|███████▏  | 721/1000 [00:04&lt;00:02, 104.15iter/s, Error=1.2571e-03]Least Squares Iteration:  72%|███████▏  | 722/1000 [00:04&lt;00:02, 104.15iter/s, Error=1.2562e-03]Least Squares Iteration:  72%|███████▏  | 723/1000 [00:04&lt;00:02, 104.15iter/s, Error=1.2553e-03]Least Squares Iteration:  72%|███████▏  | 724/1000 [00:04&lt;00:02, 104.15iter/s, Error=1.2545e-03]Least Squares Iteration:  72%|███████▎  | 725/1000 [00:04&lt;00:02, 106.63iter/s, Error=1.2545e-03]Least Squares Iteration:  72%|███████▎  | 725/1000 [00:04&lt;00:02, 106.63iter/s, Error=1.2536e-03]Least Squares Iteration:  73%|███████▎  | 726/1000 [00:04&lt;00:02, 106.63iter/s, Error=1.2527e-03]Least Squares Iteration:  73%|███████▎  | 727/1000 [00:04&lt;00:02, 106.63iter/s, Error=1.2518e-03]Least Squares Iteration:  73%|███████▎  | 728/1000 [00:04&lt;00:02, 106.63iter/s, Error=1.2510e-03]Least Squares Iteration:  73%|███████▎  | 729/1000 [00:04&lt;00:02, 106.63iter/s, Error=1.2501e-03]Least Squares Iteration:  73%|███████▎  | 730/1000 [00:04&lt;00:02, 106.63iter/s, Error=1.2492e-03]Least Squares Iteration:  73%|███████▎  | 731/1000 [00:04&lt;00:02, 106.63iter/s, Error=1.2484e-03]Least Squares Iteration:  73%|███████▎  | 732/1000 [00:04&lt;00:02, 106.63iter/s, Error=1.2475e-03]Least Squares Iteration:  73%|███████▎  | 733/1000 [00:04&lt;00:02, 106.63iter/s, Error=1.2466e-03]Least Squares Iteration:  73%|███████▎  | 734/1000 [00:04&lt;00:02, 106.63iter/s, Error=1.2458e-03]Least Squares Iteration:  74%|███████▎  | 735/1000 [00:04&lt;00:02, 106.63iter/s, Error=1.2449e-03]Least Squares Iteration:  74%|███████▎  | 736/1000 [00:04&lt;00:02, 106.63iter/s, Error=1.2441e-03]Least Squares Iteration:  74%|███████▎  | 737/1000 [00:04&lt;00:02, 109.84iter/s, Error=1.2441e-03]Least Squares Iteration:  74%|███████▎  | 737/1000 [00:04&lt;00:02, 109.84iter/s, Error=1.2432e-03]Least Squares Iteration:  74%|███████▍  | 738/1000 [00:04&lt;00:02, 109.84iter/s, Error=1.2424e-03]Least Squares Iteration:  74%|███████▍  | 739/1000 [00:04&lt;00:02, 109.84iter/s, Error=1.2415e-03]Least Squares Iteration:  74%|███████▍  | 740/1000 [00:04&lt;00:02, 109.84iter/s, Error=1.2407e-03]Least Squares Iteration:  74%|███████▍  | 741/1000 [00:04&lt;00:02, 109.84iter/s, Error=1.2398e-03]Least Squares Iteration:  74%|███████▍  | 742/1000 [00:04&lt;00:02, 109.84iter/s, Error=1.2390e-03]Least Squares Iteration:  74%|███████▍  | 743/1000 [00:04&lt;00:02, 109.84iter/s, Error=1.2381e-03]Least Squares Iteration:  74%|███████▍  | 744/1000 [00:04&lt;00:02, 109.84iter/s, Error=1.2373e-03]Least Squares Iteration:  74%|███████▍  | 745/1000 [00:04&lt;00:02, 109.84iter/s, Error=1.2364e-03]Least Squares Iteration:  75%|███████▍  | 746/1000 [00:04&lt;00:02, 109.84iter/s, Error=1.2356e-03]Least Squares Iteration:  75%|███████▍  | 747/1000 [00:04&lt;00:02, 109.84iter/s, Error=1.2347e-03]Least Squares Iteration:  75%|███████▍  | 748/1000 [00:04&lt;00:02, 109.84iter/s, Error=1.2339e-03]Least Squares Iteration:  75%|███████▍  | 749/1000 [00:04&lt;00:02, 103.18iter/s, Error=1.2339e-03]Least Squares Iteration:  75%|███████▍  | 749/1000 [00:04&lt;00:02, 103.18iter/s, Error=1.2330e-03]Least Squares Iteration:  75%|███████▌  | 750/1000 [00:04&lt;00:02, 103.18iter/s, Error=1.2322e-03]Least Squares Iteration:  75%|███████▌  | 751/1000 [00:04&lt;00:02, 103.18iter/s, Error=1.2314e-03]Least Squares Iteration:  75%|███████▌  | 752/1000 [00:04&lt;00:02, 103.18iter/s, Error=1.2305e-03]Least Squares Iteration:  75%|███████▌  | 753/1000 [00:04&lt;00:02, 103.18iter/s, Error=1.2297e-03]Least Squares Iteration:  75%|███████▌  | 754/1000 [00:04&lt;00:02, 103.18iter/s, Error=1.2289e-03]Least Squares Iteration:  76%|███████▌  | 755/1000 [00:04&lt;00:02, 103.18iter/s, Error=1.2280e-03]Least Squares Iteration:  76%|███████▌  | 756/1000 [00:04&lt;00:02, 103.18iter/s, Error=1.2272e-03]Least Squares Iteration:  76%|███████▌  | 757/1000 [00:04&lt;00:02, 103.18iter/s, Error=1.2264e-03]Least Squares Iteration:  76%|███████▌  | 758/1000 [00:04&lt;00:02, 103.18iter/s, Error=1.2255e-03]Least Squares Iteration:  76%|███████▌  | 759/1000 [00:04&lt;00:02, 103.18iter/s, Error=1.2247e-03]Least Squares Iteration:  76%|███████▌  | 760/1000 [00:04&lt;00:02, 104.05iter/s, Error=1.2247e-03]Least Squares Iteration:  76%|███████▌  | 760/1000 [00:04&lt;00:02, 104.05iter/s, Error=1.2239e-03]Least Squares Iteration:  76%|███████▌  | 761/1000 [00:04&lt;00:02, 104.05iter/s, Error=1.2231e-03]Least Squares Iteration:  76%|███████▌  | 762/1000 [00:04&lt;00:02, 104.05iter/s, Error=1.2223e-03]Least Squares Iteration:  76%|███████▋  | 763/1000 [00:04&lt;00:02, 104.05iter/s, Error=1.2214e-03]Least Squares Iteration:  76%|███████▋  | 764/1000 [00:04&lt;00:02, 104.05iter/s, Error=1.2206e-03]Least Squares Iteration:  76%|███████▋  | 765/1000 [00:04&lt;00:02, 104.05iter/s, Error=1.2198e-03]Least Squares Iteration:  77%|███████▋  | 766/1000 [00:04&lt;00:02, 104.05iter/s, Error=1.2190e-03]Least Squares Iteration:  77%|███████▋  | 767/1000 [00:04&lt;00:02, 104.05iter/s, Error=1.2182e-03]Least Squares Iteration:  77%|███████▋  | 768/1000 [00:04&lt;00:02, 104.05iter/s, Error=1.2174e-03]Least Squares Iteration:  77%|███████▋  | 769/1000 [00:04&lt;00:02, 104.05iter/s, Error=1.2165e-03]Least Squares Iteration:  77%|███████▋  | 770/1000 [00:04&lt;00:02, 104.05iter/s, Error=1.2157e-03]Least Squares Iteration:  77%|███████▋  | 771/1000 [00:04&lt;00:02, 104.05iter/s, Error=1.2149e-03]Least Squares Iteration:  77%|███████▋  | 772/1000 [00:04&lt;00:02, 108.00iter/s, Error=1.2149e-03]Least Squares Iteration:  77%|███████▋  | 772/1000 [00:04&lt;00:02, 108.00iter/s, Error=1.2141e-03]Least Squares Iteration:  77%|███████▋  | 773/1000 [00:04&lt;00:02, 108.00iter/s, Error=1.2133e-03]Least Squares Iteration:  77%|███████▋  | 774/1000 [00:04&lt;00:02, 108.00iter/s, Error=1.2125e-03]Least Squares Iteration:  78%|███████▊  | 775/1000 [00:04&lt;00:02, 108.00iter/s, Error=1.2117e-03]Least Squares Iteration:  78%|███████▊  | 776/1000 [00:04&lt;00:02, 108.00iter/s, Error=1.2109e-03]Least Squares Iteration:  78%|███████▊  | 777/1000 [00:04&lt;00:02, 108.00iter/s, Error=1.2101e-03]Least Squares Iteration:  78%|███████▊  | 778/1000 [00:04&lt;00:02, 108.00iter/s, Error=1.2093e-03]Least Squares Iteration:  78%|███████▊  | 779/1000 [00:04&lt;00:02, 108.00iter/s, Error=1.2085e-03]Least Squares Iteration:  78%|███████▊  | 780/1000 [00:04&lt;00:02, 108.00iter/s, Error=1.2077e-03]Least Squares Iteration:  78%|███████▊  | 781/1000 [00:04&lt;00:02, 108.00iter/s, Error=1.2069e-03]Least Squares Iteration:  78%|███████▊  | 782/1000 [00:04&lt;00:02, 108.00iter/s, Error=1.2061e-03]Least Squares Iteration:  78%|███████▊  | 783/1000 [00:04&lt;00:02, 107.39iter/s, Error=1.2061e-03]Least Squares Iteration:  78%|███████▊  | 783/1000 [00:04&lt;00:02, 107.39iter/s, Error=1.2053e-03]Least Squares Iteration:  78%|███████▊  | 784/1000 [00:04&lt;00:02, 107.39iter/s, Error=1.2045e-03]Least Squares Iteration:  78%|███████▊  | 785/1000 [00:04&lt;00:02, 107.39iter/s, Error=1.2037e-03]Least Squares Iteration:  79%|███████▊  | 786/1000 [00:04&lt;00:01, 107.39iter/s, Error=1.2029e-03]Least Squares Iteration:  79%|███████▊  | 787/1000 [00:04&lt;00:01, 107.39iter/s, Error=1.2021e-03]Least Squares Iteration:  79%|███████▉  | 788/1000 [00:04&lt;00:01, 107.39iter/s, Error=1.2013e-03]Least Squares Iteration:  79%|███████▉  | 789/1000 [00:04&lt;00:01, 107.39iter/s, Error=1.2005e-03]Least Squares Iteration:  79%|███████▉  | 790/1000 [00:04&lt;00:01, 107.39iter/s, Error=1.1998e-03]Least Squares Iteration:  79%|███████▉  | 791/1000 [00:04&lt;00:01, 107.39iter/s, Error=1.1990e-03]Least Squares Iteration:  79%|███████▉  | 792/1000 [00:04&lt;00:01, 107.39iter/s, Error=1.1982e-03]Least Squares Iteration:  79%|███████▉  | 793/1000 [00:04&lt;00:01, 107.39iter/s, Error=1.1974e-03]Least Squares Iteration:  79%|███████▉  | 794/1000 [00:04&lt;00:01, 105.79iter/s, Error=1.1974e-03]Least Squares Iteration:  79%|███████▉  | 794/1000 [00:04&lt;00:01, 105.79iter/s, Error=1.1966e-03]Least Squares Iteration:  80%|███████▉  | 795/1000 [00:04&lt;00:01, 105.79iter/s, Error=1.1958e-03]Least Squares Iteration:  80%|███████▉  | 796/1000 [00:04&lt;00:01, 105.79iter/s, Error=1.1951e-03]Least Squares Iteration:  80%|███████▉  | 797/1000 [00:04&lt;00:01, 105.79iter/s, Error=1.1943e-03]Least Squares Iteration:  80%|███████▉  | 798/1000 [00:04&lt;00:01, 105.79iter/s, Error=1.1935e-03]Least Squares Iteration:  80%|███████▉  | 799/1000 [00:04&lt;00:01, 105.79iter/s, Error=1.1927e-03]Least Squares Iteration:  80%|████████  | 800/1000 [00:04&lt;00:01, 105.79iter/s, Error=1.1919e-03]Least Squares Iteration:  80%|████████  | 801/1000 [00:04&lt;00:01, 105.79iter/s, Error=1.1912e-03]Least Squares Iteration:  80%|████████  | 802/1000 [00:04&lt;00:01, 105.79iter/s, Error=1.1904e-03]Least Squares Iteration:  80%|████████  | 803/1000 [00:04&lt;00:01, 105.79iter/s, Error=1.1896e-03]Least Squares Iteration:  80%|████████  | 804/1000 [00:04&lt;00:01, 105.79iter/s, Error=1.1889e-03]Least Squares Iteration:  80%|████████  | 805/1000 [00:04&lt;00:01, 102.62iter/s, Error=1.1889e-03]Least Squares Iteration:  80%|████████  | 805/1000 [00:05&lt;00:01, 102.62iter/s, Error=1.1881e-03]Least Squares Iteration:  81%|████████  | 806/1000 [00:05&lt;00:01, 102.62iter/s, Error=1.1873e-03]Least Squares Iteration:  81%|████████  | 807/1000 [00:05&lt;00:01, 102.62iter/s, Error=1.1866e-03]Least Squares Iteration:  81%|████████  | 808/1000 [00:05&lt;00:01, 102.62iter/s, Error=1.1858e-03]Least Squares Iteration:  81%|████████  | 809/1000 [00:05&lt;00:01, 102.62iter/s, Error=1.1850e-03]Least Squares Iteration:  81%|████████  | 810/1000 [00:05&lt;00:01, 102.62iter/s, Error=1.1843e-03]Least Squares Iteration:  81%|████████  | 811/1000 [00:05&lt;00:01, 102.62iter/s, Error=1.1835e-03]Least Squares Iteration:  81%|████████  | 812/1000 [00:05&lt;00:01, 102.62iter/s, Error=1.1827e-03]Least Squares Iteration:  81%|████████▏ | 813/1000 [00:05&lt;00:01, 102.62iter/s, Error=1.1820e-03]Least Squares Iteration:  81%|████████▏ | 814/1000 [00:05&lt;00:01, 102.62iter/s, Error=1.1812e-03]Least Squares Iteration:  82%|████████▏ | 815/1000 [00:05&lt;00:01, 102.62iter/s, Error=1.1804e-03]Least Squares Iteration:  82%|████████▏ | 816/1000 [00:05&lt;00:01, 93.28iter/s, Error=1.1804e-03] Least Squares Iteration:  82%|████████▏ | 816/1000 [00:05&lt;00:01, 93.28iter/s, Error=1.1797e-03]Least Squares Iteration:  82%|████████▏ | 817/1000 [00:05&lt;00:01, 93.28iter/s, Error=1.1789e-03]Least Squares Iteration:  82%|████████▏ | 818/1000 [00:05&lt;00:01, 93.28iter/s, Error=1.1782e-03]Least Squares Iteration:  82%|████████▏ | 819/1000 [00:05&lt;00:01, 93.28iter/s, Error=1.1774e-03]Least Squares Iteration:  82%|████████▏ | 820/1000 [00:05&lt;00:01, 93.28iter/s, Error=1.1767e-03]Least Squares Iteration:  82%|████████▏ | 821/1000 [00:05&lt;00:01, 93.28iter/s, Error=1.1759e-03]Least Squares Iteration:  82%|████████▏ | 822/1000 [00:05&lt;00:01, 93.28iter/s, Error=1.1752e-03]Least Squares Iteration:  82%|████████▏ | 823/1000 [00:05&lt;00:01, 93.28iter/s, Error=1.1744e-03]Least Squares Iteration:  82%|████████▏ | 824/1000 [00:05&lt;00:01, 93.28iter/s, Error=1.1737e-03]Least Squares Iteration:  82%|████████▎ | 825/1000 [00:05&lt;00:01, 93.28iter/s, Error=1.1729e-03]Least Squares Iteration:  83%|████████▎ | 826/1000 [00:05&lt;00:01, 91.52iter/s, Error=1.1729e-03]Least Squares Iteration:  83%|████████▎ | 826/1000 [00:05&lt;00:01, 91.52iter/s, Error=1.1722e-03]Least Squares Iteration:  83%|████████▎ | 827/1000 [00:05&lt;00:01, 91.52iter/s, Error=1.1715e-03]Least Squares Iteration:  83%|████████▎ | 828/1000 [00:05&lt;00:01, 91.52iter/s, Error=1.1707e-03]Least Squares Iteration:  83%|████████▎ | 829/1000 [00:05&lt;00:01, 91.52iter/s, Error=1.1700e-03]Least Squares Iteration:  83%|████████▎ | 830/1000 [00:05&lt;00:01, 91.52iter/s, Error=1.1692e-03]Least Squares Iteration:  83%|████████▎ | 831/1000 [00:05&lt;00:01, 91.52iter/s, Error=1.1685e-03]Least Squares Iteration:  83%|████████▎ | 832/1000 [00:05&lt;00:01, 91.52iter/s, Error=1.1677e-03]Least Squares Iteration:  83%|████████▎ | 833/1000 [00:05&lt;00:01, 91.52iter/s, Error=1.1670e-03]Least Squares Iteration:  83%|████████▎ | 834/1000 [00:05&lt;00:01, 91.52iter/s, Error=1.1663e-03]Least Squares Iteration:  84%|████████▎ | 835/1000 [00:05&lt;00:01, 91.52iter/s, Error=1.1655e-03]Least Squares Iteration:  84%|████████▎ | 836/1000 [00:05&lt;00:01, 92.73iter/s, Error=1.1655e-03]Least Squares Iteration:  84%|████████▎ | 836/1000 [00:05&lt;00:01, 92.73iter/s, Error=1.1648e-03]Least Squares Iteration:  84%|████████▎ | 837/1000 [00:05&lt;00:01, 92.73iter/s, Error=1.1641e-03]Least Squares Iteration:  84%|████████▍ | 838/1000 [00:05&lt;00:01, 92.73iter/s, Error=1.1633e-03]Least Squares Iteration:  84%|████████▍ | 839/1000 [00:05&lt;00:01, 92.73iter/s, Error=1.1626e-03]Least Squares Iteration:  84%|████████▍ | 840/1000 [00:05&lt;00:01, 92.73iter/s, Error=1.1619e-03]Least Squares Iteration:  84%|████████▍ | 841/1000 [00:05&lt;00:01, 92.73iter/s, Error=1.1611e-03]Least Squares Iteration:  84%|████████▍ | 842/1000 [00:05&lt;00:01, 92.73iter/s, Error=1.1604e-03]Least Squares Iteration:  84%|████████▍ | 843/1000 [00:05&lt;00:01, 92.73iter/s, Error=1.1597e-03]Least Squares Iteration:  84%|████████▍ | 844/1000 [00:05&lt;00:01, 92.73iter/s, Error=1.1590e-03]Least Squares Iteration:  84%|████████▍ | 845/1000 [00:05&lt;00:01, 92.73iter/s, Error=1.1582e-03]Least Squares Iteration:  85%|████████▍ | 846/1000 [00:05&lt;00:01, 92.25iter/s, Error=1.1582e-03]Least Squares Iteration:  85%|████████▍ | 846/1000 [00:05&lt;00:01, 92.25iter/s, Error=1.1575e-03]Least Squares Iteration:  85%|████████▍ | 847/1000 [00:05&lt;00:01, 92.25iter/s, Error=1.1568e-03]Least Squares Iteration:  85%|████████▍ | 848/1000 [00:05&lt;00:01, 92.25iter/s, Error=1.1561e-03]Least Squares Iteration:  85%|████████▍ | 849/1000 [00:05&lt;00:01, 92.25iter/s, Error=1.1553e-03]Least Squares Iteration:  85%|████████▌ | 850/1000 [00:05&lt;00:01, 92.25iter/s, Error=1.1546e-03]Least Squares Iteration:  85%|████████▌ | 851/1000 [00:05&lt;00:01, 92.25iter/s, Error=1.1539e-03]Least Squares Iteration:  85%|████████▌ | 852/1000 [00:05&lt;00:01, 92.25iter/s, Error=1.1532e-03]Least Squares Iteration:  85%|████████▌ | 853/1000 [00:05&lt;00:01, 92.25iter/s, Error=1.1525e-03]Least Squares Iteration:  85%|████████▌ | 854/1000 [00:05&lt;00:01, 92.25iter/s, Error=1.1517e-03]Least Squares Iteration:  86%|████████▌ | 855/1000 [00:05&lt;00:01, 92.25iter/s, Error=1.1510e-03]Least Squares Iteration:  86%|████████▌ | 856/1000 [00:05&lt;00:01, 91.42iter/s, Error=1.1510e-03]Least Squares Iteration:  86%|████████▌ | 856/1000 [00:05&lt;00:01, 91.42iter/s, Error=1.1503e-03]Least Squares Iteration:  86%|████████▌ | 857/1000 [00:05&lt;00:01, 91.42iter/s, Error=1.1496e-03]Least Squares Iteration:  86%|████████▌ | 858/1000 [00:05&lt;00:01, 91.42iter/s, Error=1.1489e-03]Least Squares Iteration:  86%|████████▌ | 859/1000 [00:05&lt;00:01, 91.42iter/s, Error=1.1482e-03]Least Squares Iteration:  86%|████████▌ | 860/1000 [00:05&lt;00:01, 91.42iter/s, Error=1.1475e-03]Least Squares Iteration:  86%|████████▌ | 861/1000 [00:05&lt;00:01, 91.42iter/s, Error=1.1468e-03]Least Squares Iteration:  86%|████████▌ | 862/1000 [00:05&lt;00:01, 91.42iter/s, Error=1.1461e-03]Least Squares Iteration:  86%|████████▋ | 863/1000 [00:05&lt;00:01, 91.42iter/s, Error=1.1453e-03]Least Squares Iteration:  86%|████████▋ | 864/1000 [00:05&lt;00:01, 91.42iter/s, Error=1.1446e-03]Least Squares Iteration:  86%|████████▋ | 865/1000 [00:05&lt;00:01, 91.42iter/s, Error=1.1439e-03]Least Squares Iteration:  87%|████████▋ | 866/1000 [00:05&lt;00:01, 88.89iter/s, Error=1.1439e-03]Least Squares Iteration:  87%|████████▋ | 866/1000 [00:05&lt;00:01, 88.89iter/s, Error=1.1432e-03]Least Squares Iteration:  87%|████████▋ | 867/1000 [00:05&lt;00:01, 88.89iter/s, Error=1.1425e-03]Least Squares Iteration:  87%|████████▋ | 868/1000 [00:05&lt;00:01, 88.89iter/s, Error=1.1418e-03]Least Squares Iteration:  87%|████████▋ | 869/1000 [00:05&lt;00:01, 88.89iter/s, Error=1.1411e-03]Least Squares Iteration:  87%|████████▋ | 870/1000 [00:05&lt;00:01, 88.89iter/s, Error=1.1404e-03]Least Squares Iteration:  87%|████████▋ | 871/1000 [00:05&lt;00:01, 88.89iter/s, Error=1.1397e-03]Least Squares Iteration:  87%|████████▋ | 872/1000 [00:05&lt;00:01, 88.89iter/s, Error=1.1390e-03]Least Squares Iteration:  87%|████████▋ | 873/1000 [00:05&lt;00:01, 88.89iter/s, Error=1.1383e-03]Least Squares Iteration:  87%|████████▋ | 874/1000 [00:05&lt;00:01, 88.89iter/s, Error=1.1376e-03]Least Squares Iteration:  88%|████████▊ | 875/1000 [00:05&lt;00:01, 88.66iter/s, Error=1.1376e-03]Least Squares Iteration:  88%|████████▊ | 875/1000 [00:05&lt;00:01, 88.66iter/s, Error=1.1369e-03]Least Squares Iteration:  88%|████████▊ | 876/1000 [00:05&lt;00:01, 88.66iter/s, Error=1.1362e-03]Least Squares Iteration:  88%|████████▊ | 877/1000 [00:05&lt;00:01, 88.66iter/s, Error=1.1355e-03]Least Squares Iteration:  88%|████████▊ | 878/1000 [00:05&lt;00:01, 88.66iter/s, Error=1.1349e-03]Least Squares Iteration:  88%|████████▊ | 879/1000 [00:05&lt;00:01, 88.66iter/s, Error=1.1342e-03]Least Squares Iteration:  88%|████████▊ | 880/1000 [00:05&lt;00:01, 88.66iter/s, Error=1.1335e-03]Least Squares Iteration:  88%|████████▊ | 881/1000 [00:05&lt;00:01, 88.66iter/s, Error=1.1328e-03]Least Squares Iteration:  88%|████████▊ | 882/1000 [00:05&lt;00:01, 88.66iter/s, Error=1.1321e-03]Least Squares Iteration:  88%|████████▊ | 883/1000 [00:05&lt;00:01, 88.66iter/s, Error=1.1314e-03]Least Squares Iteration:  88%|████████▊ | 884/1000 [00:05&lt;00:01, 88.52iter/s, Error=1.1314e-03]Least Squares Iteration:  88%|████████▊ | 884/1000 [00:05&lt;00:01, 88.52iter/s, Error=1.1307e-03]Least Squares Iteration:  88%|████████▊ | 885/1000 [00:05&lt;00:01, 88.52iter/s, Error=1.1300e-03]Least Squares Iteration:  89%|████████▊ | 886/1000 [00:05&lt;00:01, 88.52iter/s, Error=1.1293e-03]Least Squares Iteration:  89%|████████▊ | 887/1000 [00:05&lt;00:01, 88.52iter/s, Error=1.1287e-03]Least Squares Iteration:  89%|████████▉ | 888/1000 [00:05&lt;00:01, 88.52iter/s, Error=1.1280e-03]Least Squares Iteration:  89%|████████▉ | 889/1000 [00:05&lt;00:01, 88.52iter/s, Error=1.1273e-03]Least Squares Iteration:  89%|████████▉ | 890/1000 [00:05&lt;00:01, 88.52iter/s, Error=1.1266e-03]Least Squares Iteration:  89%|████████▉ | 891/1000 [00:05&lt;00:01, 88.52iter/s, Error=1.1259e-03]Least Squares Iteration:  89%|████████▉ | 892/1000 [00:06&lt;00:01, 88.52iter/s, Error=1.1253e-03]Least Squares Iteration:  89%|████████▉ | 893/1000 [00:06&lt;00:01, 87.63iter/s, Error=1.1253e-03]Least Squares Iteration:  89%|████████▉ | 893/1000 [00:06&lt;00:01, 87.63iter/s, Error=1.1246e-03]Least Squares Iteration:  89%|████████▉ | 894/1000 [00:06&lt;00:01, 87.63iter/s, Error=1.1239e-03]Least Squares Iteration:  90%|████████▉ | 895/1000 [00:06&lt;00:01, 87.63iter/s, Error=1.1232e-03]Least Squares Iteration:  90%|████████▉ | 896/1000 [00:06&lt;00:01, 87.63iter/s, Error=1.1225e-03]Least Squares Iteration:  90%|████████▉ | 897/1000 [00:06&lt;00:01, 87.63iter/s, Error=1.1219e-03]Least Squares Iteration:  90%|████████▉ | 898/1000 [00:06&lt;00:01, 87.63iter/s, Error=1.1212e-03]Least Squares Iteration:  90%|████████▉ | 899/1000 [00:06&lt;00:01, 87.63iter/s, Error=1.1205e-03]Least Squares Iteration:  90%|█████████ | 900/1000 [00:06&lt;00:01, 87.63iter/s, Error=1.1199e-03]Least Squares Iteration:  90%|█████████ | 901/1000 [00:06&lt;00:01, 87.63iter/s, Error=1.1192e-03]Least Squares Iteration:  90%|█████████ | 902/1000 [00:06&lt;00:01, 87.63iter/s, Error=1.1185e-03]Least Squares Iteration:  90%|█████████ | 903/1000 [00:06&lt;00:01, 90.42iter/s, Error=1.1185e-03]Least Squares Iteration:  90%|█████████ | 903/1000 [00:06&lt;00:01, 90.42iter/s, Error=1.1178e-03]Least Squares Iteration:  90%|█████████ | 904/1000 [00:06&lt;00:01, 90.42iter/s, Error=1.1172e-03]Least Squares Iteration:  90%|█████████ | 905/1000 [00:06&lt;00:01, 90.42iter/s, Error=1.1165e-03]Least Squares Iteration:  91%|█████████ | 906/1000 [00:06&lt;00:01, 90.42iter/s, Error=1.1158e-03]Least Squares Iteration:  91%|█████████ | 907/1000 [00:06&lt;00:01, 90.42iter/s, Error=1.1152e-03]Least Squares Iteration:  91%|█████████ | 908/1000 [00:06&lt;00:01, 90.42iter/s, Error=1.1145e-03]Least Squares Iteration:  91%|█████████ | 909/1000 [00:06&lt;00:01, 90.42iter/s, Error=1.1138e-03]Least Squares Iteration:  91%|█████████ | 910/1000 [00:06&lt;00:00, 90.42iter/s, Error=1.1132e-03]Least Squares Iteration:  91%|█████████ | 911/1000 [00:06&lt;00:00, 90.42iter/s, Error=1.1125e-03]Least Squares Iteration:  91%|█████████ | 912/1000 [00:06&lt;00:00, 90.42iter/s, Error=1.1119e-03]Least Squares Iteration:  91%|█████████▏| 913/1000 [00:06&lt;00:00, 92.22iter/s, Error=1.1119e-03]Least Squares Iteration:  91%|█████████▏| 913/1000 [00:06&lt;00:00, 92.22iter/s, Error=1.1112e-03]Least Squares Iteration:  91%|█████████▏| 914/1000 [00:06&lt;00:00, 92.22iter/s, Error=1.1105e-03]Least Squares Iteration:  92%|█████████▏| 915/1000 [00:06&lt;00:00, 92.22iter/s, Error=1.1099e-03]Least Squares Iteration:  92%|█████████▏| 916/1000 [00:06&lt;00:00, 92.22iter/s, Error=1.1092e-03]Least Squares Iteration:  92%|█████████▏| 917/1000 [00:06&lt;00:00, 92.22iter/s, Error=1.1086e-03]Least Squares Iteration:  92%|█████████▏| 918/1000 [00:06&lt;00:00, 92.22iter/s, Error=1.1079e-03]Least Squares Iteration:  92%|█████████▏| 919/1000 [00:06&lt;00:00, 92.22iter/s, Error=1.1073e-03]Least Squares Iteration:  92%|█████████▏| 920/1000 [00:06&lt;00:00, 92.22iter/s, Error=1.1066e-03]Least Squares Iteration:  92%|█████████▏| 921/1000 [00:06&lt;00:00, 92.22iter/s, Error=1.1059e-03]Least Squares Iteration:  92%|█████████▏| 922/1000 [00:06&lt;00:00, 92.22iter/s, Error=1.1053e-03]Least Squares Iteration:  92%|█████████▏| 923/1000 [00:06&lt;00:00, 89.89iter/s, Error=1.1053e-03]Least Squares Iteration:  92%|█████████▏| 923/1000 [00:06&lt;00:00, 89.89iter/s, Error=1.1046e-03]Least Squares Iteration:  92%|█████████▏| 924/1000 [00:06&lt;00:00, 89.89iter/s, Error=1.1040e-03]Least Squares Iteration:  92%|█████████▎| 925/1000 [00:06&lt;00:00, 89.89iter/s, Error=1.1033e-03]Least Squares Iteration:  93%|█████████▎| 926/1000 [00:06&lt;00:00, 89.89iter/s, Error=1.1027e-03]Least Squares Iteration:  93%|█████████▎| 927/1000 [00:06&lt;00:00, 89.89iter/s, Error=1.1020e-03]Least Squares Iteration:  93%|█████████▎| 928/1000 [00:06&lt;00:00, 89.89iter/s, Error=1.1014e-03]Least Squares Iteration:  93%|█████████▎| 929/1000 [00:06&lt;00:00, 89.89iter/s, Error=1.1007e-03]Least Squares Iteration:  93%|█████████▎| 930/1000 [00:06&lt;00:00, 89.89iter/s, Error=1.1001e-03]Least Squares Iteration:  93%|█████████▎| 931/1000 [00:06&lt;00:00, 89.89iter/s, Error=1.0995e-03]Least Squares Iteration:  93%|█████████▎| 932/1000 [00:06&lt;00:00, 89.89iter/s, Error=1.0988e-03]Least Squares Iteration:  93%|█████████▎| 933/1000 [00:06&lt;00:00, 86.99iter/s, Error=1.0988e-03]Least Squares Iteration:  93%|█████████▎| 933/1000 [00:06&lt;00:00, 86.99iter/s, Error=1.0982e-03]Least Squares Iteration:  93%|█████████▎| 934/1000 [00:06&lt;00:00, 86.99iter/s, Error=1.0975e-03]Least Squares Iteration:  94%|█████████▎| 935/1000 [00:06&lt;00:00, 86.99iter/s, Error=1.0969e-03]Least Squares Iteration:  94%|█████████▎| 936/1000 [00:06&lt;00:00, 86.99iter/s, Error=1.0962e-03]Least Squares Iteration:  94%|█████████▎| 937/1000 [00:06&lt;00:00, 86.99iter/s, Error=1.0956e-03]Least Squares Iteration:  94%|█████████▍| 938/1000 [00:06&lt;00:00, 86.99iter/s, Error=1.0950e-03]Least Squares Iteration:  94%|█████████▍| 939/1000 [00:06&lt;00:00, 86.99iter/s, Error=1.0943e-03]Least Squares Iteration:  94%|█████████▍| 940/1000 [00:06&lt;00:00, 86.99iter/s, Error=1.0937e-03]Least Squares Iteration:  94%|█████████▍| 941/1000 [00:06&lt;00:00, 86.99iter/s, Error=1.0931e-03]Least Squares Iteration:  94%|█████████▍| 942/1000 [00:06&lt;00:00, 83.14iter/s, Error=1.0931e-03]Least Squares Iteration:  94%|█████████▍| 942/1000 [00:06&lt;00:00, 83.14iter/s, Error=1.0924e-03]Least Squares Iteration:  94%|█████████▍| 943/1000 [00:06&lt;00:00, 83.14iter/s, Error=1.0918e-03]Least Squares Iteration:  94%|█████████▍| 944/1000 [00:06&lt;00:00, 83.14iter/s, Error=1.0912e-03]Least Squares Iteration:  94%|█████████▍| 945/1000 [00:06&lt;00:00, 83.14iter/s, Error=1.0905e-03]Least Squares Iteration:  95%|█████████▍| 946/1000 [00:06&lt;00:00, 83.14iter/s, Error=1.0899e-03]Least Squares Iteration:  95%|█████████▍| 947/1000 [00:06&lt;00:00, 83.14iter/s, Error=1.0893e-03]Least Squares Iteration:  95%|█████████▍| 948/1000 [00:06&lt;00:00, 83.14iter/s, Error=1.0886e-03]Least Squares Iteration:  95%|█████████▍| 949/1000 [00:06&lt;00:00, 83.14iter/s, Error=1.0880e-03]Least Squares Iteration:  95%|█████████▌| 950/1000 [00:06&lt;00:00, 83.14iter/s, Error=1.0874e-03]Least Squares Iteration:  95%|█████████▌| 951/1000 [00:06&lt;00:00, 78.01iter/s, Error=1.0874e-03]Least Squares Iteration:  95%|█████████▌| 951/1000 [00:06&lt;00:00, 78.01iter/s, Error=1.0867e-03]Least Squares Iteration:  95%|█████████▌| 952/1000 [00:06&lt;00:00, 78.01iter/s, Error=1.0861e-03]Least Squares Iteration:  95%|█████████▌| 953/1000 [00:06&lt;00:00, 78.01iter/s, Error=1.0855e-03]Least Squares Iteration:  95%|█████████▌| 954/1000 [00:06&lt;00:00, 78.01iter/s, Error=1.0849e-03]Least Squares Iteration:  96%|█████████▌| 955/1000 [00:06&lt;00:00, 78.01iter/s, Error=1.0842e-03]Least Squares Iteration:  96%|█████████▌| 956/1000 [00:06&lt;00:00, 78.01iter/s, Error=1.0836e-03]Least Squares Iteration:  96%|█████████▌| 957/1000 [00:06&lt;00:00, 78.01iter/s, Error=1.0830e-03]Least Squares Iteration:  96%|█████████▌| 958/1000 [00:06&lt;00:00, 78.01iter/s, Error=1.0824e-03]Least Squares Iteration:  96%|█████████▌| 959/1000 [00:06&lt;00:00, 78.01iter/s, Error=1.0817e-03]Least Squares Iteration:  96%|█████████▌| 960/1000 [00:06&lt;00:00, 79.14iter/s, Error=1.0817e-03]Least Squares Iteration:  96%|█████████▌| 960/1000 [00:06&lt;00:00, 79.14iter/s, Error=1.0811e-03]Least Squares Iteration:  96%|█████████▌| 961/1000 [00:06&lt;00:00, 79.14iter/s, Error=1.0805e-03]Least Squares Iteration:  96%|█████████▌| 962/1000 [00:06&lt;00:00, 79.14iter/s, Error=1.0799e-03]Least Squares Iteration:  96%|█████████▋| 963/1000 [00:06&lt;00:00, 79.14iter/s, Error=1.0793e-03]Least Squares Iteration:  96%|█████████▋| 964/1000 [00:06&lt;00:00, 79.14iter/s, Error=1.0787e-03]Least Squares Iteration:  96%|█████████▋| 965/1000 [00:06&lt;00:00, 79.14iter/s, Error=1.0780e-03]Least Squares Iteration:  97%|█████████▋| 966/1000 [00:06&lt;00:00, 79.14iter/s, Error=1.0774e-03]Least Squares Iteration:  97%|█████████▋| 967/1000 [00:06&lt;00:00, 79.14iter/s, Error=1.0768e-03]Least Squares Iteration:  97%|█████████▋| 968/1000 [00:06&lt;00:00, 79.18iter/s, Error=1.0768e-03]Least Squares Iteration:  97%|█████████▋| 968/1000 [00:06&lt;00:00, 79.18iter/s, Error=1.0762e-03]Least Squares Iteration:  97%|█████████▋| 969/1000 [00:06&lt;00:00, 79.18iter/s, Error=1.0756e-03]Least Squares Iteration:  97%|█████████▋| 970/1000 [00:06&lt;00:00, 79.18iter/s, Error=1.0750e-03]Least Squares Iteration:  97%|█████████▋| 971/1000 [00:06&lt;00:00, 79.18iter/s, Error=1.0744e-03]Least Squares Iteration:  97%|█████████▋| 972/1000 [00:06&lt;00:00, 79.18iter/s, Error=1.0737e-03]Least Squares Iteration:  97%|█████████▋| 973/1000 [00:07&lt;00:00, 79.18iter/s, Error=1.0731e-03]Least Squares Iteration:  97%|█████████▋| 974/1000 [00:07&lt;00:00, 79.18iter/s, Error=1.0725e-03]Least Squares Iteration:  98%|█████████▊| 975/1000 [00:07&lt;00:00, 79.18iter/s, Error=1.0719e-03]Least Squares Iteration:  98%|█████████▊| 976/1000 [00:07&lt;00:00, 76.36iter/s, Error=1.0719e-03]Least Squares Iteration:  98%|█████████▊| 976/1000 [00:07&lt;00:00, 76.36iter/s, Error=1.0713e-03]Least Squares Iteration:  98%|█████████▊| 977/1000 [00:07&lt;00:00, 76.36iter/s, Error=1.0707e-03]Least Squares Iteration:  98%|█████████▊| 978/1000 [00:07&lt;00:00, 76.36iter/s, Error=1.0701e-03]Least Squares Iteration:  98%|█████████▊| 979/1000 [00:07&lt;00:00, 76.36iter/s, Error=1.0695e-03]Least Squares Iteration:  98%|█████████▊| 980/1000 [00:07&lt;00:00, 76.36iter/s, Error=1.0689e-03]Least Squares Iteration:  98%|█████████▊| 981/1000 [00:07&lt;00:00, 76.36iter/s, Error=1.0683e-03]Least Squares Iteration:  98%|█████████▊| 982/1000 [00:07&lt;00:00, 76.36iter/s, Error=1.0677e-03]Least Squares Iteration:  98%|█████████▊| 983/1000 [00:07&lt;00:00, 76.36iter/s, Error=1.0671e-03]Least Squares Iteration:  98%|█████████▊| 984/1000 [00:07&lt;00:00, 70.77iter/s, Error=1.0671e-03]Least Squares Iteration:  98%|█████████▊| 984/1000 [00:07&lt;00:00, 70.77iter/s, Error=1.0665e-03]Least Squares Iteration:  98%|█████████▊| 985/1000 [00:07&lt;00:00, 70.77iter/s, Error=1.0659e-03]Least Squares Iteration:  99%|█████████▊| 986/1000 [00:07&lt;00:00, 70.77iter/s, Error=1.0653e-03]Least Squares Iteration:  99%|█████████▊| 987/1000 [00:07&lt;00:00, 70.77iter/s, Error=1.0647e-03]Least Squares Iteration:  99%|█████████▉| 988/1000 [00:07&lt;00:00, 70.77iter/s, Error=1.0641e-03]Least Squares Iteration:  99%|█████████▉| 989/1000 [00:07&lt;00:00, 70.77iter/s, Error=1.0635e-03]Least Squares Iteration:  99%|█████████▉| 990/1000 [00:07&lt;00:00, 70.77iter/s, Error=1.0629e-03]Least Squares Iteration:  99%|█████████▉| 991/1000 [00:07&lt;00:00, 70.77iter/s, Error=1.0623e-03]Least Squares Iteration:  99%|█████████▉| 992/1000 [00:07&lt;00:00, 70.37iter/s, Error=1.0623e-03]Least Squares Iteration:  99%|█████████▉| 992/1000 [00:07&lt;00:00, 70.37iter/s, Error=1.0617e-03]Least Squares Iteration:  99%|█████████▉| 993/1000 [00:07&lt;00:00, 70.37iter/s, Error=1.0611e-03]Least Squares Iteration:  99%|█████████▉| 994/1000 [00:07&lt;00:00, 70.37iter/s, Error=1.0605e-03]Least Squares Iteration: 100%|█████████▉| 995/1000 [00:07&lt;00:00, 70.37iter/s, Error=1.0599e-03]Least Squares Iteration: 100%|█████████▉| 996/1000 [00:07&lt;00:00, 70.37iter/s, Error=1.0593e-03]Least Squares Iteration: 100%|█████████▉| 997/1000 [00:07&lt;00:00, 70.37iter/s, Error=1.0587e-03]Least Squares Iteration: 100%|█████████▉| 998/1000 [00:07&lt;00:00, 70.37iter/s, Error=1.0581e-03]Least Squares Iteration: 100%|█████████▉| 999/1000 [00:07&lt;00:00, 70.37iter/s, Error=1.0575e-03]Least Squares Iteration: 100%|██████████| 1000/1000 [00:07&lt;00:00, 70.45iter/s, Error=1.0575e-03]Least Squares Iteration: 100%|██████████| 1000/1000 [00:07&lt;00:00, 135.15iter/s, Error=1.0575e-03]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture3/index_files/figure-html/cell-9-output-2.png" width="549" height="288" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Note that torch does have the framework to run autograd on the least squares objective itself, but for this general method we are using the adjoint to compute the gradient (and indirectly invoking autograd). This framework is the most general for when there might not be explicit analytic solutions to the least squares problem, but we have the forward operator and its adjoint.</p>


</section>

 ]]></description>
  <category>Optimization</category>
  <category>Inverse Theory</category>
  <category>Python</category>
  <category>Torch</category>
  <category>Adjoint</category>
  <guid>https://chipnbits.github.io/content/eosc555/lectures/lecture3/</guid>
  <pubDate>Tue, 17 Sep 2024 07:00:00 GMT</pubDate>
  <media:content url="https://chipnbits.github.io/content/eosc555/lectures/lecture3/imgs/gradient_flow.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Lecture 2: Image Denoising with SVD</title>
  <dc:creator>Simon Ghyselincks</dc:creator>
  <link>https://chipnbits.github.io/content/eosc555/lectures/lecture2/</link>
  <description><![CDATA[ 




<section id="image-denoising-and-deblurring" class="level1">
<h1>Image Denoising and Deblurring</h1>
<p>The motivation for the exercise comes from a real world problem. The Hubble space telescope when launched had a defect in its mirror. This defect caused the images to be blurred. The problem was initially addressed by using signal processing techniques to remove the aberrations from the images.</p>
<section id="point-spread-function" class="level3">
<h3 class="anchored" data-anchor-id="point-spread-function">Point Spread Function</h3>
<p>For such an image processing problem, we can consider the continuous incoming light as striking a 2D mirror that distorts the light, followed by a 2D sensor that captures the light. In this context we suppose that we have a noise kernel or a point spread function (PSF) that describes the distortion of the light at the mirror. The point spread function, being a convolution kernel, behaves as a Green’s function for the system in the continuous case:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cvec%7Bb%7D(x,y)%20=%20%5Cint_%7B%5Cmathcal%7BX%7D%7D%20%5Cint_%7B%5Cmathcal%7BY%7D%7D%20%5Cvec%7BG%7D(x%20-%20x',%20y%20-%20y')%20%5Cvec%7Bu%7D(x',y')%20%5C,%20dx'%20dy'%20"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bb%7D(x,y)"> is the blurred image data that is recovered at the sensor, <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bu%7D(x',y')"> is the true image data, and <img src="https://latex.codecogs.com/png.latex?%5Cvec%7BG%7D(x,y)"> is the point spread function.</p>
<p>In the special case that the point spread function is <img src="https://latex.codecogs.com/png.latex?%5Cdelta(x-x',y-y')">, then the image data is not distorted and the sensor captures the true image data. However our experiment is to consider cases where there could be even severe distortions and see how this impacts the proposition of recovering the true image data, <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bu%7D(x',y')"> from our sensor data, <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bb%7D(x,y)">.</p>
<section id="discrete-psf" class="level4">
<h4 class="anchored" data-anchor-id="discrete-psf">Discrete PSF</h4>
<p>The discrete analog of the continuous PSF can be more conveniently treated with we essentially flatten the the 2D mesh into a 1D vector, a common operation for signal processing. The unflattened case we have:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20b_%7Bij%7D%20=%20%5Csum_%7Bk=1%7D%5E%7Bn%7D%20%5Csum_%7Bl=1%7D%5E%7Bm%7D%20%5CDelta%20x%20%5CDelta%20y%20G(x_i%20-%20x_k,%20y_j%20-%20y_l)%20u_%7Bkl%7D%20"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?b"> is the blurred image data at the sensor, <img src="https://latex.codecogs.com/png.latex?u"> is the true image data, and <img src="https://latex.codecogs.com/png.latex?G"> is the discrete point spread function. If we flatten the 2D mesh into a 1D vector we can represent this as a 1D convolution operation: <img src="https://latex.codecogs.com/png.latex?%20%5Cvec%7Bb%7D%20=%20%5Cvec%7BG%7D%20*%20%5Cvec%7Bu%7D%20"></p>
<p>Since this is a convolution operation, we can process it much more quickly by leveraging the convolution theorem.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign%7D%0A%5Cmathcal%7BF%7D(%5Cvec%7Bb%7D)%20&amp;=%20%5Cmathcal%7BF%7D(%5Cvec%7BG%7D%20*%20%5Cvec%7Bu%7D)%20%5C%5C%0A%5Cmathcal%7BF%7D(%5Cvec%7Bb%7D)%20&amp;=%20%5Cmathcal%7BF%7D(%5Cvec%7BG%7D)%20%5Cmathcal%7BF%7D(%5Cvec%7Bu%7D)%20%5C%5C%0A%5Cvec%7Bb%7D%20&amp;=%20%5Cmathcal%7BF%7D%5E%7B-1%7D(%5Cmathcal%7BF%7D(%5Cvec%7BG%7D)%20%5Codot%20%5Cmathcal%7BF%7D(%5Cvec%7Bu%7D))%0A%5Cend%7Balign%7D%0A"></p>
<p>The <img src="https://latex.codecogs.com/png.latex?%5Codot"> hadamard product is element-wise multiplication, the discrete analog of multiplication of two functions except over an array.</p>
</section>
</section>
<section id="matrix-representation-of-convolution-operation" class="level3">
<h3 class="anchored" data-anchor-id="matrix-representation-of-convolution-operation">Matrix Representation of Convolution Operation</h3>
<p>If we flatten the data down into a 1D vector then it is possible to construct a matrix operator that performs the convolution. This is a Toeplitz matrix, a matrix where each descending diagonal from left to right is constant, so that the row vectors represent a sliding window of the convolution kernel. We can flatten out the PSF and construct the matrix using it as the first row entry and then shifting the PSF to the right to fill out the rest of the rows.</p>
</section>
</section>
<section id="code-implementation" class="level1">
<h1>Code Implementation</h1>
<div id="b680d063" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib</span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#matplotlib.use('TkAgg')</span></span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.optim</span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nn</span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn.functional <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> F</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.optim <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Adam</span>
<span id="cb1-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> copy</span>
<span id="cb1-11"></span>
<span id="cb1-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-13"></span>
<span id="cb1-14"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> math</span>
<span id="cb1-15"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb1-16"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> time</span>
<span id="cb1-17"></span>
<span id="cb1-18"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-19"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-20"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.fft</span></code></pre></div>
</details>
</div>
<p>We start off by introducing a point spread function within the torch framework. In the case we work with a parameterized gaussian kernel.</p>
<section id="gaussian-example" class="level3">
<h3 class="anchored" data-anchor-id="gaussian-example">Gaussian Example</h3>
<p>The multivariate extension of the gaussian function is given by: <img src="https://latex.codecogs.com/png.latex?f(x)%20=%20%5Cexp%5Cleft(-%5Cfrac%7B1%7D%7B2%7D%20(x-%5Cmu)%5ET%20%5CSigma%5E%7B-1%7D%20(x-%5Cmu)%5Cright)"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmu"> is the mean vector, <img src="https://latex.codecogs.com/png.latex?x"> is a position vector, and <img src="https://latex.codecogs.com/png.latex?%5CSigma"> is the covariance matrix. The covariance matrix essentially encodes the eigenvectors and corresponding postive eigenvalues of the matrix. The covariance matrix is always symmetric and positive definite. In the context of the code, we are using <img src="https://latex.codecogs.com/png.latex?C"> as the inverse of the covariance matrix and working with a <img src="https://latex.codecogs.com/png.latex?%5Cmu=0"> value.</p>
<div id="mv-plot" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy.ndimage <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> convolve</span>
<span id="cb2-2"></span>
<span id="cb2-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> multivariate_gaussian(pos, mean, cov):</span>
<span id="cb2-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Return the multivariate Gaussian distribution on array pos without using einsum notation."""</span></span>
<span id="cb2-5">    n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb2-6">    diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pos <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> mean</span>
<span id="cb2-7">    cov_inv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linalg.inv(cov)</span>
<span id="cb2-8">    </span>
<span id="cb2-9">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the exponent</span></span>
<span id="cb2-10">    diff_cov_inv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> cov_inv</span>
<span id="cb2-11">    exponent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> diff_cov_inv, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-12">    </span>
<span id="cb2-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the normalization factor</span></span>
<span id="cb2-14">    norm_factor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.sqrt((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.pi) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.linalg.det(cov))</span>
<span id="cb2-15">    </span>
<span id="cb2-16">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Return the Gaussian function</span></span>
<span id="cb2-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> np.exp(exponent) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> norm_factor</span>
<span id="cb2-18"></span>
<span id="cb2-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the grid limits and resolution</span></span>
<span id="cb2-20">X, Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mgrid[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>:<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>:<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>]</span>
<span id="cb2-21">pos <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.dstack((X, Y))</span>
<span id="cb2-22"></span>
<span id="cb2-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Parameters</span></span>
<span id="cb2-24">mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb2-25">eigenvalues <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>])  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Example eigenvalues</span></span>
<span id="cb2-26">principal_axis <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Example principal axis</span></span>
<span id="cb2-27"></span>
<span id="cb2-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Normalize the principal axis</span></span>
<span id="cb2-29">principal_axis <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> principal_axis <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> np.linalg.norm(principal_axis)</span>
<span id="cb2-30"></span>
<span id="cb2-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the covariance matrix</span></span>
<span id="cb2-32">D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.diag(eigenvalues)</span>
<span id="cb2-33">orthogonal_complement <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>principal_axis[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], principal_axis[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]])</span>
<span id="cb2-34">Q <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.column_stack((principal_axis, orthogonal_complement))</span>
<span id="cb2-35">cov <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Q <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> Q.T</span>
<span id="cb2-36"></span>
<span id="cb2-37"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the Gaussian function over the grid</span></span>
<span id="cb2-38">Z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> multivariate_gaussian(pos, mean, cov)</span>
<span id="cb2-39"></span>
<span id="cb2-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the Sobel operators for x and y derivatives</span></span>
<span id="cb2-41">Kdx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb2-42">                [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>],</span>
<span id="cb2-43">                [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.0</span></span>
<span id="cb2-44"></span>
<span id="cb2-45">Kdy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb2-46">                [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,  <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,  <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],</span>
<span id="cb2-47">                [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,  <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,  <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.0</span></span>
<span id="cb2-48"></span>
<span id="cb2-49"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply the Sobel filters to compute the derivatives</span></span>
<span id="cb2-50">Zdx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> convolve(Z, Kdx, mode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'constant'</span>, cval<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>)</span>
<span id="cb2-51">Zdy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> convolve(Z, Kdy, mode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'constant'</span>, cval<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>)</span>
<span id="cb2-52"></span>
<span id="cb2-53"></span>
<span id="cb2-54">plt.contourf(X, Y, Z, levels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>)</span>
<span id="cb2-55">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Gaussian Distribution'</span>)</span>
<span id="cb2-56">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X-axis'</span>)</span>
<span id="cb2-57">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Y-axis'</span>)</span>
<span id="cb2-58">plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>)</span>
<span id="cb2-59">plt.savefig(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'figure.png'</span>, dpi<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>, bbox_inches<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tight'</span>)</span>
<span id="cb2-60"></span>
<span id="cb2-61"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the Gaussian and its derivatives</span></span>
<span id="cb2-62">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>))</span>
<span id="cb2-63"></span>
<span id="cb2-64"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the Gaussian</span></span>
<span id="cb2-65">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-66">plt.contourf(X, Y, Z, levels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>)</span>
<span id="cb2-67">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Gaussian Distribution'</span>)</span>
<span id="cb2-68">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X-axis'</span>)</span>
<span id="cb2-69">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Y-axis'</span>)</span>
<span id="cb2-70">plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>)</span>
<span id="cb2-71"></span>
<span id="cb2-72"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the derivative in x</span></span>
<span id="cb2-73">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb2-74">plt.contourf(X, Y, Zdx, levels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RdBu'</span>)</span>
<span id="cb2-75">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Derivative in X (Sobel Filter)'</span>)</span>
<span id="cb2-76">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X-axis'</span>)</span>
<span id="cb2-77">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Y-axis'</span>)</span>
<span id="cb2-78">plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>)</span>
<span id="cb2-79"></span>
<span id="cb2-80"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the derivative in y</span></span>
<span id="cb2-81">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb2-82">plt.contourf(X, Y, Zdy, levels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RdBu'</span>)</span>
<span id="cb2-83">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Derivative in Y (Sobel Filter)'</span>)</span>
<span id="cb2-84">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X-axis'</span>)</span>
<span id="cb2-85">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Y-axis'</span>)</span>
<span id="cb2-86">plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>)</span>
<span id="cb2-87"></span>
<span id="cb2-88">plt.tight_layout()</span>
<span id="cb2-89">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="mv-plot-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture2/index_files/figure-html/mv-plot-output-1.png" width="587" height="449" class="figure-img"></p>
<figcaption>Multivariate Gaussian and its Derivatives</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture2/index_files/figure-html/mv-plot-output-2.png" id="mv-plot-2" width="748" height="230" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="extending-to-combination-of-gaussian-and-derivative" class="level3">
<h3 class="anchored" data-anchor-id="extending-to-combination-of-gaussian-and-derivative">Extending to Combination of Gaussian and Derivative</h3>
<p>We can compute the MV gaussian from the inverse covariance matrix <img src="https://latex.codecogs.com/png.latex?C"> with a mean of <img src="https://latex.codecogs.com/png.latex?%5Cmu=0"> along with a dimensional scaling metric <img src="https://latex.codecogs.com/png.latex?t">. For the purposes of forming interesting and varied PSFs, we include the linear combination of the gaussian and a Sobel operator to axpproximate the derivative of the gaussian.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign%7D%0AS_x%20&amp;=%20%5Cfrac%7B1%7D%7B4%7D%20%5Cbegin%7Bbmatrix%7D%20-1%20&amp;%200%20&amp;%201%20%5C%5C%20-2%20&amp;%200%20&amp;%202%20%5C%5C%20-1%20&amp;%200%20&amp;%201%20%5Cend%7Bbmatrix%7D%20%5C%5C%0AS_y%20&amp;=%20%5Cfrac%7B1%7D%7B4%7D%20%5Cbegin%7Bbmatrix%7D%20-1%20&amp;%20-2%20&amp;%20-1%20%5C%5C%200%20&amp;%200%20&amp;%200%20%5C%5C%201%20&amp;%202%20&amp;%201%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign%7D%0A"></p>
<p>These operators act like edge detection or derivatives. The <img src="https://latex.codecogs.com/png.latex?n_0">, <img src="https://latex.codecogs.com/png.latex?n_x">, and <img src="https://latex.codecogs.com/png.latex?n_y"> parameters in the code are used to scale the gaussian and the derivatives.</p>
<div id="06ff00b3" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> gaussianConv(nn.Module):</span>
<span id="cb3-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb3-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    A PyTorch module that applies a Gaussian convolution to an input image using </span></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    a parameterized Gaussian Point Spread Function (PSF). The PSF is derived </span></span>
<span id="cb3-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    from a covariance matrix and the derivatives of the Gaussian are computed </span></span>
<span id="cb3-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    for edge detection.</span></span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb3-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        C (torch.Tensor): Inverse of covariance matrix used to define the shape of the Gaussian.</span></span>
<span id="cb3-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        t (float, optional): Scaling factor for the Gaussian, default is np.exp(5).</span></span>
<span id="cb3-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n0 (float, optional): Scaling factor for the original PSF, default is 1.</span></span>
<span id="cb3-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        nx (float, optional): Scaling factor for the derivative along the x-axis, default is 1.</span></span>
<span id="cb3-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        ny (float, optional): Scaling factor for the derivative along the y-axis, default is 1.</span></span>
<span id="cb3-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb3-15">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, C, t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.exp(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>), n0<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, nx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, ny<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>):</span>
<span id="cb3-16">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>(gaussianConv, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>).<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>()</span>
<span id="cb3-17"></span>
<span id="cb3-18">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.C <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> C</span>
<span id="cb3-19">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t</span>
<span id="cb3-20">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n0</span>
<span id="cb3-21">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.nx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nx</span>
<span id="cb3-22">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.ny <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ny</span>
<span id="cb3-23"></span>
<span id="cb3-24">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, image):</span>
<span id="cb3-25">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb3-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Apply the Gaussian convolution and derivatives to an input image.</span></span>
<span id="cb3-27"></span>
<span id="cb3-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        This method performs convolution of the input image with a Gaussian</span></span>
<span id="cb3-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Point Spread Function (PSF) that includes the original Gaussian and</span></span>
<span id="cb3-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        its derivatives along x and y axes. The convolution is performed</span></span>
<span id="cb3-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        using the Fourier Transform for efficiency.</span></span>
<span id="cb3-32"></span>
<span id="cb3-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb3-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            image (torch.Tensor): Input image tensor of shape (Batch, Channels, Height, Width).</span></span>
<span id="cb3-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        </span></span>
<span id="cb3-36"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb3-37"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            torch.Tensor: The convolved image of the same shape as the input.</span></span>
<span id="cb3-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb3-39"></span>
<span id="cb3-40">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate the PSF and calculate the center shift required for alignment</span></span>
<span id="cb3-41">        P, center <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.psfGauss(image.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], image.device)</span>
<span id="cb3-42"></span>
<span id="cb3-43">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shift the PSF so that its center aligns with the origin (top-left corner)</span></span>
<span id="cb3-44">        P_shifted <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.roll(P, shifts<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>center, dims<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>])</span>
<span id="cb3-45"></span>
<span id="cb3-46">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the Fourier Transform of the shifted PSF</span></span>
<span id="cb3-47">        S <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.fft.fft2(P_shifted)</span>
<span id="cb3-48"></span>
<span id="cb3-49">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the Fourier Transform of the input image</span></span>
<span id="cb3-50">        I_fft <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.fft.fft2(image)</span>
<span id="cb3-51"></span>
<span id="cb3-52">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Multiply the Fourier Transforms element-wise (convolution theorem with Hadamard product)</span></span>
<span id="cb3-53">        B_fft <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> S <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> I_fft</span>
<span id="cb3-54"></span>
<span id="cb3-55">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the inverse Fourier Transform to get back to the spatial domain</span></span>
<span id="cb3-56">        B <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.real(torch.fft.ifft2(B_fft))</span>
<span id="cb3-57"></span>
<span id="cb3-58">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Return the convolved image</span></span>
<span id="cb3-59">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> B</span>
<span id="cb3-60"></span>
<span id="cb3-61">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> psfGauss(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, dim, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpu'</span>):</span>
<span id="cb3-62">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb3-63"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Generate the Gaussian PSF and its derivatives.</span></span>
<span id="cb3-64"></span>
<span id="cb3-65"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Args:</span></span>
<span id="cb3-66"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            dim (int): Dimension size (assumes square dimensions).</span></span>
<span id="cb3-67"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            device (str, optional): Device to create tensors on, default is 'cpu'.</span></span>
<span id="cb3-68"></span>
<span id="cb3-69"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb3-70"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            tuple:</span></span>
<span id="cb3-71"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                - PSF (torch.Tensor): The combined PSF including derivatives.</span></span>
<span id="cb3-72"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                - center (list): Shifts required to align the PSF with the origin.</span></span>
<span id="cb3-73"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb3-74">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the size of the PSF kernel (assumed to be square)</span></span>
<span id="cb3-75">        m <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dim</span>
<span id="cb3-76">        n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dim</span>
<span id="cb3-77"></span>
<span id="cb3-78">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a meshgrid of (X, Y) coordinates</span></span>
<span id="cb3-79">        x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.arange(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>m <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, m <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>device)</span>
<span id="cb3-80">        y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.arange(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>device)</span>
<span id="cb3-81">        X, Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.meshgrid(x, y, indexing<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ij'</span>)</span>
<span id="cb3-82">        X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (1, 1, m, n)</span></span>
<span id="cb3-83">        Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (1, 1, m, n)</span></span>
<span id="cb3-84"></span>
<span id="cb3-85">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract elements from the covariance matrix</span></span>
<span id="cb3-86">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assuming self.C is a 2x2 tensor</span></span>
<span id="cb3-87">        cx, cy, cxy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.C[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.C[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.C[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb3-88"></span>
<span id="cb3-89">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the Gaussian PSF using the meshgrid and covariance elements</span></span>
<span id="cb3-90">        PSF <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.exp(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (cx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> cy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> cxy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> Y))</span>
<span id="cb3-91"></span>
<span id="cb3-92">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Normalize the PSF so that its absolute sum is 1</span></span>
<span id="cb3-93">        PSF0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PSF <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(PSF.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>())</span>
<span id="cb3-94"></span>
<span id="cb3-95">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define derivative kernels (Sobel operators) for edge detection</span></span>
<span id="cb3-96">        Kdx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb3-97">                            [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>],</span>
<span id="cb3-98">                            [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]], dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>PSF0.dtype, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>device) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb3-99">        Kdy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb3-100">                            [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],</span>
<span id="cb3-101">                            [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]], dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>PSF0.dtype, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>device) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb3-102"></span>
<span id="cb3-103">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Reshape kernels to match convolution requirements</span></span>
<span id="cb3-104">        Kdx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Kdx.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (1, 1, 3, 3)</span></span>
<span id="cb3-105">        Kdy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Kdy.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shape: (1, 1, 3, 3)</span></span>
<span id="cb3-106"></span>
<span id="cb3-107">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convolve the PSF with the derivative kernels to obtain derivatives</span></span>
<span id="cb3-108">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Padding ensures the output size matches the input size</span></span>
<span id="cb3-109">        PSFdx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> F.conv2d(PSF0, Kdx, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-110">        PSFdy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> F.conv2d(PSF0, Kdy, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-111"></span>
<span id="cb3-112">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Combine the original PSF and its derivatives using the scaling factors</span></span>
<span id="cb3-113">        PSF_combined <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> PSF0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.nx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> PSFdx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.ny <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> PSFdy</span>
<span id="cb3-114"></span>
<span id="cb3-115">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate the center shift required to align the PSF with the origin</span></span>
<span id="cb3-116">        center <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> m <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb3-117"></span>
<span id="cb3-118">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Return the combined PSF and center shift</span></span>
<span id="cb3-119">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> PSF_combined, center</span></code></pre></div>
</details>
</div>
</section>
<section id="creating-a-toy-dataset" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-toy-dataset">Creating a Toy Dataset</h3>
<p>Often in computational science we test our strategies on toy datasets, simplified data that allows for easier debugging and understanding of the problem at task. In this case, rather than use a real image, we construct a geometric image that will be easier to analyse visually for its correctness when it comes to denoising and deblurring. The dataset is also dimensioned to have a batch and color channel to follow some of the conventions for working with torch tensors, and later some machine learning frameworks. That is <img src="https://latex.codecogs.com/png.latex?B%20%5Ctimes%20C%20%5Ctimes%20H%20%5Ctimes%20W">, with a single sample, single channel, and a 256x256 image having dimensions <img src="https://latex.codecogs.com/png.latex?1%20%5Ctimes%201%20%5Ctimes%20256%20%5Ctimes%20256">.</p>
<div id="cell-toy-dataset" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>)</span>
<span id="cb4-2">x[:,:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">120</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">140</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">120</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">140</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb4-3">x[:,:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">120</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">120</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb4-4"></span>
<span id="cb4-5">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))</span>
<span id="cb4-6">plt.imshow(x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:,:])</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="toy-dataset" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture2/index_files/figure-html/toy-dataset-output-1.png" width="276" height="268" class="figure-img"></p>
<figcaption>A sample toy dataset for image denoising and deblurring.</figcaption>
</figure>
</div>
</div>
</div>
<p>This simple image is a high and a low signal shown as two square regions, which we will try to recover after applying a point spread function to it (the forward model). The forward model is the convolution of the image with the PSF.</p>
<div id="cell-forward-model" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">C <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]])</span>
<span id="cb5-2">Amv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gaussianConv(C, t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.001</span>,n0<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, nx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,  ny<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb5-3"></span>
<span id="cb5-4">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Amv(x)</span>
<span id="cb5-5">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb5-6">plt.imshow(x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:,:])</span>
<span id="cb5-7">plt.colorbar()</span>
<span id="cb5-8">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb5-9">plt.imshow(y[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:,:])</span>
<span id="cb5-10">plt.colorbar()</span>
<span id="cb5-11"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>()</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code></code></pre>
</div>
<div class="cell-output cell-output-display">
<div id="forward-model" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture2/index_files/figure-html/forward-model-output-2.png" width="616" height="402" class="figure-img"></p>
<figcaption>Forward model for image denoising and deblurring.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="forming-a-convolution-matrix" class="level3">
<h3 class="anchored" data-anchor-id="forming-a-convolution-matrix">Forming a Convolution Matrix</h3>
<p>Back to the idea of forming a Toeplitz matrix, we first flatten the data to 1D and then recover the matrix in one of two ways. We can work in the spatial domain where the first row of the matrix is determined by the 1D convolution for the first element, then slide the row by one to form the matrix. The matrix can be quite large, since an <img src="https://latex.codecogs.com/png.latex?n%5Ctimes%20m"> image will have <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20m"> elements once flattened, requiring a <img src="https://latex.codecogs.com/png.latex?(n%5Ctimes%20m)%20%5Ctimes%20(n%5Ctimes%20m)"> matrix. A reduction in dimension to the <img src="https://latex.codecogs.com/png.latex?32%20%5Ctimes%2032"> image will help with the computation.</p>
<p>Note that we are working with a rolling PSF which has a strange effect in that it assumes a periodic boundary condition in both <img src="https://latex.codecogs.com/png.latex?x"> and <img src="https://latex.codecogs.com/png.latex?y">. When it comes to convolution, there are many different ways to treat the boundary condition, such as using zero padding or mirroring the boundary. Coding this by hand is a good exercise to understand the convolution operation, but not the purpose of this exercise.</p>
<section id="direct-recovery-of-convolution-matrix" class="level4">
<h4 class="anchored" data-anchor-id="direct-recovery-of-convolution-matrix">Direct Recovery of Convolution Matrix</h4>
<div id="cell-convolution-matrix" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span></span>
<span id="cb7-2">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, dim, dim)</span>
<span id="cb7-3">x[:,:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb7-4">x[:,:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb7-5"></span>
<span id="cb7-6">Amv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gaussianConv(C, t<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,n0<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, nx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,  ny<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span>
<span id="cb7-7"></span>
<span id="cb7-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Flatten the image and the PSF</span></span>
<span id="cb7-9">x_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.flatten()</span>
<span id="cb7-10"></span>
<span id="cb7-11">kernel, center <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Amv.psfGauss(x.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get a square conv kernel </span></span>
<span id="cb7-12"></span>
<span id="cb7-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Since we are using the conv kernel as a filter operation, we use the transpose of the kernel</span></span>
<span id="cb7-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># to fill the convolution matrix. </span></span>
<span id="cb7-15"></span>
<span id="cb7-16">kernel <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kernel.transpose(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>) </span>
<span id="cb7-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Roll shifts the kernel from the center of the box to the top left corner</span></span>
<span id="cb7-18">kernel_shifted <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.roll(kernel, shifts<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>center, dims<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>])</span>
<span id="cb7-19"></span>
<span id="cb7-20">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb7-21">plt.imshow(kernel[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:,:])</span>
<span id="cb7-22">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PSF Centered'</span>)</span>
<span id="cb7-23">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb7-24">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PSF Shifted with Roll'</span>)</span>
<span id="cb7-25">plt.imshow(kernel_shifted[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:,:])</span>
<span id="cb7-26"></span>
<span id="cb7-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Flatten the kernel</span></span>
<span id="cb7-28">kernel_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kernel_shifted.flatten()</span>
<span id="cb7-29"></span>
<span id="cb7-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Form the convolution matrix</span></span>
<span id="cb7-31">n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x_flat.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb7-32">m <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kernel_flat.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb7-33">A_conv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(n, n)</span>
<span id="cb7-34"></span>
<span id="cb7-35"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n):</span>
<span id="cb7-36">    A_conv[i, :] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.roll(kernel_flat, shifts<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>i, dims<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb7-37"></span>
<span id="cb7-38">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb7-39">plt.imshow(A_conv)</span>
<span id="cb7-40">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Convolution Matrix'</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="convolution-matrix" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture2/index_files/figure-html/convolution-matrix-output-1.png" width="580" height="215" class="figure-img"></p>
<figcaption>Forming a convolution matrix for the forward model.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="recovery-using-linearity-of-operator" class="level4">
<h4 class="anchored" data-anchor-id="recovery-using-linearity-of-operator">Recovery Using Linearity of Operator</h4>
<p>Since the convolution operation that is being performed is linear, one way to recover the matrix operator under this assumption is to pass through the basis vectors and recover the column vectors in this fashion:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%20a_1%20%5Cmid%20a_2%20%5Cmid%20%5Cldots%20%5Cmid%20a_n%20%5Cend%7Bbmatrix%7D%20%5Cmathbf%7Be%7D_i%20=%20%5Cmathbf%7BA%7D%20%5Cmathbf%7Be%7D_i%20%20=%20%5Cmathbf%7Ba%7D_i"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Be%7D_i"> is the <img src="https://latex.codecogs.com/png.latex?i">th basis vector.</p>
<div id="cell-convolution-matrix-2" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">A_conv_lin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(n, n)</span>
<span id="cb8-2"></span>
<span id="cb8-3">k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb8-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(x.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]):</span>
<span id="cb8-5">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(x.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]):</span>
<span id="cb8-6">    e_ij <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros_like(x)</span>
<span id="cb8-7">    e_ij[:,:, i, j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span></span>
<span id="cb8-8">    y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Amv(e_ij)</span>
<span id="cb8-9">    A_conv_lin[:, k] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y.flatten()</span>
<span id="cb8-10">    k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb8-11"></span>
<span id="cb8-12">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb8-13">plt.imshow(A_conv_lin)</span>
<span id="cb8-14">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Convolution Matrix (Linear)'</span>)</span>
<span id="cb8-15">plt.colorbar()</span>
<span id="cb8-16">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb8-17">plt.imshow(A_conv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>A_conv_lin)</span>
<span id="cb8-18">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Difference from Direct'</span>)</span>
<span id="cb8-19">plt.colorbar()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="convolution-matrix-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture2/index_files/figure-html/convolution-matrix-2-output-1.png" width="625" height="400" class="figure-img"></p>
<figcaption>Forming a convolution matrix for the forward model using linearity.</figcaption>
</figure>
</div>
</div>
</div>
<p>Now comparing this method against the known convolution result using the class defined earlier with the forward model:</p>
<div id="ccc8fd9e" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">b_forward <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Amv(x)</span>
<span id="cb9-2"></span>
<span id="cb9-3">b_mat_toeplitz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> A_conv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> x_flat</span>
<span id="cb9-4">b_mat_linear <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> A_conv_lin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> x_flat</span>
<span id="cb9-5"></span>
<span id="cb9-6">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb9-7">plt.imshow(b_forward[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:,:])</span>
<span id="cb9-8">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb9-9">plt.imshow(b_mat_toeplitz.reshape(x.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:]))</span>
<span id="cb9-10">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>) </span>
<span id="cb9-11">plt.imshow(b_mat_linear.reshape(x.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:]))</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture2/index_files/figure-html/cell-9-output-1.png" width="566" height="197" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We can see that there are some differences between the two methods but in principle they should be the same, (Not sure where the difference is coming from). The important method is actually the one which extracts the columns, as it is more generalizable. So we will continue with that.</p>
<div id="final-conv-matrix" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">Amat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> A_conv_lin</span></code></pre></div>
</details>
</div>
</section>
</section>
<section id="least-squares-recovery-with-svd-and-pseudoinverse" class="level2">
<h2 class="anchored" data-anchor-id="least-squares-recovery-with-svd-and-pseudoinverse">Least Squares Recovery with SVD and Pseudoinverse</h2>
<p>Now that we have a matrix operator recovered we can formulate the forward problem as <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cmathbf%7Bb%7D"> with our known <img src="https://latex.codecogs.com/png.latex?A"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">, and we want to recover <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">. To do this we use the SVD decomposition to gather the pseudo inverse. We can decide to filter out some of the singular values that are very small to improve the conditioning on the matrix as well, using a cutoff value for example.</p>
<section id="svd-decomposition" class="level3">
<h3 class="anchored" data-anchor-id="svd-decomposition">SVD Decomposition</h3>
<div id="08f4ecd8" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">U, S, V <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.svd(Amat.to(torch.float64))</span>
<span id="cb11-2">b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Amv(x)</span></code></pre></div>
</details>
</div>
<p>Now we make a log plot of the singular values to see how they decay, noting that we lose numerical precision around the <img src="https://latex.codecogs.com/png.latex?10%5E%7B-6%7D"> mark. We can also asses what the frobenius norm of the difference between the original matrix and the reconstructed matrix is to get a sense of the error in the decomposition and reconstruction.</p>
<div id="cell-svd-decomposition" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">plt.semilogy(S)</span>
<span id="cb12-2">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Singular Value Index'</span>)</span>
<span id="cb12-3">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Singular Value'</span>)</span>
<span id="cb12-4"></span>
<span id="cb12-5">loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> F.mse_loss(Amat, U <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> torch.diag(S) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> V.T)</span>
<span id="cb12-6"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"The loss is </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>loss<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The loss is 1.5941001880912316e-23</code></pre>
</div>
<div class="cell-output cell-output-display">
<div id="svd-decomposition" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture2/index_files/figure-html/svd-decomposition-output-2.png" width="605" height="429" class="figure-img"></p>
<figcaption>SVD Decomposition of the Convolution Matrix.</figcaption>
</figure>
</div>
</div>
</div>
<p>The loss is quite small which is a good sign that the decomposition is working well within the numerical precision of the machine.</p>
</section>
<section id="initial-attempt-at-pseudoinverse" class="level3">
<h3 class="anchored" data-anchor-id="initial-attempt-at-pseudoinverse">Initial Attempt at Pseudoinverse</h3>
<p>To recover the original image data we first naively try to invert the matrix to see what happens.</p>
<div id="cell-naive-pseudoinverse" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">xhat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.linalg.solve(Amat,b.reshape(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))</span>
<span id="cb14-2">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb14-3">plt.imshow(xhat.reshape(x.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:]))</span>
<span id="cb14-4">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Naive Inverse'</span>)</span>
<span id="cb14-5">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb14-6">plt.imshow(x.reshape(x.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:]))</span>
<span id="cb14-7">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Original Image'</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="naive-pseudoinverse" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture2/index_files/figure-html/naive-pseudoinverse-output-1.png" width="566" height="298" class="figure-img"></p>
<figcaption>Naive Pseudoinverse Recovery of the Original Image.</figcaption>
</figure>
</div>
</div>
</div>
<p>Wow, not even close! This is because the matrix is so ill conditioned that it is effectively low rank and not invertible. We can improve the situation by filtering out the singular values that are very small.</p>
</section>
<section id="pseudoinverse-with-filtering" class="level3">
<h3 class="anchored" data-anchor-id="pseudoinverse-with-filtering">Pseudoinverse with Filtering</h3>
<p>We can filter out the poor conditioning singular values and exclude those values from the inversion. To get an idea of what the values are doing, we can plot the first few singular values and the corresponding singular vector that they project onto. In the case of the SVD the most important information about the matrix is captured in the left-most vectors of the matrix <img src="https://latex.codecogs.com/png.latex?U">.</p>
<div id="7a28efa7" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span>
<span id="cb15-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n):</span>
<span id="cb15-3">  plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,n,i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb15-4">  plt.imshow(U[:,i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].reshape(x.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:]))</span>
<span id="cb15-5">  plt.title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Mode </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture2/index_files/figure-html/cell-14-output-1.png" width="566" height="151" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>For the inverse problem, the most import singular values are conversely found in the left-most vectors of the matrix <img src="https://latex.codecogs.com/png.latex?V">. We can also check what the right-most vectors are doing, as they will blow up in value when inverting small singular values. They are high frequency modes of the image, creating the reconstruction issues when they are subjected to error in numerical precision.</p>
<div id="f3f03ccb" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span>
<span id="cb16-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n):</span>
<span id="cb16-3">  plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,n,i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb16-4">  plt.imshow(V[:,i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].reshape(x.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:]))</span>
<span id="cb16-5">  plt.title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Mode </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb16-6">plt.show()</span>
<span id="cb16-7"></span>
<span id="cb16-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n):</span>
<span id="cb16-9">  plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,n,i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb16-10">  plt.imshow(V[:,<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>(i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)].reshape(x.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:]))</span>
<span id="cb16-11">  plt.title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Mode </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>V<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb16-12">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture2/index_files/figure-html/cell-15-output-1.png" width="566" height="151" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture2/index_files/figure-html/cell-15-output-2.png" width="566" height="151" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>These modes are the most important ones, as they contain the big-picture detail without the high frequency noise. We can now filter out the singular values that are very small and invert the matrix to recover the original image.</p>
<div id="cell-pseudoinverse-filter" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">b_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> b.flatten().to(torch.float64)</span>
<span id="cb17-2">x_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.flatten().to(torch.float64)</span>
<span id="cb17-3">thresholds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-8</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-10</span>]</span>
<span id="cb17-4"></span>
<span id="cb17-5">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adjust the figure size as needed</span></span>
<span id="cb17-6"></span>
<span id="cb17-7"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx, threshold <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(thresholds):</span>
<span id="cb17-8">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Filter the singular values</span></span>
<span id="cb17-9">    S_filtered <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> S.clone()</span>
<span id="cb17-10">    S_filtered[S_filtered <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> threshold] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb17-11"></span>
<span id="cb17-12">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the reciprocal of the filtered singular values</span></span>
<span id="cb17-13">    S_inv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros_like(S_filtered)</span>
<span id="cb17-14">    non_zero_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> S_filtered <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb17-15">    S_inv[non_zero_mask] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> S_filtered[non_zero_mask]</span>
<span id="cb17-16"></span>
<span id="cb17-17">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the pseudoinverse of Amat</span></span>
<span id="cb17-18">    A_pinv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> V <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> torch.diag(S_inv) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> U.T</span>
<span id="cb17-19"></span>
<span id="cb17-20">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Reconstruct the original image</span></span>
<span id="cb17-21">    xhat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> A_pinv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> b_flat</span>
<span id="cb17-22"></span>
<span id="cb17-23">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the reconstruction error</span></span>
<span id="cb17-24">    error <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.norm(xhat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> x_flat, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'fro'</span>).item()</span>
<span id="cb17-25"></span>
<span id="cb17-26">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the reconstructed image in the appropriate subplot</span></span>
<span id="cb17-27">    plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># idx + 1 because subplot indices start at 1</span></span>
<span id="cb17-28">    plt.imshow(xhat.reshape(x.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:]))</span>
<span id="cb17-29">    plt.title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Threshold </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>threshold<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Error: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>error<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb17-30">    plt.colorbar()</span>
<span id="cb17-31">    plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'off'</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Optionally turn off axis ticks and labels</span></span>
<span id="cb17-32"></span>
<span id="cb17-33">plt.tight_layout()</span>
<span id="cb17-34">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="pseudoinverse-filter" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture2/index_files/figure-html/pseudoinverse-filter-output-1.png" width="661" height="464" class="figure-img"></p>
<figcaption>Pseudoinverse Recovery of the Original Image with Filtering.</figcaption>
</figure>
</div>
</div>
</div>
<p>Looking at the results, around the <img src="https://latex.codecogs.com/png.latex?10%5E%7B-7%7D"> mark we start to a peak level of recovery, as measured by the error in the Frobenius norm of the reconstruction. But what happens when we add noise to the data signal?</p>
</section>
<section id="adding-noise-to-the-signal" class="level3">
<h3 class="anchored" data-anchor-id="adding-noise-to-the-signal">Adding Noise to the Signal</h3>
<p>Now we add some noise to the signal and try least squares again for the direct solution</p>
<div id="cell-pseudoinverse-filter-noised" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">b_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> b.flatten().to(torch.float64)</span>
<span id="cb18-2">x_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.flatten().to(torch.float64)</span>
<span id="cb18-3">Amat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Amat.to(torch.float64)</span>
<span id="cb18-4"></span>
<span id="cb18-5">alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.01</span></span>
<span id="cb18-6">noise <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn_like(b_flat) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> alpha</span>
<span id="cb18-7"></span>
<span id="cb18-8">H <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Amat.T <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> Amat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> torch.eye(Amat.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb18-9">xhat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.linalg.solve(H, Amat.T <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> (b_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> noise))</span>
<span id="cb18-10"></span>
<span id="cb18-11">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb18-12">plt.imshow(x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb18-13">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Original Image'</span>)</span>
<span id="cb18-14">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb18-15">plt.imshow(xhat.reshape(x.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:]))</span>
<span id="cb18-16">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Reconstructed Image'</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="pseudoinverse-filter-noised" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture2/index_files/figure-html/pseudoinverse-filter-noised-output-1.png" width="566" height="298" class="figure-img"></p>
<figcaption>Pseudoinverse Recovery of the Original Image with Noise.</figcaption>
</figure>
</div>
</div>
</div>
<p>The reconstruction is not very good, the noise has been amplifed all over the image. We can try the pseudoinverse method again with the noise added to the signal.</p>
<div id="cell-pseudoinverse-filter-noised-recovery" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">Amat_noisy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Amat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> torch.eye(Amat.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb19-2">Un, Sn, Vn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.svd(Amat_noisy)</span>
<span id="cb19-3"></span>
<span id="cb19-4">thresholds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.05</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.03</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.005</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.001</span>]</span>
<span id="cb19-5"></span>
<span id="cb19-6">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adjust the figure size as needed</span></span>
<span id="cb19-7"></span>
<span id="cb19-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx, threshold <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(thresholds):</span>
<span id="cb19-9">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Filter the singular values</span></span>
<span id="cb19-10">    S_filtered <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Sn.clone()</span>
<span id="cb19-11">    S_filtered[S_filtered <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> threshold] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb19-12"></span>
<span id="cb19-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the reciprocal of the filtered singular values</span></span>
<span id="cb19-14">    S_inv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros_like(S_filtered)</span>
<span id="cb19-15">    non_zero_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> S_filtered <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb19-16">    S_inv[non_zero_mask] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> S_filtered[non_zero_mask]</span>
<span id="cb19-17"></span>
<span id="cb19-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Construct the pseudoinverse of Amat</span></span>
<span id="cb19-19">    A_pinv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Vn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> torch.diag(S_inv) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> Un.T</span>
<span id="cb19-20"></span>
<span id="cb19-21">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Reconstruct the original image</span></span>
<span id="cb19-22">    xhat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> A_pinv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> (b_flat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> noise)</span>
<span id="cb19-23"></span>
<span id="cb19-24">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the reconstruction error</span></span>
<span id="cb19-25">    error <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.norm(xhat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> x_flat, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'fro'</span>).item()</span>
<span id="cb19-26"></span>
<span id="cb19-27">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the reconstructed image in the appropriate subplot</span></span>
<span id="cb19-28">    plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># idx + 1 because subplot indices start at 1</span></span>
<span id="cb19-29">    plt.imshow(xhat.reshape(x.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:]))</span>
<span id="cb19-30">    plt.title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Threshold </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>threshold<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Error: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>error<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb19-31">    plt.colorbar()</span>
<span id="cb19-32">    plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'off'</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Optionally turn off axis ticks and labels</span></span>
<span id="cb19-33"></span>
<span id="cb19-34">plt.tight_layout()</span>
<span id="cb19-35">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="pseudoinverse-filter-noised-recovery" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://chipnbits.github.io/content/eosc555/lectures/lecture2/index_files/figure-html/pseudoinverse-filter-noised-recovery-output-1.png" width="661" height="467" class="figure-img"></p>
<figcaption>Pseudoinverse Recovery of the Original Image with Noise.</figcaption>
</figure>
</div>
</div>
</div>
<p>The small addition of noise is quite significant in the recovery threshold for reconstruction. Using a higher threshold for the singular values becomes important when dealing with noise in the signal. Previously numerical precision was the main issue, but now the measurement noise is the main issue.</p>


</section>
</section>
</section>

 ]]></description>
  <category>Optimization</category>
  <category>Inverse Theory</category>
  <category>Python</category>
  <category>Torch</category>
  <category>SVD</category>
  <guid>https://chipnbits.github.io/content/eosc555/lectures/lecture2/</guid>
  <pubDate>Sun, 15 Sep 2024 07:00:00 GMT</pubDate>
  <media:content url="https://chipnbits.github.io/content/eosc555/lectures/lecture2/imgs/gaussian_plot.png" medium="image" type="image/png" height="115" width="144"/>
</item>
<item>
  <title>Lecture 1: Introduction to Inverse Theory</title>
  <dc:creator>Simon Ghyselincks</dc:creator>
  <link>https://chipnbits.github.io/content/eosc555/lectures/lecture1-2/</link>
  <description><![CDATA[ 




<section id="what-is-inverse-theory" class="level1">
<h1>What is Inverse Theory?</h1>
<p>Inverse theory is a set of mathematical techniques used to infer the properties of a physical system from observations of its output. It is a fundamental tool in many scientific disciplines, including geophysics, seismology, and medical imaging. Inverse theory is used to solve a wide range of problems, such as:</p>
<ul>
<li><strong>Parameter Estimation</strong>: Determining the values of unknown parameters in a model that best fit the observed data.</li>
<li><strong>System Identification</strong>: Identifying the structure and dynamics of a system from input-output data.</li>
<li><strong>Image Reconstruction</strong>: Reconstructing an image or object from noisy or incomplete measurements.</li>
</ul>
<p>What many of these tasks have in common is that we are working with incomplete information. There is a <em>forward</em> problem that has generated the data that we observe <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bb%7D"> from a set of input data <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bx%7D">, and we want to infer the <em>inverse</em> problem that generated the data. However the inverse problem is often ill-posed, meaning that there are multiple solutions that can fit the data equally well. Inverse theory provides a framework for finding the best solution to these problems.</p>
<p>The forward problem can be described for example as a differetial equation or operator <img src="https://latex.codecogs.com/png.latex?L"> that takes in some measured parameters <img src="https://latex.codecogs.com/png.latex?u"> with model parameters <img src="https://latex.codecogs.com/png.latex?x"> :</p>
<p><img src="https://latex.codecogs.com/png.latex?%20L(x)%5Bu%5D%20=%20q%20%5Ciff%20u%20=%20L%5E%7B-1%7D(x)%5Bq%5D%20"></p>
<p>For example making measurements of an electromagnetic field in correspondence to conductivity values that are underground we have:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cnabla%20%5Csigma%20%5Cnabla%20u%20=%20q%20+%20%5Ctext%7BBC%7D"></p>
<p>We measure the <img src="https://latex.codecogs.com/png.latex?u"> at some points and use that to try and form an estimate of the conductivity <img src="https://latex.codecogs.com/png.latex?%5Csigma">. The forward problem is to solve for <img src="https://latex.codecogs.com/png.latex?u"> given <img src="https://latex.codecogs.com/png.latex?%5Csigma"> and the inverse problem is to solve for <img src="https://latex.codecogs.com/png.latex?%5Csigma"> given <img src="https://latex.codecogs.com/png.latex?u">. The forward problem is often well-posed and the inverse problem is often ill-posed.</p>
<p>For a computational framework we can discretize the the equation so that the operator is a matrix <img src="https://latex.codecogs.com/png.latex?A"> and the data is a vector <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bb%7D">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cunderbrace%7BA%7D_%7B%5Ctext%7BForward%20Map%7D%7D%20%5Cunderbrace%7B%5Cvec%7Bx%7D%7D_%7B%5Ctext%7BModel%20Parameters%7D%7D%20+%20%5Cepsilon%20=%20%5Cunderbrace%7B%5Cvec%7Bb%7D%7D_%7B%5Ctext%7BObserved%20Data%7D%7D%20"></p>
<p>In this case we may have a sparse set of measurements <img src="https://latex.codecogs.com/png.latex?b"> and a large set of <img src="https://latex.codecogs.com/png.latex?x"> making the problem underdetermined. The goal of inverse theory is to find the best estimate of <img src="https://latex.codecogs.com/png.latex?x"> given <img src="https://latex.codecogs.com/png.latex?b">.</p>
<section id="example-the-triathlon-problem" class="level3">
<h3 class="anchored" data-anchor-id="example-the-triathlon-problem">Example: The Triathlon Problem</h3>
<p>To illustrate the concept of inverse theory, consider the following example:</p>
<blockquote class="blockquote">
<p>Suppose that you have agreed to meet a friend to watch them during a triathlon race but you showed up late and missed the start. They are expecting for you to have been there at some point during the time at which they were changing from a running phase to a cycle phase. They expect you to know the time at which they made the transition. However you only know the overall start time and finish time of the race.</p>
<p>If the race starts at time <img src="https://latex.codecogs.com/png.latex?t=0"> and then ends at time <img src="https://latex.codecogs.com/png.latex?t=b"> how do you use this information to deduce the actual time <img src="https://latex.codecogs.com/png.latex?t_r%20%5Cin%20%5B0,b%5D"> at which they crossed the transition zone of the race?</p>
</blockquote>
<p>The first restriction on feasible solutions is the domain <img src="https://latex.codecogs.com/png.latex?%5B0,b%5D"> so that we know that <img src="https://latex.codecogs.com/png.latex?0%3Ct_r%3Cb">.</p>
<p>After this there are some other techniquest that we could use to better inform the probability of the occurence at different times. For example, we might have a good idea of their fitness level or average running speed from previous experience. Or in the abscence of this information there might be average times for the competitors that are available to further inform the problem and reduce the amount of error in the estimate.</p>
</section>
<section id="the-singular-value-decomposition" class="level2">
<h2 class="anchored" data-anchor-id="the-singular-value-decomposition">The Singular Value Decomposition</h2>
<p>For cases where the matrix <img src="https://latex.codecogs.com/png.latex?A"> is not full rank, the singular value decomposition (SVD) provides a more general framework for solving the least squares problem. The SVD decomposes the matrix <img src="https://latex.codecogs.com/png.latex?A"> into three matrices <img src="https://latex.codecogs.com/png.latex?U">, <img src="https://latex.codecogs.com/png.latex?%5CSigma">, and <img src="https://latex.codecogs.com/png.latex?V"></p>
<p><img src="https://latex.codecogs.com/png.latex?%20A%20=%20U%20%5CSigma%20V%5ET%20"></p>
<p>The matrices have the following special properties:</p>
<ul>
<li><em>Orthogonal Subspaces</em>: <img src="https://latex.codecogs.com/png.latex?U"> and <img src="https://latex.codecogs.com/png.latex?V"> are orthogonal matrices, meaning that <img src="https://latex.codecogs.com/png.latex?U%5ETU%20=%20I"> and <img src="https://latex.codecogs.com/png.latex?V%5ETV%20=%20I">, that is <img src="https://latex.codecogs.com/png.latex?U%5ET%20=%20U%5E%7B-1%7D"> and $V^T = V^{-1}.</li>
<li><em>Ordered Singular Values</em>: <img src="https://latex.codecogs.com/png.latex?%5CSigma"> is a diagonal matrix with non-negative values on the diagonal, known as the singular values of <img src="https://latex.codecogs.com/png.latex?A">. The singular values are ordered such that <img src="https://latex.codecogs.com/png.latex?%5Csigma_1%20%5Cgeq%20%5Csigma_2%20%5Cgeq%20%5Cldots%20%5Cgeq%20%5Csigma_r">. The number of non-zero singular values is equal to the rank of <img src="https://latex.codecogs.com/png.latex?A">.</li>
</ul>
<p>Supposed that we have a <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Brank%7D(A)%20=%20r"> matrix <img src="https://latex.codecogs.com/png.latex?A"> which maps from <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Em%5Crightarrow%20%5Cmathbb%7BR%7D%5En">. A fundamental way to view this mapping is as a composition of three linear transformations: a rotation <img src="https://latex.codecogs.com/png.latex?V">, a scaling <img src="https://latex.codecogs.com/png.latex?%5CSigma">, and another rotation <img src="https://latex.codecogs.com/png.latex?U">. The orthogonal matrix <img src="https://latex.codecogs.com/png.latex?V"> has the property that all of its rows and columns are orthogonal to each other, and the vectors themselves are normalized to <img src="https://latex.codecogs.com/png.latex?1">. To see this property of the orthogonal matrix consider that <img src="https://latex.codecogs.com/png.latex?V%5ET%20V%20=%20I"> and <img src="https://latex.codecogs.com/png.latex?V%20V%5ET%20=%20I">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Balign%7D%0AZ%20=%20V%5ET%20V%20&amp;=%20I%20%5C%5C%0Az_%7Bij%7D%20=%20%5Clangle%20v_i,%20v_j%20%5Crangle%20&amp;=%20%5Cdelta_%7Bij%7D%20%5Cend%7Balign%7D%20"></p>
<p>Each of the elements of the matrix <img src="https://latex.codecogs.com/png.latex?V%5ET"> is the dot product of the <img src="https://latex.codecogs.com/png.latex?i">th and <img src="https://latex.codecogs.com/png.latex?j">th columns of <img src="https://latex.codecogs.com/png.latex?V">. The dotproduct of all vectors against themselves is <img src="https://latex.codecogs.com/png.latex?1"> and the dotproduct of any two different vectors is <img src="https://latex.codecogs.com/png.latex?0">. So from this we can see that all of the columns of <img src="https://latex.codecogs.com/png.latex?V"> are orthogonal to each other. The same property holds for <img src="https://latex.codecogs.com/png.latex?U">.</p>
<p><img src="https://latex.codecogs.com/png.latex?V%5ET"> by our definition of <img src="https://latex.codecogs.com/png.latex?A"> must accept a vector from <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Em"> and the matrix is square, indicating an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20m"> matrix. The matrix <img src="https://latex.codecogs.com/png.latex?U"> must output a vector in <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5En"> and the matrix is square, indicating an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> matrix. The matrix <img src="https://latex.codecogs.com/png.latex?%5CSigma"> must be <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20m"> to map from <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Em"> to <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5En">.</p>
<p>In all its glory:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AA_%7Bn%20%5Ctimes%20m%7D%20&amp;=%20U_%7Bn%20%5Ctimes%20n%7D%20%5C,%20%5CSigma_%7Bn%20%5Ctimes%20m%7D%20%5C,%20V%5ET_%7Bm%20%5Ctimes%20m%7D%20%5C%5C%0A&amp;=%20%5Cleft%5B%20%5Cbegin%7Barray%7D%7Bccc%7Cccc%7D%0A%5Cmathbf%7Bu%7D_1%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bu%7D_r%20&amp;%20%5Cmathbf%7Bu%7D_%7Br+1%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bu%7D_n%0A%5Cend%7Barray%7D%20%5Cright%5D_%7Bn%20%5Ctimes%20n%7D%0A%5Cleft%5B%20%5Cbegin%7Barray%7D%7Bccc%7D%0A%5Csigma_1%20&amp;%20%20&amp;%20%20%5C%5C%0A&amp;%20%5Cddots%20&amp;%20%20%5C%5C%0A&amp;%20%20&amp;%20%5Csigma_r%20%5C%5C%0A0%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%0A%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A0%20&amp;%20%5Ccdots%20&amp;%200%0A%5Cend%7Barray%7D%20%5Cright%5D_%7Bn%20%5Ctimes%20m%7D%0A%5Cleft%5B%20%5Cbegin%7Barray%7D%7Bccc%7Cccc%7D%0A%5Cmathbf%7Bv%7D%5ET_1%20%5C%5C%0A%5Cvdots%20%5C%5C%0A%5Cmathbf%7Bv%7D%5ET_r%20%5C%5C%0A%5Cmathbf%7Bv%7D%5ET_%7Br+1%7D%20%5C%5C%0A%5Cvdots%20%5C%5C%0A%20%20%5Cmathbf%7Bv%7D%5ET_m%0A%5Cend%7Barray%7D%20%5Cright%5D_%7Bm%20%5Ctimes%20m%7D%0A%5Cend%7Baligned%7D%0A"></p>
<p>In this case the first <img src="https://latex.codecogs.com/png.latex?r"> columns of <img src="https://latex.codecogs.com/png.latex?U"> are the range of <img src="https://latex.codecogs.com/png.latex?A">, the rest of <img src="https://latex.codecogs.com/png.latex?U"> is filled with its orthogonal complement. The first <img src="https://latex.codecogs.com/png.latex?r"> columns of <img src="https://latex.codecogs.com/png.latex?V"> are the domain of <img src="https://latex.codecogs.com/png.latex?A">, the rest of <img src="https://latex.codecogs.com/png.latex?V"> is filled with its orthogonal complement. These are the four fundamental subspaces of the matrix <img src="https://latex.codecogs.com/png.latex?A">, more information on this can be found at: <a href="https://en.wikipedia.org/wiki/Singular_value_decomposition">Wikipedia: SVD</a></p>
<p>The matrices as shown above are for a rectangular <img src="https://latex.codecogs.com/png.latex?A"> where <img src="https://latex.codecogs.com/png.latex?n%3Em"> but the same properties hold for all <img src="https://latex.codecogs.com/png.latex?n,m">. Some of the singular values <img src="https://latex.codecogs.com/png.latex?%5Csigma_i"> may be zero, in which case the matrix <img src="https://latex.codecogs.com/png.latex?A"> is not full rank.</p>
<p>Another way to decompose the SVD is to write it as a sum of outer products that are scaled by the diagonal matrix of singular values:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20A%20=%20%5Csum_%7Bi=1%7D%5Er%20%5Csigma_i%20%5Cmathbf%7Bu%7D_i%20%5Cmathbf%7Bv%7D_i%5ET%20"></p>
<p>If <img src="https://latex.codecogs.com/png.latex?%5Csigma_i%3E0"> then <img src="https://latex.codecogs.com/png.latex?v_i"> is not in the null space of <img src="https://latex.codecogs.com/png.latex?A"> because <img src="https://latex.codecogs.com/png.latex?A%20v_i%20=%20%5Csigma_i%20u_i">. If <img src="https://latex.codecogs.com/png.latex?%5Csigma_i%20=%200"> then <img src="https://latex.codecogs.com/png.latex?v_i"> is in the null space of <img src="https://latex.codecogs.com/png.latex?A"> because <img src="https://latex.codecogs.com/png.latex?A%20v_i%20=%200">.</p>
<section id="the-pseudoinverse" class="level3">
<h3 class="anchored" data-anchor-id="the-pseudoinverse">The Pseudoinverse</h3>
<p>Back to the task of inverting <img src="https://latex.codecogs.com/png.latex?Ax%20+%20%5Cepsilon%20=%20b"> we can apply the SVD decomposition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign%7D%0AU%20%5CSigma%20V%5ET%20x%20+%20%5Cepsilon%20&amp;=%20b%20%5C%5C%0A%5CSigma%20V%5ET%20x%20+&amp;=%20U%5ET%20(b-%5Cepsilon)%20%5C%5C%0AV%20%5CSigma%5E%7B-1%7D%20U%5ET%20(b-%5Cepsilon)%20&amp;=%20x%5C%5C%0AA%5E+%20(b-%5Cepsilon)%20&amp;=%20%5Chat%7Bx%7D%0A%5Cend%7Balign%7D"></p>
<p>Where <img src="https://latex.codecogs.com/png.latex?A%5E+%20=%20V%20%5CSigma%5E%7B-1%7D%20U%5ET"> is the pseudoinverse of <img src="https://latex.codecogs.com/png.latex?A">. The pseudoinverse is a generalization of the matrix inverse for non-square matrices. We recover a square matrix by removing all of the absent or zero singular values from <img src="https://latex.codecogs.com/png.latex?%5CSigma"> and inverting the rest, giving an <img src="https://latex.codecogs.com/png.latex?r%20%5Ctimes%20r"> diagonal matrix whose inverse is simply the inverse of each element.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cleft%5B%20%5Cbegin%7Barray%7D%7Bccc%7D%0A%5Csigma_1%20&amp;%20%20&amp;%20%20%5C%5C%0A&amp;%20%5Cddots%20&amp;%20%20%5C%5C%0A&amp;%20%20&amp;%20%5Csigma_r%20%5C%5C%0A0%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%0A%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A0%20&amp;%20%5Ccdots%20&amp;%200%0A%5Cend%7Barray%7D%20%5Cright%5D_%7Bn%20%5Ctimes%20m%7D%0A%5Crightarrow%20%5Cleft%5B%20%5Cbegin%7Barray%7D%7Bccc%7D%0A%5Csigma_1%5E%7B-1%7D%20&amp;%20%20&amp;%20%20%5C%5C%0A%20%20&amp;%20%5Cddots%20&amp;%20%20%5C%5C%0A%20%20&amp;%20%20&amp;%20%5Csigma_r%5E%7B-1%7D%20%5C%5C%0A%20%20%5Cend%7Barray%7D%20%5Cright%5D_%7Br%20%5Ctimes%20r%7D"></p>
<p>Then <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bx%7D%20=%20%5Csum_i%5EN%20%5Csigma_i%5E%7B-1%7D%20%5Cmathbf%7Bu%7D_i%5ET%20(b-%5Cepsilon)%20%5Cmathbf%7Bv%7D_i"> is the solution to the least squares problem. This can be solved also as a truncated sum since <img src="https://latex.codecogs.com/png.latex?0%3CN%3Cr">. In actual practice with real world measurement we end up with many singular values that may be effectively <img src="https://latex.codecogs.com/png.latex?0"> by nature of being very small relative to the noise in the data and the largest single value. We have that the solution <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bx%7D"> is a sum of <img src="https://latex.codecogs.com/png.latex?v_i"> components that form an orthogonal basis <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bx%7D%20=%20%5Csum_i%20%5Cbeta_i%20v_i"> where <img src="https://latex.codecogs.com/png.latex?%5Cbeta_i%20=%20%5Cfrac%7Bu_i%5ET%20(b-%5Cepsilon)%7D%7B%5Csigma_i%7D">. These small singular values blow up in size when inverted and so extra truncation is often necessary to avoid numerical instability and excessive amplification of noise <img src="https://latex.codecogs.com/png.latex?%5Cepsilon">.</p>
</section>
</section>
<section id="least-squares" class="level2">
<h2 class="anchored" data-anchor-id="least-squares">Least Squares</h2>
<p>Least squares and matrix inversion is a classic starting point for understanding inverse theory. Suppose that we have input data <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bx%7D"> and output data <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bb%7D"> that are related by a linear system of equations: <img src="https://latex.codecogs.com/png.latex?Ax%20=%20b"> where <img src="https://latex.codecogs.com/png.latex?A"> is a matrix of coefficients. In many cases, the system is overdetermined, meaning that there are more equations than unknowns. In this case, there is no exact solution to the system, and we must find the best solution that minimizes the error between the observed data <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bb%7D"> and the predicted data <img src="https://latex.codecogs.com/png.latex?A%5Cvec%7Bx%7D">. In the simplest form of inversion that we can attempt, we can solve the least squares solution. In this case we reject all of the observed data that is from the null space of <img src="https://latex.codecogs.com/png.latex?A"> assuming a zero value for each of those parameters.</p>
<section id="example" class="level3">
<h3 class="anchored" data-anchor-id="example">Example</h3>
<p>Let <img src="https://latex.codecogs.com/png.latex?A"> be a <img src="https://latex.codecogs.com/png.latex?3%20%5Ctimes%202"> matrix and <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bb%7D"> be a <img src="https://latex.codecogs.com/png.latex?3%20%5Ctimes%201"> vector. The <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bx%7D"> that we are trying to solve for is a <img src="https://latex.codecogs.com/png.latex?2%20%5Ctimes%201"> vector. The system of equations is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20A%20=%20%5Cbegin%7Bbmatrix%7D%20%20%5Cvec%7Ba%7D_1%20&amp;%20%5Cvec%7Ba%7D_2%20%5Cend%7Bbmatrix%7D%20%5Cquad%20%5Cvec%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%20x_1%20%5C%5C%20x_2%20%20%5Cend%7Bbmatrix%7D%20%20%5Cquad%20%5Cvec%7Bb%7D%20=%20%5Cbegin%7Bbmatrix%7D%20b_1%20%5C%5C%20b_2%20%5C%5C%20b_3%20%5Cend%7Bbmatrix%7D%20"></p>
<p>In this case we have an <em>overdetermined</em> system with three equations, two unknowns, and three data samples. If the system of equations is full rank then we are trying to map from a 2D space to a 3D space: <img src="https://latex.codecogs.com/png.latex?A:%20%5Cmathbb%7BR%7D%5E2%20%5Crightarrow%20%5Cmathbb%7BR%7D%5E3">. In this case there is no exact solution to the system for any <img src="https://latex.codecogs.com/png.latex?b"> that is not in the column space of <img src="https://latex.codecogs.com/png.latex?A">.</p>
<p>Instead we can solve for the least squares solution <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bx%7D_%7BLS%7D"> by minimizing the error between the observed data <img src="https://latex.codecogs.com/png.latex?%5Cvec%7Bb%7D"> and the predicted data <img src="https://latex.codecogs.com/png.latex?A%5Cvec%7Bx%7D"> from the forward model.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cvec%7Bx%7D_%7BLS%7D%20=%20%5Carg%20%5Cmin_%7B%5Cvec%7Bx%7D%7D%20%7C%7CA%5Cvec%7Bx%7D%20-%20%5Cvec%7Bb%7D%7C%7C_2%5E2%20"></p>
<p>We want to find the argument that minimizes the function <img src="https://latex.codecogs.com/png.latex?f(%5Cvec%7Bx%7D)%20=%20%7C%7CA%5Cvec%7Bx%7D%20-%20%5Cvec%7Bb%7D%7C%7C_2%5E2">. By first order optimality conditions, the gradient of the function must be zero at the minimum.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Balign%7D%0A%5Cnabla%20f(%5Cvec%7Bx%7D)%20&amp;=%200%20%5C%5C%0A%5Cnabla%20%7C%7CA%5Cvec%7Bx%7D%20-%20%5Cvec%7Bb%7D%7C%7C_2%5E2%20&amp;=%200%20%5C%5C%0A%5Cnabla%20(A%5Cvec%7Bx%7D%20-%20%5Cvec%7Bb%7D)%5ET%20(A%5Cvec%7Bx%7D%20-%20%5Cvec%7Bb%7D)%20&amp;=%200%20%5C%5C%0A%5Cnabla%20%5Cleft(%20%5Cvec%7Bx%7D%5ET%20A%5ET%20A%20%5Cvec%7Bx%7D%20-%202%20%5Cvec%7Bb%7D%5ET%20A%20%5Cvec%7Bx%7D%20+%20%5Cvec%7Bb%7D%5ET%20%5Cvec%7Bb%7D%20%5Cright)%20&amp;=%200%20%5C%5C%0A2%20A%5ET%20A%20%5Cvec%7Bx%7D%20-%202%20A%5ET%20%5Cvec%7Bb%7D%20&amp;=%200%20%5C%5C%0AA%5ET%20A%20%5Cvec%7Bx%7D%20&amp;=%20A%5ET%20%5Cvec%7Bb%7D%20%5C%5C%0A%5Cvec%7Bx%7D_%7BLS%7D%20&amp;=%20(A%5ET%20A)%5E%7B-1%7D%20A%5ET%20%5Cvec%7Bb%7D%0A%5Cend%7Balign%7D%20"></p>
<p>This is known as the normal equations for the least squares solution. We take a note of caution here that <img src="https://latex.codecogs.com/png.latex?A%5ET%20A"> must be invertible for this solution to exist. If <img src="https://latex.codecogs.com/png.latex?A"> is not full rank then the matrix <img src="https://latex.codecogs.com/png.latex?A%5ET%20A"> will not be invertible and other methods must be used.</p>
<p>We call the difference between the observed data and the predicted data the residual.</p>
<p><img src="https://latex.codecogs.com/png.latex?r%20=%20%5Cvec%7Bb%7D%20-%20A%5Cvec%7Bx%7D_%7BLS%7D"></p>
<p>Using this information, what we really want to minimize is the sum of the squares of the residuals: <img src="https://latex.codecogs.com/png.latex?%7C%7Cr%7C%7C_2%5E2">. This is the same as the sum of the squares of the errors in the data.</p>
<p>There is an altogether informative way to think about the minimization problem purely in terms of linear algebra and subspaces to derive the same normal equations.</p>
<div style="display: block; margin-left: auto; margin-right: auto; width: 50%; text-align: center;">
<img src="https://chipnbits.github.io/content/eosc555/lectures/lecture1-2/imgs/ls-sol.svg" alt="" width="300">
<p>
<em>Least Squares Visual</em>
</p>
</div>
<p>We have the range of <img src="https://latex.codecogs.com/png.latex?A"> or image of <img src="https://latex.codecogs.com/png.latex?A"> as the subspace of <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E3"> that is spanned by the columns of <img src="https://latex.codecogs.com/png.latex?A">. This subspace is rank <img src="https://latex.codecogs.com/png.latex?2"> because there are only two columns in <img src="https://latex.codecogs.com/png.latex?A">, <img src="https://latex.codecogs.com/png.latex?R(A)%20%5Csubset%20%5Cmathbb%7BR%7D%5E3">. The inaccessible parts of <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E3"> are in the orthogonal complement of <img src="https://latex.codecogs.com/png.latex?R(A)">, <img src="https://latex.codecogs.com/png.latex?R(A)%5E%5Cperp">. Recalling that <img src="https://latex.codecogs.com/png.latex?R(A)%5E%5Cperp%20=%20N(A%5ET)"> we can diagram the solution to least squares as a minimization of the error vector <img src="https://latex.codecogs.com/png.latex?r"> in the orthogonal complement of <img src="https://latex.codecogs.com/png.latex?R(A)">.</p>
<p>As seen the <img src="https://latex.codecogs.com/png.latex?r"> vector is perpendicular to the <img src="https://latex.codecogs.com/png.latex?x_%7BLS%7D"> solution, the projection of <img src="https://latex.codecogs.com/png.latex?r"> onto <img src="https://latex.codecogs.com/png.latex?R(A)"> is zero. Since it is in a null space of <img src="https://latex.codecogs.com/png.latex?A%5ET"> then <img src="https://latex.codecogs.com/png.latex?A%5ET%20r%20=%200">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Balign%7D%20A%5ET%20%5Cleft%20(%20Ax_%7BLS%7D%20-%20b%20%5Cright%20)%20&amp;=%200%5C%5C%0AA%5ET%20A%20x_%7BLS%7D%20&amp;=%20A%5ET%20b%20%5C%5C%0A%5Cend%20%7Balign%7D%20"></p>
<p>So we recover the normal equations without using any of the machinery of calculus.</p>
<p>For a review on the four fundamental subspaces of a matrix see the UBC Math 307 notes on the topic: <a href="https://ubcmath.github.io/MATH307/orthogonality/complement.html">Math 307</a></p>


</section>
</section>
</section>

 ]]></description>
  <category>Optimization</category>
  <category>Inverse Theory</category>
  <category>Python</category>
  <category>Torch</category>
  <category>SVD</category>
  <guid>https://chipnbits.github.io/content/eosc555/lectures/lecture1-2/</guid>
  <pubDate>Sat, 14 Sep 2024 07:00:00 GMT</pubDate>
  <media:content url="https://chipnbits.github.io/content/eosc555/lectures/lecture1-2/imgs/ls-sol.svg" medium="image" type="image/svg+xml"/>
</item>
</channel>
</rss>

<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.53">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Simon Ghyselincks">
<meta name="dcterms.date" content="2024-11-22">
<meta name="description" content="In this mathematical lecture, some of the foundational principles of Bayesian inverse problems and their statistical interpretation are discussed. A set of computational tools are shown that aid in finding the solution to some of these problems.">

<title>Lecture 10 – Simon’s Personal Website</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="../../../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="../../../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet">
<script src="../../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">Simon’s Personal Website</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../content/publications/index.html"> 
<span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../content/eosc555/index.html"> 
<span class="menu-text">EOSC 555</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../content/projects/RLUnicycle/introduction.html"> 
<span class="menu-text">Learning to Balance</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../content/about/biography.html"> 
<span class="menu-text">Bio</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#gradient-descent-with-score-function" id="toc-gradient-descent-with-score-function" class="nav-link active" data-scroll-target="#gradient-descent-with-score-function">Gradient Descent with Score Function</a>
  <ul class="collapse">
  <li><a href="#maximum-a-posteriori-estimation" id="toc-maximum-a-posteriori-estimation" class="nav-link" data-scroll-target="#maximum-a-posteriori-estimation">Maximum A Posteriori Estimation</a></li>
  </ul></li>
  <li><a href="#score-function" id="toc-score-function" class="nav-link" data-scroll-target="#score-function">Score Function</a></li>
  <li><a href="#maximum-likelihood-estimate-from-samples" id="toc-maximum-likelihood-estimate-from-samples" class="nav-link" data-scroll-target="#maximum-likelihood-estimate-from-samples">Maximum Likelihood Estimate from Samples</a></li>
  <li><a href="#an-application-of-score-langevin-dynamics" id="toc-an-application-of-score-langevin-dynamics" class="nav-link" data-scroll-target="#an-application-of-score-langevin-dynamics">An Application of Score: Langevin Dynamics</a>
  <ul class="collapse">
  <li><a href="#code-example" id="toc-code-example" class="nav-link" data-scroll-target="#code-example">Code Example</a></li>
  </ul></li>
  <li><a href="#map-estimation-with-general-gaussian" id="toc-map-estimation-with-general-gaussian" class="nav-link" data-scroll-target="#map-estimation-with-general-gaussian">MAP Estimation with General Gaussian</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lecture 10</h1>
<p class="subtitle lead">MAP, MLE, and Score Function</p>
  <div class="quarto-categories">
    <div class="quarto-category">Machine Learning</div>
    <div class="quarto-category">Bayesian Inference</div>
    <div class="quarto-category">Score</div>
  </div>
  </div>

<div>
  <div class="description">
    In this mathematical lecture, some of the foundational principles of Bayesian inverse problems and their statistical interpretation are discussed. A set of computational tools are shown that aid in finding the solution to some of these problems.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Simon Ghyselincks </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 22, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="hidden">
<p>$$ </p>
<p>$$</p>
</div>
<section id="gradient-descent-with-score-function" class="level2">
<h2 class="anchored" data-anchor-id="gradient-descent-with-score-function">Gradient Descent with Score Function</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definitions
</div>
</div>
<div class="callout-body-container callout-body">
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 40%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Component</strong></th>
<th><strong>Description</strong></th>
<th><strong>Dimensions</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(F(x)\)</span></td>
<td>Forward operator</td>
<td><span class="math inline">\(\mathbb{R}^n \rightarrow \mathbb{R}^m\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(x\)</span></td>
<td>Model parameters</td>
<td><span class="math inline">\(\mathbb{R}^n\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(b\)</span></td>
<td>Observed data</td>
<td><span class="math inline">\(\mathbb{R}^m\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\epsilon\)</span></td>
<td>Noise</td>
<td><span class="math inline">\(\mathbb{R}^m\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\pi(x)\)</span></td>
<td>Probability distribution</td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\phi(x,\theta)\)</span></td>
<td>Potential function</td>
<td><span class="math inline">\(\mathbb{R}^n \rightarrow \mathbb{R}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\theta\)</span></td>
<td>Learnable Parameters</td>
<td><span class="math inline">\(\mathbb{R}^p\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(Z(\theta)\)</span></td>
<td>Partition Function</td>
<td><span class="math inline">\(\mathbb{R}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(s(x, \theta)\)</span></td>
<td>Score Function</td>
<td><span class="math inline">\(\mathbb{R}^n\)</span></td>
</tr>
</tbody>
</table>
</div>
</div>
<p>The classic inverse problem is defined as</p>
<p><span class="math display">\[b = F(x) + \epsilon\]</span></p>
<p>where <span class="math inline">\(F(x)\)</span> is the forward operator, <span class="math inline">\(b\)</span> is the observed data, and <span class="math inline">\(\epsilon\)</span> represents the noise in the measurement or process. We often assume that <span class="math inline">\(\epsilon\)</span> is Gaussian with zero mean and covariance matrix <span class="math inline">\(\Sigma\)</span>.</p>
<p><span class="math display">\[ \epsilon \sim \mathcal{N}(0, \Sigma) \]</span></p>
<p>The probability of deviation of the observed data from the forward model in this case is given by: <span class="math display">\[
\pi(\epsilon) = \frac{1}{(2\pi)^{m/2}|\Sigma|^{1/2}} \exp\left(-\frac{1}{2}\epsilon^\intercal \Sigma^{-1} \epsilon\right)
\]</span></p>
<p>Without any prior information about the error, it is difficult to estimate the covariance matrix <span class="math inline">\(\Sigma\)</span>. For the purpose of this analysis we can assume that it is a normal distriution with zero mean and a diagonal <span class="math inline">\(\sigma^2 I\)</span> covariance matrix. The likelihood function simplifies to:</p>
<p><span class="math display">\[ \pi(\epsilon) = \frac{1}{(2\pi \sigma^2)^{m/2}} \exp\left(-\frac{1}{2\sigma^2}\|b-F(x)\|^2 \right) \]</span></p>
<p>To model the probability distribution of the inverse problem parameters <span class="math inline">\(x\)</span>, we introduce a prior distribution <span class="math inline">\(\pi(x)\)</span>. To ensure positivity of <span class="math inline">\(\pi(x)\)</span> over the entire domain and proper normalization, we define it using a <strong>potential function</strong> <span class="math inline">\(\phi(x, \theta)\)</span>: <span class="math display">\[\pi(x; \theta) = \frac{e^{-\phi(x, \theta)}}{Z(\theta)}\]</span></p>
<p>Where the <strong>partion function</strong> <span class="math inline">\(Z(\theta)\)</span> is given by:</p>
<p><span class="math display">\[Z(\theta) = \int_\Omega e^{-\phi(x, \theta)} dx\]</span></p>
<p>Note the partition function is required to make the probability distribution integrate to <span class="math inline">\(1\)</span>. The exponential operator on the potential ensures that all <span class="math inline">\(\pi(x)\)</span> values are positve since <span class="math inline">\(e^\phi &gt; 0\)</span> for all <span class="math inline">\(z \in \mathbb{R}\)</span>. In practice, it is often intractable to directly compute the partition function when updating the model parameters <span class="math inline">\(\theta\)</span> for distributions that are more complex than a Gaussian.</p>
<p><span class="math inline">\(\phi(x, \theta): \mathbb{R}^n \rightarrow \mathbb{R}\)</span> maps <span class="math inline">\(x\)</span> to a scalar value, and <span class="math inline">\(\theta\)</span> are the parameters of the model. For example if we are modeling a Gaussian, the parameters might include the covariance matrix <span class="math inline">\(\Sigma\)</span>. It has a physical interpretation as an energy of a system, where <span class="math inline">\(\phi\)</span> values correspond to low probability density regions. For this reason it is often called the <strong>energy function</strong> in physics-inspired models.</p>
<section id="maximum-a-posteriori-estimation" class="level3">
<h3 class="anchored" data-anchor-id="maximum-a-posteriori-estimation">Maximum A Posteriori Estimation</h3>
<p>The goal of <strong>maximum a posteriori (MAP)</strong> estimation is to find the most likely <span class="math inline">\(x\)</span> given the observed data <span class="math inline">\(b\)</span> and model parameters <span class="math inline">\(\theta\)</span>, maximize the posterior probability <span class="math inline">\(\pi(x|b; \theta)\)</span>:</p>
<p><span class="math display">\[
\begin{align*}
\max_x \pi(x|b; \theta) &amp;= \max_x \frac{\pi(b|x; \theta) \pi(x; \theta)}{\pi(b)}\\
\max_x \underbrace{\pi(x|b; \theta)}_{\text{Posterior}} &amp; = \max_x \underbrace{\pi(b|x; \theta)}_{\text{Likelihood}} \underbrace{\pi(x; \theta)}_{\text{Prior}}\\
\end{align*}
\]</span></p>
<p>Since <span class="math inline">\(\pi(b)\)</span> is independent of <span class="math inline">\(x\)</span>, it does not affect the maximization problem. Substituting the likelihood and prior distributions, we have:</p>
<p><span class="math display">\[
\begin{align*}
&amp; = \max_x \frac{1}{(2\pi \sigma^2)^{m/2}} \exp\left(-\frac{1}{2\sigma^2}\|b-F(x)\|^2 \right) \frac{1}{Z(\theta)} e^{-\phi(x, \theta)}
\end{align*}
\]</span></p>
<p>The logarithm is a monotonic function, we can maximize the log-likelihood instead of the likelihood with no loss of generality. <span class="math inline">\(\max_x \pi(x) = \max_x \log(\pi(x))\)</span>. Intuitively, since the logarithim is always increasing in output, <span class="math inline">\(\log(z) &gt; \log(y)\)</span> implies <span class="math inline">\(z &gt; y\)</span>. In addition the product of two exponentials is the same as the sum of the exponents, and the maximum of a function is the same as the minimum of the negative of the function. This allows us to rewrite the log-likelihood as:</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Minimization Objective
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[\max_x \log \pi(x|b; \theta) = \min_x \left( \frac{1}{2\sigma^2}\|b-F(x)\|^2 + \phi(x, \theta) \right)\]</span></p>
</div>
</div>
<p>We have looked at methods previously of how to differentiate the forward operator <span class="math inline">\(F\)</span> and perform gradient descent. We take the gradient with respect to <span class="math inline">\(x\)</span> to find the minimum of the function.</p>
<p><span class="math display">\[
\begin{align*}
g &amp;= \nabla_x \left(\frac{1}{2\sigma^2}\|b-F(x)\|^2 - \phi(x, \theta)\right)\\
&amp;= \frac{1}{\sigma^2} \frac{\partial F}{\partial x} (F(x) - b) - \nabla_x \phi(x, \theta)\\
&amp;= \frac{1}{\sigma^2} J^T(x) (F(x) - b) + s(x, \theta)
\end{align*}
\]</span></p>
<p>Using gradient descent, we can update the model parameters <span class="math inline">\(\theta\)</span> by taking steps in away from the direction of the gradient <span class="math inline">\(g\)</span>:</p>
<p><span class="math display">\[x_{k+1} = x_k - \alpha g\]</span></p>
</section>
</section>
<section id="score-function" class="level2">
<h2 class="anchored" data-anchor-id="score-function">Score Function</h2>
<p><span class="math inline">\(s(x;\theta)\)</span> is known as the <strong>score function</strong> of <span class="math inline">\(\pi(x; theta)\)</span>. <span class="math display">\[s(x, \theta):= \nabla_x \log (\pi(x)) = - \nabla_x \phi(x, \theta) + C\]</span></p>
<p>It is the negative gradient of the potential function <span class="math inline">\(\phi(x, \theta)\)</span> with respect to <span class="math inline">\(x\)</span>. The score function is a generalization of the gradient of the log-likelihood function, and is described in more detail in Schervish’s “Theory of Statistics” <span class="citation" data-cites="Schervish2012-sk">(<a href="#ref-Schervish2012-sk" role="doc-biblioref">Schervish 1995</a>)</span>.</p>
<p>Score has a physical intution connected to energy potentials and fields. In physics, the electric field <span class="math inline">\(\mathbf{E}\)</span> is the negative gradient of the electric potential <span class="math inline">\(V\)</span>: <span class="math display">\[ \mathbf{E} = -\nabla_x V(x)\]</span></p>
<p>Simalarly, the score function is the negative gradient of the potential function <span class="math inline">\(\phi(x, \theta)\)</span> in the case where <span class="math inline">\(\pi(x) = e^{-\phi(x, \theta)}\)</span>. The score function is the direction in which the probability distribution is most likely to change.</p>
<section id="example-2d-gaussian-distribution" class="level4">
<h4 class="anchored" data-anchor-id="example-2d-gaussian-distribution">Example: 2D Gaussian Distribution</h4>
<p>Consider a 2D Gaussian distribution with zero mean and covariance <span class="math inline">\(\sigma^2 I\)</span>:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 74%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Function</strong></th>
<th><strong>Expression</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Probability Distribution</strong></td>
<td><span class="math inline">\(\pi(x) = \frac{1}{2\pi \sigma^2}\exp\left( -\frac{1}{2\sigma^2} \| x \|^2 \right)\)</span></td>
</tr>
<tr class="even">
<td><strong>Potential Function</strong></td>
<td><span class="math inline">\(\phi(x, \theta) =  - \frac{1}{2\sigma^2} \| x \|^2 - \log(2\pi \sigma^2)\)</span></td>
</tr>
<tr class="odd">
<td><strong>Score Function</strong></td>
<td><span class="math inline">\(-\nabla_x \phi(x, \theta) = -\left( -\frac{x}{\sigma^2} x \right) = \frac{x}{\sigma^2}\)</span></td>
</tr>
</tbody>
</table>
<p>In regions of high probability density, the potential function is low becuase the relation <span class="math inline">\(\pi(x) = e^{-\phi(x, \theta)}\)</span> is monotonic in <span class="math inline">\(\phi(x, \theta)\)</span>. The score funtion is always pointing in the local direction of the largest directional derivative of the probability distribution <span class="math inline">\(\pi\)</span>.</p>
</section>
<section id="visualization" class="level4">
<h4 class="anchored" data-anchor-id="visualization">Visualization</h4>
<p>Below is a visualization of the probability density function (PDF), potential function, and score function of a 2D Gaussian distribution.</p>
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Make plots for a 2D Gaussian distribution heatmap, potential function, and score function</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the 2D Gaussian distribution</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gaussian_pdf(x, y, sigma<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.exp(<span class="op">-</span><span class="fl">0.5</span><span class="op">*</span>(x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> y<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>sigma<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>np.pi<span class="op">*</span>sigma<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the potential function</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> potential_function(x, y, sigma<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="fl">0.5</span><span class="op">*</span>(x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> y<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>sigma<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> np.log(<span class="dv">2</span><span class="op">*</span>np.pi<span class="op">*</span>sigma<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the score function</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> score_function(x, y, sigma<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>np.array([x, y])<span class="op">/</span>sigma<span class="op">**</span><span class="dv">2</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a grid of points</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">500</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">500</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>X, Y <span class="op">=</span> np.meshgrid(x, y)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the PDF, potential function, and score function</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>pdf <span class="op">=</span> gaussian_pdf(X, Y)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>potential <span class="op">=</span> potential_function(X, Y)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> score_function(X, Y)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the Probability Distribution with a colorbar</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">3</span>))</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>im <span class="op">=</span> plt.imshow(pdf, cmap<span class="op">=</span><span class="st">'viridis'</span>, extent<span class="op">=</span>[<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>])</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>plt.colorbar(im, shrink<span class="op">=</span><span class="fl">0.8</span>, label<span class="op">=</span><span class="st">"Density"</span>)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the Potential Function with a colorbar</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">3</span>))</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>im <span class="op">=</span> plt.imshow(potential, cmap<span class="op">=</span><span class="st">'viridis'</span>, extent<span class="op">=</span>[<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>])</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>plt.colorbar(im, shrink<span class="op">=</span><span class="fl">0.8</span>, label<span class="op">=</span><span class="st">"Potential"</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Downsample the grid for quiver plotting</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>step <span class="op">=</span> <span class="dv">50</span>  <span class="co"># Downsample by taking every 50th point</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>X_downsampled <span class="op">=</span> X[::step, ::step]</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>Y_downsampled <span class="op">=</span> Y[::step, ::step]</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>score_downsampled <span class="op">=</span> score_function(X_downsampled, Y_downsampled)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the Score Function as a quiver plot over the PDF</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">3</span>))</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>plt.imshow(pdf, cmap<span class="op">=</span><span class="st">'viridis'</span>, extent<span class="op">=</span>[<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>])</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>plt.quiver(</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>    X_downsampled, Y_downsampled, </span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>    score_downsampled[<span class="dv">0</span>], score_downsampled[<span class="dv">1</span>], </span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>    color<span class="op">=</span><span class="st">'black'</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Save to file</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">"imgs/score_function.png"</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-scores" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-scores" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-scores-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-scores-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-scores-output-1.png" data-ref-parent="fig-scores" width="322" height="241" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-scores-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Probability Distribution
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-scores" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-scores-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-scores-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-scores-output-2.png" data-ref-parent="fig-scores" width="301" height="241" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-scores-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Potential Function
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-scores" style="flex-basis: 33.3%;justify-content: flex-start;">
<div id="fig-scores-3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-scores-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="index_files/figure-html/fig-scores-output-3.png" data-ref-parent="fig-scores" width="241" height="241" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-scores-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) Score Function
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: PDF, Potential Function, and Score Function of a 2D Gaussian Normal Distribution
</figcaption>
</figure>
</div>
</section>
</section>
<section id="maximum-likelihood-estimate-from-samples" class="level2">
<h2 class="anchored" data-anchor-id="maximum-likelihood-estimate-from-samples">Maximum Likelihood Estimate from Samples</h2>
<p>A common problem is estimating a probability distribution <span class="math inline">\(\pi(x)\)</span> based on a set of empirical samples <span class="math inline">\(\{x_1, x_2, ..., x_N\}\)</span>. Often in statistical analysis, we are working with an unknown <span class="math inline">\(\pi\)</span> and attempting to make our best estimate from sampled data. If we assume that the drawn samples are independent and identically distributed (i.i.d.), then the <strong>likelihood</strong> of the samples is the product of the likelihood of each sample. Recalling that <span class="math inline">\(Z(\theta) = \int_\Omega \pi(x) dx\)</span>, the likelihood of the samples is:</p>
<p><span class="math display">\[
\begin{align*}
\pi(x_1, x_2, ..., x_N) &amp;= \prod_{i=1}^N \pi(x_i) = \pi(x_1) \pi(x_2) ... \pi(x_N) \\
&amp;= \frac{1}{Z(\theta)} \exp\left(-\phi(x_1, \theta)\right) \frac{1}{Z(\theta)} \exp\left(-\phi(x_2, \theta)\right) ... \frac{1}{Z(\theta)} \exp\left(-\phi(x_N, \theta)\right) \\
&amp;= \frac{1}{\left[Z(\theta)\right]^N} \exp\left(-\sum_{i=1}^N \phi(x_i, \theta)\right)
\end{align*}
\]</span></p>
<p>Since some <span class="math inline">\(x\)</span> are observed, the challenge is to find the potential function <span class="math inline">\(\phi(x, \theta)\)</span> that maximizes the likelihood of the samples, given the model parameters <span class="math inline">\(\theta\)</span> and a fixed family of <span class="math inline">\(\phi(,;\theta)\)</span> functions.</p>
<p>The <strong>Maximum Likelihood Estimation (MLE)</strong> is the process of finding the parameters <span class="math inline">\(\theta\)</span> that maximize the likelihood of having observed the samples. Unlike the MAP estimate, there is no posterior and prior distribution. So in this case <span class="math inline">\(\pi(x|\theta)\)</span> is being directly maximized. This is equivalent to minimizing the negative log-likelihood as before:</p>
<p><span class="math display">\[
\begin{align*}
\text{MLE} &amp;= \text{argmax}_\theta \frac{1}{\left[Z(\theta)\right]^N} \exp\left(-\sum_{i=1}^N \phi(x_i, \theta)\right)\\
&amp;= \operatorname*{argmin}_\theta N \log(Z(\theta)) + \sum_{i=1}^N \phi(x_i, \theta)\\
&amp;= \operatorname*{argmin}_\theta \log(Z(\theta)) + \frac{1}{N} \sum_{i=1}^N \phi(x_i, \theta)
\end{align*}
\]</span></p>
<p>However we again run into the problem of the partition function <span class="math inline">\(Z(\theta)\)</span> which for most distributions in higher dimensions is intractable to compute. For example we may be trying to solve an integral in <span class="math inline">\(100\)</span> dimensions with no analytical solution.</p>
<p><span class="math display">\[ \int_{x_1} \int_{x_2} ... \int_{x_{100}} e^{-\phi(x, \theta)} dx_1 dx_2 ... dx_{100} \]</span></p>
<section id="minimizing-with-gradient-descent" class="level4">
<h4 class="anchored" data-anchor-id="minimizing-with-gradient-descent">Minimizing with Gradient Descent</h4>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Minimization Objective
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[ \text{MLE} = \operatorname*{argmin}_\theta \left( \log(Z(\theta)) + \frac{1}{N} \sum_{i=1}^N \phi(x_i, \theta) \right) \]</span></p>
</div>
</div>
<p>The gradient of the MLE objective with respect to <span class="math inline">\(\theta\)</span> is:</p>
<p><span class="math display">\[
\begin{align*}
g &amp;= \nabla_\theta \left( \log(Z(\theta)) + \frac{1}{N} \sum_{i=1}^N \phi(x_i, \theta) \right)\\
&amp;= \nabla_\theta \log(Z(\theta)) + \frac{1}{N} \sum_{i=1}^N \nabla_\theta \phi(x_i, \theta)
\end{align*}
\]</span></p>
<p>The left side term can be further reduced by using the definition of the partion function <span class="math inline">\(Z(\theta) =  \int_\Omega e^{-\phi(x, \theta)} dx\)</span>, the probability distribution <span class="math inline">\(\pi_\theta(x) = e^{-\phi(x, \theta)}\)</span>:</p>
<p><span class="math display">\[
\begin{align*}
\nabla_\theta \log(Z(\theta)) &amp;= \frac{1}{Z(\theta)}\nabla_\theta \int_\Omega e^{-\phi(x, \theta)} dx\\
&amp;= \int_\Omega \frac{1}{Z(\theta)}  \nabla_\theta e^{-\phi(x, \theta)} dx\\
&amp;= - \int_\Omega \frac{1}{Z(\theta)} e^{-\phi(x, \theta)} \nabla_\theta \phi(x, \theta) dx\\
&amp;= - \int_\Omega \pi(x) \nabla_\theta \phi(x, \theta) dx\\
&amp;=  \mathbb{E}_{x \sim \pi_\theta(x)} \left[ -\nabla_\theta \phi(x, \theta) \right]\\
&amp; \approxeq \frac{1}{M} \sum_{i=1}^M -\nabla_\theta \phi(x_i, \theta)
\end{align*}
\]</span></p>
<p>We estimate the value of <span class="math inline">\(\nabla_\theta \log(Z(\theta))\)</span> by taking the expectation value of the score function over the samples. This is a Monte Carlo approximation of the true integral using the available i.i.d. samples <span class="math inline">\(\{ x_1, x_2, ..., x_N \}\)</span>. The gradient of the MLE objective is then:</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Score Matching Gradient
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[ g = \underbrace{-\frac{1}{M} \sum_{i=1}^M \nabla_\theta \phi(\tilde x_i, \theta)}_{\text{Synthesis}} + \underbrace{\frac{1}{N} \sum_{i=1}^N \nabla_\theta \phi(x_i, \theta)}_{\text{Analysis}}\]</span></p>
</div>
</div>
<p>An optimal point is reached by first order optimality conditions, where the gradient is zero. The MLE objective is minimized when the <strong>synthesis</strong> and <strong>analysis</strong> terms are equal. This is known as <strong>score matching</strong> and is a method for estimating the parameters of a probability distribution from samples. The synthesis <span class="math inline">\(\tilde x_i\)</span> terms are drawn randomly from the proposed score <span class="math inline">\(\phi(\tilde x_i, \theta)\)</span> , while the analysis <span class="math inline">\(x_i\)</span> terms are taken over the samples <span class="math inline">\(\{x_1, x_2, ..., x_N\}\)</span>.</p>
<p>As before gradient descent can be used to update the model parameters <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[\theta_{k+1} = \theta_k - \alpha g\]</span></p>
</section>
</section>
<section id="an-application-of-score-langevin-dynamics" class="level2">
<h2 class="anchored" data-anchor-id="an-application-of-score-langevin-dynamics">An Application of Score: Langevin Dynamics</h2>
<p>An example of the usage of a learned score function is in <strong>Langevin Dynamics</strong>. Langevin Dynamics is a method for sampling from a probability distribution <span class="math inline">\(\pi(x)\)</span> by simulating a stochastic differential equation (SDE) that converges to the distribution. The SDE is given by:</p>
<p><span class="math display">\[dx = -\nabla_x \phi(x, \theta) dt + \sqrt{2} dW\]</span></p>
<p>The score function pushes samples towards regions of high probability density, since it is a vector that points in the direction of maximum increase of the probability distribution. The noise term <span class="math inline">\(dW\)</span> is a Wiener process, which is a continuous-time stochastic process that is normally distributed with mean zero and variance <span class="math inline">\(dt\)</span>. The Langevin Dynamics algorithm is a discretized version of the SDE:</p>
<p><span class="math display">\[x_{k+1} = x_k - \underbrace{\Delta t \nabla_x \phi(x_k, \theta)}_\text{Score Term} + \underbrace{\sqrt{2 \Delta t} z_k}_\text{Stochastic Term}\]</span></p>
<p>Where <span class="math inline">\(z_k \sim \mathcal{N}(0,1)\)</span> is a random sample from a normal distribution with zero mean and unit variance.</p>
<p>The score points in the same direciton as the gradient of the probability distribution, so at each time step, the score term moves the sample to a higher probability region. The stochastic term adds noise to the sample, providing randomness to the process.</p>
<section id="code-example" class="level3">
<h3 class="anchored" data-anchor-id="code-example">Code Example</h3>
<p>Below is an example of Langevin Dynamics applied to a 2D Gaussian distribution. The score function is used to push the samples towards the center of the distribution, while the stochastic element adds noise and randomization to the process. The animation show an intial uniform sampling grid of points converging to the shape of the Gaussian distribution.</p>
<div id="fig-langevin" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="3">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-langevin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.animation <span class="im">as</span> animation</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure the Pillow writer is available</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.animation <span class="im">import</span> PillowWriter</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the 2D Gaussian distribution</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gaussian_pdf(x, y, sigma<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.exp(<span class="op">-</span><span class="fl">0.5</span><span class="op">*</span>(x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> y<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>sigma<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>np.pi<span class="op">*</span>sigma<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the potential function</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> potential_function(x, y, sigma<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="fl">0.5</span><span class="op">*</span>(x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> y<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>sigma<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> np.log(<span class="dv">2</span><span class="op">*</span>np.pi<span class="op">*</span>sigma<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the score function</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> score_function(x, y, sigma<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>np.array([x, y])<span class="op">/</span>sigma<span class="op">**</span><span class="dv">2</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the Langevin Dynamics update</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> langevin_dynamics(samples, sigma<span class="op">=</span><span class="dv">1</span>, dt<span class="op">=</span><span class="fl">0.05</span>):</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, samples.shape)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    score <span class="op">=</span> score_function(samples[:, <span class="dv">0</span>], samples[:, <span class="dv">1</span>], sigma)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> samples <span class="op">+</span> dt <span class="op">*</span> score.T <span class="op">+</span> np.sqrt(<span class="dv">2</span> <span class="op">*</span> dt) <span class="op">*</span> z</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> samples</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a grid of points for the contour plot</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">500</span>)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">500</span>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>X, Y <span class="op">=</span> np.meshgrid(x, y)</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the PDF for contour plotting</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> <span class="fl">.5</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>pdf <span class="op">=</span> gaussian_pdf(X, Y, sigma)</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize samples on a 5x5 grid</span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>grid_size <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>grid_range <span class="op">=</span> np.linspace(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">2.5</span>, grid_size)</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>initial_samples <span class="op">=</span> np.array([[x, y] <span class="cf">for</span> x <span class="kw">in</span> grid_range <span class="cf">for</span> y <span class="kw">in</span> grid_range])</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> initial_samples.copy()</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the figure and axis</span></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the initial contour</span></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>contour <span class="op">=</span> ax.contourf(X, Y, pdf, levels<span class="op">=</span><span class="dv">50</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> ax.scatter(samples[:, <span class="dv">0</span>], samples[:, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">30</span>, label<span class="op">=</span><span class="st">'Samples'</span>)</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a legend</span></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to update the animation at each frame</span></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update(frame):</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> samples</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> langevin_dynamics(samples, dt<span class="op">=</span><span class="fl">0.002</span>, sigma<span class="op">=</span>sigma)</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>    scatter.set_offsets(samples)</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'Langevin Dynamics Iteration: </span><span class="sc">{</span>frame<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> scatter,</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the animation</span></span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>ani <span class="op">=</span> animation.FuncAnimation(</span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>    fig, update, frames<span class="op">=</span><span class="dv">400</span>, interval<span class="op">=</span><span class="dv">200</span>, blit<span class="op">=</span><span class="va">True</span>, repeat<span class="op">=</span><span class="va">False</span></span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the animation as a GIF</span></span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a>ani.save(<span class="st">"imgs/langevin_dynamics.gif"</span>, writer<span class="op">=</span><span class="st">"imagemagick"</span>, fps<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the animation inline (if supported)</span></span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>plt.close(fig)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-langevin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2
</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="imgs/langevin_dynamics.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Langevin Dynamics to a 2d Gaussian"><img src="imgs/langevin_dynamics.gif" class="img-fluid figure-img" alt="Langevin Dynamics to a 2d Gaussian"></a></p>
<figcaption>Langevin Dynamics to a 2d Gaussian</figcaption>
</figure>
</div>
</section>
</section>
<section id="map-estimation-with-general-gaussian" class="level2">
<h2 class="anchored" data-anchor-id="map-estimation-with-general-gaussian">MAP Estimation with General Gaussian</h2>
<p>Revisitng the MAP estimation problem, we can consider a more general prior <span class="math inline">\(\pi(x)\)</span> with mean <span class="math inline">\(\mu = 0\)</span> and covariance <span class="math inline">\(\Sigma\)</span>:</p>
<p><span class="math display">\[
\begin{align*}
\pi(b|x) &amp;= \frac{1}{(2\pi \sigma^2)^{m/2}} \exp\left(-\frac{1}{2\sigma^2}\|b-F(x)\|^2 \right)\\
\pi_\theta(x) &amp;= \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}} \exp\left(-\frac{1}{2}x^\intercal \Sigma^{-1} x\right)\\
\text{MAP} &amp;= \min_x \left( \frac{1}{2\sigma^2}\|b-F(x)\|^2 + \frac{1}{2}x^\intercal \Sigma^{-1} x \right)
\end{align*}
\]</span></p>
<p>We now make a choice of which <span class="math inline">\(pi_\theta(x)\)</span> to use, as before this is a MLE based on the available empirical samples. For the purpose of finding the gradient, let the minimization parameters be <span class="math inline">\(\theta = \Sigma^{-1}\)</span>, since the true <span class="math inline">\(\Sigma\)</span> is positive definite, it can be found by inverting this result. The partition function <span class="math inline">\(Z(\theta)\)</span> is known for the case of a Gaussian distribution, and so the MLE objective is:</p>
<p><span class="math display">\[
\begin{align*}
\pi(x) &amp;= \max_\theta \Pi_{i=1}^N \pi_\theta(x_i)\\
&amp;= \max_\theta \frac{1}{Z(\theta)^N} \exp\left(-\sum_{i=1}^N \frac{1}{2}x_i^\intercal \Sigma^{-1} x_i\right)\\
&amp;= \min_\theta N \log(Z(\theta)) + \frac{1}{2} \sum_{i=1}^N x_i^\intercal \Sigma^{-1} x_i\\
&amp;= \min_\theta -\log((2\pi)^{n/2}|\Sigma|^{1/2}) + \frac{1}{2N} \sum_{i=1}^N x_i^\intercal \Sigma^{-1} x_i\\
&amp;= \min_\theta -\frac{1}{2}\log(|\Sigma|) + \frac{1}{2N} \sum_{i=1}^N x_i^\intercal \Sigma^{-1} x_i
\end{align*}
\]</span></p>
<section id="finding-the-gradient" class="level4">
<h4 class="anchored" data-anchor-id="finding-the-gradient">Finding the Gradient</h4>
<p><strong>Left Term:</strong> To find the min using gradient descent we take the gradient of each term with respect to <span class="math inline">\(\Sigma^{-1}\)</span>. The gradient of a log determinant can be found in the matrix cookbook <span class="citation" data-cites="Petersen2012">(<a href="#ref-Petersen2012" role="doc-biblioref">Petersen and Pedersen 2012</a>)</span> formula (57): <span class="math display">\[ \nabla_{A} \log(|A|) = (A^{-1})^\intercal \]</span></p>
<p>This can be rewritten as:</p>
<p><span class="math display">\[ \nabla_A \log(|A^{-1}|) = A^\intercal\]</span></p>
<p>Applying this to the left term we get:</p>
<p><span class="math display">\[ \nabla_{\Sigma^{-1}} \left( -\frac{1}{2}\log(|\Sigma|) \right) = -\frac{1}{2} \Sigma\]</span></p>
<p><strong>Right Term:</strong> The gradient of the second term is found by reformulating it as a trace of a new matrix <span class="math inline">\(X = \sum x_i x_i^\intercal\)</span>:</p>
<p><span class="math display">\[
\begin{align*}
\sum x_j^\intercal \Sigma^{-1} x_j &amp;= \sum \text{trace} \left( x_j^\intercal  \Sigma^{-1} x_j \right)\\
&amp;= \sum \text{trace} \left(  \Sigma^{-1} x_j x_j^\intercal \right)\\
&amp;= \text{trace} \left(  \Sigma^{-1} X\right)\\
\end{align*}
\]</span></p>
<p>The matrix cookbook <span class="citation" data-cites="Petersen2012">(<a href="#ref-Petersen2012" role="doc-biblioref">Petersen and Pedersen 2012</a>)</span> formula (100) gives the gradient of the trace of a matrix product:</p>
<p><span class="math display">\[ \nabla_X \text{trace}(XB) = B^\intercal\]</span></p>
<p>Applying this we get:</p>
<p><span class="math display">\[ \nabla_{\Sigma^{-1}} \left( \frac{1}{2N} \sum x_i^\intercal \Sigma^{-1} x_i \right) = \frac{1}{2N} X^\intercal = \frac{1}{2N} \sum x_i x_i^\intercal\]</span></p>
<p><strong>Combined Result:</strong></p>
<p>Combining the two terms we get the gradient of the MLE objective with respect to <span class="math inline">\(\Sigma^{-1}\)</span>: <span class="math display">\[
\begin{align*}
g &amp;= \nabla_{\Sigma^{-1}} \left( \frac{1}{2}\log(|\Sigma|^{-1}) + \frac{1}{2N} \sum_{i=1}^N x_i^\intercal \Sigma^{-1} x_i \right)\\
&amp;= \frac{1}{2} \Sigma^\intercal - \frac{1}{2N} \sum_{i=1}^N x_i x_i^\intercal
\end{align*}
\]</span></p>
<p>Solving for where the gradient is zero, we find the optimal value of <span class="math inline">\(\Sigma\)</span>, since <span class="math inline">\(\Sigma = \Sigma^\intercal\)</span>:</p>
<p><span class="math display">\[ \Sigma = \frac{1}{N} \sum_{i=1}^N x_i x_i^\intercal\]</span></p>
<p>This is the maximum likelihood estimate of the covariance matrix <span class="math inline">\(\Sigma\)</span> given the samples <span class="math inline">\(\{x_1, x_2, ..., x_N\}\)</span>, which can be interpreted as the expectation value of the outer product of the samples. The estimated covariance matrix is the actual true covariance matrix of the sampled data. This is a common result in statistics, where the sample mean is the MLE of the true mean of the distribution.</p>
<p>Unfortunately, estimating parameters can be very difficult to do for non-Gaussian <span class="math inline">\(\pi_\theta\)</span> due to the partition function <span class="math inline">\(Z(\theta)\)</span> being intractable.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>MAP estimation on an inverse problem may require the use of a prior distribution <span class="math inline">\(\pi(x)\)</span> to regularize the solution. The potential function <span class="math inline">\(\phi(x, \theta)\)</span> is used to define the probability distribution <span class="math inline">\(\pi(x; \theta)\)</span>, and the score function <span class="math inline">\(s(x, \theta)\)</span> is the negative gradient of the potential function.</p>
<p>If the prior is not known, an MLE estimate can be made to find the parameters <span class="math inline">\(\theta\)</span> that maximize the likelihood of the samples based on an assumed parameterized model. The score matching gradient is used to estimate the gradient of the MLE objective with respect to <span class="math inline">\(\theta\)</span>.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Petersen2012" class="csl-entry" role="listitem">
Petersen, K. B., and M. S. Pedersen. 2012. <span>“The Matrix Cookbook.”</span> Technical University of Denmark. <a href="http://www2.compute.dtu.dk/pubdb/pubs/3274-full.html">http://www2.compute.dtu.dk/pubdb/pubs/3274-full.html</a>.
</div>
<div id="ref-Schervish2012-sk" class="csl-entry" role="listitem">
Schervish, Mark J. 1995. <em>Theory of Statistics</em>. Springer Series in Statistics. New York, NY: Springer.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/chipnbits\.github\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2025, Simon Ghyselincks</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://chipnbits.github.io/">
      <i class="bi bi-house" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/chipnbits">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>
    <script type="text/javascript">
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let pseudocodeOptions = {
          indentSize: el.dataset.indentSize || "1.2em",
          commentDelimiter: el.dataset.commentDelimiter || "//",
          lineNumber: el.dataset.lineNumber === "true" ? true : false,
          lineNumberPunc: el.dataset.lineNumberPunc || ":",
          noEnd: el.dataset.noEnd === "true" ? true : false,
          titlePrefix: el.dataset.captionPrefix || "Algorithm"
        };
        pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
      });
    })(document);
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let captionSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
        if (captionSpan !== null) {
          let captionPrefix = el.dataset.captionPrefix + " ";
          let captionNumber = "";
          if (el.dataset.pseudocodeNumber) {
            captionNumber = el.dataset.pseudocodeNumber + " ";
            if (el.dataset.chapterLevel) {
              captionNumber = el.dataset.chapterLevel + "." + captionNumber;
            }
          }
          captionSpan.innerHTML = captionPrefix + captionNumber;
        }
      });
    })(document);
    </script>
  
<script>var lightboxQuarto = GLightbox({"descPosition":"bottom","loop":false,"selector":".lightbox","openEffect":"zoom","closeEffect":"zoom"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>
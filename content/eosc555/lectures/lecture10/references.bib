@article{Lewis2000,
  title = {Direct search methods: then and now},
  volume = {124},
  ISSN = {0377-0427},
  url = {http://dx.doi.org/10.1016/S0377-0427(00)00423-4},
  DOI = {10.1016/s0377-0427(00)00423-4},
  number = {1–2},
  journal = {Journal of Computational and Applied Mathematics},
  publisher = {Elsevier BV},
  author = {Lewis,  Robert Michael and Torczon,  Virginia and Trosset,  Michael W.},
  year = {2000},
  month = dec,
  pages = {191–207}
}

@website{wikipedia_directsearch,
  title={Pattern search (optimization)},
  author={Wikipedia},
  year={2024},
  url={https://en.wikipedia.org/wiki/Pattern_search_(optimization)}
}

@article{Kolda2003,
  title = {Optimization by Direct Search: New Perspectives on Some Classical and Modern Methods},
  volume = {45},
  ISSN = {1095-7200},
  url = {http://dx.doi.org/10.1137/S003614450242889},
  DOI = {10.1137/s003614450242889},
  number = {3},
  journal = {SIAM Review},
  publisher = {Society for Industrial & Applied Mathematics (SIAM)},
  author = {Kolda,  Tamara G. and Lewis,  Robert Michael and Torczon,  Virginia},
  year = {2003},
  month = jan,
  pages = {385–482}
}

@BOOK{Schervish2012-sk,
  title     = "Theory of statistics",
  author    = "Schervish, Mark J",
  publisher = "Springer",
  series    = "Springer series in statistics",
  month     =  dec,
  year      =  1995,
  address   = "New York, NY",
  language  = "en"
}

@article{hyvarinenScoreMatching2005,
	title = {Estimation of {Non}-{Normalized} {Statistical} {Models} by {Score} {Matching}},
	abstract = {One often wants to estimate statistical models where the probability density function is known only up to a multiplicative normalization constant. Typically, one then has to resort to Markov Chain Monte Carlo methods, or approximations of the normalization constant. Here, we propose that such models can be estimated by minimizing the expected squared distance between the gradient of the log-density given by the model and the gradient of the log-density of the observed data. While the estimation of the gradient of log-density function is, in principle, a very diﬃcult non-parametric problem, we prove a surprising result that gives a simple formula for this objective function. The density function of the observed data does not appear in this formula, which simpliﬁes to a sample average of a sum of some derivatives of the log-density given by the model. The validity of the method is demonstrated on multivariate Gaussian and independent component analysis models, and by estimating an overcomplete ﬁlter set for natural image data.},
	language = {en},
	author = {Hyvarinen, Aapo},
	keywords = {Read},
	file = {Hyvarinen - Estimation of Non-Normalized Statistical Models by.pdf:C\:\\Users\\sghys\\Zotero\\storage\\GFBUV9WT\\Hyvarinen - Estimation of Non-Normalized Statistical Models by.pdf:application/pdf},
}

@MISC{Petersen2012,
    author       = "K. B. Petersen and M. S. Pedersen",
    title        = "The Matrix Cookbook",
    year         = "2012",
    month        = "nov",
    keywords     = "Matrix identity, matrix relations, inverse, matrix derivative",
    publisher    = "Technical University of Denmark",
    address      = "",
    note         = "Version 20121115",
    url          = "http://www2.compute.dtu.dk/pubdb/pubs/3274-full.html",
    abstract     = "Matrix identities, relations and approximations. A desktop reference for quick overview of mathematics of matrices."
}

@misc{Lin2023,
  doi = {10.48550/ARXIV.2307.12551},
  url = {https://arxiv.org/abs/2307.12551},
  author = {Lin,  Xi and Yang,  Zhiyuan and Zhang,  Xiaoyuan and Zhang,  Qingfu},
  keywords = {Machine Learning (cs.LG),  Artificial Intelligence (cs.AI),  Neural and Evolutionary Computing (cs.NE),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Continuation Path Learning for Homotopy Optimization},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{Kaiming2015,
  doi = {10.48550/ARXIV.1512.03385},
  url = {https://arxiv.org/abs/1512.03385},
  author = {He,  Kaiming and Zhang,  Xiangyu and Ren,  Shaoqing and Sun,  Jian},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Deep Residual Learning for Image Recognition},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@article{CrespoMarques2019,
  title = {A Review of Sparse Recovery Algorithms},
  volume = {7},
  ISSN = {2169-3536},
  url = {http://dx.doi.org/10.1109/ACCESS.2018.2886471},
  DOI = {10.1109/access.2018.2886471},
  journal = {IEEE Access},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author = {Crespo Marques,  Elaine and Maciel,  Nilson and Naviner,  Lirida and Cai,  Hao and Yang,  Jun},
  year = {2019},
  pages = {1300–1322}
}